This agreement with the Government of Canada will enhance the ability of our softwood lumber industry to compete by negating the impact of Canadian provincial practices which the U.S. Department of Commerce preliminarily determined to confer subsidies.

This agreement successfully addresses the problems that led the U.S. softwood lumber industry to file a petition under the countervailing duty law with the Department of Commerce. As a result, the U.S. industry is withdrawing its petition and the Department of Commerce will terminate its investigation.

Under the Memorandum of Understanding, the Government of Canada will impose a 15 percent tax on exports of softwood lumber to the United States. This tax may be phased out proportionately as the Canadian provinces increase the charges imposed on softwood lumber production.

January marks the 10th anniversary of the founding of the Czechoslovak human rights initiative, Charter 77. The declaration of Charter 77 enumerated ways in which the Government denied the people of Czechoslovakia the basic rights provided for in the country's legal code, in the Helsinki accords, and in international covenants. The charter, which also spelled out the responsibility of citizens in ensuring compliance with those principles, first appeared on January 1, 1977, carrying the signatures of 241 persons from a wide cross section of Czechoslovak society. On January 6 representatives of Charter 77 first tried to present the text of that document to the Czechoslovak authorities. Though, then and now, government officials have tried to characterize the signers of the Charter as criminals, they could not diminish the moral authority of those who had the courage to hold them accountable to basic laws and principles.

Europe's longest lasting human rights initiative, served for 10 years as a champion of civil and human rights, a repository for national values, and a cultural and publishing network at home and abroad that has kept unified and alive a rich national literature. Pluralistic in its membership and interests, the Charter has avoided the role of a political opposition. Despite imprisonment and intimidation, chartists have persisted in issuing numerous documents on many aspects of Czechoslovak life and on international affairs, witnessing steadfastly for the humanistic and democratic convictions of its reformist, Christian, and cultural memberships. The Charter also gave rise to the Committee for the Defense of Unjustly Persecuted (VONS), which has documented and focused international attention on a vast number of injustices.

The more than 1,000 signatures of the charter to date have had influence far beyond their numbers. They articulate the ideals of an uncountable number of their fellow Czechoslovaks and, indeed, of all who want to see human rights respected. By their activities, Charter 77 signers have in countless small and large ways pushed back the gloom over Czechoslovakia's barren political landscape.

Year, is a season of love and hope; a time for reflection; a time of expectation; a time when people in America, just like people all over the world, gather with family and friends to remember in many different ways the blessings of God and to look to the future with hope. That's what I would like to do with you, the Soviet peoples, tonight -- share our common hopes for the future, our hopes for peace on Earth, our hopes for good will among all humanity, our hopes for a better world for ourselves and our children. Yes, there are enormous differences between our two systems, but there is also something the American and the Soviet people share -- something as universal and eternal as what a mother feels when she hears the cry of her newborn child -- and it is those common hopes.

New Year's Day I spoke to you of my hopes and prayers and those of the American people for lasting peace between our two countries. I said I was determined that our two governments should build on the foundations of the Geneva summit and make advances in all areas of our relations. Well, since then a lot has happened.

Both governments have worked hard together. As you know, there have been setbacks and frustrations, as well as progress. I'm disappointed that we didn't accomplish more. And yet in 1986 the United States and Soviet Union took major steps toward lasting peace.

I think the most important thing is where you succeed, and we have succeeded in a lot. At the Geneva summit, our two governments agreed to accelerate negotiations in all aspects of our relationship -- including reducing nuclear stockpiles and increasing both sides' security, encouraging respect for human rights, resolving regional conflicts peacefully, and broadening contacts between our two countries. And so, in the months that followed the summit, our negotiators worked long and hard. Then this fall, Mr. Gorbachev and I met again in Reykjavik, Iceland, to see if we could speed up progress even further. And we did move things a good distance forward.

At Reykjavik we agreed on the desirability of real reductions in nuclear arsenals and on the ultimate goal of eliminating all nuclear weapons. We agreed that as a start, we could eliminate all but a small number of U.S. and Soviet intermediate-range nuclear missiles. We also agreed to cut in half the number of strategic arms over a 5-year period. And we agreed that it's necessary to have effective verification of any final agreements. We discussed as well approaches to strategic defenses, approaches that the United States believes would protect the security and interests of both sides. As part of the strategic defense discussion, I proposed the elimination of all U.S. and Soviet offensive ballistic missiles over a 10-year period. I suggested that, as we had agreed, we cut strategic offensive forces in half in the first 5 years, and then that we go on to eliminate all remaining offensive ballistic missiles of all ranges in the next 5 years. As you've heard, we did not reach an agreement on any plan for the second 5 years. We in America are ready to discuss this or other proposals for moving beyond the reduction of the first 5 years.

After our Reykjavik meeting, both sides took time to reflect on what had been accomplished and on ways to move forward again. And then the United States followed up at the Geneva negotiations with concrete proposals to implement the understandings of Reykjavik.

As we look to the new year, we in America remain ready to continue to do everything necessary to turn this hard work into verifiable agreements. Our hope is that the Soviet Union will approach negotiations with this same spirit. Peace is built not just on agreements about arms reduction but on understanding between peoples. It hasn't always made the headlines of either your newspapers or ours, but the United States and the U.S.S.R. have made progress here too by expanding exchanges and other contacts between our countries. Scientific, educational, cultural, and people-to-people exchanges, especially among our young people, have grown. We in America would like to see more of these exchanges in all areas. The American people are deeply concerned with the fate of individual people, wherever they might be throughout the world. We believe that God gave sacred rights to every man, woman, and child on Earth.

Whenever there's a restoration of those rights to a man or a woman [Andrei Sakharov and Yelena Bonner], as has happened recently, it helps strengthen the foundations for trust and cooperation between our countries. And by the same token, whenever those rights are denied the foundation is seriously weakened. Much more can and should be done to strengthen that foundation. We welcome progress in this area as much as we welcome it in the effort to secure nuclear arms reduction. In fact, progress here and in all key areas of our relationship is essential if we are to build on this foundation.

Peace between our countries is also affected by events throughout the world. We Americans are proud that on this New Year's Day not a single American soldier is engaged in combat anywhere. But even so, we cannot forget that many tragic and bloody conflicts rage around the globe -- conflicts that are causing untold human suffering, and that could spread. The United States stands ready to support all serious efforts to find peaceful solutions to regional conflicts. And we're ready to work with the Soviet Union and any other country to that end. There are many complex issues to be discussed between the United States and the Soviet Union. Resolving them will not be easy, but the things most worth doing seldom are.

In 1987 we'll make more, I'm sure. We must continue together on the journey toward lasting peace. Yes, peace is a journey. Peace is also a dream. For two centuries, men and women from all over the world have left their homelands to make often dangerous passages to the shores of my country, to a land of peace where they had the freedom to make their hopes into realities for their families and themselves. They had a dream, and we in America call it the American dream. But to live in a land of peace and hope is not just the American dream; it's the dream of all people, of all lands.

There's an old verse that goes, ``Happy or sad, my beloved, you are as beautiful as a Russian song, as beautiful as a Russian soul.'' All the world knows and honors the suffering and courage of the Soviet peoples in the Second World War, just as all the world knows and honors the nobility of your diverse heritage in literature and the arts. That great heritage springs from a magnificence of the soul that no suffering can ever obscure. That suffering has also only ennobled a soul and culture that have in turn enriched all of civilization. Let us in this season of hope hear the voice of this soul that encompasses so many peoples and traditions. Let us hear the voice of all humanity's soul -- the voice that speaks through Leo Tolstoy and through William Faulkner, through the martyrs, the poets, and the saints. And, yes, the voice that speaks also through a mother's prayer -- with a message that you can see in a child's eyes, a prayer for peace and a message of good will to all.

This is to register my concerns with the provisions of H.J. Res. 395, the Continuing Resolution, which I understand is scheduled to be considered in the House in the near future. While members of the House and Senate are working to develop legislation that would implement our bipartisan budget agreement, it would be counterproductive for the Congress to act on a measure that clearly violates both the spirit and the terms of that agreement.

Let me also point out there are many extraneous provisions included in the Resolution to which I must take exception. In addition I am informed that further objectionable measures may be incorporated into the Resolution by the Rules Committee.

It is imperative in my view that essential nonlethal aid to the Nicaraguan democratic resistance be continued in the Resolution. To fail to provide such assistance at this critical time would undercut the peace process and undermine our commitment to democracy in Central America.

I trust that we can continue our bipartisan effort and work toward implementation of the agreement reached last month. I urge you and your colleagues to develop a Continuing Resolution that is faithful to our agreement.

We are working to carry out the Administration's part of this agreement, and I trust the House will do the same. If H.J. Res. 395 were sent to me in its current form for signature, I would have no hesitation in vetoing the measure.

Secretary Bennett, and Members of the Congress who are here, and all of you, thank you very much. I'm going to keep my remarks brief. I'm not going to take a chance on being voted in your yearbooks the President most likely to talk until June. [Laughter] You know, it's good to get out of Washington, where we spend a lot of time worrying about things that are only important there. Here you have perspective and realize what the important issues are -- who's got a Christmas dance date and who hasn't.

But now, before I get started, I have a special message from Nancy. Whenever I speak to students, she asks me to remind you: For your families, for your friends, and just for yourselves, just say no to drugs and alcohol. By the way, there's an important event taking place elsewhere in town today: the White House Conference on a Drug Free America under the leadership of Lois Herrington. And Nancy and I applaud her team's efforts to rid America of drugs.

Today is not just a high school convocation, it's a family day as well. So, let me ask the parents who are here today -- could you stand for a moment just so we could see you? [Applause] I'll applaud that, too. Mothers and fathers, your dedication to your children and the schools has made this community what it is today. Your support is the foundation on which the success of Duval County's schools has been built and on which your own children's success will be built throughout life.

Secretary of Education Bill Bennett tells me that wherever you find parents and communities who care -- principals who set goals and keep track of progress, teachers who pay attention to basics, and students who work hard -- in those places you find America's great school systems. He also tells me that Duval County has some of America's great schools. Now, I'm going to talk to you for a few minutes about your great public schools, but I know you have great private and parochial schools, as well. You know, it makes me think that quality and Duval County just seem to go together.

I've heard that you have a slogan around here: ``Winners are finishers.'' It means stay in school, stick it out through tough times as well as good, finish and you'll be a winner, too. But I can't help thinking: Doesn't that have a lot to do with how your school system itself became a winner? Success wasn't handed on a platter. It didn't come because you had lots of money. In fact, your spending per pupil is regularly below the national average. But as Dr. Sang has taught, progress and money are not the same. And boy, that's one lesson in Washington that we should write a hundred times on the blackboard.

No, you didn't do it with lots of money; you did it with the courage to be different. When others had lost faith, you did it with your belief in hard work and real standards and with the American tradition of trusting in the future and your ability to build for it with your own hands and your own minds and your own determination. You didn't look to Washington for an easy way out; you did it yourselves. It was the British philosopher Sir Francis Bacon who said that: ``By far the greatest obstacle to true progress is found in this -- that men despair and think things impossible.'' I've found that's true in almost every area of life, whether it's building better schools or better mousetraps or a better country.

Well, if America is to be prepared with jobs, skills, and technology for the next century, we must make way for people who see what can be done and what is possible, not what isn't -- make way for people like those who rebuilt this school system. In Washington some things haven't changed much since President McKinley's time. Almost everyone can still tell you 20 reasons why you can't do things -- why you can't cut tax rates, why you can't lower Federal spending, why you can't reduce the number of Soviet and American nuclear weapons, and why you can't develop a strategic defense against ballistic missiles.

America wasn't built by people who said, I can't. Every pioneer who crossed our frontier said, I can. Every man or woman who ever started a new business, discovered a new invention, explored a new idea said, I can. You will graduate from high school because you said, I can. The two most important words anyone can ever learn are those words: I can. You know, I've always thought that the best hope for America's future was to get as many things as possible out of the gloomy, pessimistic halls of Washington and back to the optimistic air of the real America, where people don't say, I can't, they say, I can.

More decisions outside of Washington, fewer inside, fewer Federal rules, more opportunity -- that's the idea behind our support for choice in education. Let parents choose the schools they believe will best prepare their children for the jobs and opportunities of the future. It's the idea behind our enterprise zone proposal. And when Congress failed to act, Florida and 25 other States said, we can, and they went ahead with their own enterprise zone programs. And now there are thousands of jobs and choices in areas where there were few before.

I've come here this morning with a simple message about your future, you who are students. And that is that America's freedom is a precious opportunity, and the first step to using that opportunity is to say, I can. One of America's greatest philosophers, Henry David Thoreau, reminded us that to Americans ``this world is but canvas to our imaginations.'' If you use your imagination, set goals, make plans, work hard, keep at it, and don't worry too much about who gets the credit, there's no limit to what you can achieve.

Federal Government does a lot to shape the future. And there are many times when it would be helpful if government just left things alone. Our goal should be to make government the servant of the people and not the other way around.

That is one of the reasons that, over the last 7 years, our administration has pushed for more individual freedom and less government interference. In dealing with the Federal budget deficit, our goal has been to provide those services that are necessary, to provide for our national defense, and to do so at the lowest cost to the average American taxpayer; because what we spend today will be a burden to you tomorrow.

I feel it's time for us to step forward and provide a clear direction for continued economic growth and opportunity. Eleven days ago I joined with the bipartisan leaders in Congress in forging a budget compromise that will put the Nation on a road toward a balanced budget and keep us on that track. I said it was time to roll up our sleeves and get the job done. Well, today I hope you will join with me in this crusade to balance the Federal budget. Let's commit ourselves to do all that we can now and to do even more in the years ahead to continue our economic expansion. It's a time to put aside partisan and personal preferences and join together. It's a time to say, I can and I will.

That's how America itself has moved the entire world toward true peace and greater freedom in the last 7 years, and that's how we restored America's strength. And I hope you won't mind me adding with some pride that it's how our men and women in uniform rescued freedom in the small Caribbean country of Grenada. In just a few days, I'll meet with General Secretary Gorbachev of the Soviet Union. We will sign the first arms reduction agreement in the history of relations between our two countries.

For many years critics around the world have insisted that it would be impossible to get an agreement along the lines we've now worked out. Six years ago, when I proposed the elimination of an entire category of U.S. and Soviet intermediate-range missiles, they sneered and said I couldn't be serious. It was a sure sign, they said, that I was against arms reductions altogether, and they added that I ought to offer something the Soviets would agree to, even if I didn't believe it was in America's best interests. And yet we -- and I mean here you and all Americans who supported rebuilding our national defense and our determination that it was better to have no arms agreement than a bad arms agreement -- all of us stuck together. We set goals.

Many of those same critics also said that it was provocative to tell the truth about repression in the Soviet Union, about Soviet overseas adventures, about Soviet violations of past agreements. We said that the United States of America must never be afraid to tell the truth about anyone. Well, now, as a result of lots of hard work and patience, we're about to sign an agreement that will do just what I proposed 6 years ago and that the critics said was impossible. For the first time in history, we will wipe an entire category of American and Soviet nuclear weapons from the face of the Earth.

After the summit, we'll keep our negotiators working on an agreement that could lead to cutting the U.S. and Soviet long-range nuclear arsenals in half and reducing the disparities in conventional forces, that is, the armies that face each other in Europe. Those disparities favor the Soviets. With the Intermediate-range Nuclear Forces agreement, we take a first step across the open frontier toward a safer world for you and your children. And my plan -- our plan -- should be to keep right on marching.

But in the excitement of the summit, the treaty signing, and all the rest, we must not forget that peace means more than arms reduction. More than a decade ago, there was a warming in U.S.-Soviet affairs that we called detente. But while talking friendship, the Soviets worked even faster on the largest military buildup in world history. They stepped up their aggression around the world.

Eastern European dissident thinker has written that ``respect for human rights is the fundamental condition and the sole guarantee of true peace.'' Well, I believe he's right. True peace and freedom are indivisible. That's why it's important to all of us that the Soviets have released over 200 political prisoners over the past year and that they appear to have eased censorship somewhat in the arts and media.

It's also why we're concerned that many more political prisoners remain in jail, internal exile, and psychiatric hospitals. As many as 10,000 Jews await permission to emigrate. Persecution of religious believers continues. Some, including Ludmilla Andrushenko and Father Alsonsas Svarinskas, wait in prison. Their only crime: They wanted to practice their religion and worship God as they pleased. Well, Mr. Gorbachev and I are going to have a few words about that.

We're also going to have words about Soviet expansionism around the world, for example, in Afghanistan. Since the Red Army invaded 8 years ago, the Afghan people have suffered a million casualties, and at least 4 million others have been driven to exile, as freedom fighters have taken up arms against the invader.

Who are these freedom fighters? Well, many of them would be your classmates if they lived here in Jacksonville. That's how young they are. They've taken up arms against one of the largest and best equipped armies in the world, because they've seen what Communist oppression means. To some it means being prevented from living by the rules of their religions. To others it means parents murdered and crops, and even entire villages, destroyed in random and repeated Soviet raids. Or it means a little brother or sister whose hand was blown off by Soviet mines disguised as toys. Oppression means many things.

Soviet territory. They don't now. They never have. The Soviet Union has no legitimate purpose in this war. And I will tell Mr. Gorbachev it is time for the Soviets to set a date certain for withdrawal, to talk with the freedom fighters, and to allow the people of Afghanistan to determine their own destiny.

I will also say it's time for them to leave Cambodia, Ethiopia, Angola, and Nicaragua. Even as the five Central American countries search for peace, the Soviet bloc continues to pour billions of dollars in guns, planes, bullets, tanks, and other assistance into Nicaragua. Why? To quote one of our leading national strategists, Zbigniew Brzezinski: ``Potentially at stake in Central America is America's capacity to defend Western interests throughout the world.'' And he adds: ``If the Soviet-Cuban presence in Nicaragua destabilizes the entire region, the United States will inevitably pull back'' from Europe and the Pacific to defend our own border.

I want my meeting with Mr. Gorbachev to help build a true peace that will last for your lifetime and that of your children and of their children. And that's why we will review our areas of agreement, but also emphasize our points of disagreement. Some say it will be impossible for the Soviets to listen. But we've come a long way already by being strong, steady, and determined. We Americans set our goals. We were realistic about how to go after them. We kept on working, in good times and bad. We believed in America's strength and in America's ability to use its strength to make the world better. For the last 7 years, through us, through all of us here today and millions of others, America has said, I can. And around the world, because of that, peace is more secure and freedom more widely shared. At home, because of that, we're in the longest peacetime economic expansion on record, and unlimited opportunities are waiting for you after graduation. Think of what those two words, ``I can,'' have meant to the story of our nation and the world in our time.

Think of how God graced you when he set you down in this land of liberty and of peace and of opportunity, this land of neighbor helping neighbor and family helping family. I have often thought -- maybe you could call it mysticism if you will -- but I've thought that God placed these American continents here between the two great oceans for the most adventurous, the bravest, and the most resourceful people on Earth to find, people from every corner of the Earth who had a little extra love for freedom and the ambition that brought them here and settled them here in this land of ours, bringing you here by deciding how you want to use America's opportunities and then by saying, I can.

I just have one other thing that I'd like to leave with you. I'm sure in this year of the 200th anniversary of our Constitution you probably have been taught a little extra about the Constitution, but if not, I would like to tell you something that -- I have read a lot of constitutions. Every country has a constitution, it seems. And then I was struck one day by -- well, they talked about freedom of this and that, and freedom to do such and such, and well then why was our Constitution so different? And finally the answer came to me. All those other constitutions said, We the government allow you the people to have the following freedoms and do the following things. Our Constitution says, We the people allow the government to do certain things, and it can do no other things that aren't covered in this covenant, this document. I told that story at a state dinner in the White House to the wife of the Crowned Prince of Japan. And she added another line to my story, because when I finished saying what I've just said to you, she very quietly said to me, ``Our constitution, too, says, We the people.'' And I couldn't hide my surprise. That's right.

Sang. Mr. President, your aides have indicated that you might give us a few more minutes, and our students love to ask questions. In fact, they really work our teachers over. And we selected six of our outstanding academic achievers, and with your permission, they would like to each ask you a question. And I see one already over here to my right.

The President. Well, if the summit meeting carries out as we optimistically think today that it will -- that for one thing, we will have started down the road to the elimination of nuclear weapons. We will have done away with those weapons of ours that are based on the NATO line. They were put there in response -- we did not put them there first -- in response to the Soviets aiming what are called SS - 20 missiles at all the targets of Europe. And we tried to persuade them not to do that -- this was before I was in office -- and they didn't stop. And then Europe asked us to give them something to counter this threat. And by that time, I got here and felt a need to be in charge of placing our weapons there. And they objected very strenuously on the other side. In 1981 I proposed the answer was the elimination -- zero on both sides -- of those particular weapons. And 4 years later they came back, and we started negotiating about that. So, I think we're going to sign that agreement this time, complete with verification.

But for all of you, this threat that's alive in the world today of missiles that can -- well, I've said that a nuclear war can never be won and must never be fought. By never being won, I mean that, by the time two great nations exchange the thousands of nuclear missiles -- firing at each other -- where would those people who weren't blown up -- who still remained left -- where would they live? The very soil would be poisoned -- radioactivity. There would be no place for anyone to live. So, I think that we can't do it all at once. But if we've started down that path, and as you come up and take over from the rest of us -- maybe there'll still be some of the job done -- we can once and for all rid the world of nuclear weapons. And that, I think, will make for a far better life for all of you.

Mr. President, my name's Jason Doman, from Fletcher Senior High School. And I would like to know, in terms of conventional warfare, how will this proposed treaty affect the balance of power between the United States and the Soviet Union?

The President. Well, now, that's something that we have looked at down the way in the future, and it is no question the Soviet Union has outbuilt NATO -- not just the United States -- by 2\1/2\ times as many tanks, 3 times as many artillery pieces, and so forth. But there is a weapon still on the battlelines. There are nuclear weapons that are called tactical weapons. These are, among other things, shells fired from artillery, from cannons. But when the shell explodes, it isn't gunpowder; it's an atomic explosion, a nuclear explosion. And so, both sides have those.

I think that we've got a lot of people on both sides standing in the wings, waiting now for us to approach that problem of that kind of weapon. And we have determined that when you start to talk about eliminating those then you must, at the same time, discuss the balancing of the conventional weapons. Because if we all eliminated right now our nuclear battlefield weapons that can balance things up -- but if we all did away with those weapons, both sides, we would have given the Soviet Union then a hard and fast advantage because of their conventional superiority. So, when we come to discussing those short-range battlefield weapons, we must also discuss and get from them a concession of conventional weapons being equal. It means a reduction from both sides.

Mr. President, my name is Tracie Pough, and I bring you greetings from Jean Ribault Senior High School. I would like to know if you would reiterate the importance to our future of developing and having a Star Wars space-base missile defense system?

For example, from the Soviet Union, if they fired their missiles at us, those missiles get here in 30 minutes or less. You've got a half an hour for doing anything. And they agreed that possibly there was, and so a study went into effect. And what we are working on now is a system -- I just visited one of the plants where some of this is going forward out in Colorado last week, and I was amazed and gratified to see the miracles that are being performed.

What we have in mind -- Strategic Defense Initiative, it's called, that's the SDI -- what we have in mind is a defensive system that can begin by hitting those weapons as they come out of the silos. And those that manage to get through, those warheads -- there is a second stage then that goes up and catches them before they come back into the atmosphere and, finally, a third stage to catch any that might come through. The main thing about it is it could really make nuclear weapons obsolete, because what country would, if we have such a system -- even if they thought that some might get through, they wouldn't be certain enough to start a nuclear attack, because they would know our ability to attack them back.

So, what I have in mind is that -- I won't be around by the time we've got it completed, but what we should do is, when that is completed and we begin to deploy that, we should say to the rest of the world, including the Soviets, if everybody, including us, will get rid of our nuclear weapons, we'll give this to everybody, because we all know how to make them. So, someday we can't be sure that there might not come a madman someplace like a Hitler, who knowing how to make them and knowing that no one else in the world had them, he might decide that he was going to do it. I've likened it to our people as when we got together after World War I and everybody decided that we would no longer use poison gas, but everybody kept their gas masks. Well, I think of this as a gigantic gas mask, and maybe this will be the thing that could bring about the end of nuclear missiles.

The President. I have more faith in the American people than that. We're a pretty independent people. You find that out in any number of things that go on any day on the city streets. And I think that the American people are aware of the shortcomings of communism -- the boy that can't tell you what he's going to do with his life until they tell him what he's going to do. Do you know that in graduation from high schools in that country they come in the rooms where they've got the graduates and they pick them out and tell them who is going to go to college and who is going to go to work in the factory -- and they assign them to these places. So, I don't fear America doing that, and I don't mind that Gorbachev has been, let us say, quite different than past Soviet leaders. I've met with a number of them, and he is different.

Now, at the same time, I'm not going to tell you that he doesn't believe in their system. He was born and raised in that system, and he believes in much of their propaganda. But he is the first one -- no other Russian leader has ever agreed to eliminate weapons they already have. He is the first one to do that. Now, there is one other thing I'm watching. He is also the first Russian leader who has never reiterated before the great national Communist congress that the Soviets are pledged to a world expansion -- a one-world Communist state. That has been the stated goal of previous leaders. He has said no such thing.

The President. You have touched on what has been the touchiest point all the way: verification. And this is what's been going on now in these meetings between Foreign Minister Shevardnadze and our Secretary of State George Shultz -- is to try and iron out this thing of, yes, how do we establish that there is no cheating and that we're really destroying the weapons that we're supposed to destroy? And we apparently have worked out an agreement that is the strongest verification agreement that has ever been worked out in any kind of arms negotiations. It will have us with the ability to not only supervise areas where such things would be made but also to make spot checks -- just decide we want to go and take a look. And they can do the same, of course, with us. And I think that that is -- well, that was the absolute essential thing. As a matter of fact, I'm no linguist, but I did learn a very brief Soviet proverb, which I made it a point to recite to General Secretary Gorbachev when we first started negotiations. It goes: Dovorey no provorey -- trust but verify.

The President. If I could ever give advice to Mr. Gorbachev? To really stick with his program of glasnost and with this worry that they have about people wanting to emigrate from their country, to make their country like ours to the place that people don't want to leave. And I would begin with the most important part of that. I think when the day comes that the people of the Soviet Union can worship God as they please and in the way they want to that must be the first step toward that freedom. Today the Jewish emigration from there -- those people are Russians. They love their country, their motherland. And I'm quite sure that if they were allowed to practice their religion, to have their synagogues, to allow rabbis to be taught in their country that not very many of them would want to emigrate.

Soviet people is the hunger for religion. And he says you become aware of it, even though they don't dare admit it. And he said sometime, if on television you see the little old ladies going to church, as they do -- the orthodox church is allowed to go on -- and they're watched; the KGB watches to see who goes to church. And he said, look closely sometime at the faces under those babushkas of those little shuffling figures, and you'll find some very youthful faces -- that the youth of the Soviet Union is hungry for God.

I have a little Bible in a plastic cover about that high and no thicker than my finger. And inside are some verses that are in there. When they can get their hands on a Bible -- it is so difficult there, and they're not supposed to have them -- they cut them up and make them into these little books so that everybody has just a few verses of their own of the Bible. And one of those was sent to me to show me what they do. So, efforts like that -- they're going forward. And, yes, I may find myself bending his ear on that very subject and telling him maybe his problems would be a lot less.

Dennard. Mr. President, we are sincerely grateful to you for coming to Jacksonville and addressing students and parents this afternoon. We'd like to present to you this plaque as a reminder of your stay here and a reminder of our appreciation and best wishes.

President today announced his intention to appoint Perry Joseph to be a member of the Advisory Committee to the Pension Benefit Guaranty Corporation for a term expiring February 19, 1990. This is a reappointment.

The information contained in this report, in addition to that provided in our previous reports, is essential to understanding the problems we face in seeking to achieve sound, equitable and verifiable agreements for arms reductions that will strengthen our security and that of our allies.

Union to date has not corrected its noncompliance activities. Indeed, since the last report, there has been an additional case of Soviet violation of the ABM Treaty in the deployment of an ABM radar at Gomel, and other violations are continuing.

No violations of a treaty can be considered to be a minor matter, nor can there be confidence in agreements if a country can pick and choose which provisions of an agreement it will comply with. The Gomel violation can be quickly corrected by the Soviet Union if it so chooses. We are urging them to take the actions needed to do so, and to resolve other longstanding violations, especially that of their radar located at Krasnoyarsk. Correcting their violations will be a true test of Soviet willingness to enter a more constructive relationship and broaden the basis for cooperation between our two countries on security matters.

Congressional support and consensus on this issue is an essential element of our efforts to secure corrective actions, and pursue the kind of arms reductions agreements that will best serve the interests of the United States and the world.

At the request of Congress, I am submitting this report on Soviet Noncompliance with Arms Control Agreements. This Report represents another in a series of reports to Congress by this Administration regarding this serious issue. The series includes Reports dated January 1984, February and December 1985, March 1987, and the 1984 Report on Soviet Noncompliance prepared for me by the independent General Advisory Committee on Arms Control. Each of these reports has enumerated and documented, in detail, issues of Soviet noncompliance and our attempts to resolve the issues. Likewise, this Report addresses questions of Soviet noncompliance with existing arms control agreements, including the Anti-Ballistic Missile Treaty, the Biological and Toxin Weapons Convention, the Geneva Protocol on Chemical Weapons, and the Limited Test Ban Treaty. Now that we have put the SALT I Interim Agreement and the SALT II Treaty behind us, Soviet activities with respect to those agreements are not treated in this Report. I will report on the Threshold Test Ban Treaty at a later date. The provisions of the Helsinki Final Act that relate to military security and confidence-building have been superseded by the Stockholm Document, a development that is treated later in this introduction. When taken as a whole, this series of reports provides a clear picture of continuing Soviet violations and forms the basis for our concern that future agreements must be effectively verifiable and complied with.

The compliance concerns enumerated in this Report are not unfamiliar to the Soviet Union. I expressed my personal interest in these issues directly to General Secretary Gorbachev during my meetings with him, both in 1985 in Geneva and then again in Reykjavik in October 1986. In addition, the Standing Consultative Commission discusses compliance concerns in detail during its biannual sessions. The classified Report includes detailed summaries of this SCC dialogue. Most recently, Secretary of State Shultz raised U.S. concerns about Soviet noncompliance during his October 1987 visit to Moscow.

Additional time has passed and, despite these continuing intensive efforts and the critical stage we have entered in the negotiation of arms reductions of historic proportion, the Soviet Union has failed to correct its noncompliant activities; neither have they provided explanations sufficient to alleviate our concerns on other compliance issues. Indeed, recent Soviet activities at an electronics facility at Gomel have raised an additional compliance issue with regard to the ABM Treaty.

Despite these continuous efforts, I regret to report that during the period since my last Report, the Soviet Union has failed to correct its noncompliance activity or to provide explanations sufficient to alleviate our concerns.

Soviet explanations and actions are fully described in the Report. The Report presents and distinguishes between both violations and possibly noncompliant actions which are historical in nature and instances of ongoing and new noncompliant behavior.

One of our principal concerns is with the Krasnoyarsk radar which is a clear violation of the Treaty. The radar demonstrates that the Soviets were designing and programming a prospective violation of the ABM Treaty even while they were negotiating a new agreement on strategic offensive weapons with the United States.

LPARs, such as the Krasnoyarsk radar, have the inherent capability to track large numbers of objects accurately. Thus, they not only could perform as ballistic missile detection, warning, and tracking radars, but also have an inherent technical potential, depending on location and orientation, of contributing to ABM battle management.

Soviet activities during the past year have contributed to our concerns. Construction is continuing on three additional LPARs similar to the Krasnoyarsk radar. These new radars are located near the periphery of the western USSR and oriented consistent with the ABM Treaty's provisions on ballistic missile early warning radars (if they are for early warning). The primary mission of these radars is ballistic missile detection and tracking.

Soviets have sought recently to convey the impression that they are addressing our concerns in a responsible fashion, but have not taken any actions which in fact redress our concerns regarding their possible preparation of a territorial defense. For example, on September 5, 1987, a U.S. Congressional Delegation was permitted to visit the Krasnoyarsk radar. Although the Soviet invitation represented a departure from the long Soviet history of secrecy in such matters, the observations of the Congressional Delegation regarding the stage of construction, the quality of construction, and other features of the radar in no way change the assessment that the radar is designed for ballistic missile detection and tracking. The radar is unquestionably an LPAR, whose location and orientation are inconsistent with the ABM Treaty.

In recent years, we have gathered an increased amount of evidence on activities that could be associated with Soviet concurrent operations. This may or may not indicate an increase in Soviet concurrent operations. Also of significant concern is the initial deployment in the western USSR to Soviet ground forces of the SA - 12 defensive system, a variant of which has been tested against tactical ballistic missiles and may have some ABM capability.

Our continuing reexamination of Soviet ABM-related activities demonstrates that the Soviets have not corrected their outstanding violation, the Krasnoyarsk radar. With regard to Krasnoyarsk, on October 23, General Secretary Gorbachev told Secretary of State Shultz that the Soviets were imposing a one-year construction moratorium on Krasnoyarsk. Although activities at Krasnoyarsk continue to be noted, the remaining work needed on the radar is interior work, so that it would be difficult to ascertain whether the Soviets have indeed ceased construction at the site.

As a result of the 1986 BWC Review Conference, States party to the Convention agreed to exchange information on facilities built for high-risk (high-containment) biological experiments and facilities engaged in other activities relating to the convention. The Soviet submission is an unprecedented public declaration of permitted Soviet BW-related facilities and is a welcome step.

An example of the discrepancy between Soviet public and private arms control diplomacy is the recent Soviet treatment of our concerns regarding an outbreak of anthrax in Sverdlovsk in 1979. The U.S. has evidence that the outbreak occurred as a result of an accidental release of large quantities of anthrax spores from a prohibited BW facility, contributing to our concerns about the Soviet BW program. We have raised the issue repeatedly with the Soviets as early as March 1980, and have been told that the outbreak stemmed from the consumption of contaminated meat.

Again, while we welcome the provision of new information and the opportunity to discuss these issues, our concerns regarding the Soviet biological warfare program and capability are unassuaged. The Soviets have maintained a prohibited offensive biological warfare capability. It may include advanced biological agents about which we have little knowledge and against which we have no defense. The Soviets continue to expand their chemical and toxin warfare capabilities, contrary to their public claims. Neither NATO retaliatory nor defensive programs can begin to match the Soviet effort. And, even though there have been no confirmed reports of attacks with lethal chemical, biological or toxin agents since 1984, previous activities have provided the Soviets with valuable testing, development, and operational experience.

During their 1985 - 86 moratorium, the Soviets undoubtedly maintained their test sites because they quickly resumed testing and have since conducted a series of tests. One of these tests raised sufficient concern about Soviet compliance with the 150 kt limit of the Threshold Test Ban Treaty (TTBT) that the U.S. raised the issue with the Soviets.

In the March 1987 Report we reaffirmed the December 1985 U.S. Government judgment that, ``Soviet nuclear testing activities for a number of tests constitute a likely violation of legal obligations under the Threshold Test Ban Treaty.'' We also reported that the finding would stand until a number of studies, which had been initiated in an attempt to provide a somewhat improved basis for assessing Soviet compliance, could be completed. While significant progress has been made on those technically difficult issues, we do not expect to provide an update until next spring.

United States and the Soviet Union have met several times at the experts level to discuss the broad range of issues relating to nuclear testing. In a joint statement issued at the time of the September 1987 meeting between Secretary of State Shultz and Soviet Foreign Minister Shevardnadze, the two sides indicated their intention to design and conduct joint verification experiments at each other's test sites. On November 9, 1987, the United States and Soviet Union began full-scale, stage-by-stage negotiations in which the first step is to agree on effective verification measures which will make it possible to ratify the U.S-U.S.S.R.

Security-Building Measures containing new standards for notification, observation, and verification of military activities, including on-site inspection, went into effect January 1, 1987. To date, Soviet military activity forecasts, subsequent notifications, and the acceptance of requests for two inspections have been consistent with their obligations under the new agreement. The Soviets have provided the minimum information required and have, therefore, remained within the scope of their obligations. In view of this and without any new evidence, this compliance issue will not be treated in this report. However, we have exercised our prerogative for on-site inspection and will be carefully monitoring Soviet compliance with these new standards.

A consistent and fundamental priority of my Administration has been achieving deep and equitable reductions in the nuclear offensive arsenals of the U.S. and U.S.S.R. That goal is closer to reality than it has ever been in the history of mankind, but it will be achieved only if effective verification and total compliance are integral elements of the process both with respect to existing arms control agreements and possible new ones.

We must insist on effective verification of the provisions of these new agreements, respond appropriately to any Soviet noncompliance, and continue to make our strategic decisions based on the nature and magnitude of the Soviet threat. A double standard of compliance with arms control obligations is unacceptable.

To preclude the development of a territorial defense or providing the base for a territorial ABM defense, the ABM Treaty provides that radars for early warning of ballistic missile attack may be deployed only at locations along the periphery of the national territory of each Party and that they be oriented outward. The Treaty permits deployment (without regard to location or orientation) of large phased-array radars for purposes of tracking objects in outer space or for use as national technical means of verification of compliance with arms control agreements.

The U.S. Government reaffirms the conclusion in the March 1987 Report that the new large phased-array radar under construction at Krasnoyarsk constitutes a violation of legal obligations under the Anti-Ballistic Missile Treaty of 1972 in that in its associated siting, orientation, and capability, it is prohibited by this Treaty. Construction continued in 1987.

The absence of credible alternative explanations have reinforced our assessment of its purpose. Despite U.S. requests, no corrective action has been taken. This and other ABM-related activities suggest that the USSR may be preparing an ABM defense of its national territory.

The March 1987 Report examined whether the Soviet Union has developed a mobile land-based ABM system, or components for such a system, in violation of its legal obligation under the ABM Treaty. We have reexamined this issue and considered the impact of the Soviet actions at Gomel.

The U.S. Government reaffirms the judgment of the March 1987 Report that the evidence on Soviet actions with respect to ABM component mobility is ambiguous, but that the USSR's development and testing of components of an ABM system, which apparently are designed to be deployable at sites requiring relatively limited special-purpose site preparation, represent a potential violation of its legal obligation under the ABM Treaty. The recent movement of parts of a Flat Twin and Pawn Shop reinforces our concerns about ABM system component mobility. This and other ABM-related Soviet activities suggest that the USSR may be preparing an ABM defense of its national territory.

Parties may have ABM systems and components for development and testing purposes so long as they are located at agreed test ranges. The Treaty also prohibits giving components, other than ABM system components, the capability ``to counter strategic ballistic missiles or their elements in flight trajectory'' and prohibits the Parties from testing them ``in an ABM mode.'' The Parties agreed that the concurrent testing of SAM and ABM system components is prohibited.

SAM and ABM system components in violation of its legal obligation since 1978 not to do so. It was the purpose of that obligation to further constrain testing of air defense systems in an ABM mode. We have reexamined this issue.

The March 1987 Report examined whether the Soviet Union has tested a SAM system or component in an ABM mode or given it the capability to counter strategic ballistic missiles or their elements in flight trajectory in violation of their legal obligation under the ABM Treaty. We have reexamined this issue.

The ABM Treaty limits to 100 the number of deployed ABM interceptor launchers and deployed interceptor missiles at launch sites. It does not limit the number of interceptor missiles that can be built and stockpiled. Paragraph 2, Article V, of the Treaty prohibits the development, testing or deployment of ``automatic or semi-automatic or other similar systems for rapid reload'' of the permitted launchers.

The U.S. Government reaffirms the judgment made in the March 1987 Report that, on the basis of the evidence available, the USSR's actions with respect to the rapid reload of ABM launchers constitute an ambiguous situation as concerns its legal obligations under the ABM Treaty not to develop systems for rapid reload.

To preclude the deployment of a territorial defense or providing the base for a territorial defense, the ABM Treaty provides that ABM components cannot be deployed outside of the one permitted ABM system deployment area or designated ABM test ranges for any purpose.

In March 1987, the U.S. Government observed the appearance of major parts of the original Flat Twin radar, including all of the modular sections of the radar body, and a Pawn Shop van at an electronics plant in Gomel, about 550 kilometers southwest of Moscow. The timing of the arrival of parts of the Flat Twin and Pawn Shop indicates that they came from the radars that were removed from the Sary Shagan Missile Test Center where, by January 1987, the Soviets were observed disassembling a number of these ABM components. U.S. concern regarding the issue of mobile ABM components previously raised with the Soviets could be exacerbated by this Soviet action.

Flat Twin ABM radar and a Pawn Shop van, a component of an ABM system, from a test range and initiating deployment at a location outside of an ABM deployment area or ABM test range constitutes a violation of the ABM Treaty. While it is not likely that the actions at Gomel are to support an ABM defense at that locality, deployment of such radars at Gomel to carry out any function is inconsistent with ABM Treaty obligations. This and other ABM-related Soviet activities suggest that the USSR may be preparing an ABM defense of its national territory.

The ABM Treaty and Protocol allow each Party a single deployment area, explicitly permit modernization and replacement of ABM systems or their components, and explicitly recognize the existence of ABM test ranges for the development and testing of ABM components. The ABM Treaty prohibits, however, the deployment of an ABM system for defense of the national territory of the Parties and prohibits the Parties from providing a base for such a defense.

Protocol are multilateral treaties to which both the United States and the Soviet Union are Parties. Soviet action not in accord with these treaties and customary international law relating to the 1925 Geneva Protocol are violations of legal obligations.

The BWC bans the development, production, stockpiling or possession, and transfer of microbial or other biological toxins except for a small quantity for prophylactic, protective or other peaceful purposes. It imposes the same obligations in relation to weapons, equipment and means of delivery of agents or toxins. The 1925 Geneva Protocol and related rules of customary international law prohibit the use in war of asphyxiating, poisonous or other gases and of all analogous liquids, materials, or devices and prohibits use of bacteriological methods of warfare.

The March 1987 Report examined whether the Soviets are in violation of provisions that ban the development, production, transfer, possession, and use of biological and toxin weapons and whether they have been responsible for the use of lethal chemicals. We have reexamined this issue.

The U.S. Government judges that continued activity during 1987 at suspect biological and toxin weapon facilities in the Soviet Union, and reports that a Soviet BW program may now include investigation of new classes of BW agents, confirm the conclusion of the March 1987 Report that the Soviet Union has maintained an offensive biological warfare program and capability in violation of its legal obligation under the Biological and Toxin Weapons Convention of 1972.

There have been no confirmed attacks with lethal chemical or toxins in Cambodia, Laos, or Afghanistan in 1987 according to our strict standards of evidence. Nonetheless, there is no basis for amending the March 1987 conclusion that, prior to this time, the Soviet Union has been involved in the production, transfer, and use of trichothecene mycotoxins for hostile purposes in Laos, Cambodia, and Afghanistan in violation of its legal obligation under international law as codified in the Geneva Protocol of 1925 and the Biological and Toxin Weapons Convention of 1972.

The March 1987 Report examined whether the USSR's underground nuclear tests have caused radioactive debris to be present outside of its territorial limits. We have reexamined this issue including evidence obtained since the Soviets resumed nuclear underground testing in February 1987.

The U.S. Government reaffirms the judgment made in the March 1987 Report that the Soviet Union's underground nuclear test practices resulted in the venting of radioactive matter on numerous occasions and caused radioactive matter to be present outside the Soviet Union's territorial limits in violation of its legal obligation under the Limited Test Ban Treaty. The Soviet Union failed to take the precautions necessary to minimize the contamination of man's environment by radioactive substances despite numerous U.S. demarches and requests for corrective action. This practice has continued. Since the resumption of Soviet underground testing in February 1987 the United States has presented demarches to the Soviet Union on two separate occasions when unambiguously attributable venting has occurred.

Sound agreements that result in genuine reductions, equality of U.S. and Soviet forces, and are effectively verifiable contribute to our security if they are faithfully carried out. All treaty violations are significant, because they undermine confidence in the process of arms control if a country can pick and choose with which provisions of treaties it will comply.

This year's report reaffirms the findings of the March 1987 report with respect to Soviet violation of the ABM treaty, the biological and toxin weapons convention, the Geneva protocol on chemical weapons, and the limited test ban treaty. In addition, we have evidence of an additional Soviet violation of the ABM treaty in the deployment of an ABM radar at Gomel.

Soviet violations are continuing. All of these violations are a matter of serious concern to us, and we have urged the Soviets to do what is necessary to end them. Correcting their violations will be a true test of Soviet willingness to enter a more constructive relationship and broaden the basis for cooperation between our two countries on security matters.

The success of our policy and naval presence in the Persian Gulf is reflected in the action of the Arab States at their summit meeting in Amman, their unprecedented cooperation with us in the Gulf, and the presence in the Gulf of naval forces from five of our NATO allies. [Israeli] Prime Minister Shamir's recent statements strongly supporting our Gulf posture and its contribution to stability and greater realism in the area also bear testimony to the wisdom of our approach. A critical element in the success of our policy is that our moderate Arab friends and our allies see the United States as being reliable.

The emergence of legislation in the Congress that would prohibit the sale of STINGER air defense missiles to countries with a legitimate need for them is a source of serious concern. The immediate target of the proposed amendment is a limited sale of STINGER's to Bahrain.

For the past 40 years, Bahrain has been a good friend to the United States, consistently hosting our regional naval presence. In fact, it would have been impossible to accomplish the recent naval buildup in the Gulf to protect U.S. flag ships from Iranian attack without the help of Bahrain. At the same time, Bahrain's extraordinary support for the United States has made it even more vulnerable to Iranian military threats.

Improved Bahraini defense against such attacks would protect American forces as well as Bahrain. The STINGER system is precisely what Bahrain needs to fill gaps in its defenses against the most likely threat, and no other system can do the job as well. U.S. Navy ships in the Gulf are equipped with STINGER's to defend against the very same Iranian aerial threat.

We fully share congressional concerns about preventing diversion of STINGER's into hostile or terrorist hands, and so does Bahrain. That is why we have always insisted on reliable safeguards that rule out the possibility of transfer or diversion as an absolute precondition for any STINGER sale. Any government that will not accept such safeguards will not be sold STINGER's. We must not forget that the likely alternative to careful, tightly controlled and monitored STINGER sales to states who legitimately need them and with whom we have important defense relationships is a further proliferation of unsafeguarded, man-portable Soviet systems. That would increase, not decrease, the terrorist threat in the area.

The administration is actively seeking to work with Congress on this important issue to develop a mutually acceptable solution. The more we can cooperate in projecting an image of steadiness and resolve in the Gulf, the more progress we are likely to make in reassuring our friends, deterring our adversaries, and defending our vital interests in that critical region.

I am pleased to sign H.R. 2112, the Intelligence Authorization Act, Fiscal Year 1988. This legislation authorizes the appropriation of funds for United States intelligence and intelligence-related activities. It represents the combined efforts of the Senate and House Intelligence and Armed Services Committees as well as the various agencies in the intelligence community to assure adequate funding for these important activities. The bill also contains many positive legislative initiatives that are the product of cooperation between these committees and the community. I am gratified to see the results of this cooperation and will work to ensure that it continues in the future.

I was disappointed that the authorization levels in this bill are less than I had requested. However, the intelligence community will do everything possible to meet the complex and diverse challenges it faces within current budgetary limits. In these times of fiscal constraint, it is necessary for all agencies to share in budget reductions, and the community stands ready to do its part. I will continue to work with the Congress to ensure the continuation of a strong intelligence capability for the United States.

I must express my view that section 501 of the bill is unconstitutional. This section would require the Attorney General to report to the Congress internal disagreements between executive officials about the admission of foreign officials to the United States. These internal disagreements reflect communications and deliberations that are protected from disclosure because of the need for candor and objectivity among executive officials. The President, of course, has the exclusive constitutional authority to ``receive Ambassadors and other public Ministers.'' Since the Presidency of George Washington, it has been consistently recognized that the executive branch cannot be made to disclose to the Congress information relating to actions taken pursuant to an authority assigned by the Constitution exclusively to the President. Accordingly, requiring this annual report by the Attorney General would violate long-established constitutional principles and, pursuant to my constitutional authority, I will instruct the Attorney General not to submit an annual report to the Congress pursuant to section 501. I do not, however, believe the unconstitutionality of section 501 affects the validity of the remainder of the bill.

Thank you, and I appreciate all of you being here. You represent groups that have a keen interest in the discussions that will be taking place during the upcoming visit of General Secretary Gorbachev. And I'm happy to have this opportunity to confirm to you that, although we're making a serious effort to improve relations between the Soviet Union and the United States, we will not do it by compromising our national interests or diminishing our commitment to the universality of human rights.

Our dedication to liberty and justice for all is not negotiable, not to this generation or not to any generation of Americans. This year we celebrate the 200th anniversary of the signing of our Constitution, which of course contains not just an organizational structure for the Federal Government but also the Bill of Rights. The structure divides power so that no person or group can be so powerful that they can trample on the rights of the people. And I think it's interesting to note that the reason the Bill of Rights was added to the document was that some believed the Constitution might not have been ratified otherwise. Such was our forefathers' devotion to liberty.

In my upcoming meetings, I know that sitting next to me will be unseen guests, men and women whose only hope is that they're not forgotten here in the West: dissidents who are inhumanely committed to mental institutions, often subdued with mind-altering drugs; Soviet Jews, Armenians, Germans, and others who have applied to emigrate and have endured incredible hardships as a result; divided families and spouses who are cruelly separated from their loved ones. These people are not now, nor will they ever be, forgotten by our administration.

Well, let me assure you and, through you, all those whose cause you champion, we deeply care about the well-being of these unseen guests, and their presence will be felt throughout my summit discussions. The goal of this visit and any subsequent visits is not simply arms reduction. Certainly, that's one priority, yet it remains on a par with solving certain bilateral issues: ending regional conflicts and of course improving human rights.

Well, today our discussions on this issue are wide-ranging, and human rights is accepted as an integral component of our bilateral discussions. In the last 2 years we've witnessed a loosening of the grip. Over 200 political prisoners have been released from the gulag. There's a higher rate of emigration. Some long-divided families have been reunited. There has even been a relaxing of some of the controls on freedom of expression. Earlier this year, for example, there were demonstrations in the Baltic nations on the anniversaries of the Hitler-Stalin pact and the day marking the beginning of the Soviet occupation in 1940. The fact that these protests were permitted at all was heartening.

The free people of the West are watching to see if the emigration doors, now cracked, will continue to open. And inside we wait and pray for believers, people of every creed. All prisoners of faith have not been released, and clearly religious freedom is still an aspiration yet to be achieved. We care about people whose human rights are violated and who are abused or imprisoned in every country. We care of what they symbolize and because they're human beings. And we're outraged at the way they're being treated.

Bernard Shaw once wrote: ``The worst sin towards our fellow creatures is not to hate them but to be indifferent to them: That is the essence of inhumanity.'' Well, today, we're pleased with any releases, any unification of separated families, any lessening of the iron grip on the freedoms of expression and religion. But we will not be indifferent to those who are left behind, and we will not be lulled into ignoring the fact that the apparatus of the state repression remains intact in the Soviet Union. The real joy will come, and trust between East and West will flourish, not only when prisoners are released but when the instruments of repression are dismantled and repressive laws and practices are abolished.

Jim shares my vision for a transportation policy that will remove government barriers to the private sector so it can provide the transportation service that America needs. Much has been done to continue deregulation of these industries, particularly in the airline, railroad, and trucking industries. But there's even more to be done in the next 14 months to return control to the private sector.

Jim, throughout your life you've demonstrated a dedication to the life of the Nation and to the ideals for which America stands. And now that you've taken your oath of office, I would only observe: This is a duty for which you're fully prepared and an honor that you fully deserve.

America's economy and its ability to compete in world markets depend on a dynamic and growing transportation industry. And I recognize the tremendous responsibility that I'm assuming to continue your administration's efforts to be sure that government is not impeding such growth while, at the same time, continuing to provide the traveling public with the highest level of safety. And I have the great advantage of being able to build upon the very solid foundation laid by Drew Lewis and Elizabeth Dole, clearly the two most successful Secretaries of Transportation in the Department's 20-year history.

I am privileged to have an extremely talented and capable team of individuals working with me: the 100,000 men and women that you made reference to who are the Department of Transportation. With millions of Americans on our roads, trains, airways, and waterways every day, their safety is a responsibility that I and the people of the Department take very personally and seriously.

I am no stranger to the Department, I'm ready to begin immediately to lead them in making the last year of your administration one of continuing substantial progress in assuring the American people the safest, most efficient transportation system in the world. So, it's with deep, personal gratitude to you, Mr. President, that I assume this office, and I look forward to working with you and the Congress and the Cabinet in the year ahead.

Next week Mikhail Gorbachev will be in Washington. The two of you are expected to sign an agreement for the elimination of all medium-range nuclear missiles in the world, even though this week you are accusing the Soviets of violating the antiballistic missile treaty, and even though a lot of people say that that will leave the Soviets in a superior position in Europe, because they have more men, more tanks, more helicopters. Now, if this were another President making this deal, wouldn't the old Ronald Reagan be the first to speak out against it?

The President. No, because I think this deal is different than anything that's ever been attempted before in arms negotiations between our two countries. For one thing, this is the first Russian leader -- or Soviet leader, I should say, that has ever expressed a willingness to eliminate weapons they already have. But as to whether this changes the military balance, you're absolutely right that in conventional weapons -- tanks, artillery, and so forth -- the Soviet Union does have tremendous advantage over the NATO countries and over the United States as a member of NATO.

But there are still thousands and thousands of nuclear weapons -- tactical weapons, battlefield weapons -- that can be fired from artillery and so forth that still exist. These weapons that are disappearing were weapons that -- if the Soviet Union used them, they wouldn't be hitting military targets, they would be hitting the capital cities of all of Europe. And if it comes to the point of us negotiating, as I hope it does one day, on those battlefield tactical weapons, then conventional weapons must be negotiated, as well. There would be no point then in removing those weapons, which now do give us a balance and counter their conventional superiority, and leaving them with that other superiority. Both would have to be -- one eliminated and the other brought down to parity.

And we're not anywhere near facing those yet. We're facing the terror weapons -- first, these that we want to eliminate totally and that I asked for in 1981, and the next step, the so-called START agreement, where we are talking of starting with eliminating 50 percent of the intercontinental ballistic missiles. Those are the destabilizing weapons that bring terror to the world.

Those are the weapons that threaten us with mutual destruction if they're ever loosed -- someone pushes a button and within 30 minutes there is devastation and horror in our country, or, if we've done it to them, in their country. And that would be the next step.

Mr. President, on this treaty, you've not even signed on the dotted line, and yet five of the Republican Presidential candidates have deserted you. The conservatives, the right wing of your party, are after your scalp. My question is: If you are not a lameduck President, would this INF treaty sail through the Senate?

The President. Well, I hope it is going to sail through anyway. I think that the objections that we are hearing -- and, yes, from some of our own, you might say, allies and own forces -- they're based on a lack of knowledge as to what this treaty contains, and particularly are they ignorant of the advances that have been made in verification. No treaty before has ever been based on as much verification and on-site inspection and so forth as this one. This is what has been holding it up for so long until we finally got over that hurdle. And I think that this thing hinges something on the first question, also: that they think that somehow this is leaving the Soviet Union with its superiority in conventional weapons. And I've just explained that it isn't. But also I think we have to look at the very fact that we have obtained apparently their agreement to a treaty in which they're destroying four times as many nuclear missiles or warheads as we are.

Mr. President, Winston Churchill once said that trying to maintain a good relationship with the Communists was not unlike trying to woo a crocodile: that when it opened its mouth, you never could be quite certain whether it was trying to smile or eat you up. [Laughter] Now, Americans respect you, love you, and are pulling for; but they're concerned that perhaps you are going to -- or already have allowed Gorbachev to eat you and us up. We have a new CBS News-New York Times poll out tonight, and it indicates that the majority of those polled, 45 percent, the largest number, are convinced that you'll make too many compromises to Gorbachev. And the question is: What assurances can you give -- how can you convince Americans that you have the command of the kind of complex information that's necessary here? -- not to have this young, energetic, intelligent, tough Marxist-Leninist eat you and us up?

The President. Well, I haven't changed from the time when I made a speech about an evil empire. And I think I could sum up my own position on this with the recitation of a very brief Russian proverb: Dovorey no provorey.

It means trust, but verify. And there would be no way that I could sign a treaty just to be signing a treaty and with my fingers crossed that everything was all right. This is why it is hinged on arriving at solid verification measures and their agreement to them. And I think that in the past there has been a willingness on some to just look on the bright side and accept a treaty so that they could say, look, we've signed a treaty, whether the treaty worked or whether it benefited us or not. And there's no way that I could do that. And I assure the people now that that will never happen.

That's why I walked out of Reykjavik. In Reykjavik we had come to an agreement on literally total nuclear disarmament, except that at the very last minute they said it could only take place if we gave up SDI. And that's when I came home.

The President. The Soviet Union has, back through the years, made it plain, and certainly leader after leader has declared his pledge that they would observe the Marxian concept of expansionism: that the future lay in a one world, Communist state. All right, we now have a leader that is apparently willing to say -- or has never made that claim, but is willing to say that he's prepared to live with other philosophies in other countries. But again, as I say, that doesn't mean that we take his word for that and sign a treaty he alone may not be able to deliver on something of that kind. We'll sign a treaty -- as I've repeatedly said here -- when we're sure that that treaty is as beneficial to us as it is to them.

I would like to call your attention to the fact that in 1981, when I proposed the zero option of these intermediate weapons, they indignantly walked out of the negotiations and said they wouldn't be back. Well, they came back. And as a matter of fact, they came back and announced a zero-zero as their own idea.

Now, I think that some of the people who are objecting the most and just refusing even to accede to the idea of ever getting any understanding, whether they realize it or not, those people, basically, down in their deepest thoughts, have accepted that war is inevitable and that there must come to be a war between the two superpowers.

I think as long as you've got a chance to strive for peace you strive for peace. But you don't have peace and surrender. And there's no way that we're going to surrender, no way that we're going to sign a treaty that is not, as I say, to the benefit of all of us.

Mr. President, in something of the same vein about Mr. Gorbachev, I think all our polls this week may show the same thing. The ABC News-Washington Post polls show surprisingly that Mr. Gorbachev's favorable rating in this country is only 4 percent lower than your own. He's made a strong impression. The other day when you were asked about difficulties with him, you turned to the side with something of a joke. You said you'd played with Errol Flynn. Can you give us a more serious assessment now of Mr. Gorbachev and how tough he is to do business with?

The President. Well, all of you, in reporting my line about Errol Flynn, sort of skipped over what the young man had asked me. He had made it out that you'd all built up Mr. Gorbachev to the place that didn't I have some concern about sort of standing up there alongside him and being -- well, he'd be the scene-stealer and so forth. And that's when I couldn't help but say I costarred with Errol Flynn. So, that's all that that was about.

But with regard to those poll figures and polls, I have to say, you have to know what questions are asked and how they're being asked. Because our Dr. Wirthlin, that I think is probably the finest on-the-record pollster in the Nation, has more recently taken a poll, and he found that 56 percent of the people in America support the treaty and SDI. And then when they heard his interview and him admitting that they, too, were working on an SDI, that figure went up to 71 percent of the American people want Strategic Defense Initiative.

Mr. President, we learned again this week that Mikhail Gorbachev has a very hard-line view about human rights in his country and a very distorted view about the human rights equation in this country. He seems not to understand, firsthand, the depth of feeling in America, and even in his own country, about the need for people to have freedom to come and go as they please, to live in dignity. Could you not bring that feeling to him by inviting some refuseniks to the State dinner next week, so that when he is your guest he can meet them firsthand?

The President. Well, I'm sure that there are going to be a number of people at that dinner who have different views from him. Whether that's the place, though, for what you're suggesting, I don't know. But I do know that we've talked all this time here on disarmament and virtually this single treaty, but that is only one of the four major courses that we're going to be discussing with him, as we have on all the other occasions -- and that is human rights -- one of them -- and we have made some headway. There has been an increase. A number of the so-called refuseniks who have been allowed to come to this country have been requests by us by name in which we have named individuals that have come to our attention. And we've got to go further.

What you first suggested there -- we've got to make them see that the full human rights, the rights that they agreed to in the Helsinki pact, have got to be observed: the right of people to live where they want to live. And perhaps we can point out in our discussions that we're not trying to interfere with their internal workings. That's the answer that they've given so many times to us on this particular subject. But maybe we could make them see that if their people had more of that glasnost that he's been talking about they wouldn't want to emigrate.

I'm quite sure that there are people there who love their country, but it's the manner in which it is being run that makes them think they have to go someplace else. But how much emigration on the basis of religious beliefs would there be if they would simply repeal the restrictions that they've imposed on various religions and admit that people can believe in God and worship God in their own way, whatever their denomination might be. As a matter of fact, people who have been there and people who have a reason to know, not just tourists, have said that there is a growing desire on the part of the Soviet people for the right to worship. And maybe in all of our meetings -- maybe we could help him understand that and help him get his glasnost.

But part of the problem on human rights, it seems to a lot of people, is that we have no effective pressure on them, no linkage. And you have been talking here again today about the need to reduce long-range missiles by 50 percent.

Plainly, Gorbachev is interested in that. If you can work out an accommodation on SDI, the Strategic Defense Initiative, and work your way toward a 50-percent reduction in long-range missiles, would you sign that if there were no measurable significant progress as well in human rights by a set standard?

I think you shouldn't link these various programs, but we will be working just as hard with regard to human rights, just as hard with regard to the regional things, such as getting out of Afghanistan, and pointing out that if he means his desire for a better, more open relationship between the two countries, then these are things that are essential to that and that he can come closer to what he expresses as his desire if he meets us halfway on these other issues.

The President. I would have no way of knowing that. I have to say this in favor of him on this thing: that having been born and raised within the Soviet framework, I have felt that he sincerely believes in that philosophy and also believes a lot of the propaganda about the Western World and about our country -- that it isn't just spouting off about shortcomings here in this country; he really believes them.

That's why I am desirous of having him be able to come to our country -- he has never been here before -- to come to our country when it is not a summit, but when he would be free to see what there is to see in this country. I'm a little frustrated when I think you couldn't take him to see it, because then he'd think it was all staged, because he sincerely believes the shortcomings that he discusses of ours. And I'm still going to hope that the other can take place.

The President. Well, I think I'd stop short of that, but I'd be very disappointed. And I just don't think it's going to happen. I think that we're going to have a meeting in Moscow, and I think there is a reasonably good chance that we will make another gigantic step forward in the elimination of nuclear weapons.

The President. Well, you must remember that there were other leaders under which this happened. He inherited that. And those leaders are the ones who had created the puppet government. Now, whether he knows to what extent they did that, I don't know. But I'm quite sure, on the other hand, that he feels comfortable with the idea that if they left Afghanistan that there would be a government similar to the Eastern-bloc nations in Afghanistan, not necessarily a government that was chosen by the people of Afghanistan.

Well, on our side, our job is to make him see that not only must their troops leave Afghanistan but that the people of Afghanistan, just as the people of Nicaragua, must have the right to determine the government that they're going to have in those countries and not simply accept the present stooges or the Communist world.

There's a lot of talk, Mr. President, about you facilitating a Soviet withdrawal from Afghanistan. Would you, for example, make a commitment not to supply the antigovernment forces for a year if the Soviets committed to get out of Afghanistan within that period of time?

The President. I don't think we could do anything of that kind, because the puppet government that has been left there has a military, and it would be the same as what I'm arguing about with regard to the freedom fighters in Nicaragua. You can't suddenly disarm them and leave them prey to the other government -- and this is p - r - e - y, not p - r - a - y. No, the people of Afghanistan must be assured of the right of all of them to participate in establishing the government they want, and that requires more than just getting his forces out of there. But I think that we have to look at one other thing here. You spoke of the need for pressure sometimes to get some of the things we want. The pressure on him, and on the Soviet Union, is that that great military power in some almost 8 years has been unable to overpower the freedom fighters there. They're fighting on literally even terms.

Another question, sir, about withdrawal. You're very up about the INF agreement. You're optimistic about the possibility of getting your reduction in strategic nuclear weapons. The Soviets have talked a lot about reducing their conventional forces in Europe. Is it time to consider bringing some American troops home from Europe?

The President. Well, not at a time when we already are outweighed by the opposition. That would come as part of an agreement if you were coming down to parity so that there would not be anyone with a great superiority. So, no, they would have to come down quite a ways by themselves before they would reach our level. I think if you look at the figures on tanks, mechanized warfare, artillery pieces, they outnumber the NATO forces by as much as three times as many weapons in those fields as NATO has.

Mr. President, there is some feeling, as I'm sure you're aware, that you're eager to make this arms control deal in part because you need a political victory, especially after the Iran-contra affair. There is some unfinished business. There are some open questions around Washington and the country. One of the principal ones is that if Colonel North and Admiral Poindexter are indicted would you pardon them?

I don't think anyone should try to answer at a time like this. You tempt me into remarking something about the Iran-contra affair. I refuse to believe that accepting a request from individuals not in the government -- or not government forces of Iran to discuss the possibilities of a future government of Iran having a better relationship with the United States -- that it was a scandal for me to accept that invitation and have some people make contact with them.

The President. Yes, I'm the one that told all of you that there was money diverted, and I didn't know it until after that leak in a paper in Beirut exposed the meeting we were having. We were having a covert operation there, because we didn't want to cause the death of the people who had wanted to talk to us.

Mr. President, in 1980 George Bush was put on your ticket. It was a shotgun marriage. Is that one of the reasons why now you can't find the will to embrace him, to endorse his candidacy? Some people say if you don't speak out, in effect, it will be the kiss of death.

The President. No, I think most people would overlook then that the President is really the titular head of his party, whichever party he belongs to. And therefore, while it is a party choice that must be made as to who a nominee is -- I had to be this way when I was a Governor. I have to be this way as President. But I can only tell you that whichever individual the party chooses I will wholeheartedly support them as obviously the best choice for this office, having viewed the candidates of the other party. But I can say this: The Vice President, I think, has been the finest Vice President in my memory in this country. He has participated in all the major operations that -- I had that belief when I came here, and I'd had it when I was a Governor with a Lieutenant Governor -- that it isn't someone just sitting there waiting to see if you get up in the morning, whether they've got another job. He's an executive Vice President. He's a major part. He's one of only two of us that are chosen by all the people in this country for the jobs that we hold. And so, he understands that -- but I have to remain neutral until the decision is made by the party as to who their nominee will be.

Mr. President, Bernie's [Bernard Shaw, Cable News Network] question raises an interesting point. Vice President Bush has said a number of times that he gave you some counsel about the secret shipment of some of our best missiles to the Ayatollah and sending the Ayatollah a birthday cake and that whole thing. But he hasn't said what it was. Don't you feel -- or do you feel that the American people are entitled to know, given the fact that Vice President Bush wants to be President, what that advice was and will you tell us?

Thursday until this campaign got underway -- we have lunch together, just the two of us. And we discuss, as you can imagine, all the things that are going on and so forth. And he does not hesitate, when I ask, to give me his opinion on something. But here again, you've tempted me into another direction. Because again, that misunderstanding out of the Iran - contra so-called affair -- that missiles to the Ayatollah -- the people that contacted us from Iran -- the people we were dealing with -- if the Ayatollah found out, they'd be dead before nightfall. We weren't dealing at all with the Ayatollah. Now, I think he's as big a Satan as he thinks I am.

This came as a request from those individuals: that if we could do that, first of all, it would assure them that the people they were dealing with surreptitiously were speaking for the Government, had some standing here in our country. And also, if they could provide those to the military -- not to the revolutionary guard -- to the military, it would give them the prestige.

The thing that's been overlooked in all of the examinations was that when all of that was happening virtually every day you and others in the press were commenting on how long the Ayatollah was going to live. It sounded as if he wouldn't be around by the next week. And there was factionalism rising in Iran as to who then was going to take over. Well, this is what this operation was about. These people were an element that wanted to have the kind of government that we once were closely allied to in Iran. And this was why we started doing business with them.

Now, when they asked for that token shipment of arms to verify and so forth our credentials, we turned around and cited that we didn't go along with governments that supported terrorism. They made it pretty plain they didn't support terrorism either. And we then -- or I said, well, all right, let them prove their good faith if we do this in using whatever influence they have to see if they could get those terrorists to release our hostages.

Never at any time did we view this as trading weapons for hostages, because we weren't doing anything for the kidnapers. But we knew someone that evidently might have an ability to open a door, and they did get two of them out. And when the news broke that blew the whole thing over, we were expecting two more in the next 48 hours that are still hostages.

Let me just finish, and then I will -- but what you said about George. I don't think it'd be right for me to discuss what his position was on things. But there was a disagreement among our people that they -- not that I was trading arms for hostages, but that that, if it became known, what we were doing, it would be viewed as that. And those individuals were absolutely right, because everybody has viewed it since and misconstrued it that we were trading, as a ransom, hostages for arms.

The President. Well, I don't think we've done anything to contribute to its falling further. It isn't a case at where sometimes in the past when it was certainly overpriced that we have made efforts to balance it up. I've often wondered sometimes -- they keep talking about the government -- or the dollar falling, or is it maybe that some of those foreign currencies that were way below value have come up to where they properly should be. But it is fluctuating, and we're interested in stabilization. And I think that some of the things we've done are leading, and have led to, that. A sudden surge of cutting interest rates in some of our trading allies abroad did have the effect again of making the dollar fall, but that was their doing, not ours.

General Secretary Gorbachev will soon be in Washington for a new meeting with you. Do you feel that since the first Soviet-American meeting (between you and Mr. Gorbachev) in Geneva, the world has become a slightly safer place and that something has changed for the better in relations between our countries?

The President. The world has unquestionably become safer, and the improvement in U.S.-Soviet relations has been a contributing factor. Both sides are pursuing a policy of ever-increasing dialog. In the 2 years since General Secretary Gorbachev and I first met in Geneva, our governments have made important progress together on arms reductions, human rights issues, and bilateral exchanges. The world welcomes this.

Americans have also noted with great interest the efforts at reform underway in your country. We wish the people of the Soviet Union well in all efforts to improve the quality of their lives and to liberalize the Soviet system. This is primarily your internal concern, of course, but there is no question that it can have international significance, as well. It could contribute to an improved international climate and a relaxation of tensions. The American political system is truly open; we are naturally sympathetic to movement in the same direction elsewhere.

Mistrust and suspicion have built up over many years, and they have their basis in history and current realities. Forty years after Hitler's defeat, Europe remains divided by artificial and inhumane barriers. In other regions of the globe, we are worried about the continuing Soviet occupation of Afghanistan and your government's support for repressive regimes in Angola, Ethiopia, Nicaragua, Cambodia, and elsewhere -- regimes that are at war with their own people.

I take satisfaction from the fact that we have established a dialog that deals candidly with the entire range of issues that concern, and often divide, our two countries. We need to continue that dialog and strengthen it in every way we can. That is what our meeting in Washington is all about.

The Soviet-American agreement on the complete elimination of two classes of nuclear weapons -- medium-range missiles and operational, tactical missiles -- stems from your negotiations with General Secretary Gorbachev in Geneva and, to an even greater degree, in Reykjavik. In your opinion, what is the significance of this agreement, important in and of itself, for the process of disarmament?

The President. The INF treaty is significant because for the first time in history the major nuclear powers have agreed to reduce, not simply limit, the buildup of nuclear weapons. It eliminates an entire class of U.S. and Soviet intermediate-range nuclear weapons. This, of course, was the American proposal I put forward in 1981, the zero option.

INF treaty specifies the most stringent verification regime ever. No longer shall we rely only upon national technical means to monitor compliance, for the treaty gives both sides the right to onsite inspection, including short-notice inspection of sites where activity forbidden by the treaty might be suspected.

Both the United States and the U.S.S.R., moreover, will maintain inspectors on a continuous basis outside a relevant missile plant on each other's territory. This is a truly revolutionary concept and will increase confidence that the treaty is being complied with. Even today the United States has serious concerns about Soviet compliance with existing and earlier agreements, thus a new approach has been needed.

I hope the INF treaty will be a step toward more glasnost in Soviet military affairs. You should strive for broader disclosure to your own citizens of your military budgets, force structures, and weapons modernization programs. This could help to build confidence needed for more comprehensive arms reductions as well as better political relations. The INF treaty is a good omen, for it shows that through hard work and a realistic approach we can achieve positive results.

Can we hope that a limit to the arms race will not stop with an agreement for medium- and short-range missiles? In particular, one is reminded of your joint statement with General Secretary Gorbachev in Geneva about the inadmissibility of transferring the arms race into space. What solution do you propose to this problem?

The President. I have no intention of stopping with the INF treaty. In fact, the United States and the U.S.S.R. have agreed to try to seek the earliest possible agreement on reducing U.S. and Soviet strategic nuclear arms by 50 percent, as the U.S. has proposed. Our Foreign Ministers agreed on October 30th that the Washington summit would consider thoroughly the development of instructions to our Geneva negotiators on a future agreement for 50-percent reductions in strategic offensive weapons and, given this, another agreement for the observance of and nonwithdrawal from the ABM treaty for an agreed period. There have been intensive discussions on this over the last few weeks, and I am optimistic. I am hopeful General Secretary Gorbachev and I will make progress in Washington.

From the beginning of my administration, I placed the highest priority on achieving deep and equitable cuts in strategic offensive arms. To ensure that such an agreement genuinely enhances strategic stability, we have insisted that it reduce and limit the number of warheads on ballistic missiles. These weapons are particularly dangerous and destabilizing, because they can reach their targets in less than 30 minutes. We will also insist the treaty be effectively verifiable -- an especially complex task. I am encouraged by the unprecedented scope of the verification measures agreed to in the INF treaty, but a START agreement would, of course, be more far-reaching.

Deep reductions in offensive weapons would significantly help reduce the danger of nuclear attack, so would further advances in the development of strategic defenses. I know your government claims that my Strategic Defense Initiative is a destabilizing ``militarization of space,'' but this, frankly, is a gross misrepresentation. The world will be a safer place if both superpowers shift toward strategic defenses while radically reducing strategic offensive arsenals. Strategic defenses can intercept an attacker's missiles, but do not threaten people. They permit a military strategy that deters war by protecting people instead of targeting them. SDI is a scientific research and development program to explore whether new, advanced technologies might make effective defenses possible in the near future.

The whole world knows that the U.S.S.R. has pioneered the field of strategic defenses and has had a program to develop them long before my 1983 decision on SDI. In a recent interview on American television, General Secretary Gorbachev acknowledged that the Soviet Union is doing ``all that the United States is doing'' in this field. We estimate that over the past 10 years the Soviet Union has spent roughly as much of its military budget on strategic defense as it has on strategic offensive forces. Longstanding Soviet programs in this area include the world's most extensive air and civil defenses and the world's only active antiballistic missile system, deployed around Moscow and recently being modernized. Since both sides are determined to explore advanced strategic defenses, we propose that our two sides talk in practical terms about how we can make a transition jointly and safely to greater reliance on such defenses.

In addition to achieving large reductions in strategic nuclear forces, we should also move ahead to correct dangerous imbalances of conventional and chemical forces, where the U.S.S.R. enjoys large advantages. This will be a complex process, because allies are directly concerned, and because the military forces themselves are complicated. But I am happy to say that both sides express willingness to move forward.

One of the most dramatic and potentially explosive problems of our time is the enormous external debt of many developing countries. Many experts believe that this cannot possibly end well. In general, if one looks at the situation more broadly, without a solution to the problems of the developing world, there is not, nor can there be, genuine security for anyone.

The President. In recent decades, the developing world has been the scene of a more fundamental trend, namely, the flourishing of economies that have avoided the rigidities of centralized planning and given full scope to individual initiative and entrepreneurship. For instance, many of the developing economies of the Asia-Pacific region are booming, particularly in those nations where economic freedom provides people with the incentive to better their lives. And some African countries have recently experienced accelerated growth, particularly in agriculture, as a result of easing centralized restrictions.

Foreign borrowing in itself is not a problem. Countries need foreign and domestic capital to make the investments that will lead to economic growth and development. The United States and other successful industrialized countries have prospered in part because of the inflow of foreign capital to finance factories, mines, and other investments essential for long-term growth. Today some developing countries have difficulty servicing their debt, because this borrowed capital was used to increase consumption and finance capital flight rather than for investment.

United States remains committed to a cooperative solution to the debt problem. Such a solution involves a partnership among developed and developing nations, commercial banks, and international financial institutions. The United States has proposed a positive program built on the need to increase the level of economic activity in developing nations.

Lasting growth can only be achieved by allowing more scope at home for individual initiative and entrepreneurship. And the United States and our partners in the industrialized world are making a crucial contribution to these efforts by providing a growing market for the products of developing countries.

World War II, we have seen a remarkable trend toward interdependence among national economies. Combined with policy reforms to liberate the creative potential of individual men and women, policies that foster open competition and free trade can create a favorable environment for developed and developing nations to solve economic problems and to raise standards of living for their people.

We also recognize that the developing world needs special assistance to promote economic development. No country has been more generous than America in helping others. In 1987 alone, the U.S. Government has given about $9 billion in development assistance to developing countries and international financial institutions, such as the World Bank and the International Monetary Fund.

Mr. President, if we say that the most important international affairs topic for American public opinion is the upcoming meeting with General Secretary Gorbachev, then, judging by the American press, the number one domestic concern right now is the recent crash of the stock market, its consequences for Americans and for the economy of the country. Please explain to our readers what, in your opinion, is the cause of the crash? How serious is it?

The President. Let me begin by saying that the American economy is currently stronger and healthier than ever. We are experiencing the longest economic expansion since World War II. As we speak, the standard of living of the average American is among the highest in the world. Nearly two-thirds of American households own their own homes. Americans drive more than 160 million motor vehicles, more than 1\1/2\ cars per driver.

The overwhelming majority of Americans have private telephones and televisions which in most areas of the country can pick up dozens, and in some cases hundreds, of television stations. We are in the midst of a high-tech explosion with computer home shopping, compact disc stereo, and modular car telephones, to name a few -- all available to consumers. Mr. Gorbachev will be able to see the results of this sustained prosperity when he comes to Washington.

The stock market today is at roughly the same level it was throughout 1986, and at that time, it had never been higher. The continuing high level of stock and bond assets represents real wealth for millions of Americans. More than 70 percent of American households own interest-earning assets at financial institutions, and one-fifth own stocks and mutual funds. As a result, millions of ordinary people have a stake in the economic growth and prosperity of their country.

It is important to recognize the role that stock markets play in the global economy. Stock ownership entitles individuals to vote in selecting the management of a company and to share in the profits of the enterprise.

Institutions such as labor union pension funds also own and trade shares for the benefit of millions of workers. This system of open markets, built upon the principles of entrepreneurship and stock ownership, has resulted in average income levels in non-Communist developed countries some 60 percent higher per capita than that in East-bloc countries. And it is why per capita consumption in the United States is three times higher than that in the Soviet Union by the most conservative estimates.

It is the nature of markets to fluctuate, both up and down. But it is the sharing of both the risks and rewards in markets that provides the foundation for the creation of wealth and a higher standard of living. Through public stock markets, any individual can sell his idea and raise money to pursue it by starting his own company. Larger enterprises can raise needed capital only by convincing the marketplace of the economic value of their planned investments.

The fact that our economy has remained on a healthy growth path throughout the recent adjustment in stock markets is testimony to the strength of economics based on individual initiative and open competition.

Soviet-American relations depends on fulfilling certain demands concerning changes in our society. The correctness and the fairness of these questions is something that can be argued. Our question concerns something else: What, in your opinion, can and must the United States itself do for the improvement and development of relations between our countries?

The President. You are wrong to speak of American ``demands.'' Who can doubt the interest that the world community has in the changes taking place inside the Soviet Union? Moreover, the obligations of states are codified in international agreements, such as the Helsinki Final Act and the Universal Declaration of Human Rights. The possibility of reform and liberalization in your country is of interest to the world. We need to have a full understanding of these dynamics within your society.

Western World, and increasingly the outside world, has a well-developed and tested concept of democracy. Democracy means the rule of law, a system of checks and balances that limits the power of the state and protects the rights of individual citizens. It means regular elections contested by different parties presenting competing programs for the people's choice and mandate. It requires an independent judiciary that effectively protects due process of law and the inalienable rights to freedom of speech, conscience, press, assembly, and worship.

You ask what the United States can do to improve relations. First, let me say that all Americans join me in seeking improved relations. We know that our two systems, however different, must and can coexist. We can coexist as do two wrestlers in a ring if necessary, but we would much prefer to coexist as partners and as friends. We want, therefore, to expand the educational, cultural, and people-to-people exchanges that lead to broader cooperation between our two nations.

I can assure you that I and my successors, too, will continue to confront the problems in our relations both realistically and constructively. We shall maintain and build upon the engagement we have begun. The American people will remain as they have always been: peaceloving, generous, and friendly -- extending a warm welcome to visitors to our shores.

Total employment in November rose by 327,000, and the unemployment rate declined by .1 percent to 5.8 percent. Especially encouraging is that manufacturing employment rose by 69,000 jobs, with widespread gains in most industrial categories. The economic expansion continues into its 60th month, and the signs indicate that the expansion will continue much longer. The strong employment growth in November is one sign that confidence in the economy remains steadfast. This is especially encouraging in view of the recent stock market declines.

As the unemployment rate continues to improve, the new deficit reduction agreement keeps swiftly making its way through the legislative process. The Senate Finance Committee has reported out a revenue package that is in keeping with the budget agreement approved by the President. While we do have some reservations about some of the provisions, we commend Senator Lloyd Bentsen and his committee for their quick and dedicated action on this important piece of the economic puzzle.

First, it does not specifically include the $2.6 billion in discretionary spending cuts called for by the agreement between the President and congressional leadership. Second, it does not continue the important aid to the Nicaraguan resistance. And it contains various extraneous provisions that do not belong.

The administration is continuing to work closely with the appropriate committees to ensure a responsible budget package, one that maintains the integrity of the deficit reduction package. We urge the leadership to quickly and fully implement all aspects of the budget agreement.

President is pleased that the objectionable provisions of this bill pertaining to arms control have been deleted or modified in an acceptable form. We hope that partisan or unilateral action can be avoided in this area in the future and that the Congress will work cooperatively with the executive branch as we continue high-level discussions with the Soviet Union. It is imperative that our government speak with one voice in order to protect and advance U.S. interests in these negotiations. The authorization bill allows $3.9 billion for the Strategic Defense Initiative, up slightly from $3.6 billion in 1987. This funding level will permit a strong technology program, however there will be delays in important experiments in both space- and ground-based technologies.

We are also pleased to note that yesterday the Senate Appropriations Committee showed bipartisan support for the Strategic Defense Initiative by approving the same $3.9 billion level and by passing language unanimously that supports the program fully. Their bill also contains no harmful arms control provisions.

The President. It's an honor to be here in this place dedicated to our history with all of you who do so much to preserve the record of that history and to make it come alive for your fellow Americans. Special greetings to the Wilson family.

But we've come together today to witness an important event in the history of our National Archives: the swearing-in of Don W. Wilson as the first Archivist selected to manage the National Archives as an independent agency. Mr. Wilson is more than qualified, as you've already heard, for this high post, both by academic background and years of experience. He holds a doctorate in American history. He served as Historian and Deputy Director of the Eisenhower Library in Abilene. He has held the post of associate director of the State Historical Society of Wisconsin. And since 1981, Mr. Wilson has served as the Director of the Gerald Ford Library and Museum in Grand Rapids.

Perhaps most important, Mr. Wilson has a vision -- a vision of what the National Archives can become. He has said that he would like the Archives to grow into a national cultural resource as treasured as the Smithsonian and the Library of Congress. And he has stated -- and here I quote: ``Traditionally, our foremost concern in the National Archives has been the historical researcher. While this will, and should, remain undisturbed as a basic mission, many of us recognize that the Archives could serve a larger audience -- a history-minded public excited about their country's past.'' With that in mind and conscious of the documents that are with us in this room, I wonder whether you would join me in considering three moments in the history of our nation.

First, it is 1787. Fifty-five delegates have gathered in Philadelphia from the newly independent and united States, charged with revising the weak Articles of Confederation. The men inside Independence Hall are worried. Just a few years before, many had risked property and life itself in signing the Declaration of Independence -- that very document. And now they faced a sobering question: Had they and their countrymen overreached? Could this raw, new Republic survive? Or would it be torn apart by disputes between the States, lack of finance, pressure from the great powers of Europe? The delegates faced those challenges and surmounted them, producing the Constitution of the United States -- that very document -- now two centuries old, in reverence and honor.

Now it is February 1861. Abraham Lincoln has been making his way slowly eastward from Springfield to Washington to take the oath of office as President. And like the men of 1787, Lincoln faced a question. Once again, that question: Could the Republic survive? Before dawn on the 22d, he spoke to a crowd that had gathered to catch a glimpse of him. He had often asked himself, Mr. Lincoln said, what great principle or idea it was that had held the Union together for so long.

Well, the final moment that I'd like you to join me in considering requires no imagining. It is now, the present. Like the men of 1787, like Lincoln in 1861, indeed, like every generation of Americans throughout our history, we, too, face the question: Will this nation, founded in freedom, flourish? Will it continue to extend the hope of liberty to all the world?

It's my belief that during these past 7 years we've done much to restore our nation -- restore our economy and defenses, restore our basic values, even restore a sense of our own fundamental goodness as a people. Yes, I feel certain that despite the challenges that beset us, this nation of freedom will flourish.

But if we're to succeed in the future, we must learn our own past and learn to look at these and other documents and hear the echoes and sense the greatness and draw strength. For to study American history is, in a sense, to study free will. It is to see that all our greatness has been built up by specific acts of choice and determination, and it is to see how very fragile our nation is, how very quickly so much that we cherish could be lost.

All this is really only a way of elaborating what I suggested at the beginning: that what you at the National Archives do is of tremendous significance and that Don Wilson's vision for the Archives is a vision of national importance. And to all of you, my thanks. And to Don Wilson, congratulations.

The Archivist. President Reagan, distinguished guests, colleagues, first let me say that I am both excited and very honored to assume this office as Archivist of the United States. I thank each and every one of you for being here today to share with me in this important occasion. I believe it pays tribute to the National Archives and honors it as an institution. A special thank you to President Reagan, to Dick Cheney, to David Matthews, and Bob Warner, for taking time out of their very busy schedules to participate in this ceremony.

I give a very few brief remarks on a couple of goals that I have, there are two other people I want to publicly recognize today. The first is Dr. Frank Burke, whose able leadership as Acting Archivist over the last 32 months has kept the institution growing and has provided many strong foundations upon which we can continue to build. Thank you, Frank. The second person I want to recognize is my wife, Patsy, whose personal strength and confidence in my abilities have often times exceeded my own over the past few years.

Archives, I believe, provides an unparalleled opportunity to expand the agency's impact. To lead the National Archives at this important juncture is a personal and professional challenge which I accept enthusiastically. First and foremost, I believe we must remember that the National Archives is more than this beautiful building gracing Pennsylvania Avenue midway between the Capitol and the White House. It is truly a national agency, with over 3,000 dedicated employees in more than 30 locations in 14 States. It has the potential to influence every area of archives and manuscripts in the United States and most of the world.

I believe the time has come for this important agency to serve a broader audience and develop an expanded mission. The bicentennial celebration of the birth of our government and our forms of government and their institutions provide a unique opportunity for the National Archives to begin to grow in this area.

Another future opportunity for the National Archives leadership lies in formulating a national archival collecting policy. It is, it seems to me, time for the Nation's largest and most significant archives to move beyond concern for its own records and play a leadership role in determining a policy for documenting our national heritage. I am convinced that the National Archives can articulate the national interest and identification preservation in making available the archival records at all levels of government. I think that the National Archives can energize. It can coordinate, promote, and consult without centralizing or seeking to control. Generations of specialized researchers and ordinary citizens will benefit if we are now able to establish a sound and thoughtful national records policy.

I believe all agree that the basic mission of the National Archives is to preserve for posterity our nation's most important documents. As Archivist of the United States, I intend to fulfill that mission by providing the agency with aggressive, creative, professional leadership, to work to give the staff of the National Archives the resources needed to carry out the responsibilities given us. I believe that innovation and the ability to adapt to present-day needs must be among the agency's highest priorities.

The tasks facing us are both enormous and challenging. The National Archives today requires leadership, ingenuity, and a long-term professional commitment to recordskeeping and public service. Now is a time when there is a greater awareness than ever before of the needs of the National Archives.

Today we have more concerted, collective support and appreciation of its mission by users, by constituent groups, by the White House, and by Congress, than any time in its history. That makes now a time of opportunity as well as great obligation. As seventh Archivist of the United States, I am prepared to fully commit myself to these challenges and these responsibilities. Thank you.

Seeing all of you here today is a particular pleasure for me, because together you speak for some of the causes that are closest to my heart, some of the most important reasons our administration came to Washington in the first place.

Some of you are law enforcement officers. Some are civilians who work for victims' rights. Some are fighting obscenity and the unspeakable evil of child pornography. Others are working to prevent drug abuse. In the past 4 or 5 months, I've heard a lot of talk -- much of it, to put it most kindly, inaccurate -- about our social agenda, particularly as it applies to the courts. Well, if anyone wants to know our true agenda, there's no need to go any farther than this room, because your agenda is our agenda.

I don't need to tell anyone here the sad, often tragic story of years of judicial solicitation for every conceivable right of criminals and neglect for the victims of crime, of playing fast and loose with first amendment rights in a way that gave too many pornographers free rein, of fanciful constitutional arguments used to throw out long and hard police work, and of the price our nation has paid for all of this.

One way, for example, that we've paid that price has been in the wider and wider availability of pornography. The sale of pornography was once said to be victimless. But common sense should have told us all along that pornography has many victims -- among them, children. I read a statistic recently that, in a single day, one dial-a-porn company has received 800,000 calls. I'm told that the great proportion of those calls are thought to have been made by children. There's nothing victimless about those children. The time has come for this to stop.

But incredible as it may seem, there are well-meaning people who will oppose it. The most extreme say that the first amendment protects child pornographers as they publish and distribute their products. However well-intended, that kind of extremism should not be allowed to prevail. It's not what the Constitution requires.

I hope I can count on your support on something else as well, and it's the principal reason that we're here today. I have nominated a judge to the Supreme Court who is realistic about pornography and crime in general: Judge Anthony M.

Realism runs through all his work on the bench. He argued in one dissent, for example, for a ``good faith'' exception to the exclusionary rule, and saw his position ultimately adopted by the Supreme Court. That was in a drug case, by the way.

Another example of his realism -- last year Judge Kennedy upheld a lower court when it imposed the maximum sentence allowed by law against a child pornographer. His opinion focused on the severe psychological harm victims of child pornography endure and the great likelihood that child pornographers will, when released, commit the same crimes again. We need more realism like that on the Nation's highest court. We need Judge Kennedy on our highest court.

But let me add another thought here. Being tough on crime doesn't require tortured constitutional reasoning. The Constitution itself is tough on crime; it was intended to ``establish justice'' and ``ensure domestic tranquility.'' It provides a system for discovering the truth, releasing the innocent, and punishing the guilty, not for subjecting the police to an endless guessing game about the rules.

Not long ago, I heard about a case that involved a particularly horrible murder and that illustrates just what's too often wrong in our courts. A man threw his girlfriend's 10-month-old child down the trash chute of her 11-story apartment building. He was arrested, tried, and convicted. But the conviction was thrown out on appeal. Citing heavily from U.S. Supreme Court rulings, the State appeals court decided that the man had been denied equal justice under the law, because he was not taken before a court commissioner within 24 hours of arrest.

No, he was taken 24 hours and 12 minutes after arrest. So, he's out walking the streets now. We've had enough decisions like that. The Supreme Court sets the tone for all courts in our land, as well as establishing precedence in the Federal judiciary. I hope we'll have your active support as the Senate deliberates on confirming Judge Anthony Kennedy to the Supreme Court.

I would like to thank all of the law enforcement agencies involved, including the Federal Bureau of Prisons, the FBI, the Immigration and Naturalization Service, the U.S. Marshals Service, the Community Relations Service, and the State and local law enforcement agencies in Georgia and Louisiana. The patience and professionalism demonstrated by all of the agencies involved have been rewarded.

The President. The nations of East Asia are becoming increasingly prosperous and politically stable. This is in our interest as well as theirs, and our aim is to work with the region's nations as partners in promoting prosperity and stability. All partnerships require a balancing of benefits and burdens. For example, U.S. diplomatic efforts and military presence contribute directly to the region's peace and stability, which in turn foster economic prosperity. We look to our East Asian allies to share with us this mutually beneficial burden according to their means. Of course, we will maintain our commitments to defend their security.

Asia's prosperity depends significantly on continuing the liberal world trading system we and our trading partners have enjoyed for the last 20 years, but there are threats appearing to this system. Some of our major trading partners still maintain restrictive trade policies, and there is rising protectionist sentiment in the United States. My efforts to resist this protectionist pressure will succeed only so long as our major trading partners take some steps themselves toward structural adjustment of their economies. These steps include strengthening domestic demand, dismantling trade barriers that discourage U.S. exports, and adopting exchange rate policies that reflect their economies' underlying strength.

I am confident your readers recognize that working together to keep the peace and promote everyone's prosperity benefits all of us. The United States has been active on the East Asian scene for more than 100 years, and we look forward to continuing our productive cooperation with friends and allies in the region.

The newly appointed Prime Minister of Japan, Mr. Noboru Takeshita, plans to come to Washington in January 1988 to have his first summit meeting with you. In view of the ongoing serious bilateral problems confronting our two nations, what would you expect out of that January meeting? And what kind of feeling do you have toward a new Japanese Prime Minister who has been almost unknown to the Western World?

The President. First, I am very pleased that Prime Minister Takeshita has accepted my invitation to visit Washington. I look forward to seeing him again, this time in his new capacity. I recall that we met in January 1986, when he was visiting the United States to receive an honorary doctorate from Columbia University, and we met again at the Tokyo Economic Summit, when Mr. Takeshita was Finance Minister.

To answer your second question first, I would like to point out that people who are ``almost unknown to the Western World'' do not normally meet with Western heads of state and receive honorary degrees from leading Western universities.

I have known the Prime Minister for some time now, and I look forward to getting to know him better in his new position. I think that what we can all expect to come out of the January meeting is a reaffirmation of the importance of U.S.-Japan relations, not only to our two countries but to the world, and a renewed commitment to pursue our many common interests and tackle our bilateral problems in the spirit of cooperation.

You have said that this INF agreement and the progress made towards a strategic arms reduction treaty would not have been possible without the Strategic Defense Initiative. Do you also think it would have been possible without the change in the Soviet leadership? Realistically, what are the chances of reaching an agreement on strategic nuclear forces -- reducing them by 50 percent by next spring?

We have made considerable progress toward agreement on our proposal to reduce U.S. and Soviet strategic nuclear arsenals by 50 percent. We believe such an agreement can be concluded next year if the Soviets apply themselves with the same seriousness as the United States and if they abandon their effort to hold it hostage to crippling restrictions on our Strategic Defense Initiative.

President Aquino and the government she heads. We are unalterably opposed to any attempts to destabilize her government. As a matter of law, the United States must cut off foreign assistance to any country whose duly elected leader is overthrown by a military coup. That said, I see no need to speculate on what would happen if there is a coup in Manila.

At the forthcoming review of the military bases agreement with the Philippines, Manila is certain to ask for a much larger compensation than currently allowed. In view of the shrinking foreign aid budget, how would you accommodate such a request?

The President. The forthcoming review of the military bases agreement will offer us the chance to go over security as well as economic aspects of the agreement. Both sides are well aware of the severe pressures on the U.S. foreign assistance budget. Nevertheless, I am confident that in the review, as well as in the renegotiation which will follow the review and address the post-1991 period, we can work out arrangements which will be in our two countries' mutual interests.

Forces' strength in Japan and South Korea as retaliation for their refusal to open their markets more to exports from the United States and elsewhere. Do you believe this would be an appropriate response to East Asian protectionism if other means of persuasion fail?

The President. Successive administrations have maintained our military presence in Japan and Korea, because our mutual security interests are served by keeping a credible deterrent against aggression in northeast Asia. It is important to keep security interests in mind and separate from detailed trade concerns.

Thus it would not be in our national interest to reduce our military strength in Japan or South Korea for any such reason, including as retaliation for difficulties in opening markets in those countries. We will, of course, continue to seek further opening of markets in Japan and South Korea. After all, open markets are also in our mutual interest -- they are necessary to preserve the world's free trade system -- and are a pillar of our strength.

Pacific region has waxed and waned through history. Following a period of neglect under General Secretary Brezhnev and his immediate successors, the Soviets apparently have decided again to pay attention to this important area, one in which the United States has been actively engaged for more than 100 years.

Unlike the United States, however, which has extensive trade, investment, cultural, political, and military links with almost all the countries of the Pacific, the Soviets need to create reasons to become involved. In the absence of solid relationships in most of the region, it is perhaps understandable that the Soviets have to fall back on high-sounding rhetoric and vague generalities, but that kind of thing does not meet the concrete and pressing needs of the region.

United States and most Asian nations are firmly in agreement about what needs to be done on a large number of real issues, like getting Soviet troops out of Afghanistan, stopping Soviet support for the Vietnamese occupation of Cambodia, stopping the Soviet buildup of military facilities at Cam Ranh Bay, encouraging North Korea to talk sensibly to the South Koreans to reduce tensions on the peninsula, resolving the northern territories dispute with Japan, and reducing the military threat to China.

Soviets already know that they can do a great deal for peace and stability in Asia by resolving these important, tangible problems, and we take almost every opportunity to remind them of that. Moreover, the United States is working hand in glove with almost every country in Asia and the Pacific on real world issues, like economic development, collective security, the almost universal longing for greater democracy, the growth of trade in free market conditions, and humanitarian issues. We think that real contributions to human welfare beat lofty phrases every time.

The President. A world free of nuclear weapons would be a much less frightened world, and I think that nothing is more important than working to make that goal a reality. But achieving that goal safely demands a massive amount of work which cannot be short-circuited.

Nuclear free zone treaties are at their best when they provide a bulwark against nuclear proliferation, as might be the case in South Asia or Latin America, for example. Where that is not the case, however -- and I think that the South Pacific is not such a case -- we have to be a little careful about encouraging growth of the notion that writing a treaty that would wall off a portion of the world from nuclear weapons somehow makes a contribution to world peace. It might do exactly the opposite.

Since the Soviet Union exploded its first nuclear weapon in 1949, the world has been saved from nuclear warfare and, indeed, from major conventional aggression by the credible threat of the Western nuclear powers to use all means necessary to defend themselves against aggression. This is how deterrence works.

Anything that may weaken deterrence does a disservice to the cause of world peace, because it is on deterrence that world peace since the start of the nuclear age has been based. The spread of nuclear free zones can make the job of maintaining deterrence much harder.

In regard to the resolution that has passed the House of Representatives, if it becomes a ``sense of the Congress'' resolution, of course we will give it careful consideration when it arrives here. From what I have said about nuclear free zones in general, however, it should be apparent that our reconsideration of the South Pacific Nuclear Free Zone issue is unlikely, in current circumstances, to produce a change of our policy.

The President. Korea is about to hold its first direct Presidential elections in well over a decade. The campaign is being contested vigorously. This is a sign, I think, of a new, more open political system. Koreans have shown they are a can-do people -- look at their economic achievement. I believe they will be equally successful in their efforts at democratic political development.

As for the Olympics, the Koreans are working hard to make the games a success. I am sure they will be. We hope that all the nations of the world will attend and make the games the international celebration they should be.

In a moment I'd like to discuss the coming summit meeting between myself and General Secretary Gorbachev. But first, let me tell you about a pressing domestic matter: the recent budget agreement between our administration and congressional leaders that will soon go before the full Congress for a vote.

The agreement will cut the Federal deficit by some $76 billion over the next 2 years and will put a cap on spending for fiscal year 1989. That's a considerable achievement, and one that reassures the financial markets about the determination and willingness of your leaders here in Washington to get the budget process back under control.

It's important to keep in mind that this agreement preserves our national security and protects vital domestic programs, such as air safety. But perhaps the best aspect of the entire budget agreement is what it doesn't do. You see, it doesn't impose any new across-the-board taxes, and that means it doesn't touch marginal income tax rates, the very heart and soul of economic incentives. So, our tax reforms of 1981 and 1986 will remain in effect, and your income tax rates will stay low -- and in some cases, drop even lower with the beginning of the new year.

After all, it was in 1982, after our administration's first tax rate cuts had gone into effect that today's economic expansion began. The current budget agreement will protect your low tax rates and keep our economy growing strong.

Let me turn now to the summit meeting. The agenda for talks between myself and Mr. Gorbachev will be determined by the four-part agenda for United States-Soviet relations that our administration has always insisted on: human rights; bilateral relations, in particular, people-to-people contacts; regional conflicts; and arms reductions. I've spoken of this four-part agenda before, but it seems to me that, especially now, it needs to be restated.

On human rights, yes, we've seen the Soviet Union release some political prisoners, but thousands more remain in prison. And political, religious, and economic oppression remains a solemn concern of the United States. So, I will raise human rights forcefully during our meetings. And it's one of my deepest hopes that during this, his first visit to America, Mr. Gorbachev will have an opportunity to sense something of the dignity and power of human liberty.

People-to-people contacts between our two countries have already been expanded, but I will ask Mr. Gorbachev: Why not more? Why should the people of America and the Soviet Union not travel as freely to each others' countries as do, for example, the people of America and Western Europe?

On regional conflicts, the peoples of Nicaragua, Afghanistan, Angola, and Cambodia are entitled to free, independent, and democratically chosen governments. And I will make it unmistakably clear that we view the freedom and independence of Nicaragua -- a country on our very own continent -- as vital to our own national security. Regarding Afghanistan, the Soviets assure us of their intention to get out. Well, we'll ask them to set a date certain for their withdrawal and talk to the freedom fighters. And I will assure Mr.

On arms reductions, Mr. Gorbachev and I will be able to celebrate a joint achievement: the signing of a treaty completely eliminating an entire class of American and Soviet intermediate-range nuclear missiles. You'll be hearing much about the details of this treaty in coming days. For now, permit me to say only that it represents a good bargain, one that completely meets the longstanding goals of the United States and our allies, and advances the interests of peace.

And this brings me to the final thought I'd like to share. Yes, deep, fundamental differences separate us from the Soviets, differences that center upon our own belief in God and human freedom, differences that we cannot compromise. Yet even as we Americans strive to spread freedom through the world, we must also recognize our obligation to ensure the peace, in particular, to search for areas where America and the Soviet Union can act together to reduce the risk of war. This summit meeting and treaty represent just that: steps taken together to ensure the peace.

This year more than 450 million American passengers will use aircraft, the world's fastest and safest transportation. In the 84 years since the Wright Brothers' first flight, American aviation, in cooperation with the Federal government, has continued to improve the safety and the efficiency of air travel. Thanks to both industry and the Federal Aviation Administration, this effort goes on today.

Wright Brothers Day we recall and revere not only the ability and the inventiveness of Wilbur and Orville Wright but also the unshakable conviction that led them into the skies and into history's pantheon of explorers, discoverers, and benefactors of mankind.

Witness Whereof, I have hereunto set my hand this fifth day of December, in the year of our Lord nineteen hundred and eighty-seven, and of the Independence of the United States of America the two hundred and twelfth.

The President. And in less than 24 hours, I'll be welcoming General Secretary Gorbachev. With our earlier meeting, we will pursue a broad range of issues. The highlights of the summit will be the signing, I think, of the INF treaty. I've always said that I'd rather have no treaty than one that doesn't add to our security and that of our allies, and the INF treaty meets that test. It's an accomplishment of the United States and our allies. And for the first time, we will reduce nuclear weapons rather than just limit their building. By having global limits, we'll make Asia as well as Europe more secure. We've done this without weakening the other elements of our defensive posture in Europe, and we'll have the toughest verification provisions of any treaty on the books.

It's only because I know that I can get the candid views of America's military leaders that I can have confidence in the wisdom of going forward with this agreement. Our regular meetings to discuss our national security have been invaluable to me. I remember we talked about the issue of European security at our last meeting, when we were joined by General Galvin, the NATO Supreme Allied Commander; and I am looking forward to continuing that discussion. What I get from such discussions is that our security and Europe's remain firmly linked, and we're going to keep it that way.

In addition to signing a treaty that will eliminate an entire class of offensive nuclear missiles, I want to use the summit to move forward in other areas. I want a START agreement, but only if it's a good one -- one we can verify and which enhances our security. At the same time, I want to set the stage for one day deploying effective defenses in a manner that will strengthen our strategic stability. Admiral Crowe has given me your thoughts on how to move toward these goals in several recent meetings.

The purpose of this provision is to preclude potential litigation regarding the applicability of the Sentencing Reform Act to offenses that occurred before the act's effective date of November 1, 1987. Consistent with past law on the subject, I understand section 2 of S. 1822 to mean that the Sentencing Reform Act applies to offenses completed after it took effect.

The bill modifies, in section 3, the standard for imposing a sentence that departs from the applicable sentencing guidelines. The Sentencing Reform Act as originally enacted requires the court to impose a sentence within the applicable guideline range ``unless the court finds that an aggravating or mitigating circumstance exists that was not adequately taken into consideration by the Sentencing Commission in formulating the guidelines and that should result in a sentence different from that described.'' The amendment authorizes the court to depart from the guidelines if there exists such a circumstance ``of a kind or to a degree'' not adequately taken into consideration by the Commission. I understand this amendment merely to clarify the intent behind the past standard for sentencing outside the applicable sentencing guidelines and not to expand the extremely limited basis for such sentencing. Any other construction would undermine the guidelines and the purpose of the underlying statute of reducing unwarranted sentencing disparity. A narrow reading of the departure standard is vital to the proper implementation of the Sentencing Reform Act.

The sacrifices of our military personnel at Pearl Harbor became the prelude to those our brave fighting forces were to endure around the globe for the next three and one-half years. When the terrible conflict ceased and the peace was won, America's freedom remained intact and we had taken on a crucial role as the leader of the world's democracies and bulwark of international peace.

December 7, America remembers much and resolves much. We remember Pearl Harbor's dead and wounded and its courageous survivors who fought that day and many other days as well. We remember too one of history's clearest lessons, that weakness and unpreparedness do not build peace but invite aggression. We remember that our freedom, purchased at so dear a price, can be taken from us. And we resolve that that shall never be. We resolve that our strength, our vigilance, and our devotion will forever keep America the land of the free and the home of the brave. We resolve that we will keep faith with those we have loved and lost. And we resolve that, always, we will remember Pearl Harbor.

Witness Whereof, I have hereunto set my hand this seventh day of December, in the year of our Lord nineteen hundred and eighty-seven, and of the Independence of the United States of America the two hundred and twelfth.

My fellow citizens, the 1987 Pageant of Peace has a special significance this year. The lighting of the National Christmas Tree with its Star of Peace atop could not come at a more symbolic moment. Two hours ago, General Secretary Gorbachev's plane touched down on American soil. I invited him to come and discuss ways in which we can reduce the tensions between our two countries. He and I will meet in hopes of promoting peace for our peoples and all the people of the Earth.

Peace on Earth, good will toward men -- I cannot think of a better spirit in which to begin the meetings of the next several days. As a small reminder of that spirit, the Star of Peace atop the National Christmas Tree will be lit day and night during the time our Soviet guests are here. And as we look out from the White House during our discussions, let the star remind us why we've gathered and what we seek.

House in these last 7 years. And today marks a visit that is perhaps more momentous than many which have preceded it, because it represents a coming together not of allies but of adversaries. And yet I think you'll find during your stay that the American people believe that a stranger is a friend they have yet to meet and that there is still a wellspring of good will here.

I know that many of our citizens have written to you and Mrs. Gorbachev and have even sent to you the keys to their homes. That honest gesture certainly reflects the feelings of many Americans toward you and Mrs. Gorbachev and toward your people. I have often felt that our peoples should have been better friends long ago.

But let us have the courage to recognize that there are weighty differences between our governments and systems, differences that will not go away by wishful thinking or expressions of good will no matter how sincerely delivered. This uncomfortable reality need not be reason for pessimism, however; it should provide us with a challenge, an opportunity to move from confrontation toward cooperation.

General Secretary, there is a saying in your country that a poor peace is better than a good quarrel. Well, it's up to us, with hard work, commitment, and a heavy dose of realism, to change the poor peace that has existed between our countries and make it into a good one. Today we will take a giant step in that direction by signing an historic treaty that will rid the world of an entire class of U.S. and Soviet nuclear weapons. Mr. Gorbachev: mir na nas smotrit, the world is watching, and we've got something to show them. And over the next few days, it is my hope that progress will be made toward achieving another agreement that will lead to the cutting in half of our strategic nuclear arsenals.

Well, during the Second World War, Soviet General -- later Marshal -- Chuikov, a frontline commander, liked to tell the story of a soldier who said he had captured a bear. And he was asked to bring it along.

Secretary Gorbachev, like the soldier in Marshal Chuikov's story, our peoples for too long have been both the masters and the captives of a deadly arms race. This situation is not preordained and not part of some inevitable course of history. We make history. Changing its direction is within our power. However, such change is not easy and can be accomplished only when leaders of both sides have no illusions, talk with candor, and meet differences head on. Such, I hope, will be the spirit of our upcoming meetings.

On the table will be not only arms reduction but also human rights issues about which the American people and their government are deeply committed. These are fundamental issues of political morality that touch on the most basic of human concerns. I would hope we will also candidly discuss regional conflicts. The parties to these conflicts should negotiate solutions that restore the peace and advance the rights and freedom of the peoples involved. We cannot afford to view these as far away brushfires. Even small flames risk larger conflagrations and undermine positive developments between our two countries.

Let us also consider ways to expand the contact between our own citizens. The Soviet and American peoples can and should know more about each other. The barriers between them should be taken down, restrictions on travel and communications lifted, personal relations between our young people fostered.

Gorbachev, I hope that during your short time here you'll see that we Americans are a dynamic and energetic lot, people of enterprise and an abiding love of freedom. We believe in God and care about others who are in need. We are proud and independent. Like the peoples of your country, we believe our country should be strong, but we desire peace. Have no doubt about that. The longing for peace runs deep here, second only to our fervency for the preservation of our liberty. Americans believe people should be able to disagree and still respect one another, still live in peace with one another. That is the democratic spirit that I will bring to our meetings.

History has charged the governments of our countries and the two of us, Mr. President, with a solemn duty to justify the hopes of Americans and Soviet people and of people the world over to undo the logic of the arms race by working together in good faith. In the world's development, much will depend upon the choice that we are to make, upon what is to triumph: fears and prejudice inherited from the cold war and leading to confrontation or common sense which calls for action to ensure the survival of civilization. We in the Soviet Union have made our choice.

We realize that we are divided not only by the oceans but also by profound historical, ideological, socioeconomic, and cultural differences. But the wisdom of politics today lies in not using those differences as a pretext for confrontation, enmity, and the arms race.

We are beginning our visit 46 years after the days when the United States entered the Second World War, and it was in those same days in 1941 that the rout of Nazi forces began near Moscow. That is symbolic.

Those days mark the beginning of our common path to victory over the forces of evil in a war which we fought as allies. History is thus reminding us both of our opportunities and of our responsibility. Indeed, the very fact that we are about to sign a treaty eliminating Soviet and U.S. intermediate- and shorter-range nuclear missiles, which are now going to be scrapped, shows that at crucial phases in history our two nations are capable of shouldering their high responsibility.

This will, of course, be the first step down the road leading to a nuclear-free world, whose construction you, Mr. President, and I discussed at Reykjavik. Yet it is a great step into the future, the future to which our two peoples and the peoples of all countries aspire. I have come to Washington with the intention of advancing the next and more important goal of reaching agreement to reduce by half strategic offensive arms in the context of a firm guarantee of strategic stability. We are also looking forward to a most serious and frank dialog on other issues of Soviet-American relations.

Soviet foreign policy today is most intimately linked with perestroika, the domestic restructuring of Soviet society. The Soviet people have boldly taken the path of radical reform and development in all spheres -- economic, social, political, and intellectual. Democratization and glasnost are the decisive prerequisites for the success of those reforms. They also provide the guarantee that we shall go a long way and that the course we are pursuing is irreversible. Such is the will of our people. In charting these ambitious plans, the Soviet people have a vital stake in preserving and strengthening peace everywhere on Earth.

President, ladies and gentlemen, may I express the hope that the Soviet Union and the United States, working together with all nations, will take their place in the history of the outgoing 20th century not only as allies in the battle against nazism but also as nations that have paved mankind's way to a safe world, free from the threat of nuclear annihilation.

The General Secretary. Well, I don't think that policies are made with surprises. Responsible policies, particularly by countries such as the Soviet Union and the United States, have to be well thought over. And on the basis of that, responsible decisions have to be taken.

The General Secretary. Well, I have heard some new words in the President's welcoming remarks, and I welcome this fact. And of course, there are political declarations, political statements, and then there is reality, real policies. And you might have noted that there is a great similarity in the outlook of things on the world in our remarks today, myself and the President. So, how to implement what we declared in our speeches? This is what we are getting to discuss with the President. We have five meetings planned with the President.

The President. Thank you all very much. Welcome to the White House. This ceremony and the treaty we're signing today are both excellent examples of the rewards of patience. It was over 6 years ago, November 18, 1981, that I first proposed what would come to be called the zero option. It was a simple proposal -- one might say, disarmingly simple. [Laughter] Unlike treaties in the past, it didn't simply codify the status quo or a new arms buildup; it didn't simply talk of controlling an arms race.

For the first time in history, the language of ``arms control'' was replaced by ``arms reduction'' -- in this case, the complete elimination of an entire class of U.S. and Soviet nuclear missiles. Of course, this required a dramatic shift in thinking, and it took conventional wisdom some time to catch up. Reaction, to say the least, was mixed. To some the zero option was impossibly visionary and unrealistic; to others merely a propaganda ploy. Well, with patience, determination, and commitment, we've made this impossible vision a reality.

Secretary Gorbachev, I'm sure you're familiar with Ivan Krylov's famous tale about the swan, the crawfish, and the pike. It seems that once upon a time these three were trying to move a wagonload together. They hitched and harnessed themselves to the wagon. It wasn't very heavy, but no matter how hard they worked, the wagon just wouldn't move. You see, the swan was flying upward; the crawfish kept crawling backward; the pike kept making for the water. The end result was that they got nowhere, and the wagon is still there to this day.

The numbers alone demonstrate the value of this agreement. On the Soviet side, over 1,500 deployed warheads will be removed, and all ground-launched intermediate-range missiles, including the SS - 20's, will be destroyed. On our side, our entire complement of Pershing II and ground-launched cruise missiles, with some 400 deployed warheads, will all be destroyed. Additional backup missiles on both sides will also be destroyed.

But the importance of this treaty transcends numbers. We have listened to the wisdom in an old Russian maxim. And I'm sure you're familiar with it, Mr. General Secretary, though my pronunciation may give you difficulty. The maxim is: Dovorey no provorey -- trust, but verify.

This agreement contains the most stringent verification regime in history, including provisions for inspection teams actually residing in each other's territory and several other forms of onsite inspection, as well. This treaty protects the interests of America's friends and allies.

We can only hope that this historymaking agreement will not be an end in itself but the beginning of a working relationship that will enable us to tackle the other urgent issues before us: strategic offensive nuclear weapons, the balance of conventional forces in Europe, the destructive and tragic regional conflicts that beset so many parts of our globe, and respect for the human and natural rights God has granted to all men.

The General Secretary. Mr. President, ladies and gentlemen, comrades, succeeding generations will hand down their verdict on the importance of the event which we are about to witness. But I will venture to say that what we are going to do, the signing of the first-ever agreement eliminating nuclear weapons, has a universal significance for mankind, both from the standpoint of world politics and from the standpoint of humanism.

For everyone, and above all, for our two great powers, the treaty whose text is on this table offers a big chance at last to get onto the road leading away from the threat of catastrophe. It is our duty to take full advantage of that chance and move together toward a nuclear-free world, which holds out for our children and grandchildren and for their children and grandchildren the promise of a fulfilling and happy life without fear and without a senseless waste of resources on weapons of destruction.

December 8, 1987, become a date that will be inscribed in the history books, a date that will mark the watershed separating the era of a mounting risk of nuclear war from the era of a demilitarization of human life.

In accordance with the provisions of this Treaty which includes the Memorandum of Understanding and Protocols which form an integral part thereof, each Party shall eliminate its intermediate-range and shorter-range missiles, not have such systems thereafter, and carry out the other obligations set forth in this Treaty.

The term ``ballistic missile'' means a missile that has a ballistic trajectory over most of its flight path. The term ``ground-launched ballistic missile (GLBM)'' means a ground-launched ballistic missile that is a weapon-delivery vehicle.

The term ``cruise missile'' means an unmanned, self-propelled vehicle that sustains flight through the use of aerodynamic lift over most of its flight path. The term ``ground-launched cruise missile (GLCM)'' means a ground-launched cruise missile that is a weapon-delivery vehicle.

The term ``deployment area'' means a designated area within which intermediate-range missiles and launchers of such missiles may operate and within which one or more missile operating bases are located.

The term ``missile support facility,'' as regards intermediate-range or shorter-range missiles and launchers of such missiles, means a missile production facility or a launcher production facility, a missile repair facility or a launcher repair facility, a training facility, a missile storage facility or a launcher storage facility, a test range, or an elimination facility as those terms are defined in the Memorandum of Understanding.

The term ``transit'' means movement, notified in accordance with paragraph 5(f) of Article IX of this Treaty, of an intermediate-range missile or a launcher of such a missile between missile support facilities, between such a facility and a deployment area or between deployment areas, or of a shorter-range missile or a launcher of such a missile from a missile support facility or a missile operating base to an elimination facility.

The term ``non-deployed launcher'' means a launcher of an intermediate-range missile located outside a deployment area or a launcher of a shorter-range missile located outside a missile operating base.

Each Party shall eliminate all its intermediate-range missiles and launchers of such missiles, and all support structures and support equipment of the categories listed in the Memorandum of Understanding associated with such missiles and launchers, so that no later than three years after entry into force of this Treaty and thereafter no such missiles, launchers, support structures or support equipment shall be possessed by either Party.

Each Party shall eliminate all its shorter-range missiles and launchers of such missiles, and all support equipment of the categories listed in the Memorandum of Understanding associated with such missiles and launchers, so that no later than 18 months after entry into force of this Treaty and thereafter no such missiles, launchers or support equipment shall be possessed by either Party.

No later than 90 days after entry into force of this Treaty, each Party shall complete the removal of all its deployed shorter-range missiles and deployed and non-deployed launchers of such missiles to elimination facilities and shall retain them at those locations until they are eliminated in accordance with the procedures set forth in the Protocol on Elimination. No later than 12 months after entry into force of this Treaty, each Party shall complete the removal of all its non-deployed shorter-range missiles to elimination facilities and shall retain them at those locations until they are eliminated in accordance with the procedures set forth in the Protocol on Elimination.

Notwithstanding paragraph 1 of this Article, each Party shall have the right to produce a type of GLBM not limited by this Treaty which uses a stage which is outwardly similar to, but not interchangeable with, a stage of an existing type of intermediate-range GLBM having more than one stage, providing that that Party does not produce any other stage which is outwardly similar to, but not interchangeable with, any other stage of an existing type of intermediate-range GLBM.

If a GLBM is of a type developed and tested solely to intercept and counter objects not located on the surface of the earth, it shall not be considered to be a missile to which the limitations of this Treaty apply.

The range capability of a GLBM not listed in Article III of this Treaty shall be considered to be the maximum range to which it has been tested. The range capability of a GLCM not listed in Article III of this Treaty shall be considered to be the maximum distance which can be covered by the missile in its standard design mode flying until fuel exhaustion, determined by projecting its flight path onto the earth's sphere from the point of launch to the point of impact. GLBMs or GLCMs that have a range capability equal to or in excess of 500 kilometers but not in excess of 1000 kilometers shall be considered to be shorter-range missiles. GLBMs or GLCMs that have a range capability in excess of 1000 kilometers but not in excess of 500 kilometers shall be considered to be intermediate-range missiles.

The maximum number of warheads an existing type of intermediate-range missile or shorter-range missile carries shall be considered to be the number listed for missiles of that type in the Memorandum of Understanding.

The number of missiles each launcher of an existing type of intermediate-range missile or shorter-range missile shall be considered to be capable of carrying or containing at one time is the number listed for launchers of missiles of that type in the Memorandum of Understanding.

A ballistic missile which is not a missile to be used in a ground-based mode shall not be considered to be a GLBM if it is test-launched at a test site from a fixed land-based launcher which is used solely for test purposes and which is distinguishable from GLBM launchers. A cruise missile which is not a missile to be used in a ground-based mode shall not be considered to be a GLCM if it is test-launched at a test site from a fixed land-based launcher which is used solely for test purposes and which is distinguishable from GLCM launchers.

Each Party shall have the right to produce and use for booster systems, which might otherwise be considered to be intermediate-range or shorter-range missiles, only existing types of booster stages for such booster systems.

Stages of intermediate-range missiles shall be located in deployment areas, at missile support facilities or moving between deployment areas, between missile support facilities or between missile support facilities and deployment areas.

Article V of this Treaty, all shorter-range missiles and launchers of such missiles shall be located at missile operating bases, at missile support facilities or shall be in transit. Shorter-range missiles or launchers of such missiles shall not be located elsewhere.

All deployment areas, missile operating bases and missile support facilities are specified in the Memorandum of Understanding or in subsequent updates of data pursuant to paragraphs 3, 5(a) or 5(b) of Article IX of this Treaty.

Neither Party shall increase the number of, or change the location or boundaries of, deployment areas, missile operating bases or missile support facilities, except for elimination facilities, from those set forth in the Memorandum of Understanding. A missile support facility shall not be considered to be part of a deployment area even though it may be located within the geographic boundaries of a deployment area.

Beginning 30 days after entry into force of this Treaty, neither Party shall locate intermediate-range or shorter-range missiles, including stages of such missiles, or launchers of such missiles at missile production facilities, launcher production facilities or test ranges listed in the Memorandum of Understanding.

A non-deployed intermediate-range or shorter-range missile shall not be carried on or contained within a launcher of such a type of missile, except as required for maintenance conducted at repair facilities or for elimination by means of launching conducted at elimination facilities.

Training missiles and training launchers for intermediate-range or shorter-range missiles shall be subject to the same locational restrictions as are set forth for intermediate-range and shorter-range missiles and launchers of such missiles in paragraph 1 and 3 of this Article.

The Memorandum of Understanding contains categories of data relevant to obligations undertaken with regard to this Treaty and lists all intermediate-range and shorter-range missiles, launchers of such missiles, and support structures and support equipment associated with such missiles and launchers, possessed by the Parties as of November 1, 1987. Updates of that data and notifications required by this Article shall be provided according to the categories of data contained in the Memorandum of Understanding.

No later than 30 days after entry into force of this Treaty, each Party shall provide the other Party with updated data, as of the date of entry into force of this Treaty, for all categories of data contained in the Memorandum of Understanding.

No later than 30 days after the end of each six-month interval following the entry into force of this Treaty, each Party shall provide updated data for all categories of data contained in the Memorandum of Understanding by informing the other Party of all changes, completed and in process, in that data, which have occurred during the six-month interval since the preceding data exchange, and the net effect of those changes.

Upon entry into force of this Treaty and thereafter, each Party shall notify the other Party, no less than ten days in advance, of the scheduled date and location of the launch of a research and development booster system as described in paragraph 12 of Article VII of this Treaty.

Each Party shall eliminate its intermediate-range and shorter-range missiles and launchers of such missiles and support structures and support equipment associated with such missiles and launchers in accordance with the procedures set forth in the Protocol on Elimination.

Verification by on-site inspection of the elimination of items of missile systems specified in the Protocol on Elimination shall be carried out in accordance with Article XI of this Treaty, the Protocol on Elimination and the Protocol on Inspection.

When a Party removes its intermediate-range missiles, launchers of such missiles and support equipment associated with such missiles and launchers from deployment areas to elimination facilities for the purpose of their elimination, it shall do so in complete deployed organizational units. For the United States of America, these units shall be Pershing II batteries and BGM - 109G flights. For the Union of Soviet Socialist Republics, these units shall be SS - 20 regiments composed of two or three battalions.

Elimination of intermediate-range and shorter-range missiles and launchers of such missiles and support equipment associated with such missiles and launchers shall be carried out at the facilities that are specified in the Memorandum of Understanding or notified in accordance with paragraph 5(b) of Article IX of this Treaty, unless eliminated in accordance with Sections IV or V of the Protocol on Elimination. Support structures, associated with the missiles and launchers subject to this Treaty, that are subject to elimination shall be eliminated in situ.

Intermediate-range and shorter-range missiles and launchers of such missiles and support structures and support equipment associated with such missiles and launchers shall be considered to be eliminated after completion of the procedures set forth in the Protocol on Elimination and upon the notification provided for in paragraph 5(e) of Article IX of this Treaty.

Such deployment areas, missile operating bases and missile support facilities shall be considered to be eliminated either when they have been inspected pursuant to paragraph 4 of Article XI of this Treaty or when 60 days have elapsed since the date of the scheduled elimination which was notified pursuant to paragraph 5(a) of Article IX of this Treaty. A deployment area, missile operating base or missile support facility listed in the Memorandum of Understanding that met the above conditions prior to entry into force of this Treaty, and is not included in the initial data exchange pursuant to paragraph 3 of Article IX of this Treaty, shall be considered to be eliminated.

If a Party intends to convert a missile operating base listed in the Memorandum of Understanding for use as a base associated with GLBM or GLCM systems not subject to this Treaty, then that Party shall notify the other Party, no less than 30 days in advance of the scheduled date of the initiation of the conversion, of the scheduled date and the purpose for which the base will be converted.

Beginning 30 days after entry into force of this Treaty, each Party shall have the right to conduct inspections at all missile operating bases and missile support facilities specified in the Memorandum of Understanding other than missile production facilities, and at all elimination facilities included in the initial data update required by paragraph 3 of Article IX of this Treaty.

These inspections shall be completed no later than 90 days after entry into force of this Treaty. The purpose of these inspections shall be to verify the number of missiles, launchers, support structures and support equipment and other data, as of the date of entry into force of this Treaty, provided pursuant to paragraph 3 of Article IX of this Treaty.

Each Party shall have the right to conduct inspections to verify the elimination, notified pursuant to paragraph 5(a) of Article IX of this Treaty, of missile operating bases and missile support facilities other than missile production facilities, which are thus no longer subject to inspections pursuant to paragraph 5(a) of this Article. Such an inspection shall be carried out within 60 days after the scheduled date of the elimination of that facility. If a Party conducts an inspection at a particular facility pursuant to paragraph 3 of this Article after the scheduled date of the elimination of that facility, then no additional inspection of that facility pursuant to this paragraph shall be permitted.

Party whose facility is to be inspected pursuant to this paragraph shall ensure that the other Party is able to establish a permanent continuous monitoring system at that facility within six months after entry into force of this Treaty or within six months of initiation of the process of final assembly described in subparagraph (a). If, after the end of the second year after entry into force of this Treaty, neither Party conducts the process of final assembly described in subparagraph (a) for a period of 12 consecutive months, then neither Party shall have the right to inspect by means of continuous monitoring any missile production facility of the other Party unless the process of final assembly as described in subparagraph (a) is initiated again. Upon entry into force of this Treaty, the facilities to be inspected by continuous monitoring shall be: in accordance with subparagraph (b), for the United States of America, Hercules Plant Number 1, at Magna, Utah; in accordance with subparagraph (a), for the Union of Soviet Socialist Republics, the Votkinsk Machine Building Plant, Udmurt Autonomous Soviet Socialist Republic, Russian Soviet Federative Socialist Republic.

Each Party shall conduct inspections of the process of elimination, including elimination of intermediate-range missiles by means of launching, of intermediate-range and shorter-range missiles and launchers of such missiles and support equipment associated with such missiles and launchers carried out at elimination facilities in accordance with Article X of this Treaty and the Protocol on Elimination. Inspectors conducting inspections provided for in this paragraph shall determine that the processes specified for the elimination of the missiles, launchers and support equipment have been completed.

Each Party shall have the right to conduct inspections to confirm the completion of the process of elimination of intermediate-range and shorter-range missiles and launchers of such missiles and support equipment associated with such missiles and launchers eliminated pursuant to Section V of the Protocol on Elimination, and of training missiles, training missile stages, training launch canisters and training launchers eliminated pursuant to Sections II, IV and V of the Protocol on Elimination.

For the purpose of ensuring verification of compliance with the provisions of this Treaty, each Party shall use national technical means of verification at its disposal in a manner consistent with generally recognized principles of international law.

Each Party shall, in exercising its national sovereignty, have the right to withdraw from this Treaty if it decides that extraordinary events related to the subject matter of this Treaty have jeopardized its supreme interests. It shall give notice of its decision to withdraw to the other Party six months prior to withdrawal from this Treaty. Such notice shall include a statement of the extraordinary events the notifying Party regards as having jeopardized its supreme interests.

This Treaty, including the Memorandum of Understanding and Protocols, which form an integral part thereof, shall be subject to ratification in accordance with the constitutional procedures of each Party. This Treaty shall enter into force on the date of the exchange of instruments of ratification.

Pursuant to and in implementation of the Treaty Between the United States of America and the Union of Soviet Socialist Republics on the Elimination of Their Intermediate-Range and Shorter-Range Missiles of December 8, 1987, hereinafter referred to as the Treaty, the Parties hereby agree upon procedures governing the elimination of the missile systems subject to the Treaty.

In order to ensure the reliable determination of the type and number of missiles, missile stages, front sections, launch canisters, launchers, missile transporter vehicles, missile erectors and launch stands, as well as training missiles, training missile stages, training launch canisters and training launchers, indicated in Section I of this Protocol, being eliminated at elimination facilities, and to preclude the possibility of restoration of such items for purposes inconsistent with the provisions of the Treaty, the Parties shall fulfill the requirements below.

The conduct of the elimination procedures for the items of missile systems listed in paragraph 1 of this Section, except for training missiles, training missile stages, training launch canisters and training launchers, shall be subject to on-site inspection in accordance with Article XI of the of the Treaty and the Protocol on Inspection. The Parties shall have the right to conduct on-site inspections to confirm the completion of the elimination procedures set forth in paragraph 11 of this Section for training missiles, training missile stages, training launch canisters and training launchers. The Party possessing such a training missile, training missile stage, training launch canister or training launcher shall inform the other Party of the name and coordinates of the elimination facility at which the on-site inspection may be conducted as well as the date on which it may be conducted. Such information shall be provided no less than 30 days in advance of that date.

Each Party shall select the particular technological means necessary to implement the procedures required in paragraphs 10 and 11 of this Section and to allow for on-site inspection of the conduct of the elimination procedures required in paragraph 10 of this Section in accordance with Article XI of the Treaty, this Protocol and the Protocol on Inspection.

Immediately prior to the initiation of the elimination procedures set forth in paragraph 10 of this Section, an inspector from the Party receiving the pertinent notification required by paragraph 5(c) of Article IX of the Treaty shall confirm and record the type and number of items of missile systems, listed in paragraph 1 of this Section, which are to be eliminated. If the inspecting Party deems it necessary, this shall include a visual inspection of the contents of launch canisters.

A missile stage being eliminated by burning in accordance with the procedures set forth in paragraph 10 of this Section shall not be instrumented for data collection. Prior to the initiation of the elimination procedures set forth in paragraph 10 of this Section, an inspector from the inspecting Party shall confirm that such missile stages are not instrumented for data collection.

The completion of the elimination procedures set forth in this Section, except those for training missiles, training missile stages, training launch canisters and training launchers, along with the type and number of items of missile systems for which those procedures have been completed, shall be confirmed in writing by the representative of the Party carrying out the elimination and by the inspection team leader of the other Party. The elimination of a training missile, training missile stage, training launch canister or training launcher shall be considered to have been completed upon completion of the procedures set forth in paragraph 11 of this Section and notification as required by paragraph 5(e) of Article IX of the Treaty following the date specified pursuant to paragraph 2 of this Section.

The Parties agree that all United States and Soviet intermediate-range and shorter-range missiles and their associated reentry vehicles shall be eliminated within an agreed overall period of elimination. It is further agreed that all such missiles shall, in fact, be eliminated fifteen days prior to the end of the overall period of elimination. During the last fifteen days, a Party shall withdraw to its national territory reentry vehicles which, by unilateral decision, have been released from existing programs of cooperation and eliminate them during the same timeframe in accordance with the procedures set forth in this Section.

Canister: launch canister shall be destroyed by explosive demolition together with a missile, or shall be destroyed separately by explosion, cut into two pieces of approximately equal size, crushed or flattened.

Transporter Vehicle: mounting components for a missile and for a missile's erector mechanism as well as supports for erecting a missile onto a launcher shall be cut off transporter vehicle at locations that are not assembly joints.

Such launches shall involve ignition of all missile stages. Neither Party shall transmit or recover data from missiles being eliminated by means of launching except for unencrypted data used for range safety purposes.

The completion of the elimination procedures set forth in this Section, and the type and number of missiles for which those procedures have been completed, shall be confirmed in writing by the representative of the Party carrying out the elimination and by the inspection team leader of the other Party.

A missile shall be considered to be eliminated by means of launching after completion of the procedures set forth in this Section and upon notification required by paragraph 5(e) of Article IX of the Treaty.

Training missiles, training missile stages, training launch canisters and training launchers being eliminated in situ shall be eliminated in accordance with the specific procedures set forth in paragraph 11 of Section II of this Protocol.

Each Party shall have the right to conduct an on-site inspection to confirm the completion of the elimination procedures for training missiles, training missile stages, training launch canisters and training launchers.

The Party possessing such a training missile, training missile stage, training launch canister or training launcher shall inform the other Party of the place-name and coordinates of the location at which the on-site inspection provided for in paragraph 3(c) of this Section may be conducted as well as the date on which it may be conducted. Such information shall be provided no less than 30 days in advance of that date.

Elimination of a training missile, training missile stage, training launch canister or training launcher shall be considered to have been completed upon the completion of the procedures required by this paragraph and upon notification as required by paragraph 5(e) of Article IX of the Treaty following the date specified pursuant to paragraph 3(d) of this Section.

If an item listed in Section I of this Protocol is lost or destroyed as a result of an accident, the possessing Party shall notify the other Party within 48 hours, as required in paragraph 5(e) of Article IX of the Treaty, that the item has been eliminated.

The Parties shall have the right to eliminate missiles, launch canisters and launchers, as well as training missiles, training launch canisters and training launchers, listed in Section I of this Protocol by placing them on static display. Each Party shall be limited to a total of 15 missiles, 15 launch canisters and 15 launchers on such static display.

Prior to being placed on static display, a missile, launch canister or launcher shall be rendered unusable for purposes inconsistent with the Treaty. Missile propellant shall be removed and erector-launcher mechanisms shall be rendered inoperative.

The Party possessing a missile, launch canister or launcher, as well as a training missile, training launch canister or training launcher that is to be eliminated by placing it on static display shall provide the other Party with the place-name and coordinates of the location at which such a missile, launch canister or launcher is to be on static display, as well as the location at which the on-site inspection provided for in paragraph 2(d) of this Section, may take place.

Each Party shall have the right to conduct an on-site inspection of such a missile, launch canister or launcher within 60 days of receipt of the notification required in paragraph 2(c) of this Section.

Elimination of a missile, launch canister or launcher, as well as a training missile, training launch canister or training launcher, by placing it on static display shall be considered to have been completed upon completion of the procedures required by this paragraph and notification as required by paragraph 5(e) of Article IX of the Treaty.

Protocol is an integral part of the Treaty. It shall enter into force on the date of the entry into force of the Treaty and shall remain in force so long as the Treaty remains in force. As provided for in paragraph 1(b) of Article XIII of the Treaty, the Parties may agree upon such measures as may be necessary to improve the viability and effectiveness of this Protocol. Such measures shall not be deemed amendments to the Treaty.

The term ``inspector'' means an individual designated by one of the Parties to carry out inspections and included on that Party's list of inspectors in accordance with the provisions of Section III of this Protocol.

The term ``period of inspection'' means the period of time from arrival of the inspection team at the inspection site until its departure from the inspection site, exclusive of time spent on any pre- and post-inspection procedures.

The term ``aircrew member'' means an individual who performs duties related to the operation of an airplane and who is included on a Party's list of aircrew members in accordance with the provisions of Section III of this Protocol.

Each Party takes note of the assurances received from the other Party regarding understandings reached between the other Party and the basing countries to the effect that the basing countries have agreed to the conduct of inspections, in accordance with the provisions of this Protocol, on their territories.

Inspections to ensure verification of compliance by the Parties with the obligations assumed under the Treaty shall be carried out by inspectors designated in accordance with paragraphs 3 and 4 of this Section.

No later than one day after entry into force of the Treaty, each Party shall provide to the other Party: a list of its proposed aircrew members; a list of its proposed inspectors who will carry out inspections pursuant to paragraphs 3, 4, 5, 7 and 8 of Article XI of the Treaty; and a list of its proposed inspectors who will carry out inspection activities pursuant to paragraph 6 of Article XI of the Treaty. None of these lists shall contain at any time more than 200 individuals.

Each Party shall review the lists of inspectors and aircrew members proposed by the other Party. With respect to an individual included on the list of proposed inspectors who will carry out inspection activities pursuant to paragraph 6 of Article XI of the Treaty, if such an individual is unacceptable to the Party reviewing the list, that Party shall, within 20 days, so inform the Party providing the list, and the individual shall be deemed not accepted and shall be deleted from the list. With respect to an individual on the list of proposed aircrew members or the list of proposed inspectors who will carry out inspections pursuant to paragraphs 3, 4, 5, 7 and 8 of Article XI of the Treaty, each Party, within 20 days after the receipt of such lists, shall inform the other Party of its agreement to the designation of each inspector and aircrew member proposed. Inspectors shall be citizens of the inspecting Party.

Each Party shall have the right to amend its lists of inspectors and aircrew members. New inspectors and aircrew members shall be designated in the same manner as set forth in paragraph 3 of this Section with respect to the initial lists.

Within 30 days of receipt of the initial lists of inspectors and aircrew members, or of subsequent changes thereto, the Party receiving such information shall provide, or shall ensure the provision of, such visas and other documents to each individual to whom it has agreed as may be required to ensure that each inspector or aircrew member may enter and remain in the territory of the Party or basing country in which an inspection site is located throughout the in-country period for the purpose of carrying out inspection activities in accordance with the provisions of this Protocol. Such visas and documents shall be valid for a period of at least 24 months.

To exercise their functions effectively, inspectors and aircrew members shall be accorded, throughout the in-country period, privileges and immunities in the country of the inspection site as set forth in the Annex to this Protocol.

Without prejudice to their privileges and immunities, inspectors and aircrew members shall be obliged to respect the laws and regulations of the State on whose territory an inspection is carried out and shall be obliged not to interfere in the internal affairs of that State. In the event the inspected Party determines that an inspector or aircrew member of the other Party has violated the conditions governing inspection activities set forth in this Protocol, or has ever committed a criminal offense on the territory of the inspected Party or a basing country, or has ever been sentenced for committing a criminal offense or expelled by the inspected Party or a basing country, the inspected Party making such a determination shall so notify the inspecting Party, which shall immediately strike the individual from the lists of inspectors or the list of aircrew members. If, at that time, the individual is on the territory of the inspected Party or a basing country, the inspecting Party shall immediately remove that individual from the country.

Within 30 days after entry into force of the Treaty, each Party shall inform the other Party of the standing diplomatic clearance number for airplanes of the Party transporting inspectors and equipment necessary for inspection into and out of the territory of the Party or basing country in which an inspection site is located. Aircraft routings to and from the designated point of entry shall be along established international airways that are agreed upon by the Parties as the basis for such diplomatic clearance.

No less than three hours prior to the scheduled departure of the inspection team from the last airfield prior to entering the airspace of the country in which the inspection is to take place, the inspected Party shall ensure that the flight plan filed in accordance with paragraph 3 of this Section is approved so that the inspection team may arrive at the point of entry by the estimated arrival time.

Either Party may change the point or points of entry to the territories of the countries within which its deployment areas, missile operating bases or missile support facilities are located, by giving notice of such change to the other Party. A change in a point of entry shall become effective five months after receipt of such notification by the other Party.

Government of either the inspected Party or the basing country in which the inspection site is located shall meet the inspection team and aircrew members at the point of entry as soon as the airplane of the inspecting Party lands.

The number of aircrew members for each airplane shall not exceed ten. The in-country escort shall expedite the entry of the inspection team and aircrew, their baggage, and equipment and supplies necessary for inspection, into the country in which the inspection site is located. A diplomatic aircrew escort shall have the right to accompany and assist aircrew members throughout the in-country period. In the case of an inspection taking place on the territory of a basing country, the in-country escort may include representatives of that basing country.

An inspector shall be considered to have assumed his duties upon arrival at the point of entry on the territory of the inspected Party or a basing country, and shall be considered to have ceased performing those duties when he has left the territory of the inspected Party or basing country.

Equipment and supplies which the inspecting Party brings into the country in which an inspection site is located shall be subject to examination at the point of entry each time they are brought into that country. This examination shall be completed prior to the departure of the inspection team from the point of entry to conduct an inspection. Such equipment and supplies shall be examined by the in-country escort in the presence of the inspection team members to ascertain to the satisfaction of each Party that the equipment and supplies cannot perform functions unconnected with the inspection requirements of the Treaty. If it is established upon examination that the equipment or supplies are unconnected with these inspection requirements, then they shall not be cleared for use and shall be impounded at the point of entry until the departure of the inspection team from the country where the inspection is conducted. Storage of the inspecting Party's equipment and supplies at each point of entry shall be within tamper-proof containers within a secure facility. Access to each secure facility shall be controlled by a ``dual key'' system requiring the presence of both Parties to gain access to the equipment and supplies.

Throughout the in-country period, the inspected Party shall provide, or arrange for the provision of, meals, lodging, work space, transportation and, as necessary, medical care for the inspection team and aircrew of the inspecting Party. All the costs in connection with the stay of inspectors carrying out inspection activities pursuant to paragraph 6 of Article XI of the Treaty, on the territory of the inspected Party, including meals, services, lodging, work space, transportation and medical care shall be borne by the inspecting Party.

The inspected Party shall provide parking, security protection, servicing, and fuel for the airplane of the inspecting Party at the point of entry. The inspecting Party shall bear the cost of such fuel and servicing.

For inspections conducted on the territory of the Parties, the inspection team shall enter at the point of entry on the territory of the inspected Party that is closest to the inspection site. In the case of inspections carried out in accordance with paragraphs 3, 4 or 5 of Article XI of the Treaty, the inspection team leader shall, at or before the time notified pursuant to paragraph 1(a)(iii) of Section IV of this Protocol, inform the inspected Party at the point of entry through the in-country escort of the type of inspection and the inspection site, by place-name and geographic coordinates.

Inspectors shall not disclose information received during inspections except with the express permission of the inspecting Party. They shall remain bound by this obligation after their assignment as inspectors has ended.

In discharging their functions, inspectors shall not interfere directly with on-going activities at the inspection site and shall avoid unnecessarily hampering or delaying the operation of a facility or taking actions affecting its safe operation.

The in-country escort shall have the right to accompany and assist inspectors and aircrew members as considered necessary by the inspected Party throughout the in-country period. Except as otherwise provided in this Protocol, the movement and travel of inspectors and aircrew members shall be at the discretion of the in-country escort.

Article XI of the Treaty shall be allowed to travel within 50 kilometers from the inspection site with the permission of the in-country escort, and as considered necessary by the inspected Party, shall be accompanied by the in-country escort. Such travel shall be taken solely as a leisure activity.

Inspectors shall have the right throughout the period of inspection to be in communication with the embassy of the inspecting Party located within the territory of the country where the inspection is taking place using the telephone communications provided by the inspected Party.

The inspection team may bring onto the inspection site such documents as needed to conduct the inspection, as well as linear measurement devices; cameras; portable weighing devices; radiation detection devices; and other equipment, as agreed by the Parties. The characteristics and method of use of the equipment listed above, shall also be agreed upon within 30 days after entry into force of the Treaty. During inspections conducted pursuant to paragraphs 3, 4, 5(a), 7 or 8 of Article XI of the Treaty, the inspection team may use any of the equipment listed above, except for cameras, which shall be for use only by the inspected Party at the request of the inspecting Party.

During inspections conducted pursuant to paragraph 5(b) of Article XI of the Treaty, all measurements shall be made by the inspected Party at the request of the inspecting Party. At the request of inspectors, the in-country escort shall take photographs of the inspected facilities using the inspecting Party's camera systems which are capable of producing duplicate, instant development photographic prints. Each Party shall receive one copy of every photograph.

For inspections conducted pursuant to paragraphs 3, 4, 5, 7 or 8 of Article XI of the Treaty, inspectors shall permit the in-country escort to observe the equipment used during the inspection by the inspection team.

Measurements recorded during inspections shall be certified by the signature of a member of the inspection team and a member of the in-country escort when they are taken. Such certified data shall be included in the inspection report.

Inspectors shall have the right to request clarifications in connection with ambiguities that arise during an inspection. Such requests shall be made promptly through the in-country escort. The in-country escort shall provide the inspection team, during the inspection, with such clarifications as may be necessary to remove the ambiguity. In the event questions relating to an object or building located within the inspection site are not resolved, the inspected Party shall photograph the object or building as requested by the inspecting Party for the purpose of clarifying its nature and function. If the ambiguity cannot be removed during the inspection, then the question, relevant clarifications and a copy of any photographs taken shall be included in the inspection report.

In carrying out their activities, inspectors shall observe safety regulations established at the inspection site, including those for the protection of controlled environments within a facility and for personal safety. Individual protective clothing and equipment shall be provided by the inspected Party, as necessary.

Treaty, pre-inspection procedures, including briefings and safety-related activities, shall begin upon arrival of the inspection team at the inspection site and shall be completed within one hour. The inspection team shall begin the inspection immediately upon completion of the pre-inspection procedures.

The period of inspection shall not exceed 24 hours, except for inspections pursuant to paragraphs 6, 7 or 8 of Article XI of the Treaty. The period of inspection may be extended, by agreement with the in-country escort, by no more than eight hours. Post-inspection procedures, which include completing the inspection report in accordance with the provisions of Section XI of this Protocol, shall begin immediately upon completion of the inspection and shall be completed at the inspection site within four hours.

Treaty shall include no more than ten inspectors, except for an inspection team conducting an inspection pursuant to paragraphs 7 or 8 of that Article, which shall include no more than 20 inspectors and an inspection team conducting inspection activities pursuant to paragraph 6 of that Article, which shall include no more than 30 inspectors. At least two inspectors on each team must speak the language of the inspected Party. An inspection team shall operate under the direction of the team leader and deputy team leader. Upon arrival at the inspection site, the inspection team may divide itself into subgroups consisting of no fewer than two inspectors each. There shall be no more than one inspection team at an inspection site at any one time.

Within one hour after the time for the specification of the inspection site notified pursuant to paragraph 1(a) of Section IV of this Protocol, the inspected Party shall implement pre-inspection movement restrictions at the inspection site, which shall remain in effect until the inspection team arrives at the inspection site. During the period that pre-inspection movement restrictions are in effect, missiles, stages of such missiles, launchers or support equipment subject to the Treaty shall not be removed from the inspection site.

The inspected Party shall transport the inspection team from the point of entry to the inspection site so that the inspection team arrives at the inspection site no later than nine hours after the time for the specification of the inspection site notified pursuant to paragraph 1(a) of Section IV of this Protocol.

Neither Party shall conduct more than one inspection pursuant to paragraph 5(a) of Article XI of the Treaty at any one time, more than one inspection pursuant to paragraph 5(b) of Article XI of the Treaty at any one time, or more than 10 inspections pursuant to paragraph 3 of Article XI of the Treaty at any one time.

Except in the case of an inspection conducted pursuant to paragraphs 4 or 5(b) of Article XI of the Treaty, upon arrival of the inspection team at the inspection site, the in-country escort shall inform the inspection team leader of the number of missiles, stages of missiles, launchers, support structures and support equipment at the site that are subject to the Treaty and provide the inspection team leader with a diagram of the inspection site indicating the location of these missiles, stages of missiles, launchers, support structures and support equipment at the inspection site.

Subject to the procedures of paragraphs 8 through 14 of this Section, inspectors shall have the right to inspect the entire inspection site, including the interior of structures, containers or vehicles, or including covered objects, whose dimensions are equal to or greater than the dimensions specified in Section VI of the Memorandum of Understanding for the missiles, stages of such missiles, launchers or support equipment of the inspected Party.

A missile, a stage of such a missile or a launcher subject to the Treaty shall be subject to inspection only by external visual observation, including measuring, as necessary, the dimensions of such a missile, stage of such a missile or launcher. A container that the inspected Party declares to contain a missile or stage of a missile subject to the Treaty, and which is not sufficiently large to be capable of containing more than one missile or stage of such a missile of the inspected Party subject to the Treaty, shall be subject to inspection only by external visual observation, including measuring, as necessary, the dimensions of such a container to confirm that it cannot contain more than one missile or stage of such a missile of the inspected Party subject to the Treaty. Except as provided for in paragraph 14 of this Section, a container that is sufficiently large to contain a missile or stage of such a missile of the inspected Party subject to the Treaty that the inspected party declares not to contain a missile or stage of such a missile subject to the Treaty shall be subject to inspection only by means of weighing or visual observation of the interior of the container, as necessary, to confirm that it does not, in fact, contain a missile or stage of such a missile of the inspected Party subject to the Treaty. If such a container is a launch canister associated with a type of missile not subject to the Treaty, and declared by the inspected Party to contain such a missile, it shall be subject to external inspection only, including use of radiation detection devices, visual observation and linear measurement, as necessary, of the dimensions of such a canister.

A structure or container that is not sufficiently large to contain a missile, stage of such a missile or launcher of the inspected Party subject to the Treaty shall be subject to inspection only by external visual observation including measuring, as necessary, the dimensions of such a structure or container to confirm that it is not sufficiently large to be capable of containing a missile, stage of such a missile or launcher of the inspected Party subject to the Treaty.

Within a structure, a space which is sufficiently large to contain a missile, stage of such a missile or launcher of the inspected Party subject to the Treaty, but which is demonstrated to the satisfaction of the inspection team not to be accessible by the smallest missile, stage of a missile or launcher of the inspected Party subject to the Treaty shall not be subject to further inspection. If the inspected Party demonstrates to the satisfaction of the inspection team by means of a visual inspection of the interior of an enclosed space from its entrance that the enclosed space does not contain any missile, stage of such a missile or launcher of the inspected Party subject to the Treaty, such an enclosed space shall not be subject to further inspection.

The inspection team shall be permitted to inspect any vehicle capable of carrying missiles, stages of such missiles, launchers or support equipment of the inspected Party subject to the Treaty at any time during the course of an inspection and no such vehicle shall leave the inspection site during the course of the inspection until inspected at site exits by the inspection team.

Prior to inspection of a building within the inspection site, the inspection team may station subgroups at the exits of the building that are large enough to permit passage of any missile, stage of such a missile, launcher or support equipment of the inspected Party subject to the Treaty. During the time that the building is being inspected, no vehicle or object capable of containing any missile, stage of such a missile, launcher or support equipment of the inspected Party subject to the Treaty shall be permitted to leave the building until inspected.

Treaty, it shall be the responsibility of the inspected Party to demonstrate that a shrouded or environmentally protected object which is equal to or larger than the smallest missile, stage of a missile or launcher of the inspected Party subject to the Treaty is not, in fact, a missile, stage of such a missile or launcher of the inspected Party subject to the Treaty. This may be accomplished by partial removal of the shroud or environmental protection cover, measuring, or weighing the covered object or by other methods. If the inspected Party satisfies the inspection team by its demonstration that the object is not a missile, stage of such a missile or launcher of the inspected Party subject to the Treaty, then there shall be no further inspection of that object. If the container is a launch canister associated with a type of missile not subject to the Treaty, and declared by the inspected Party to contain such a missile, then it shall be subject to external inspection only, including use of radiation detection devices, visual observation and linear measurement, as necessary, of the dimensions of such a canister.

Inspections of the process of elimination of items of missile systems specified in the Protocol on Elimination carried out pursuant to paragraph 7 of Article XI of the Treaty shall be conducted in accordance with the procedures set forth in this paragraph and the Protocol on Elimination.

Inspectors shall check the data which are specified in the notification provided by the inspected Party regarding the number and type of items of missile systems to be eliminated against the number and type of such items which are at the elimination facility prior to the initiation of the elimination procedures.

Subject to paragraphs 3 and 11 of Section VI of this Protocol, inspectors shall observe the execution of the specific procedures for the elimination of the items of missile systems as provided for in the Protocol on Elimination. If any deviations from the agreed elimination procedures are found, the inspectors shall have the right to call the attention of the in-country escort to the need for strict compliance with the above-mentioned procedures. The completion of such procedures shall be confirmed in accordance with the procedures specified in the Protocol on Elimination.

During the elimination of missiles by means of launching, the inspectors shall have the right to ascertain by visual observation that a missile prepared for launch is a missile of the type subject to elimination. The inspectors shall also be allowed to observe such a missile from a safe location specified by the inspected Party until the completion of its launch. During the inspection of a series of launches for the elimination of missiles by means of launching, the inspected Party shall determine the means of transport and route for the transportation of inspectors between inspection sites.

Protocol on Elimination carried out pursuant to paragraph 8 of Article XI of the Treaty shall be conducted in accordance with the procedures set forth in Sections II, IV or V of the Protocol on Elimination or as otherwise agreed by the Parties.

The inspected Party shall maintain an agreed perimeter around the periphery of the inspection site and shall designate a portal with not more than one rail line and one road which shall be within 50 meters of each other. All vehicles which can contain an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party shall exit only through this portal.

The inspecting Party shall have the right to establish continuous monitoring systems at the portal specified in paragraph l of this Section and appropriate sensors at the exits specified in paragraph 3 of this Section and carry out necessary engineering surveys, construction, repair and replacement of monitoring systems.

Party shall not deny the inspected Party access to any existing structures or security systems. The inspecting Party shall not take any actions with respect to such structures without consent of the inspected Party. If the Parties agree that such structures are to be rebuilt or demolished, either partially or completely, the inspecting Party shall provide the necessary compensation.

The inspecting Party shall have the right to use its own two-way systems of radio communication between inspectors patrolling the perimeter and the data collection center. Such systems shall conform to power and frequency restrictions established on the territory of the inspected Party.

GLBM or longest stage of such a GLBM of the inspected Party shall be declared by the inspected Party to the inspection team before the shipment arrives at the portal. The declaration shall state whether such a shipment contains a missile or missile stage as large or larger than and as heavy or heavier than an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party.

The inspection team shall have the right to weigh and measure the dimensions of any vehicle, including railcars, exiting the site to ascertain whether it is large enough and heavy enough to contain an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party. These measurements shall be performed so as to minimize the delay of vehicles exiting the site. Vehicles that are either not large enough or not heavy enough to contain an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party shall not be subject to further inspection.

Vehicles exiting through the portal specified in paragraph 1 of this Section that are large enough and heavy enough to contain an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party but that are declared not to contain a missile or missile stage as large or larger than and as heavy or heavier than an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party shall be subject to the following procedures.

If the inspecting Party can determine by visual observation or dimensional measurement that, inside a particular vehicle, there are no containers or shrouded objects large enough to be or to contain an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party, then that vehicle shall not be subject to further inspection.

If inside a vehicle there are one or more containers or shrouded objects large enough to be or to contain an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party, it shall be the responsibility of the inspected Party to demonstrate that such containers or shrouded objects are not and do not contain intermediate-range GLBMs or the longest stages of such GLBMs of the inspected Party.

Measuring equipment shall be placed only outside of the launch canister or shipping container; all measurements shall be made by the inspecting Party using the equipment provided for in paragraph 6 of this Section. Such measurements shall be observed and certified by the in-country escort.

The inspecting Party shall also have the right to inspect any other containers or shrouded objects inside the vehicle containing such a missile or missile stage in accordance with the procedures in paragraph 13 of this Section.

An inspection shall be cancelled if, due to circumstances brought about by force majeure, it cannot be carried out. In the case of a delay that prevents an inspection team performing an inspection pursuant to paragraphs 3, 4 or 5 of Article XI of the Treaty, from arriving at the inspection site during the time specified in paragraph 2 of Section VII of this Protocol, the inspecting Party may either cancel or carry out the inspection.

For inspections conducted pursuant to paragraphs 3, 4, 5, 7, or 8 of Article XI of the Treaty, during post-inspection procedures, and no later than two hours after the inspection has been completed, the inspection team leader shall provide the in-country escort with a written inspection report in both the English and Russian languages. The report shall be factual. It shall include the type of inspection carried out, the inspection site, the number of missiles, stages of missiles, launchers and items of support equipment subject to the Treaty observed during the period of inspection and any measurements recorded pursuant to paragraph 10 of Section VI of this Protocol. Photographs taken during the inspection in accordance with agreed procedures, as well as the inspection site diagram provided for by paragraph 6 of Section VII of this Protocol, shall be attached to this report.

For inspection activities conducted pursuant to paragraph 6 of Article XI of the Treaty, within 3 days after the end of each month, the inspection team leader shall provide the in-country escort with a written inspection report both in the English and Russian languages. The report shall be factual. It shall include the number of vehicles declared to contain a missile or stage of a missile as large or larger than and as heavy or heavier than an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party that left the inspection site through the portal specified in paragraph 1 of Section IX of this Protocol during that month. The report shall also include any measurements of launch canisters or shipping containers contained in these vehicles recorded pursuant to paragraph 11 of Section VI of this Protocol. In the event the inspecting Party, under the provisions of paragraph 14(c) of Section IX of this Protocol, has viewed the interior of a launch canister or shipping container declared to contain a missile or stage of a missile as large or larger than and as heavy or heavier than an intermediate-range GLBM or longest stage of such a GLBM of the inspected Party, the report shall also include the measurements of the length and diameter of missile stages obtained during the inspection and recorded pursuant to paragraph 11 of Section VI of this Protocol. Photographs taken during the inspection in accordance with agreed procedures shall be attached to this report.

The Parties shall, when possible, resolve ambiguities regarding factual information contained in the inspection report. Relevant clarifications shall be recorded in the report. The report shall be signed by the inspection team leader and by one of the members of the in-country escort. Each Party shall retain one copy of the report.

In order to exercise their functions effectively, for the purpose of implementing the Treaty and not for their personal benefit, the inspectors and aircrew members referred to in Section III of this Protocol shall be accorded the privileges and immunities contained in this Annex. Privileges and immunities shall be accorded for the entire in-country period in the country in which an inspection site is located, and thereafter with respect to acts previously performed in the exercise of official functions as an inspector or aircrew member.

The living quarters and office premises occupied by an inspector carrying out inspection activities pursuant to paragraph 6 of Article XI of the Treaty shall be accorded the inviolability and protection accorded the premises of diplomatic agents pursuant to Article 30 of the Vienna Convention on Diplomatic Relations.

The papers and correspondence of inspectors and aircrew members shall enjoy the inviolability accorded to the papers and correspondence of diplomatic agents pursuant to Article 30 of the Vienna Convention on Diplomatic Relations. In addition, the aircraft of the inspection team shall be inviolable.

Inspectors and aircrew members shall be accorded the immunities accorded diplomatic agents pursuant to paragraphs 1, 2 and 3 of Article 31 of the Vienna Convention on Diplomatic Relations. The immunity from jurisdiction of an inspector or an aircrew member may be waived by the inspecting Party in those cases when it is of the opinion that immunity would impede the course of justice and that it can be waived without prejudice to the implementation of the provisions of the Treaty. Waiver must always be express.

Inspectors and aircrew members of a Party shall be permitted to bring into the territory of the other Party or a basing country in which an inspection site is located, without payment of any customs duties or related charges, articles for their personal use, with the exception of articles the import or export of which is prohibited by law or controlled by quarantine regulations.

If the inspected Party considers that there has been an abuse of privileges and immunities specified in this Annex, consultations shall be held between the Parties to determine whether such an abuse has occurred and, if so determined, to prevent a repetition of such an abuse.

Well, thank you, and thank you all very much, and I think that maybe I got out the wrong set of notes here. Still, I do say thank you very much. General Secretary Gorbachev and distinguished guests, my fellow Americans and citizens of the Soviet Union, the American philosopher, Ralph Waldo Emerson, once wrote that there is properly no history, only biography. He meant by this that it is not enough to talk about history as simply forces and factors. History is ultimately a record of human will, human spirit, human aspirations of Earth's men and women, each with the precious soul and free will that the Lord bestows.

In the next few days, we will discuss further arms reductions and other issues, and again it will take time and patience to reach agreements. But as we begin these talks, let us remember that genuine international confidence and security are inconceivable without open societies with freedom of information, freedom of conscience, the right to publish, and the right to travel. So, yes, we will address human rights and regional conflicts, for surely the salvation of all mankind lies only in making everything the concern of all. With time, patience, and willpower, I believe we will resolve these issues. We must if we're to achieve a true, secure, and enduring peace.

Too often in the decades since then the soldier's dream -- a time to live -- has been put off, at least as far as it concerned genuine peace between our two countries. Yet we Americans have never stopped praying for peace. In every part of the world we want this to be a time to live.

Only those who don't know us believe that America is a materialistic land. But the true America is not supermarkets filled with meats, milk, and goods of all descriptions. It is not highways filled with cars. No, true America is a land of faith and family.

You can find it in our churches, synagogues, and mosques -- in our homes and schools. As one of our great writers put it: America is a willingness of the heart -- the universal, human heart -- for Americans come from every part of Earth, including the Soviet Union. We want a peace that fulfills the dream of all peoples to raise their families in freedom and safety. And I believe that if both of our countries have courage and the patience, we will build such a peace.

In the next 2 months, people throughout the world will take part in two great festivals of faith: Hanukkah and Christmas. One is a celebration of freedom, the other of peace on Earth, good will toward men. My great hope is that the biographies of our times will record that we had the will to make this the right season for this summit.

The President. Mr. General Secretary and Mrs. Gorbachev, Foreign Minister Shevardnadze, honored guests: In our public statements and in our meetings together, Mr. General Secretary, we've always paid each other the compliment of candor. So, let us continue to do so.

By now, Mr. General Secretary, you may have concluded that while we have fundamental disagreements about how human communities should govern themselves, it's possible, all the same, for us to work together.

As we complete the first full day of this historic meeting, let us look back together at the developments of the past 2 years and the significance of what is taking place. For we find ourselves involved in a dramatic march of events that has captured the attention of our two peoples and the entire world. Since you and I first met in Geneva in November 1985, Mr.

General Secretary, our two countries have moved toward a new period in the history of our relations. The highlight of your visit is the signing of the first U.S.-Soviet arms control agreement in nearly a decade -- the first ever to mandate actual reductions in our arsenals of nuclear weapons. We're making significant progress in other important areas of arms reduction, and have the opportunity, with mutual commitment and hard work, to achieve much more in the coming months.

But our relationship -- the United States and the Soviet Union -- is not founded just on arms control but reaches across a broad spectrum of issues. A relationship that addresses the basic problems of self-determination in the areas of regional conflicts and human rights.

A century-and-a-half ago, the brilliant French observer, de Tocqueville, foresaw that our two countries would be the major countries of the world. History, geography, the blessings of resources, and the hard work of our peoples have made it so. And between us, there has also been a profound competition of political and economic philosophy, making us the protagonists in a drama with the greatest importance for the future of all mankind. Man's most fundamental beliefs about the relationship of the citizen to the state and of man to his creator lie at the core of the competition between our two countries. History has indeed endowed our relationship with a profound meaning.

Certainly we will not settle those issues this week. But the tasks before us require a full awareness of those issues and of a responsibility that is binding on us both. I speak of a responsibility we dare not compromise or shirk. I speak of the responsibility to settle our differences in peace. Already, by virtue of hard work and hard bargaining, we've accomplished much, and our negotiators deserve great credit. But we cannot afford to rest. There is more work to be done, and time and history are marching on.

The General Secretary. I take power into my hands now, while the President is busy. [Laughter] Esteemed Mr. President, esteemed Mrs. Reagan, ladies and gentlemen, comrades: Last summer it took a daring American girl by the name of Lynn Cox a mere 2 hours to swim the distance separating our two countries. On television we saw how sincere and cordial the meeting was between our people and the Americans when she stepped onto the Soviet shore. By her courage she showed how close to each other our two peoples live.

Without minimizing the great political and ideological distances between us, we want to seek and find avenues of rapprochement in areas where this is of vital importance for our two countries and for all humankind. That is precisely what we are here for. In my 1986 New Year's Eve address on American television, I spoke of our hopes for a better future. By that time, Mr. President, you and I had already had 2 days of face-to-face talks in Geneva. This enabled me to tell Americans in my New Year address that the winter of our discontent may one day come to an end. Today, following Reykjavik and the extensive preparatory work that has made our meeting in Washington possible, it can be said that the winter is on the wane.

A boundless world stretches far and wide beyond the walls of this house. And you and I, if you will, are accountable to it and to the peoples of our two countries, to our allies and friends and to all our contemporaries. The Russian word, perestroika, can be applied to the process now underway all over the world of rethinking the realities of a nuclear and space age. It must now be clear to all that the problems of today's world will not be solved through old approaches. The goal we are setting today is to build a nuclear-free world. The road leading to it is difficult and thorny, but with new thinking it is attainable. As you can see, here, too, changes are necessary -- changes in the minds and changes in actions.

The great age of geographical discoveries amounted to more than one caravel or one newly found continent. Our journey toward a nuclear-free world cannot amount to reaching one or two islands named INF and shorter range INF. It is my hope that we shall promptly move further ahead toward the goal of reducing and then eliminating strategic offensive arms which make up the main and decisive portion of the nuclear arsenal.

As the clock of life brings us closer and closer to the 21st century, we are duty bound to remember that each one of us, within the limits of our capability and ability, personifies the link between the transient and the eternal. As our famous poet Afanasiy Fet, said, ``Although man is not eternal, what is human is eternal.'' It is in the name of eternal humanity that we have today performed our momentous deed.

And my first salute is to that event. It will be cherished by our two peoples. So, I address these words of congratulation to the Soviet and American people whose will is embodied in the agreement. I want to emphasize that this is the fruit of the efforts not only of us both but also of our allies and representatives of all countries and all public movements whose effort and contribution rightfully make them parties to this historic event.

It would be fair today to pay tribute to the efforts of those who were directly involved in preparing the treaty. May I wish good health to you, Mr. President, and to Mrs. Reagan; happiness and well-being to all those present here tonight; peace and prosperity to the peoples of our two countries.

President is very gratified by the ABA's announcement and believes that after concluding its hearings the Senate will agree with the assessment of the American Bar Association that Judge Kennedy possesses the highest qualifications to be a Justice of the United States Supreme Court.

According to the ABA, this rating is ``reserved for those who meet the highest standard of professional competence, judicial temperament and integrity. The person in this category must be among the best available for appointment to the Supreme Court.'' The ABA's decision followed a detailed examination of Judge Kennedy's professional qualifications, his writings, and his decisions on the bench, as well as extensive interviews with persons familiar with his record.

The President. Well, it is. And I know that most of the things we hear is that they believe that somehow by this INF agreement we have changed the balance of power in Europe, and that the Soviets, who do have, admittedly, a conventional superiority, have been given an advantage. But that isn't so. There are still hundreds and hundreds of nuclear weapons left in Europe -- the tactical battlefield weapons. And those are the weapons that do equalize that imbalance in conventional weapons.

Now, before you would go into any treaty about those tactical battlefield weapons, that would have to follow parity in the conventional weapons because if we eliminated and they eliminated the tactical battlefield weapons they automatically would end up with a great superiority if it was reduced to conventional weapons. And in this instance, I feel they're so wrong because they are giving up four times as many warheads as we have to give up. In our Pershings and cruise missiles, we didn't have anywhere near the number of warheads, and their intermediate-range missiles were not targeted on military targets. They covered all the way to London.

The President. They have -- he has expressed and is -- in fact, not just to me but publicly, that they want to get out of Afghanistan. And I can't go beyond that, other than that saying that the people we have working on all of these things are working on that particular question right now, as to when and how.

The President. Oh, well, she seems very pleasant, and we just had a little moment here. Maybe I shouldn't give this away, but I will. His schedule was very busy today, and our meeting ran over here in the Oval Office. And I kept -- finally, as I told him, I said, I've been told that I'm to take him over to the Diplomatic Entrance there to meet his wife who was with Nancy, and then so they could go on with their schedule. And then when we got there, we found out that Nancy and Raisa were having coffee together, and they were late. [Laughter] So, when we stood down there in the Dip Room waiting for them to come down, I suggested something to him, and we both did it -- that when finally they came around and through the door, he and I were both looking at our watches. [Laughter] We got a laugh.

As everyone in the United States knows, I have a weakness for anecdotes. So, if I may, I'd like to begin with a story I was so moved by recently that I mentioned it in my address to the people of the Soviet Union. It's an account of one of our diplomats, a young man then, stationed in our Embassy in Moscow during World War II. He was there when news of victory, V-E Day reached that city, and he said Red Square erupted in a spontaneous demonstration of thankfulness and joy.

Embassy's chancery was just across from the Kremlin, and many of the Americans stationed there in those days were still in uniform. When they walked outside to join in the celebration, the crowd spotted them, lifted them onto their shoulders, and carried them on to Red Square. But the young diplomat said he was even more moved by the words of one Red Army major standing near him in the crowd, words filled with new found hope: ``Now it's time to live,'' he said.

Mr. General Secretary, we've accomplished much so far in this summit -- a pathbreaking agreement that for the first time will eliminate an entire class of U.S. and Soviet nuclear weapons. But I'm convinced that history will ultimately judge this summit and its participants not on missile count but on how far we moved together to the fulfillment of that soldier's hopes.

We have prided ourselves, Mr. General Secretary, on our realism, that we've come to this summit without illusions, with no attempts to gloss over the deep differences that divide us, differences that reach to the core values upon which our political systems are based. But we said, even so, we can make progress; even so, we can find areas of agreement and cooperation.

But perhaps in this Christmas season, we should look at an even deeper and more enduring realism. It is a reality that precedes states and governments, that precedes and surpasses the temporary realities of ideology and politics. It is the reality that binds each of us as individual souls, the bond that united Soviets and Americans in exultation and thanksgiving on that day of peace, 42 years ago.

Secretary Gorbachev, you've declared that in your own country there is a need for greater glasnost, or openness, and the world watches expectantly and with great hopes to see this promise fulfilled. For in talking of openness and promising truth, you've called on the deepest hungers of the human heart, hungers shared by all, whether they be Soviet or American or the citizens of any nation on Earth.

There's an old Russian saying: ``Every man is the blacksmith of his own happiness.'' And like all folk sayings, it contains a profound understanding of the human condition. We can, with our free will, shape our future. We can make it what that Soviet soldier saw in his vision of a better world, a vision of peace and freedom.

In memory of that day in Red Square when Soviet citizens carried American soldiers on their shoulders, in memory of that day when the Red Army embraced a new world of hope, I raise my glass. Mr. General Secretary and Mrs. Gorbachev, Foreign Minister Shevardnadze, thank you. And Ambassador and Mrs. Dubinin, thank you for your hospitality this evening. And for my last attempt at Russian: Za vashe zdorovye [To your health].

November 1985 meeting in Geneva, the President and the General Secretary held comprehensive and detailed discussions on the full range of issues between the two countries, including arms reductions, human rights and humanitarian issues, settlement of regional conflicts, and bilateral relations. The talks were candid and constructive, reflecting both the continuing differences between the two sides, and their understanding that these differences are not insurmountable obstacles to progress in areas of mutual interest.

The leaders reviewed progress to date in fulfilling the broad agenda they agreed at Geneva and advanced at Reykjavik. They took particular satisfaction in the conclusion over the last two years of important agreements in some areas of this agenda.

President and the General Secretary affirmed the fundamental importance of their meetings in Geneva and Reykjavik, which laid the basis for concrete steps in a process intended to improve strategic stability and reduce the risk of conflict. They will continue to be guided by their solemn conviction that a nuclear war cannot be won and must never be fought. They are determined to prevent any war between the United States and the Soviet Union, whether nuclear or conventional. They will not seek to achieve military superiority.

The two leaders recognized the special responsibility of the United States and the Soviet Union to search for realistic ways to prevent confrontation and to promote a more sustainable and stable relationship between their countries. To this end, they agreed to intensify dialogue and to encourage emerging trends toward constructive cooperation in all areas of their relations. They are convinced that in so doing they will also contribute, with other nations, to the building of a safer world as humanity enters the third millennium.

The two leaders signed the Treaty between the United States of America and the Union of Soviet Socialist Republics on the Elimination of Their Intermediate-Range and Shorter-Range Missiles. This treaty is historic both for its objective -- the complete elimination of an entire class of U.S. and Soviet nuclear arms -- and for the innovative character and scope of its verification provisions.

President and the General Secretary discussed the negotiations on reductions in strategic offensive arms. They noted the considerable progress which has been made toward conclusion of a treaty implementing the principle of 50-percent reductions. They agreed to instruct their negotiators in Geneva to work toward the completion of the Treaty on the Reduction and Limitation of Strategic Offensive Arms and all integral documents at the earliest possible date, preferably in time for signature of the treaty during the next meeting of leaders of state in the first half of 1988. Recognizing that areas of agreement and disagreement are recorded in detail in the Joint Draft Treaty Text, they agreed to instruct their negotiators to accelerate resolution of issues within the Joint Draft Treaty Text including early agreement on provisions for effective verification.

In so doing, the negotiators should build upon the agreements on 50-percent reductions achieved at Reykjavik as subsequently developed and now reflected in the agreed portions of the Joint Draft START Treaty Text being developed in Geneva, including agreement on ceilings of no more than 1600 strategic offensive delivery systems, 6000 warheads, 1540 warheads on 154 heavy missiles; the agreed rule of account for heavy bombers and their nuclear armament; and an agreement that as a result of the reductions the aggregate throw-weight of the Soviet Union's ICBMs and SLBMs will be reduced to a level approximately 50-percent below the existing level, and this level will not be exceeded by either side. Such an agreement will be recorded in a mutually satisfactory manner.

The counting rules governing the number of long-range, nuclear-armed air-launched cruise missiles (ALCMs) to be attributed to each type of heavy bomber. The Delegations shall define concrete rules in this area.

Such limitations will not involve counting long-range, nuclear-armed SLCMs within the 6000 warhead and 1600 strategic offensive delivery systems limits. The sides committed themselves to establish ceilings on such missiles, and to seek mutually acceptable and effective methods of verification of such limitations, which could include the employment of National Technical Means, cooperative measures and on-site inspection.

Data exchanges, to include declarations by each side of the number and location of weapon systems limited by the Treaty and of facilities at which such systems are located and appropriate notifications. These facilities will include locations and facilities for production and final assembly, storage, testing, and deployment of systems covered by this Treaty. Such declarations will be exchanged between the sides before the Treaty is signed and updated periodically after entry into force.

The right to implement, in accordance with agreed-upon procedures, short-notice inspections at locations where either side considers covert deployment, production, storage or repair of strategic offensive arms could be occurring.

Provisions prohibiting the use of concealment or other activities which impede verification by national technical means. Such provisions would include a ban on telemetry encryption and would allow for full access to all telemetric information broadcast during missile flight.

Measures designed to enhance observation of activities related to reduction and limitation of strategic offensive arms by National Technical Means. These would include open displays of treaty-limited items at missile bases, bomber bases, and submarine ports at locations and times chosen by the inspecting party.

Taking into account the preparation of the Treaty on Strategic Offensive Arms, the leaders of the two countries also instructed their delegations in Geneva to work out an agreement that would commit the sides to observe the ABM Treaty, as signed in 1972, while conducting their research, development, and testing as required, which are permitted by the ABM Treaty, and not to withdraw from the ABM Treaty, for a specified period of time. Intensive discussions of strategic stability shall begin not later than three years before the end of the specified period, after which, in the event the sides have not agreed otherwise, each side will be free to decide its course of action. Such an agreement must have the same legal status as the Treaty on Strategic Offensive Arms, the ABM Treaty, and other similar, legally binding agreements. This agreement will be recorded in a mutually satisfactory manner. Therefore, they direct their delegations to address these issues on a priority basis.

President and the General Secretary reviewed a broad range of other issues concerning arms limitation and reduction. The sides emphasized the importance of productive negotiations on security matters and advancing in the main areas of arms limitation and reduction through equitable, verifiable agreements that enhance security and stability.

U.S. and Soviet sides have agreed to begin before December 1, 1987, full-scale stage-by-stage negotiations which will be conducted in a single forum. In these negotiations the sides as the first step will agree upon effective verification measures which will make it possible to ratify the U.S.-USSR Threshold Test Ban Treaty of 1974 and Peaceful Nuclear Explosions Treaty of 1976, and proceed to negotiating further intermediate limitations on nuclear testing leading to the ultimate objective of the complete cessation of nuclear testing as part of an effective disarmament process. This process, among other things, would pursue, as the first priority, the goal of the reduction of nuclear weapons and, ultimately, their elimination. For the purpose of the elaboration of improved verification measures for the U.S.-USSR Treaties of 1974 and 1976 the sides intend to design and conduct joint verification experiments at each other's test sites. These verification measures will, to the extent appropriate, be used in further nuclear test limitation agreements which may subsequently be reached.

The leaders also welcomed the prompt agreement by the sides to exchange experts' visits to each other's nuclear testing sites in January 1988 and to design and subsequently to conduct a Joint Verification Experiment at each other's test site. The terms of reference for the Experiment are set forth in the statement issued on December 9, 1987, by the Foreign Ministers of the United States and the Soviet Union. The leaders noted the value of these agreements for developing more effective measures to verify compliance with the provisions of the 1974 Threshold Test Ban Treaty and the 1976 Peaceful Nuclear Explosions Treaty.

United States and the Soviet Union to the non-proliferation of nuclear weapons, and in particular to strengthening the Treaty on the Non-Proliferation of Nuclear Weapons. The two leaders expressed satisfaction at the adherence since their last meeting of additional parties to the Treaty, and confirmed their intent to make, together with other states, additional efforts to achieve universal adherence to the Treaty.

President and the General Secretary expressed support for international cooperation in nuclear safety and for efforts to promote the peaceful uses of nuclear energy, under further strengthened IAEA safeguards and appropriate export controls for nuclear materials, equipment and technology. The leaders agreed that bilateral consultations on non-proliferation were constructive and useful, and should continue.

The leaders expressed their commitment to negotiation of a verifiable, comprehensive and effective international convention on the prohibition and destruction of chemical weapons. They welcomed progress to date and reaffirmed the need for intensified negotiations toward conclusion of a truly global and verifiable convention encompassing all chemical weapons-capable states. The United States and Soviet Union are in favor of greater openness and intensified confidence-building with respect to chemical weapons both on a bilateral and a multilateral basis. They agreed to continue periodic discussions by experts on the growing problem of chemical weapons proliferation and use.

President and the General Secretary discussed the importance of the task of reducing the level of military confrontation in Europe in the area of armed forces and conventional armaments. The two leaders spoke in favor of early completion of the work in Vienna on the mandate for negotiations on this issue, so that substantive negotiations may be started at the earliest time with a view to elaborating concrete measures. They also noted that the implementation of the provisions of the Stockholm Conference on Confidence- and Security-Building Measures and Disarmament in Europe is an important factor in strengthening mutual understanding and enhancing stability, and spoke in favor of continuing and consolidating this process. The President and the General Secretary agreed to instruct their appropriate representatives to intensify efforts to achieve solutions to outstanding issues.

They expressed their determination, together with the other 33 participants in the Conference on Security and Cooperation in Europe, to bring the Vienna CSCE Follow-Up Conference to a successful conclusion, based on balanced progress in all principal areas of the Helsinki Final Act and Madrid Concluding Document.

President and the General Secretary engaged in a wide-ranging, frank and businesslike discussion of regional questions, including Afghanistan, the Iran-Iraq War, the Middle East, Cambodia, southern Africa, Central America and other issues. They acknowledged serious differences but agreed on the importance of their regular exchange of views. The two leaders noted the increasing importance of settling regional conflicts to reduce international tensions and to improve East-West relations. They agreed that the goal of the dialogue between the United States and the Soviet Union on these issues should be to help the parties to regional conflicts find peaceful solutions that advance their independence, freedom and security. Both leaders emphasized the importance of enhancing the capacity of the United Nations and other international institutions to contribute to the resolution of regional conflicts.

President and the General Secretary reviewed in detail the state of U.S.-Soviet bilateral relations. They recognized the utility of further expanding and strengthening bilateral contacts, exchanges and cooperation.

Having reviewed the state of ongoing U.S.-Soviet negotiations on a number of specific bilateral issues, the two leaders called for intensified efforts by their representatives, aimed at reaching mutually advantageous agreements on: commercial maritime issues; fishing; marine search and rescue; radio navigational systems; the U.S.-USSR maritime boundary; and cooperation in the field of transportation and other areas.

The two leaders took note of progress in implementing the U.S.-Soviet General Exchanges Agreement in the areas of education, science, culture and sports, signed at their November 1985 Geneva meeting, and agreed to continue efforts to eliminate obstacles to further progress in these areas. They expressed satisfaction with plans to celebrate jointly the 30th anniversary of the first Exchanges Agreement in January 1988.

The two leaders reaffirmed the importance of contacts and exchanges in broadening understanding between their peoples. They noted with particular satisfaction the progress made in the development of people-to-people contacts under the initiative they launched at their 1985 meeting in Geneva -- a process which has involved tens of thousands of U.S. and Soviet citizens over the past two years. The leaders reaffirmed their strong commitment further to expand such contacts, including among the young.

With reference to their November 1985 agreement in Geneva to cooperate in the preservation of the environment, the two leaders approved a bilateral initiative to pursue joint studies in global climate and environmental change through cooperation in areas of mutual concern, such as protection and conservation of stratospheric ozone, and through increased data exchanges pursuant to the U.S.-Soviet Environmental Protection Agreement and the Agreement Between the United States of America and the Union of Soviet Socialist Republics Concerning Cooperation in the Exploration and Use of Outer Space for Peaceful Purposes. In this context, there will be a detailed study on the climate of the future. The two sides will continue to promote broad international and bilateral cooperation in the increasingly important area of global climate and environmental change.

President and the General Secretary supported further cooperation among scientists of the United States, the Soviet Union and other countries in utilizing controlled thermonuclear fusion for peaceful purposes. They affirmed the intention of the U.S. and the USSR to cooperate with the European Atomic Energy Community (EURATOM) and Japan, under the auspices of the International Atomic Energy Agency, in the quadripartite conceptual design of a fusion test reactor.

The two leaders noted with satisfaction progress under the bilateral Agreement on Peaceful Uses of Atomic Energy towards establishing a permanent working group in the field of nuclear reactor safety, and expressed their readiness to develop further cooperation in this area.

President and the General Secretary agreed to develop bilateral cooperation in combatting international narcotics trafficking. They agreed that appropriate initial consultations would be held for these purposes in early 1988.

The two leaders exchanged views on means of encouraging expanded contacts and cooperation on issues relating to the Arctic. They expressed support for the development of bilateral and regional cooperation among the Arctic countries on these matters, including coordination of scientific research and protection of the region's environment.

The two sides stated their strong support for the expansion of mutually beneficial trade and economic relations. They instructed their trade ministers to convene the U.S.-USSR Joint Commercial Commission in order to develop concrete proposals to achieve that objective, including within the framework of the Long-Term Agreement between the United States of America and the Union of Soviet Socialist Republics to Facilitate Economic, Industrial, and Technical Cooperation. They agreed that commercially viable joint ventures complying with the laws and regulations of both countries could play a role in the further development of commercial relations.

Both sides agreed on the importance of adequate, secure facilities for their respective diplomatic and consular establishments, and emphasized the need to approach problems relating to the functioning of Embassies and Consulates General constructively and on the basis of reciprocity.

President and the General Secretary agreed that official contacts at all levels should be further expanded and intensified, with the goal of achieving practical and concrete results in all areas of the U.S.-Soviet relationship.

The President. Mr. General Secretary, these last few days have been exciting, indeed, for both of us and for our fellow countrymen who followed the course of our discussions. I'm pleased to report that upon the completion of our business that this summit has been a clear success. Like the star on the top of the National Christmas Tree, which was lit the evening you arrived, Mr. General Secretary, this summit has lit the sky with hope for all people of good will. And as we leave, it is up to both sides to ensure that the luster does not wear off and to follow through on our commitments as we move forward to the next steps in improving the relations between our countries and peoples.

I believe both the General Secretary and I can walk away from our meetings with a sense of accomplishment. We have proven that adversaries, even with the most basic philosophical differences, can talk candidly and respectfully with one another and, with perseverance, find common ground. We did not hide from the weighty differences that separate us; many of them, of course, remain. One of my predecessors, President Franklin Roosevelt, once said: ``History cannot be rewritten by wishful thinking.'' Our discussions, in that spirit, were straightforward and designed to open a thoughtful communication between our governments on the critical issues that confront us.

Our exchange on the subject of human rights underscored the priority we in the Western democracies place on respect for fundamental freedoms. I'm pleased that during this summit we addressed this area of heartfelt importance and have ensured a continuing dialog on human rights at the highest levels of our governments.

Our discussions on regional conflicts were no less to the point. These conflicts continue to take a heavy toll in lives and impose a heavy burden on East-West relations. The General Secretary and I expressed different points of view -- we did so bluntly -- and for that reason alone, our talks have been useful in this area. Moreover, we agree that it is necessary to search for real political solutions to these conflicts. But so far, we cannot be satisfied with what has been achieved. We must now press ahead in the search for political solutions that advance the cause of peace and freedom for the people suffering in these wars. The door has been opened, and it will stay open to serious discussion of ending these regional conflicts.

And as far as open doors, Mr. Gorbachev and I both agree on the desirability of freer and more extensive personal contact and the breaking down of artificial barriers between the peoples of the Soviet Union and the United States. As I said in my welcoming remarks, the fact that our governments have disagreements should not prevent our peoples from being friends.

Of course, the greatest accomplishment of these 3 days was the signing of a treaty to eliminate a whole class of U.S. and Soviet nuclear weapons. Another one of my predecessors, a President I have admired since my youth, Calvin Coolidge, once said: ``History is made only by action.'' Well, it took enormous effort and almost superhuman tenacity on the part of negotiators on both sides, but the end product is a treaty that does indeed make history.

It is in the interest of both our peoples, yet I cannot help but believe that mankind is the biggest winner. At long last, we have begun the task of actually reducing these deadly weapons rather than simply putting limits on their growth.

INF treaty, as proud of it as we are, should be viewed as a beginning, not an end. Further arms reduction is now possible. I am pleased some progress has been made toward a strategic arms reduction treaty over the last 3 days.

Individual agreements will not, in and of themselves, result in sustained progress. We need a realistic understanding of each other's intentions and objectives, a process for dealing with differences in a practical and straightforward manner; and we need patience, creativity, and persistence in achieving what we set out to do. As a result of this summit, the framework for building such a relationship has been strengthened.

General Secretary -- is a more constructive relationship between our governments, long-lasting rather than transitory improvements. Together, we can bring about a more secure and prosperous future for our peoples and a more peaceful world. Both of us are aware of the difficult challenges and special responsibilities inherent in this task.

World War II, when so many young Russians served at the front, the poem ``Wait For Me'' became a prayer spoken on the lips of Russian families who dreamed one day of the happiness that their reunion would bring.

Secretary Gorbachev, Mrs. Gorbachev, it is good that you came to America, and Nancy and I are pleased to have welcomed you here. Your visit was short, yet I hope you'll take with you a better sense of the spirit and soul of the United States of America. And when you get back to Moscow, please pass on to the Soviet people the best wishes of the American people for a peaceful and prosperous new year.

A good deal has been accomplished. I would like to emphasize in particular an unprecedented step in the history of the nuclear age: the signing of the treaty under which the two militarily and strategically greatest powers have assumed an obligation to actually destroy a portion of their nuclear weapons, thus, we hope, setting in motion the process of nuclear disarmament.

In our talks with President Ronald Reagan, some headway has been made on the central issue of that process -- achieving substantial reductions of strategic offensive arms, which are the most potent weapons in the world -- although we still have a lot of work to do. We have had a useful exchange of views, which has clarified each other's positions concerning regional conflicts, the development of our bilateral ties, and human rights. On some of these aspects, it seems likely that we can soon identify specific solutions satisfactory both to us and to other countries. A useful result of the Washington talks is that we have been able to formulate a kind of agenda for joint efforts in the future. This puts the dialog between our two countries on a more predictable footing and is undoubtedly constructive.

While this visit has centered on our talks with the President of the United States, I have no intention of minimizing the importance of meetings with Members of Congress, with other political leaders, public figures, members of the business and academic communities, cultural figures, and media executives. Such contacts enable us to gain a better and more profound knowledge of each other, provide a wealth of opportunities for checking one's views, assessments, and even established stereotypes. All this is important, both for policymaking and for bringing peoples and countries closer together. These meetings have confirmed the impression that there is a growing desire in American society for improved Soviet-American relations. In short, what we have seen here is a movement matching the mood that has long been prevalent among Soviet people.

In bidding farewell to America, I am looking forward to a new encounter with it, in the hope that I will then be able to see not only its Capital but also to meet face-to-face with its great people, to chat and to have some lively exchanges with ordinary Americans. I believe that what we have accomplished during the meeting and the discussions will, with time, help considerably to improve the atmosphere in the world at large and in America itself, in terms of its more correct and tolerant perception of my country, the Soviet Union.

Today the Soviet Union and the United States are closer to the common goal of strengthening international security, but this goal is yet to be reached. There is still much work to be done, and we must get down to it without delay. Mr. President, esteemed citizens of the United States, we are grateful for your hospitality, and we wish success, well-being, and peace to all Americans.

Founders of our country believed the rights of the individual are God-given, not originating from or granted by the state. Their timeless vision of individual liberties for all people is why we pause each December to express thanks for our heritage and to renew our commitment to the vital cause of human rights around the globe. We also celebrate the adoption of the Universal Declaration of Human Rights, which set human rights standards for all nations.

Tragically, governments in many lands deny this vision. Some make elaborate claims that citizens under their rule enjoy human rights and even offer illusory guarantees of those rights -- but then reveal their absence through lack of due process, free elections, or freedom of religion, expression, and assembly. Their constitutions often declare openly that citizens' rights are subordinate to the interests of the state. Even if words look good on paper, the absence of structural safeguards against abuse of power means that freedoms may be taken away as easily as they are allowed. In countries where monopoly power rests with a single group or political entity, the scope for human liberty is narrow indeed.

These states pose the greatest threat to liberty, not only because under them people are denied the exercise of the most fundamental freedoms, but because they pose external as well as internal dangers. Unlimited power, exercised in the name of universalist ideologies, often tries to extend its control beyond borders, denying other peoples their human rights and self-determination.

Standing against these dangers are those people the world over who, undaunted by tremendous odds and great personal risk, continue to press for individual rights and freedoms. Their courageous struggle for human dignity is a triumph in itself, but the United States pledges continuing support to their efforts on behalf of human rights, fundamental freedoms, and democracy.

Witness Whereof, I have hereunto set my hand this 10th day of December, in the year of our Lord nineteen hundred and eighty-seven, and of the Independence of the United States of America the two hundred and twelfth.

The President. I think you recognize the gentleman with me, my Chief of Staff, Senator Baker. Well, please be seated. I'm grateful to have this opportunity to speak with you and to answer some of your questions. Having worked as a journalist of sorts -- I was a sports broadcaster -- I sympathize with what some of you must have been going through, facing a deadline, yet with little information about what was going on behind closed doors. I must believe that what you reported from this summit was some of the best news the American people and our allies have heard in a long time.

INF agreement signed at this summit will bring about the first mutual reduction in Soviet and American nuclear arsenals ever, and the first step back toward a safer world has been agreed to. The word historic is frequently used in describing the INF agreement, and I know that adjective is overused, but in this case I think it's appropriate. This is the most important action since World War II in reducing the arms race. Instead of trying to put a ceiling on future growth of the number of weapons, both sides are now focused on ways to mutually reduce our nuclear forces. And we're in a better position to make tangible gains in arms reduction than at anytime in the last 40 years.

Of course, arms reduction is only one of several significant areas of discussion between the East and West. For example, I made it clear to the General Secretary that the continuing occupation of Afghanistan undermines the progress that we would like to see between our two countries. I also emphasized that there are people fighting for their freedom in many parts of the world. In Nicaragua, freedom fighters face a Communist Sandinista military machine supportive of the Soviet Union. And now is not the time for Congress to turn away from those who are fighting for freedom.

Similarly, on human rights, I explained how difficult it is for the people of the Western democracies to have trust in a government that doesn't trust its own people and denies their human rights. So, be assured that General Secretary Gorbachev is aware that forward movement in areas like arms reduction will be helped considerably by the solution of regional conflicts and more respect for human rights.

A moment ago I mentioned the Western democracies. I would like to stress that in preparation for this summit I frequently sought advice and counsel from other Western leaders. And today I've spoken on the telephone with Chancellor Kohl and Prime Minister Takeshita to convey my impressions of General Secretary Gorbachev and the summit and to consult on the next steps.

And later today I'll be talking with Prime Minister Thatcher and communicating with other key allied leaders. Our allies have been most supportive, and I'm gratified at the unity and responsibility demonstrated by the alliance during the sensitive negotiations we've gone through in the summit and in the weeks and months before the summit.

Secretary Gorbachev this week go around the Capital, meet with the people on the street, with reporters, with business groups, we saw one perspective. From your aides and advisers, we hear another perspective: as a tight bargainer as opposed to the polished salesman of himself and his country. Could you tell us, please, from your impression, which is the real Mikhail Gorbachev?

If I could follow up: The relationship between the two of you also seems to change. From Reykjavik, where it seemed a little bit strained, to this time, it seemed a little more natural. Was that just a general progression of a relationship as people know better, or was there a difference in bargaining?

The President. I think you're taking Reykjavik down to one final hour, because, no, we found that we had quite an open relationship from the very first, in Geneva and in Reykjavik. But in Reykjavik, toward the end of the final session when we thought we had made a great many breakthroughs -- then for the first time, an issue was raised by him that just simply halted everything that we thought we had agreed to. And if I seemed a little upset, I was.

The President. We have made great progress in that particular area. As a matter of fact, by agreement, we will go forward with our research and development of SDI completely, with whatever is needed in that development. And then, after a certain point, if and when we have succeeded in putting together this initiative, then we will deploy.

The President. Well, by the time we got here -- and we had so many things yet to do in that final session that -- no, there wasn't any discussion of that. Some of the television did overhear and carried what I said when he got out of the car a few hours late. I told him I thought he'd gone home. [Laughter] And he laughed. He didn't take any exception to what I had said. But, no, but I think that's rather typical.

Trudy Reuben, from the Philadelphia Inquirer. To follow up on the SDI question, Mr. President, have the Soviets agreed to drop their objections to the U.S. testing under the broad interpretation of the ABM Treaty, and was the agreement that you reached a breakthrough? Does the formula resolve the issue, or does it merely postpone it for now?

The President. No, it resolves it -- the very fact that we have agreed that we are going forward with whatever is necessary in the research and development without any regard to an interpretation of ABM. On the other hand, we do have an agreement also that there will be a period of time in which both countries have agreed we will continue the ABM, although that does not affect our testing. And actually, that time, we do not believe, represents any undue delay for us because the information we have on the potential possibility or probability of getting SDI is going to take a certain length of time.

The President. I don't think there's any impediment there at all. Well, yes, we could have the normal impediment that we have sometimes here in our own circles, that is, if the Congress will be forthcoming on the funds that are needed to proceed as we want to proceed with it.

The President. Well, the progress that we've made so far has led to an increase in the number of actual individuals who have been prevented from getting visas or who are incarcerated. And this is because what we've been following here is a policy of getting at names and creating lists. And we've presented those lists to them as the people that we know about and that we're interested in seeing freed and seeing allowed to emigrate. And they have been forthcoming on that, and that's why there's been quite an increase. At the same time, we've got a long way to go on this whole matter of total emigration.

I think, again, the discussions that we've had have, I think, improved the situation, but you have to recognize also that, as I say, he believes in their system and so forth. And since these few days here in Washington, his only experience in the United States -- I've issued an invitation for them anytime, please, to come back when -- not a summit, but when they can go touring the countryside and see America and get acquainted with it. They don't think they're violating any human rights. They think we are.

Edwards, WKBW Buffalo. Western New York is the home of the Chatauqua Institution, where for the last 3 years we have had private peace initiatives and exchanges with the Soviets. We are going back again next May. How do you view these private peace initiatives following your summit?

The President. Well, not only do we view them well and approve heartily but we have negotiated on that basis and agreed on the subject of more exchanges between our people, wherever possible, and so forth. That, we think, is very, very helpful.

Mr. President, Bob Lee, from Oakland Communications. Both you and Mr. Gorbachev have spoken about the improved relationship between the two of you as being one of the benefits of the summit. If that's the case, why not expand upon it and do as you just suggested: meet more often, even when there isn't a treaty signing, or do like you did that morning, pick up the phone and call him more often?

The President. Well, we stay in communication. It doesn't mean now that this has ended and now there will be no relationship until the next summit in Moscow. No. And our teams that are in Geneva are going to continue, now, going forward with the things that were discussed here in 3 days. You can't completely agree on all the things that must be resolved. But we will be going forward in contact with him, but with also our teams working together so that -- just as when we came here and found we had a treaty we could sign on the first day. Hopefully, that will take place also.

Mr. President, Jeff Marx, from Lexington, Kentucky. We've heard a lot about nuclear weapons. Can you tell us a little bit about what has been done this week with chemical weapons and where you see that heading?

The President. I think one of the most hopeful signs is that he, not me, was the first one to bring up conventional weapons and chemical warfare as something that we had to resolve and go forward with further reductions in those weapons. He wants reduction in arms all the way across the board.

The President. Well, as I say, he brought that up as a part of the subject that we've got to go forward with as -- right, and specifically we're going on the -- as I say, the nuclear weapons, because these are the things we've been discussing. But he made it plain that he doesn't want to stop there. He wants arms reduction, period.

The President. That's a difficult question to answer, because, as I say, there was a certain chemistry between us. On the other hand, I think I've been involved in the Communist situation long before I was in this office. I was once president of the union in the motion picture industry in a period in which, immediately after the war, the Soviet Union, through their local chapters here in our country, were doing their best to infiltrate and gain control over that industry, which could be such a propaganda machine. And so, I have to say that, yes, there is a chemistry and all of that; but I repeatedly used their own language to them, and still do, with regard to any of these issues: Dovorey no provorey -- trust but verify.

The President. Well, I think the very situation that has, in a way, helped bring about these meetings, an agreement with regard to arms, has been the enormous economic problem that he, as the new leader of the Soviet Union, is faced with. And his own proposals and -- about which he's running into some opposition in his own country for glasnost, for an opening of his society -- is an indication with regard to whether that system, as it has been in the past, can continue without winding up in the dustbin of history. That's true.

On the other fact -- or on the other hand, with regard to the evil empire, I meant it when I said it, because under previous leaders they have made it evident that they were based -- or their program was based on expansionism, on going forward toward the Marxian philosophy of the one-world Communist state. All of those things were true.

The first day I ever stood here in a press conference with our own press people in Washington, they -- most of them -- they've cited what I said about no morality unless it furthered the cause of socialism, but they forgot it was answering a question about how could they be trusted. And it was true that there was a philosophy then, under the previous leaders, that there was no immorality in anything that furthered the cause of socialism, therefore permitting themselves to violate trust, to lie, and so forth. There seems to be an entirely different relationship.

The President. You always have to be concerned about that, just as I'm sure they are, too. But never have we ever had an agreement that had the verification principles that are embodied in this agreement, on the INF agreement. They will have people at the assembly plant for that type of weapon in our country for 13 years, and we will have people there. We will have the ability to stop a weapon coming out of the plant, have the hood removed, and count the number of warheads that it contains to see that it is meeting the requirements. We've agreed in both cases for on-spot checks, in which in addition to these permanent things that we have, that if we have some suspicion or get some hint that something is going on, we can go in, like that, to that particular area, wherever it might be, to check on it. And they can do likewise.

The President. No, I think that we would have to face that problem and take up that issue when it happened -- as to what our course would be. And with regard to SALT II, you remember, we're talking about something -- there was a treaty that was never ratified, that was then a kind of an agreement between the two that, well, they'd go ahead and try to stay within the parameters of what the treaty would have called for had it been ratified.

Charleston Daily Mail. What do you think of some kind of Senate amendment or reservation that would have the effect of setting a timetable on withdrawal of Soviet troops from Afghanistan? And do you think it might have the effect of killing the whole treaty?

What do you think of some kind of Senate reservation that would have the effect of setting a timetable on the withdrawal of troops from Afghanistan? And do you think that a Senate action of that kind would have the effect of killing the treaty altogether?

The President. Well, no, this is something that we have underway in negotiation. And he has made it plain that he really does want to withdraw, and he would do that within a 12-month period, at the most. And, yes, he has some concerns then about our continued support to the Mujahidin.

I related to him what our concern is: that anything that -- well, it's very similar to Nicaragua -- anything that would force us to weaken the freedom fighters in either country at the same time that the governments of those two countries have a military. The Afghan army -- it's not only the Soviets that have been fighting. The Afghans have an army in that puppet government. The Sandinistas have a military even while they're pleading and demanding that the contras should disarm themselves.

I in turn have made it plain to them that there's no way that we could create such an imbalance, that what we must have is an agreement that sees the ability of the people in each country and on both sides to come together, and the people of that country decide on the kind of government they want, and a neutral government.

The President. I wouldn't like to see the Senate start amending this that would have to bring us back into negotiations of a treaty that is already resolved and, we believe, is probably really an historic event and the most forward thing that has happened between our two countries in the last 40 years. And, as I say, these other things are still -- they're not in a part of a treaty. They're part of the continuing negotiations.

The President. Well, I'm very pleased that it happened, because for a number of years, before I ever got here, I have been concerned about the very presence of nuclear weapons. And to hear this man now, without any urging from me, express his wish that we could totally eliminate nuclear weapons because of the threat they represent -- and he quoted back to me a line that I used as long ago as 1982 in speaking to some foreign parliaments, such as the British and the Japanese, and that is: A nuclear war cannot be won and must never be fought.

The President. I don't expect to be looking back 100 years from now. [Laughter] And I don't know whether that's the most important or not. I think that it's kind of important that for the last couple of years the battle going on in Congress between our two parties has not been a battle of how big will the new spending programs be, but a battle between what method we should take to eliminate the deficit. And I think that's kind of a step forward.

Jan Fisher, WTBJ in Miami. We, too, in south Florida are a little concerned about the Communist influence in our back door. Recently we have normalized relations with -- well, not normalized, but relaxed immigration policies with Cuba. What would you have to say to the folks in south Florida about all of this at this point?

Governor of a State myself and believing in federalism, I have to say that there are many things that I believe are rights that belong to the States and the local communities. And in fact, I am trying to have the Federal Government give back more authority to the States. I could quote Franklin Delano Roosevelt from his 1932 campaign for the Presidency -- and I was old enough that I was voting then, and did vote for him. But he said that one of his goals was to restore to the States and the local communities the rights that had been unjustly seized by the Federal Government. So, whatever they want to do on that -- but I do believe this: that there is no question but that Cuba is totally dedicated to the Communist cause and to that philosophy.

Cubans we expect to be coming into south Florida, there are real and severe economic concerns about how we can cope with 100,000 more folks coming into our area. Does the Federal Government have any plan at this point to help out with the city of Miami and Dade County?

But again, I have to say that -- because as a Governor I found so many times that when the Federal Government tried to help it couldn't do as well as the State could have done if we had been left alone. So, I am not going to make a snap answer here.

The President. They know very well how we feel about that. And we are going forward with clearing up our Embassies, and they won't be beset with the build-in bugs and so forth from here on. We've just simply declared what we are going to do in that regard. And the first part of your question was?

The President. Oh, let me just say I know there has been concern about that, and believe me, that is all taken under consideration -- for example, this matter in our position and where our frontline is in NATO, the people that have been concerned that somehow in this treaty we've weakened NATO because of the superiority of the Soviet Union in their conventional weapons.

No, we've still thousands, literally, of warheads on that front, which alleviate that difference between us. And it's true they have several times as many tanks and artillery pieces and so forth as NATO does. But tactical battlefield nuclear weapons have evened up that competition. And I can tell you now that it has always been our intention, and will continue to be, that before anything is done about those weapons there will have to be a parity achieved in arms reduction in the conventional state. And that's why we were so pleased when he himself volunteered his willingness that we should have equalizing and reduction of conventional weapons.

To follow up on an earlier question -- I'm Ken Watts, WAGA in Atlanta. We've learned today that on November 24th you signed an Executive order regarding the use of Federal troops at the Atlanta pen during the Cuban uprising. Could you explain that order and exactly what those troops would have been authorized to do by order?

The President. Very quietly, I issued an order that troops could be made available only on the basis to be used if it was necessary to save human life. And they quietly moved in. There was no great fuss about it, but they were available if they were needed to protect human life. And that was the total extent of the order.

During the past 5 years, thousands of dedicated citizen volunteers throughout our Nation have taken part in the programs and activities of National Drunk and Drugged Driving Awareness Week. These efforts just before the holiday season have proven enormously successful in increasing public awareness of the dangers of driving while impaired by alcohol or drugs. As the 1987 holiday season approaches, we need to focus once again on the terrible cost in human lives and suffering caused by drunk and drugged driving.

Although alcohol is still involved in more than half of all highway deaths, we are beginning to see signs of real progress in our battle against drunk driving. In 1986, 41 percent of the total traffic fatalities throughout our Nation involved at least one driver or pedestrian who was intoxicated, down from 46 percent in 1982. During the same period, the proportion of intoxicated teenaged drivers involved in fatal crashes dropped from 28 percent to 21 percent, the largest decrease for any driver age group. This is progress, but our battle is far from over. If we hope to realize our goal of eliminating intoxicated drivers from our streets and highways, we must continue the positive momentum of the last few years and resolve to do even more in the future.

Each of us can help reduce the senseless carnage on our highways by refusing to tolerate drunk and drugged driving and by becoming more aware of what can and ought to be done. We must insist upon efficient and effective criminal justice, find improved ways to detect and stop impaired drivers before a crash occurs, and increase our willingness to communicate our concerns to friends and family.

Of increasing concern is the combination of alcohol and drugs and its impact on the incidence of motor vehicle crashes. We should all be aware that driving after the use of drugs -- including prescription and over-the-counter drugs -- may create safety hazards on our roads and highways, and that combining drugs with alcohol increases these hazards.

In order to encourage citizen involvement in prevention efforts and to increase awareness of the seriousness of the threat to our lives and safety, the Congress, by Senate Joint Resolution 136, has designated the week of December 13 through December 19, 1987, as ``National Drunk and Drugged Driving Awareness Week'' and authorized and requested the President to issue a proclamation in observance of this week.

America, do hereby proclaim the week of December 13 through December 19, 1987, as National Drunk and Drugged Driving Awareness Week. I ask all Americans to show concern and not to drink or take drugs and drive or to permit others to do so. I also call upon public officials at all levels and all interested citizens and groups to observe this week with appropriate ceremonies and activities in reaffirmation of our commitment to refuse to tolerate drunk and drugged driving.

Witness Whereof, I have hereunto set my hand this 11th day of December, in the year of our Lord nineteen hundred and eighty-seven, and of the Independence of the United States of America the two hundred and twelfth.

As you know, we had an important visitor in Washington this week. General Secretary Gorbachev was in town for only 3 days, but though our time was short, we accomplished much. Now, with all the reports of INF, ICBM's, and SDI you've been hearing the last few days, I wouldn't be surprised if some people are a little bit confused by all those letters -- sounds like alphabet soup. So, let me just begin by trying to put all this into English that everybody can understand.

INF stands for intermediate-range nuclear forces. They include nuclear missiles deployed in the Soviet Union and Europe. When the Soviets first started deploying new INF missiles in the 1970's, the triple-warhead SS - 20's, they represented a totally new nuclear threat to our friends in Europe and Asia for which we had no comparable counter. In response, despite intense pressure exerted by the Soviet Union in Europe, NATO decided in 1979 that we would deploy a limited number of comparable missiles and, at the same time, push hard in negotiations to do away with this new nuclear threat.

For the first time in history, in the treaty that General Secretary Gorbachev and I just signed, arms control has been replaced by arms reduction. Well, actually, I should say arms elimination, because with this treaty an entire class of INF missiles, both U.S. and Soviet, will be destroyed. Now, the Soviets presently have many more INF missiles than we do, so they'll be destroying some 1,600 deployed warheads, while we destroy about 400. Now that the treaty has been signed, it will be submitted to the Senate for the next step: the ratification process. I met with the leadership of Congress yesterday morning, and I am confident that the Senate will now act in an expeditious way to fulfill its duty under our Constitution. So, I hope in the near future INF will be one part of the alphabet soup you won't have to remember.

Other letters you'll hear more about are START, strategic arms reduction talks, because we've made progress toward 50-percent reductions in strategic nuclear arsenals. This could be another historic achievement, provided the Soviets don't try to hold it hostage to restrictions on SDI. SDI stands for our Strategic Defense Initiative, the high-tech defense we're investigating to protect America and its allies against ballistic missile attack.

I met with General Secretary Gorbachev in Geneva in 1985 and in Reykjavik, Iceland, last year, he exerted every bit of pressure he could to try to make us give up SDI. Well, I, of course, had to disappoint him each time. Building a defense against nuclear weapons is a moral as well as strategic imperative, and we will never give it up. Our bottom line on SDI is simple: We will research it; we will test it. And when it is ready, we will deploy it.

Soviets have persisted in efforts to limit our vital testing in this area. But providing a strategic defense is too important to restrict the promise it holds for future generations. Defense, not just offense -- that is the promise SDI holds. The fact is -- and I'm afraid most of us in this country aren't fully aware of this fact -- the United States presently has to rely on a policy in which our nations hold each other hostage to nuclear terror and destruction. This is an intolerable situation. We will move forward with SDI; it is our moral duty.

I don't want you to think that this summit was taken up exclusively with arms reduction. I talked extensively with Mr. Gorbachev about our insistence that his policy of glasnost become more than a slogan, that we begin to see real progress on human rights. As I emphasized to Mr.

Gorbachev, nothing would convince us of the sincerity of glasnost so much as seeing progress in emigration, release of political prisoners, and allowing his people their most basic right to worship their Maker in peace, free of fear.

Finally, we talked directly about regional issues such as Afghanistan, Iran-Iraq, Angola, Cambodia, and Nicaragua. We stressed the urgency of action between our two countries in order to bring more cooperation to our efforts to resolve these conflicts on terms that promote peace and freedom. So, we have a long road to travel. But we've taken important steps, and with your help we'll make that journey.

It's an honor to address the Center for Strategic and International Studies, all the more so in this, your 25th anniversary year. During this past quarter of a century, CSIS has brought to bear upon our national security policy an extraordinary array of intelligence and insight, drawing from the academic, diplomatic, and business worlds alike. Always you've taken the high ground -- intellectually and morally. Always you've insisted upon bipartisanship, stressing that any successful foreign policy must be built, not upon a Republican or Democratic consensus but upon an American consensus.

It goes without saying that the Nation owes each of you a profound debt of gratitude. And if I may, I'd like to add a special word of thanks to one who, during his term as your president, has served this institution and the Nation itself, untiringly. Joe Jordan, would you please stand? And to another of your number, one to whom we owe gratitude as a founder of this institution, one to whom we all extend our best wishes as he prepares to become your new president -- former NATO Ambassador and my former Special Counsellor, David Abshire, would you rise? And I am also pleased to see in the audience my former National Security Adviser, Bud McFarlane.

Yet, as for a consensus on the specific policy means by which these American values are to be carried into action, that policy consensus is one that, with each major development in our foreign affairs, we must build for ourselves. So, I come to you today. The treaty that General Secretary Gorbachev and I signed last week represents, as you've been told, a landmark achievement and an important step toward a safer world. But there's promise of still greater progress in bolstering our security and in putting East-West relations on a sounder footing. And I want, as well, to share some thoughts on this.

And this brings me to my first point: The INF treaty that Mr. Gorbachev and I signed is not intended to achieve some kind of superficial shuffling of the superpower arsenals, some sort of rearrangement of the pieces on a chessboard.

All the talk of numbers, numbers, numbers in recent days might quite naturally have led people to feel this. Yet we must remind ourselves that what the treaty will accomplish is, if you will, something entirely real: Not the rearrangement of numbers, but the elimination of a grave danger to our NATO allies and our own troops in Europe and to our friends and allies in Asia.

Well, no doubt the Soviets intended to test NATO's resolve. And to be sure, the deployment of our Pershing II and ground-launched cruise missiles had to be carried out in the face of sharp protest, even mass demonstrations. I remember speaking in Bonn in 1982. Across a river, thousands of demonstrators chanted and marched. And I couldn't help thinking: What irony. For it was to secure the peace they sought that NATO decided to deploy the missiles they protested, and missiles such as they protested helped ensure their very freedom to protest. Yet NATO held fast. The deployment of our missiles commenced. And yes, it was when we showed strength, when it became clear that we would not be intimidated -- only after this had taken place did the Soviets finally begin to negotiate in earnest. The INF treaty represents the culmination -- the historic culmination -- of that long and arduous process. A first step -- and a critical one -- toward building a more durable peace.

Two final points about the process itself: First, as will be clear from all I just described -- I shuffled my notes up here pretty good. If I get off track, I will have to stop and tell another story. [Laughter] As will be clear from all I just described, this was not only an American effort but truly a Western effort. NATO had said from the first that we should be prepared to halt, modify, or reverse NATO deployments if the Soviets would eliminate the SS - 20 threat. At all NATO ministerial meetings since 1980, foreign and defense ministers have endorsed American efforts toward reaching a treaty, including our putting forward the zero-option proposal. And at a number of points during this process, our allies have asked that we alter or reshape our negotiating stance. And we did so. Our allies have been with us throughout, and we've been with them.

Well, given that the treaty accomplishes NATO aims and has the firm support of our NATO allies, but more important, given our duty to build a safer peace as we work to expand freedom, how can we fail in the end to hail this treaty as an historic achievement? No one thought before that first deployment that NATO had been ``denuclearized.'' No one then believed that the United States and Western Europe had been in any way been ``decoupled.'' Neither, then, can these charges be leveled against this treaty.

I know that some in Europe and in the United States, perhaps some in this room, view the treaty with anxiety. I welcome the Senate ratification hearings as a forum in which every concern arising from the treaty can be examined. I am convinced that simply by following their own course the hearings will lay anxieties to rest and help to build up the needed consensus. In the meantime, permit me to lay before you some considerations which I believe should form a major part of this dialog.

Well, join me now in looking beyond the treaty, in considering our treaty for the future. It's clear, to begin with, that maintaining the strength of the alliance is essential. For our part, let me assure you that we'll keep our American servicemen stationed in Western Europe. And let me ask, what more convincing form of ``coupling'' could there be than these hundreds of thousands of Americans and their dependents living and working among our European allies? Furthermore, let there be no doubt our commitment to the NATO strategy of flexible response will remain steadfast, assuring that aggression at any level cannot be successful. Specifically, we'll retain a modern nuclear deterrent on the ground, in the air, and at sea. Our commitment to NATO's permanent readiness to respond as necessary to any form of aggression also remains steadfast.

As you know, we're doing all we can to go on diminishing the nuclear threat. Above all, I'm pressing ahead for an effectively verifiable START treaty, reducing U.S. and Soviet strategic arms by 50 percent. And during the just-completed summit further concrete progress was made in this regard. As another vital component of our strategy for a safer future, we'll continue to move forward with our SDI program. As I said last Thursday in my address to the Nation, when we have a strategic defense ready to deploy, we will do so.

That, then, is the American position. With regard to our allies, in recent years we've seen the emergence of a willingness to seek a larger, more closely coordinated role for Western Europe within the broader framework of the alliance. We have seen, for example, the issuing of the Western European Union Proclamation on European Security, Franco-German defense cooperation, and steps by the United Kingdom and France to modernize their independent nuclear deterrence.

Well, we welcome this. Indeed, I would point out that while -- from 1981 to early 1986 -- the Soviets made it a condition of any INF agreement that French and British nuclear forces be included, we adamantly and successfully resisted this demand. We said there was no way, that we couldn't negotiate for our allies. As I said earlier this year at West Point, for these four decades, NATO has too often seemed an alliance between a number of partners and one very senior partner. Well, now the alliance must become more and more an alliance among equals; indeed, an alliance between two continents.

In the words of a member of your board of trustees, Henry Kissinger, the United States must -- and I'll quote -- ``welcome a European identity in defense, which in the end is bound to spur Atlantic cooperation.'' It'll be in this spirit that we and our allies will soon go forward to negotiate with the East on redressing the imbalances in conventional forces in Europe, while, of course, taking the steps we need to strengthen our own conventional forces. And we attach a similar high priority to redressing -- again, both through negotiations and our own force modernization -- the imbalance of chemical weapons which, at present, favors the Soviet Union. And we're acting here with a clear understanding that these imbalances must be addressed prior to any further reductions in the nuclear forces committed to NATO.

I've spoken today almost exclusively about arms reductions, I want to emphasize the Soviet relationship involves far more -- that arms reductions represent only one point of the four-part agenda we adopted for Geneva, Reykjavik, and Washington, and that we will insist on in Moscow as well. The other three points: genuine cooperation on bilateral matters; solid and lasting improvements on human rights; and as for regional conflicts, an end to Soviet efforts around the world to impose totalitarian regimes by force.

Unity, strength, persistence, and consistency -- these are the lessons of the INF negotiations, and they must form the basis on which we and our allies go on to new negotiations. Yet at the same time that we insist upon candor and realism -- insist, if you will, upon keeping our feet firmly planted on the ground -- let us not be afraid to dream and to let our hearts soar. ``Do not mock our dreamers,'' Heinrich Heine has written. ``Their words become the seeds of freedom.'' Who, indeed, would have thought during the difficult years of the late seventies and early eighties -- during nuclear freeze protests here at home and mass demonstrations in Europe -- who would have thought that a treaty like the one Mr. Gorbachev and I signed last week would ever be achieved?

So, yes, let us think realistically, but let us dream great dreams. And let us remember that perhaps the most fundamental consensus about our nation's role in the world is this: As Americans, it is our duty to ensure the peace while we work untiringly for freedom. Thank you. God bless you.

The crisis between the United States and Libya that led to my declaration on January 7, 1986, of a national emergency has not been resolved. The Government of Libya continues to use and support international terrorism, in violation of international law and minimum standards of human behavior. Such Libyan actions and policies pose a continuing unusual and extraordinary threat to the national security and vital foreign policy interests of the United States. For these reasons, I have determined that it is necessary to maintain in force the broad authorities necessary to apply economic pressure to the Government of Libya to reduce its ability to support international terrorism.

Like its predecessors, H.R. 2939, the Independent Counsel Reauthorization Act of 1987, raises constitutional issues of the most fundamental and enduring importance to the Government of the United States. During the years leading up to the original enactment of this statute, and thereafter, the Department of Justice has repeatedly expressed profound concern over the serious departures authorized by the act from separation of powers principles. The Congress has not heeded these concerns, apparently convinced that it is empowered to divest the President of his fundamental constitutional authority to enforce our nation's laws. In fact, H.R. 2939 contains a number of new provisions that aggravate the infirmities in existing law.

I fully endorse the goal manifested in the Independent Counsel Act of ensuring public confidence in the impartiality and integrity of criminal law investigations of high-level executive branch officials. Indeed, despite constitutional misgivings, my administration has faithfully and consistently complied with all of the requirements of the act. Even as the constitutional issues grew more clear, aided by the pronouncements of the Supreme Court in INS v. Chadha in 1983 and Bowsher v. Synar in 1986, we took extraordinary measures to protect against constitutional challenge the work of the more recently appointed independent counsel by offering each of them appointments in the Department of Justice.

Continuance of these independent counsel investigations was deemed important to public confidence in our government. Nevertheless, this goal, however sound, may not justify disregard for the carefully crafted restraints spelled out in the Constitution. An officer of the United States exercising executive authority in the core area of law enforcement necessarily, under our constitutional scheme, must be subject to executive branch appointment, review, and removal. There is no other constitutionally permissible alternative, and I regret that the Congress and the President have been unable to agree under that framework on a procedure to ensure impartial, forthright, and unimpeded criminal law investigations of high-level executive branch officials.

In view of the longstanding and continuing differences in the positions maintained by the executive and the legislative branches about the constitutionality of a statutory scheme providing for judicial appointment and supervision of officers exercising executive power, I am gratified that the constitutional issues presented by the statute are now squarely before the United States Court of Appeals for the District of Columbia Circuit. We will continue to express our constitutional objections in that case as it moves through the courts.

Action on this bill, however, cannot await the resolution of that case. In order to ensure that public confidence in government not be eroded while the courts are in the process of deciding these questions, I am taking the extraordinary step of signing this bill despite my very strong doubts about its constitutionality.

I am happy to send greetings to Jews everywhere as they celebrate the festival of Hanukkah. At this special time there is great joy in commemorating both the victory of the Maccabees and the miracle of the lights in ancient Israel.

There has been more than enough tragedy in Jewish history, but Jews have always believed in their own future. This faith brought victory to the Maccabees, accounts for the founding of the modern State of Israel, and explains the equally inspiring birth of the Soviet Jewry movement and the responsive chord it has struck among Jews throughout the world. These examples show that the message of Hanukkah is timeless. Its lessons inspire the struggles of today and the victories of tomorrow.

Conflict in the Third World can pose serious threats to our security interests. Low intensity conflicts, which take place at levels below conventional war, but above routine peaceful competition among states, can be particularly troublesome.

The attached report, prepared pursuant to section 1311 of the National Defense Authorization Act of 1987, responds to legislation passed by the Congress in 1986. It describes actions taken, and ongoing, as a result of our experience with low intensity conflicts over the last several years and highlights a broad-range effort to address problems associated with low intensity conflict and our Special Operations Forces. In that regard, in June of this year, I approved a new national policy and strategy for low intensity conflict and established a Board for Low Intensity Conflict that is chaired by my National Security Adviser. The essential elements of our low intensity conflict policy and strategy are described in the report.

We have also activated the new Unified Command for Special Operations, improved our special operations capabilities, and established the office of the new Assistant Secretary of Defense for Special Operations and Low Intensity Conflict.

More work lies ahead. The United States must continue to respond to challenges arising from low intensity conflict -- to defend our interests and support those who put their lives on the line in the common cause of freedom. For the United States to be effective in this most important undertaking, there must be public understanding and strong congressional support. I hope this report will contribute to a broader understanding of low intensity conflict and the support that our policy requires.

The President. It's our great pleasure to welcome to the White House a guest from a country with which we Americans have indissoluble ties of history, culture, and shared values: Prime Minister Goria from Italy. Although this is the first time that the Prime Minister and I have had the opportunity to talk alone, I welcome him as I would an old friend for Italy is an ally whose friendship America values and whose counsel we seek and trust.

Secretary Gorbachev and I signed the INF treaty. We in the United States are keenly aware that it was the political will and determination of European governments and peoples and our joint commitment to the NATO alliance that enabled us to conclude that treaty.

Yes, we had a plan: building a safer peace and freedom through strength. We stuck to the plan, even when many who are now taking bows tried to force us to abandon it, and the plan worked. Mr. Prime Minister, from the moment in 1979 when Italy stepped forward to do its part in deployment of INF weapons, it has been an indispensable partner and leader in this process for peace.

In addition to developments in Europe, the Prime Minister and I discussed the Persian Gulf, where the Italian and American Navies work side by side to keep international sealanes open. Both our countries understand that the war between Iran and Iraq poses dangers that extend far beyond that troubled region. Both our nations will continue strong support in the United Nations Security Council for the efforts of the Secretary-General to bring an end to the conflict.

Prime Minister Goria and I last saw each other, he was Minister of the Treasury, and we were both participants in the Venice economic summit. Today we again talked about the international economic situation and the steps necessary to strengthen international trade and finance.

Over the next few days, Prime Minister Goria will be meeting with Secretary Shultz, Secretary Baker, Secretary Carlucci, congressional leaders, and private businessmen, among others. I'm happy to report that as he embarks on the remainder of this busy and important visit U.S.-Italian relations could hardly be better. Mr. Prime Minister, we're indeed pleased and honored to have you as our guest.

President Ronald Reagan for the particularly friendly welcome he extended to me in Washington today. This testifies to the longstanding friendship; solid alliance; and common cultural, moral, and ideal values which historically bind Italy to the United States.

I have conveyed to President Reagan the greetings which the Italian Nation; the President of the Republic, Honorable Francesco Cossiga; and the Government send to him and to the American people, a greeting which in its warmth reflects our enduring friendship, our present sound cooperation and alliance, and our common and firm conviction of the need to work together for the future of our two countries.

I had the pleasure of recognizing, once and again, in President Reagan a statesman that the whole world respects and the friend which the Italian Nation particularly admires -- the statesman who was able to give a new and radically innovative dimension to the problems of nuclear disarmament by accomplishing the destruction of arms not through other arms but by means of an international treaty. Our talks were marked by a great mutual cordiality and have proved to be extremely fruitful. We reconfirmed our common commitment to seeking a more secure, more stable, and less threatened peace that we will be pursuing in the framework of the alliance which binds us.

I listened with the utmost interest to what the President told me about his recent historic meeting with the General Secretary of the Soviet Communist Party, Mikhail Gorbachev. I very much wish to personally express the Italian Government's profound satisfaction in the results achieved during this summit, along with the deep-felt hope that the understandings reached may further develop, thus opening new negotiating prospects in the field of nuclear as well as conventional and chemical disarmament.

The agreement reached has the full support of the Italian Government, which expresses the hope that it will be promptly ratified. The agreement resulted in great part from the cohesion and steadfast determination which the Atlantic alliance demonstrated. In this context, President Reagan has particularly valued the role which Italy played in maintaining Western solidarity. We expressed the common hope that within this framework of renewed dialog with the Soviet Union a solution may also be found to the question of Afghanistan.

East and the prospects of overcoming this longstanding crisis in the full respect for the sovereignty of the states and the rights of the peoples in the region. A common concern was expressed over the war between Iran and Iraq in the Persian Gulf and the continuing conflicts and tensions in that delicate area despite United Nations repeated appeals for a cessation of hostilities.

I confirmed to President Reagan our commitment towards seeking a solution to these questions, also within the framework of the seven most industrialized countries of the West, in view of the Toronto summit next June.

We restated our intent to ever increasingly develop the bilateral relations between Italy and the United States and to promote trade and cooperation in all fields, as their progress must fully reflect the excellent political relations existing between our two countries. We agreed that the same open spirit must inspire the relations between the United States and the European Community, a community which Italy considers a major point of reference and an essential political goal, which our country unanimously wishes to strengthen.

Nancy and I are sorry to learn the jury's decision in Mike Deaver's trial. He has been a longtime friend and has served with dedication. Beyond that I cannot comment further at this time, since the decision will likely be appealed through our court system.

I very reluctantly accept your resignation as Ambassador to Switzerland, as I have so highly valued your splendid services. I do understand, however, your strong desire to be closer to your lovely family and to begin your pursuits in the private sector.

You have been one of my most steadfast and effective supporters, and I have greatly appreciated your efforts on my behalf before I became President and throughout these past seven years. I also know you will leave Switzerland reluctantly, as you did when I called upon you in 1983 to serve on the senior White House staff as Assistant for Public Liaison. Your sacrifice and exemplary performance in the White House helped to create the enormous public support we received for a second term and for many of the policies I asked you to advocate. I have missed you since your return to Switzerland in 1985, but commend you on resuming your duties as Ambassador with customary grace, warmth, and intelligence. I am sure the Swiss will miss you, too. Throughout your two tours as Ambassador, you upheld the highest standards of diplomacy. The fact that Swiss-American relations are cordial and harmonious is a testament to your considerable ability, charm, and energy. But we have your promise that, even in the private sector, you will keep your great talents employed to advance the principles of liberty and peace through strength, and for that I am extremely grateful.

Having had the great privilege and honor of serving in your Administration for close to seven years, I believe I must begin to make plans to return to the United States and to my three children, all of whom are now residing there. With this in mind, I intend to offer you my resignation and, by your leave, will depart my post on July 15, 1988.

With the opportunities I will be pursuing in the private sector, I wish to assure you that one of my foremost aims will be to continue to advance the principles which you have so ably represented to the American people. It is those principles which attracted me to you when I served as a delegate committed to your candidacy at the 1980 Convention when it was also my special privilege to serve as co-chairman of the platform subcommittee on foreign policy and defense. I was deeply moved, therefore, when you offered me the opportunity, in September of 1981, to serve as Ambassador to Switzerland; then in March of 1983 to serve as your Assistant for Public Liaison in the White House; and then in May of 1985, to serve again as Ambassador to Switzerland.

The steadfast support you have given me during the times I have been Ambassador to Switzerland and during my service to you in the White House has been a source of great satisfaction. It is particularly gratifying that you asked me to serve for the balance of your Presidential term.

I believe, however, that I have accomplished the major tasks you set for me. This year alone we have concluded four major agreements with the Swiss government in the areas of judicial assistance, law enforcement cooperation, civil aviation, and export control.

Despite the progress we have made in strengthening Swiss-American relations, it is with utmost reluctance that I will leave this beautiful country that has such a deep reservoir of goodwill for the United States. The strong character of the Swiss people, their devotion to the sanctity of the individual, decentralized government, democratic capitalism and military preparedness as the best guarantee of peace with freedom make them natural friends of liberty everywhere. Their understanding of American ideals is profound and enduring, as their own Constitution attests.

The President. All the same, I will keep my remarks this day brief. I often think that when Grant arrived in Washington in 1864 to be nominated General-in-Chief the longest speech he managed was: ``Gentlemen, in response it will be impossible to do more than thank you.'' Then there's the comparison of course between George Washington and William Henry Harrison. Washington gave an inaugural address of fewer than 200 words and went on to become a great President. Harrison spoke for almost 2 hours at his inauguration, caught pneumonia, and was dead within a month.

The reason for brevity today is that this is virtually a family event. Ann McLaughlin has served our administration in the Treasury Department and the Department of the Interior. She's proven her skill and dedication. She's placed her stamp on our so-called revolution. And today she's stepping up to a position in which she'll be able to do still more.

The purpose of the Department of Labor is, in the words of the act that created it, ``to foster, promote, and develop the welfare of the wage earners of the United States.'' Ann will bring to the Department her own special competence, to quote her before the Senate: ``I will be fair but firm.'' Well, then, too, she will bring to the Department her passionate sense of commitment. As I said, she'll work to further the economic beliefs that have gone into the making of our revolution, especially the belief that the best we can do for America's workers is not give them endless government programs but provide them with new jobs and a growing economy. Indeed, for some 60 months now, the American economy has averaged well over 200,000 new jobs a month.

Ann, you must ensure that the work force of the future is ready and willing to keep America the most productive and innovative nation on Earth. At the same time that she'll be planning for the future, Ann will be on Capitol Hill dealing with Congress on major issues, such as parental leave and mandatory health benefits. And underlying all Ann's energy and skill, all her immense administrative ability, will be an abiding faith in the dignity of work. In her words: ``Hard-working women and men built America. To be able to assist them is a singular responsibility, because it is in our daily work that we find some of our greatest opportunities for good.'' -- her words to the Senate. Ann McLaughlin, congratulations.

You know, Mr. President, in the months that I spent away from official Washington, I never really felt apart from this team at all. This is a testimony to what your leadership means to me and what I think it means to every American. We're all renewed by your vitality, by your ideals, and your focus on America's future. Evidence of that during this last historic week was certainly ample.

Today the American worker's take-home pay is no longer ravaged by that double-digit inflation or by spiraling taxes. Today over 14.5 million more jobs exist in this the longest peacetime recovery in history. Today we are confident of ourselves and of our nation. But also, today I think of what remains to be done. American workers deserve safe and protected workplaces. They need affordable child care. They deserve secure pensions, fair and equitable wages, benefits, education, training opportunities. You know, workers are people we know -- our parents, our sons, our daughters, our friends, our colleagues, and our neighbors. The future of the American work force and the American workplace will look nothing like it does today and will bring tremendous challenges. My responsibility to you and to the millions of American workers is to prepare them, and us, for that tomorrow.

I believe the Labor Department's role is to ensure the transition to a continuing competitive and productive future. We must provide for an economy where labor and management will work together to meet the competition from abroad. The day must never come when skilled workers have to be imported. We must never have a worker deficit in this country, because we've failed as a nation to provide opportunities for excellence in education and training. These past 6 years, we have put millions of Americans back to work. Now our goal is to keep America working.

I am deeply honored, Mr. President, by the office you have entrusted to me. With your support and the support of friends and family in this room and with my dedicated staff at Labor and the wonderful Labor Department workers, there is nothing we cannot achieve in this next year. I feel awed by the responsibility, but tremendously eager and enthusiastic to take on the challenges. Thank you so much.

The President. It's been a great pleasure for me today to meet with Senator Dole and to discuss his support for the treaty signed here during last week's summit. The INF treaty was the end result of a process that took over 6 years to arrive at the moment of signing.

As a matter of fact, I did so at the National Press Club. And many of the points contained in the agreement were hammered out through tough negotiations on both sides. I welcome the support of the Senate Republican leader and count on his efforts to help ensure Senate ratification.

I understand there's a certain degree of apprehension about reaching any agreement with the Soviet Union, but I believe that once the details have been closely examined the consensus will be that the INF treaty is a solid step forward, a recognizably positive move for America. The treaty is consistent with the goal set out by the administration from its first days.

Building up our defensive strength was designed to convince the Soviet leadership that they couldn't win an arms race. The second half of the formula is reaching agreements to reduce weapons on both sides to an equal and verifiable level. Such reductions are in our interest and the interest of world peace. This treaty accomplishes exactly what we set out to do.

First and foremost, it is the first agreement in history to reduce, not simply limit, the buildup of nuclear weapons. The Soviets are in fact giving up more weapons in order to reach equality at a lower level. This is a breakthrough precedent that can serve as the basis for progress in other areas. Furthermore, this treaty is not based on some notion that the Soviets can now be implicitly trusted. Given their record, I would never have signed a treaty that did not contain the most stringent verification regimen.

There's been an impressive exchange of data, and there will be continuing exchanges after the treaty goes into effect. There will also be the right of on-site inspections to confirm what we've been told. During the entire process of destroying the INF missiles, each side has the right to observe in order to ensure compliance with the treaty. We will even be monitoring the facility where their SS - 20 missiles were assembled and have the right to visit other INF missile facilities on short notice. It's not a matter of trust. We will watch, inspect, and be present for the destruction of these missiles. And for 13 years after the treaty enters into force, American personnel will be on-site in the Soviet Union to make sure there are no more SS - 20's being produced.

Succinctly put, this treaty contains verification provisions and other safeguards that should impress even hardened skeptics, however. But I believe some of our opposition is not just a result of a perceived defect in the treaty but also flows from a concern that our country will continue to deal with the Soviets from a position of realism and candor. This treaty is reason for hope. It is a good first step, but we're not letting our guard down, and we don't want anyone to have expectations that cannot be met or verified. As Jefferson and other Presidents before me have stated and restated: Eternal vigilance is the price of liberty. That's never been more true than today, and we'll remain vigilant and realistic in dealing with the Soviet Union. This treaty is consistent with that commitment: a verifiable trust. I'm confident that over these next several weeks, as more Senators have the opportunity to review the terms and provisions of this agreement, that they'll come to the conclusion that it deserves ratification.

Dole. As I told the President a couple weeks ago when we were asked about the treaty, I said give us some time to look at it, some time to read it, and some time to analyze it. And I've done precisely what I told the President I would do. I've not only read the treaty, I've had the opportunity to have it analyzed by experts, in and out of government. And I've spoken directly with our key NATO allies. And I've had a series of meetings with the President and members of the administration to address my concerns.

In all of this, I've been concerned not only about the treaty itself but also about its strategic and political implications. Now that the treaty has been negotiated and signed, the focus will shift to the Senate. The Senate will decide whether this treaty goes into effect or not. And as the Republican leader, I will lead the fight for its approval in the Senate. I've been the point man in the Senate for the President's national security programs. And over the years we've won big critical fights, and I hope that we can win this one, too. What we want, and what I told the President just a few moments ago, is a big bipartisan majority.

I think it's also fair to say -- and we've discussed this with the President, with Colin Powell and others -- that there are areas of concern that have been identified, special concerns to me and my colleagues, whether it's verification or compliance and the imbalance of conventional forces in Europe. And I think by addressing these areas, working with the President, working with the administration, the Senate can strengthen the treaty even further, while not requiring renegotiation with the Soviets. And I think we've been assured that we can work together on these areas. And that's the only intent and the only purpose of it.

I guess I would say, as I said a couple of weeks ago, that as soon as I've been satisfied that we could verify and that there was compliance and there was strong support from the allies -- pretty much what the President said in his next-to-last paragraph -- as soon as other Senators go through this process, you're going to see support building for the treaty.

And finally, I think we're all very grateful to the President -- talking now about my colleagues in the Congress, in both parties -- for his outstanding work, and for his efforts that led to the signing of this very significant agreement a little over a week ago.

The President. No, there's nothing of that kind here. I am, and have always been, neutral with regard to the political race. I'll answer that one to get that in the clear. He's here as the leader for our side in the Senate, and I was here to bring him here, because we have a common interest in getting a treaty ratified.

President has been briefed on yesterday's elections in the Republic of Korea. He will be sending his congratulations to the winner. The enthusiasm of the Korean campaign and the remarkable voter turnout of 90 percent is impressive.

As we approach the end of the year, I thought I'd give you a brief update on several important issues. First, the historic treaty we signed last week eliminating an entire class of U.S. and Soviet INF missiles -- it's taken 6 years of tough negotiating to get this far, but signing a treaty doesn't end the process. It must now go before the full Senate for ratification. They will certainly want to look very closely at this complex treaty, but I'm confident that once they do they'll find it solid, verifiable, and most definitely in America's interest.

Well, next let's turn to events on the other side of the world. South Korea has long been a brave, free world outpost on the border of a hostile northern neighbor. Economically one of the freest nations on Earth, they have demonstrated to the world the wonders of economic liberty. In three short decades, South Korea's vibrant free markets have catapulted that nation out of the ranks of the Third World and into the forefront of world economic growth.

South Korea has long known most of the freedoms we now enjoy in this country: freedom to work where and how one pleases, freedom of speech, freedom of worship. And this week, South Korea has taken a great stride toward full democracy. For the first time in 16 years, they voted in a direct election for their President. Ninety percent of the country turned out to show its commitment to the democratic process. Mr. Roh Tae Woo, the candidate of the Democratic Justice Party, has emerged the winner by almost 2 million votes, and I've sent my congratulations to him. But the most important victory is for democracy. As Americans know, and as Koreans are finding out, elections have losers as well as winners. The essence of democracy is the willingness to accept the results and, perhaps, to try again at the next election. I particularly welcome Mr. Roh's calls for reconciliation as he undertakes to form a government with broad national support. We look forward to continuing cooperation in security and trade and competing in next September's Olympics in Seoul.

Now, if I may return to Washington, I'd like to speak for a moment on the budget process. I have often criticized Congress' habit of putting the appropriations for almost the entire Federal Government into one mammoth bill called a continuing resolution. Each year, I'm given a choice: hold my nose and swallow it whole, wasteful spending and all, or veto the entire bill, closing down much of the Federal Government. I do not believe that this is what the Founding Fathers had in mind when they gave the President the power to veto individual appropriations bills. That said, I expect this year's continuing resolution to meet the budget agreements worked out between the administration and the congressional leadership. One item we'll be looking very closely to see included is funding for the freedom fighters in Nicaragua.

Recently, a high-ranking defector from the Sandinista Communist government has come forward with some shocking revelations. The Nicaraguan Communists, it seems, have been planning all along to use the Central American peace process as a weapon to consolidate their power. Daniel Ortega as much as confirmed this last week when he publicly stated that, elections or no elections, the Sandinista Communists would never give up power. To make sure they would never have to, the Sandinistas have negotiated a secret agreement with the Soviets and Cubans that calls for a major military escalation in Nicaragua over the next 7 years, including the delivery of MiG - 21 jet fighters and enough military supplies to increase the army to 500,000 soldiers. Such an escalation would create an unprecedented threat to the national security of the United States. As these secret plans were being made public, the Sandinistas' Defense Minister confirmed them -- bragging, in fact, of a 600,000-man army by 1995. So, it's clear to all but the most naive that the Sandinista Communists have been cynically manipulating the peace process, trying to lull others into a false sense of security while they busily plan military dominance of the entire region.

It has never been more clear why we must fund the freedom fighters. The freedom fighters brought the Sandinistas to the negotiating table; only the freedom fighters can keep them there. That's why our continued support is imperative and why I will insist that the continuing resolution contains adequate funding for adequate aid. If there were any doubts before, it's certainly clear now: Making sure the freedom fighters remain a viable force in Nicaragua is the only way to make the peace process go forward, to give peace and democracy a chance in Nicaragua.

Montreal Protocol provides for internationally coordinated control of ozone-depleting substances in order to protect public health and the environment from potential adverse effects of depletion of stratospheric ozone.

In this historic agreement, the international community undertakes cooperative measures to protect a vital global resource. The United States played a leading role in the negotiation of the Protocol. United States ratification is necessary for entry into force and effective implementation of the Protocol.

By the authority vested in me as President by the Constitution and laws of the United States of America, and having concluded that the ability of the United States to achieve the statutorily prescribed policy (35 U.S.C. 200) of using the patent system to promote the utilization of inventions arising from federally supported research or development requires that Federal agencies follow uniform policies in administering patents and licenses conceived or first reduced to practice during the course of federally funded research, Executive Order No.

Section 1. All Executive departments and agencies of the Federal Government shall be closed and their employees excused from duty for the last half of the scheduled workday on Christmas Eve, December 24, 1987, except as provided in Section 2 below.

The President. I have a brief statement here. The first thing I think I should explain is, no, I have not been cleaning out my desk. These stacks of paper contain the Federal budget for 1988 and represent a lot of hard work to forge an agreement between the administration and the Congress to place our country on the right course toward reducing the Federal budget deficit and continuing the longest peacetime expansion in history. The bipartisan leadership in the House and Senate is to be commended, not just for reaching a 2-year deficit reduction agreement on November 20th but for implementing the first installment of that $75 billion plan.

October 21st I issued a call for action on the Federal budget deficit, and together my representatives and those from the Congress spent the next 4 weeks forging this package. That agreement was the first step toward placing our country on a reliable and credible budget course, but there's still more to be done. My pledge to you, then and now, is to move forward with our deficit reduction plan. So, today I'm signing these bills. The first contains the 13 regular appropriations or spending bills, and the second includes the necessary revenue and entitlement changes. But there are several other items about these bills that are extremely important.

First, funding for those fighting for freedom in Nicaragua will be continued. As the Central American peace plan enters a critical period early next year, it's important that our support for the freedom fighters in Nicaragua not waver, particularly when the Sandinistas have confirmed plans to build up to a 600,000-person military force in that country.

So, while I agree with these bills at this time, it must be said that wrapping up the entire legislative business of our country into two thousand-page bills on the eve of Christmas is not the way to do business. The normal legislative process should have produced 13 separate appropriation bills. It did not.

Instead, we ran the Government on a string of stopgap funding measures, pushing the Government right to the brink of defaulting on its commitments to the American people. As we look forward to the new year, our commitment should be to correct the inequities and the deficiencies in the Federal budget process. The foundation has already been laid with this 2-year budget plan, and I hope the Congress will join me in building for the future prosperity of our country.

The President. Well, we think it is regrettable, and our State Department has been talking to both sides in this, trying to get both sides -- there has been provocation on both sides -- to get them to cease.

Mr. President, on the budget, sir, this whole exercise was designed, at one point, to send a signal to Wall Street of confidence in the economy and confidence in the way that the administration and Congress were going to attack the deficit. Yet the markets went down again today; the dollar was still going down today. And the verdict seems to come back of one of failure or at least of having done too little, too late.

The President. I'm more concerned about the way it is being presented -- ignoring the fact that in many of the cases the charges appear on the front page, and then when it's determined that the charge was meaningless and had no foundation, that appears on page 29.

Under our constitutional system of separation of powers, the President has special responsibilities in the area of foreign affairs. As the Supreme Court noted in United States v. Curtiss-Wright Export Co., the President is ``the sole organ of the Federal government in the field of international relations.'' Certain provisions in H.R. 1777, however, could be construed so as to interfere with the discharge of these responsibilities. The Act forbids the closing of any consulates and requires both the initiation of specific foreign negotiations and the termination of the United States-Soviet Embassy Agreements. I am signing the Act only because, pursuant to House Joint Resolution 395 (the continuing appropriations measure which I also signed today), these provisions will not take effect until two years from today. During the remainder of my Administration, I shall seek repeal of these provisions.

Other provisions of H.R. 1777 require or prohibit the initiation of negotiations in the field of international relations. Consistent with my constitutional responsibility to conduct these negotiations, I construe these provisions as being subject to my exclusive authority to determine the time, scope, and objectives of any negotiations.

Section 163 of the Act the Department of State, by regulation, shall implement a program of counter-intelligence polygraph examinations for members of the Diplomatic Security Service. I am interpreting this requirement consistent with my position concerning the discretion of agency heads to determine when polygraph examinations will be conducted in specific cases.

Christmas, as the carol tells us, is ``the most wonderful time of the year.'' We see it in the excited eyes of a child -- an excitement easy to explain. What with the sights of brilliantly decorated trees, the sounds of familiar hymns and songs, and tastes of fresh-baked cookies and other treats, and above all the long-anticipated visit from St. Nick, Christmas for children is a time unlike any other.

That is true for grownups as well, of course; the joy and meaning of Christmas only deepen as we grow older. We still find pleasure in exchanging greetings and gifts, and we still delight in the warm and colorful images of the holiday. But we perceive ever more clearly, as did Scrooge, that the true beauty and wonder of the season lie in the Christmas spirit of giving of ourselves for others -- the message of the Prince of Peace whose birth we celebrate. At Christmastime we accompany shepherds and Wise Men to the stable as of old, where we relearn the timeless and priceless lessons of love, humility and sacrifice, where we see the Christmas spirit as God's love flowing through so many people all at once.

We can all be truly proud of the contributions of Swedish Americans to our beloved land, of the close ties between the United States and Sweden over the years, and of the devotion to democracy that our peoples share.

Americans first discovered both the potential uses and the attractions of skiing from reports of the achievements of an early skier, pioneer mail carrier John A. ``Snowshoe'' Thompson, who transported letters and parcels in a backpack as he covered his 90-mile territory through the Sierra Nevada. During his two decades of devoted service, 1856 - 1876, he won a well-earned reputation for heroism and faithfulness as he traversed the mountains, first on his large, handmade skis and later by sleigh, to keep frontier communication open between Nevada and California.

Through the years, skiing has experienced revolutions in equipment, technique, and participation. Wood skis were replaced by metal ones, which then gave way to fiberglass, and bindings have improved greatly. Today some 15 million Americans engage in Alpine or Nordic skiing, and highly skilled and dedicated skiers and biathletes vie for coveted positions on America's Winter Olympics squads.

Skiing helps people improve coordination as they attain or maintain good physical condition. Skiing provides enjoyment for spectators as well as participants, fosters appreciation for the outdoors, and affords the opportunity to enjoy winter and its splendors. Skiing also increases the recreational uses of national forests and provides winter employment and income for residents of rural communities.

Witness Whereof, I have hereunto set my hand this twenty-third day of December, in the year of our Lord nineteen hundred and eighty-seven, and of the Independence of the United States of America the two hundred and twelfth.

Roosevelt once said: ``The foundation stone of national life is and ever must be the individual character of the individual citizen.'' Nowhere has that fact been better demonstrated than in our national quest for excellence, which has spurred Americans to strive to live up to the highest ideals of our nature and our heritage.

For three decades, that quest has been best symbolized by the magnificent achievements of our space program. The program has proved beyond a doubt that, with will and resolve, Americans can draw upon the insights and inventions of generations past and accomplish great things. In striving for excellence in space, we have expanded the horizon of human potential, brought countless scientific and economic benefits back to Earth, and demonstrated to ourselves and to the world our national vitality, courage, and imagination.

When the space shuttle is launched again, the world will know that, once again, the United States is back in space -- ready to accept its boundless challenges and eager to pursue its countless opportunities. With the shuttle, we will move toward our next logical step -- building and operating a permanently manned space station.

Witness Whereof, I have hereunto set my hand this 24th day of Dec., in the year of our Lord nineteen hundred and eighty-seven, and of the Independence of the United States of America the two hundred and twelfth.

Specifically, after considering various private sector requests for review concerning worker rights in Chile, and in accordance with section 502(b)(7) of the Act, I have determined that Chile, which was previously designated as a beneficiary country, is not taking steps to afford internationally recognized worker rights. Therefore, I intend to notify the Congress of the United States and the Government of Chile of my intention to suspend indefinitely the GSP eligibility of Chile.

I have further determined to suspend the application of increased duties so long as the European Community member states continue their present importation practices with respect to United States exports of relevant meat products.

The United States Trade Representative is authorized to suspend, modify, terminate, or terminate the suspension of the increased duties imposed by this Proclamation, upon publication in the Federal Register of his determination that such action is in the interest of the United States.

This Proclamation, including the imposition of increased duties and their immediate suspension, shall be effective with respect to articles entered, or withdrawn from warehouse for consumption, on or after January 2, 1988.

Unless EC member states are allowed derogations to continue their present importation practices, implementation of the Directive will prohibit imports into the European Community of any meat produced from animals treated with growth hormones, thereby severely disrupting exports of U.S. meat to the European Community. Such a prohibition is not supported by valid scientific evidence.

However, the European Community has provided assurances that all member states will be permitted to continue, and will continue, their present practices with regard to the importation of U.S. meat products for an additional 12 months. Therefore, I am suspending the application of those measures so long as the EC member states continue their present importation practices with respect to United States exports of relevant meat products. I expect the European Community to allow appropriate dispute settlement procedures to proceed expeditiously.

November 25, 1987, I announced my intention to raise customs duties to a level of 100 percent ad valorem on as much as $100 million in EC exports to the United States in response to the implementation of the Directive. I also announced that the products against which retaliatory action would be taken would be selected after a comment period ending on December 11, 1987. Finally, I announced that the sanctions would be effective soon after January 1, 1988, unless the EC had acted by that time to ensure that the Directive does not impede United States meat exports.

President today signed a proclamation imposing and temporarily suspending duties on approximately $100 million worth of exports from the European Community (EC) to the United States. This implements his November 23 decision to retaliate against an EC unfair trade practice, but to suspend the sanctions for as long as it does not restrict U.S. meat exports to Europe. The action follows careful analysis of comments received in public hearings.

EC recently voted to allow meat imports to continue for an additional year; therefore, the President has suspended today's sanctions provided U.S. meat exports to Europe continue without interruption. He has instructed the U.S. Trade Representative to monitor the situation. If U.S. meat exports to the Community are found to be interrupted during this period, the Trade Representative is authorized to reimpose the sanctions. The President hopes that a permanent solution can be found to this problem based on scientific evidence over the next year.

This action is being taken under authority granted to the President in section 301 of the Trade Act of 1974. This administration has been more aggressive in using this enforcement tool against unfair trade practices than any previous administration. Today's actions are intended to maintain unimpeded access for American producers in a fair, competitive marketplace, without improper interference from foreign governments. The President intends to continue to pursue aggressive enforcement of these laws and, when necessary, take retaliatory measures equal in severity to those unfair trade practices aimed at American exporters.

Nancy and I hope you and your family are enjoying this holiday season. This is a time of two religious observances which go to the heart of America's Judeo-Christian heritage: Christmas and Hanukkah. This is also a traditional time of merriment and good cheer, a time of family and home and of Christmas trees and gift-giving. That spirit of generosity that is so evident during the holiday season is something we've tried to foster during the past 7 years of this administration. Here at the White House, we call it the Private Sector Initiative Program. You probably think of it as good, old-fashioned Americanism -- neighbor helping neighbor.

One of the opportunities my current job affords me is having the access to information that gives me a broad picture of what is happening throughout our country. There is always much to improve. But I can assure you that the spirit of good will and benevolence, an aspect of our national character recognized since the early days of our Republic, remains a vibrant part of the American way of life. You may be surprised to learn, for example, that since 1980 charitable giving in the United States has increased 77 percent, from $49.08 billion to $87.22 billion in l986. I don't think there's any better gauge for the soul of a nation or the essential goodness of a people than an accounting of their personal involvement in helping others, either through donations of money or time. And voluntarism is still a strong force in communities throughout our country.

The stories are as numerous as they are heartwarming. One of them is about an engineer from Vicksburg, Mississippi, named Bob Carver. For 5 years straight, Bob spent the holiday season driving a truck to raise money for the Salvation Army. To date, he has raised over $20,000, which has bought Christmas toys and food for the needy, sent children to summer camp, and helped pay the utility bills for the elderly. Bob uses his annual leave to haul cargo for his tractor-trailer rig, which is affectionately known as the ``Santa Express.'' The profits go to helping others. God bless you, Bob.

Then there's Ruth Heywood, of Casa Grande, Arizona -- a single woman, 74 years old, living only on her pension benefits. Even though her own financial resources are limited, she overflows with love and is dedicated to helping others. Each year she spearheads a local effort to provide the needy and the poor in spirit a festive Thanksgiving and Christmas celebration. Ruth provides the energy and the inspiration. As the holiday season approaches, she visits grocers all over town to solicit donations of food, plates, and utensils. She coordinates transportation and arranges meals to be delivered to the homebound. She also handwrites hundreds of invitations and personally gives them to the less-fortunate citizens of her community. Every year people who thought they were unloved and forgotten are shown that people do care. The people of Casa Grande are proud of Ruth. We can all be proud of her.

I recently received a letter from David Rayl of Bald Knob, Arkansas, telling me about how, with hard work and private and corporate donations, he is able to play Santa to hundreds of needy families. His yearly project makes a lot of kids happy who otherwise might face a bleak holiday. David, who teaches at a local elementary school, added in his letter, ``Perhaps you're not too interested in something this small, but small things add up to big things.'' Well, I happen to believe that it is the small things, the little acts of love and kindness happening every day across this country, that make us a great nation. Yes, small things add up to big things. This country can be no greater than the goodness of its people.

Helping others is just our way, part of our national character. Perhaps it reflects that we as a people not only enjoy this holiday every year as time off from work but also take to heart the spiritual meaning of Christmas and Hanukkah.

This is the time of year when Americans gather in the company of their families and friends, make resolutions for the New Year, and reflect on the year gone by. It is precisely at this time, when we are thankful for our blessings of liberty, that we should remember the valiant struggle of a brave people located far from our shores.

Eight years ago, on December 27, 1979, the Soviet Union invaded Afghanistan in an unprovoked and blatant affront to both human decency and international law. The Soviets promptly installed a series of puppet dictators and since then have attempted ruthlessly and systematically to destroy the ability of the Afghan people to resist. Despite 8 years of occupation, they have not been able to subdue the proud people of Afghanistan.

Gorbachev and I discussed this issue during our recent meetings here in Washington. At that time I asked him to announce a timetable for troop withdrawal, including dates when this withdrawal would begin and end. I call once again on the Soviet Union to translate its declared intentions into reality by promptly and irrevocably withdrawing all Soviet forces from Afghanistan. Let 1988 be the year of action, the year that will see the Soviet Union end once and for all its brutal occupation of Afghanistan. After 8 long years and despite their unrelenting efforts, the Soviets simply have failed to defeat the Afghan resistance on the battlefield. At the same time, the world has repeatedly and clearly called for the prompt withdrawal of all Soviet troops. The United Nations most recently approved by record votes resolutions against the Soviet occupation and abuse of human rights in Afghanistan.

The people of Afghanistan have, as much as any people in history, won the right to freedom and independence. We applaud their commitment and steadfastness, for their cause is the cause of free people everywhere. Let us pray that in the year to come a free and independent Afghanistan will again take its place among the community of nations.

Adjustment Act of 1987. This legislation will provide, as proposed by the administration, a 4.2-percent cost-of-living increase in the monthly benefit checks of over 2.2 million veterans with service-connected disabilities and their dependents and to about 310,000 surviving spouses and children of veterans whose deaths were service-connected. The 4.2-percent increase is the same as the percentage increase that Social Security beneficiaries and veterans pensioners will receive.

However, the substantial lead time required to make computer system changes will result in March payments being the first to reflect the increase. The March payment will also include a lump sum adjustment for the January and February payments.

The administration earlier this year submitted to the Congress a legislative proposal to make the cost-of-living adjustment automatic for veterans' compensation programs. This would place compensation recipients on par with veterans' pension and Social Security recipients, who will see the 4.2-percent increase in their January payments. Enactment of the administration's legislative proposal will assure a similar delay will not occur again.

Mr. President, you said several months ago that you believed both Colonel North and Admiral Poindexter eventually would be found innocent of any crimes in connection with Iran-contra. Do you still believe that?

The President. Yes, from the very beginning I've said that to consider a pardon would leave -- even if I did that -- would leave them under a shadow of guilt for the rest of their lives. I think, we have to let the judicial process proceed.

I feel confident that the work we've begun will be carried even further, to new heights, by a man I know well: George Bush, the next President of the United States. In fact, I want to salute George for how far he has already helped us come these last 8 years.

We've been partners in a revolution, and I know that I speak for everyone here tonight when I assure him that all he need do is sound the trumpet and the great army of idealists and activists that we've counted on will be ready to charge.

One of the sponsors of tonight's dinner, the Heritage Foundation, with its president, Ed Feulner, has been a vital force in what we've accomplished. The Heritage Foundation 8 years ago set out what it termed a ``Mandate for Leadership,'' which came as a warning shot, telling the liberal establishment that a new sheriff and new deputies had ridden into town and they could not expect to carry on business as usual. Well, tonight I think the liberal pundits can read our lips: That mandate has been renewed.

One of the deputies -- a man who, when the clock struck high noon, was always at my side -- is leaving office this year. He helped to settle a tough frontier, the Congress, loading his six-gun with solid gold bullets. But above all, Jack Kemp is a man of ideas. And I think, really, it's those ideas that brought most of you here tonight, and it's on that basis that we should praise him. Certainly he's held high office; and, yes, from the gridiron to the political field of battle, Jack is a man of action and a man of courage. But the largeness of this quarterback is his sweeping vision of human freedom, profound in its depth, majestic in its reach.

I will speak tonight particularly of supply-side economics. However, let me say first that our vision does not begin or end with tax rates, for we conservatives are not materialists or economic determinists. Our vision is grounded in the most fundamental truth of all: that the God that created man and woman in His own image created us to be free. And this is true, as Jack often says, not for one people but for all people, and not for one time but for all time.

Now, when we think of those things that could be described as God-given, I don't think anyone -- at least not anyone here tonight -- would suggest that we include something the Keynesians called aggregate demand management. I believe we really can, however, say that God did give mankind virtually unlimited gifts to invent, produce, and create. And for that reason alone, it would be wrong for governments to devise a tax structure or economic system that suppresses and denies those gifts.

Incentive economics works because it places the individual at the center of the economy and unleashes the full human power of invention, production and, yes, compassion and generosity. It recognizes the creativity that is lodged in each person, the power of will and the act of faith that launches even great enterprises. As George Gilder wrote in ``Wealth and Poverty'': ``Our greatest and only resource is the miracle of human creativity in a relation of openness to the divine.'' Well, isn't that really the context in which to discuss economics?

You know, I've often quoted a philosopher and historian, ibn-Khaldun, who observed that at the beginning of the empire the tax rates are low and the revenues high, but at the end of an empire the rates are high and the revenues low. Now, he had a bit of a jump on me. He wrote in the 14th century -- which doesn't make us contemporaries. [Laughter] But in a speech I gave 27 years ago, I pointed out that the top Federal income tax brackets, which at that time ran from 50 percent up to more than 90 percent, brought the Government very little revenue. I said that ``the Government can only justify these brackets on a punitive basis.'' In the early 1960's and before, when I called for cutting taxes, for replacing progressive marginal rates with a flat tax, it couldn't be called supply-side economics because that name had not been coined yet. But our critics were not at a loss for words. They had all sorts of names for ideas, most of which I'd better not repeat.

Back in the 1970's in Washington, our ideas were relegated to the fringe. Prevailing economic wisdom took it as a given that the Federal Government could manage the economy to success, while the conservative vision of government and political economy barely had a foothold in Washington.

And then Jack Kemp came on the field. Working with a small group of maverick economic thinkers, Jack began to read economic history and arcane studies of tax and monetary policy. He learned of the effect of the tax cuts under Presidents Coolidge and Kennedy, and he listened to the working people of his congressional district in northern New York.

So, while the beltway crowd despaired of ever reforming the Tax Code, even as my predecessor in the White House called it a ``disgrace to the human race,'' there were, nonetheless, a visionary few who were undaunted. In 1977 Jack put forward the Kemp-Roth bill to cut personal income tax rates 30 percent across the board. Still the reigning orthodoxy held firm to its prescription of high taxes and easy money, even as the stagflation soared. But other thinkers replied that the solution was just the opposite: low taxes and stable money.

No, it lay in offering the American people more -- more jobs, more income, more opportunity, and more freedom. It was much more than our opponents could conceive of and far more than they could hope to match, because our opponents could only offer the people things that they had taken from them while we could offer the American people far more than they ever had: the full fruits of their own abundant creativity.

And that, as I said, is a promise that we've kept. Today America is experiencing record prosperity. Our people have created 18\1/2\ million new jobs and almost 5 million new business incorporations. The unemployment rate is at its lowest level in 14 years; more Americans are working today than ever before. Real family income has hit an all-time high. And we're in the longest peacetime expansion ever recorded: 71 months of growth.

A recent article in the Public Interest by Paul Craig Roberts compares this expansion with the longest previous one, and the contrast is striking. Not only is our expansion over a year longer, but just looking at the same length of time, the first 58 months, we held inflation down to a third of what it was in the previous expansion while we reduced the unemployment rate by almost twice as much.

Well, we've helped prove that economic truth is a lever that can move governments, move history, and truly change the world. But I'm still waiting to see if it can make the nightly news. [Laughter] But whether it does or not, it's made history -- and not just in our own country but around the globe.

What we've done here in America, the economic model that we have created, truly has become what Jude Wanninski described as ``The Way the World Works.'' All the major industrialized nations either have or are in the process of cutting tax rates. Privatization is sweeping the Third World.

Developing countries no longer look to the state for growth, but instead to private industry and international trade. Even the Communist countries are reforming their system to permit more economic freedom. And for Jack and his new Institute of Free Enterprise Development, the greatest world market is the market for ideas, from the Laffer Curve to money that's as good as gold. He sees a planet hungry for a vision that can bring freedom and prosperity to every nation on Earth.

In places like the Republic of Korea, Taiwan, and Chile, we see how economic freedom yields more than increasing prosperity: it also nourishes a powerful popular force for greater political freedom and democracy. And our revolutionary vision of democracy also means supporting the freedom fighters who take up arms against brutal Communist dictatorships; and this we have proudly done in Asia, Africa, and Central America. America must always be a champion of freedom and a friend to those oppressed.

And we must continue to pursue our Strategic Defense Initiative that would free the people of the world from nuclear terror, as Jack just told you. We believe that America must be defended and that the free men and free minds of the free world can create the technology to do just that.

I can say to you that on every important issue Jack has been a leader. And he has stayed loyal to principle and party. And this year, when Jack saw that this was meant to be George Bush's time, from that point on, no one worked harder or with greater enthusiasm to help assure that George Bush became the next President of the United States. And that is something Jack can be proud of and for which we can all be grateful, for it is compelling testimony to the caliber of both men.

When you talk about Jack Kemp one word comes to mind: the cause. Wherever he is, he'll fight for that cause; he'll work for that cause. And what unites every single soul in this room is our shared commitment to that cause. Jack Kemp has already fought and won more battles than most men dream of. But I also remember that on the last Saturday before the election Jack and I were out campaigning for George Bush, and we met up in Macomb County, Michigan. It was a cold and rainy morning. But once we were inside the hall, Jack spoke to the crowd first, and he fired them up. I heard that audience respond to him, and what they told me was that Jack Kemp's future is even greater than what's already passed. His greatest game has not yet been played. His longest touchdown pass has not yet been thrown.

Jack is fond of saying that this administration gave America back its future. Well, if I can return the compliment, Jack, I would just like to say that your ideas helped fuel us to go further into the future than we ever dreamed possible. So, to you and to Joanne and your wonderful family that is so much a reflection of your love and spirit, you have our gratitude.

And come January, when I saddle up and ride off into the sunset -- [laughter] -- it will be with the knowledge that we've done great things. We kept faith with a promise as old as this land we love and as big as the sky, a brilliant vision of America as a shining city on a hill. Thanks to all of you, and with God's help, America's greatest chapter is still to be written, for the best is yet to come.

Of the many messages found in the Hanukkah story, the one that has always inspired me most is this: with a strong faith in the Almighty, nothing is impossible; and without the help of our Creator, we labor in vain.

When the Maccabees vanquished the Syrians and recaptured the Holy Temple, they found only a small portion of the pure oil needed to light the Menorah and rededicate the sacred place. Men of less faith would have despaired, but the leaders of that time knew that trust in the Almighty would see them through. Their determination was, of course, rewarded; and today, many centuries later, the miracle of the lights is celebrated with undiminished wonder, thanks, and joy.

This is the last occasion I will have as President to send warm wishes to the Jewish people on a holiday. It is my hope that this festival will renew and strengthen the spirit of Jewish families everywhere, just as it lifts the hearts of all who look to the care and mercy of our eternal Father. May He bless you and grant you His abiding peace.

Union has not corrected the noncompliant activities cited in the last report. In this regard, I want to emphasize a particular Soviet failing: the Krasnoyarsk radar is a significant violation of a central element of the ABM Treaty. We have informed the Soviets that the radar calls into question the viability of the ABM Treaty and makes it impossible to conclude future arms control agreements in the START or Defense and Space areas. The violation caused by the Krasnoyarsk radar will continue to raise the issues of material breach and proportionate responses until it is resolved. In order to broaden the basis for cooperation between our two countries, the Soviets must correct their violations and noncompliant activities with respect to the ABM Treaty and other arms control agreements.

This report also provides a summary of Soviet implementation of the INF Treaty. The INF Treaty is meeting our goal of complete elimination of an entire class of U.S. and Soviet missiles under conditions of strict verification. Instances of Soviet noncompliance, which we have raised with the Soviets, have been resolved to our satisfaction or are in the process of resolution.

President today sent to the Congress the classified and unclassified versions of the annual report on Soviet noncompliance with arms control agreements mandated by Public Law 99 - 145. The findings and analysis contained in this report are an integral part of our approach to arms control and national security policy. We seek sound agreements that are equitable, effectively verifiable, and can strengthen U.S. and allied security.

But such agreements must be faithfully carried out if they are to fulfill those objectives and contribute to a more secure international environment. Ensuring that a country lives up to the commitments it has freely undertaken is essential to the confidence necessary to the whole arms control process.

This year's report reaffirms our 1987 findings of Soviet violations or probable violation of the ABM treaty, the biological and toxin weapons convention, the Geneva protocol on chemical weapons, the limited test ban treaty, the threshold test ban treaty, and provisions of the Conference on Security and Cooperation in Europe Final Act that relate to military security and confidence-building.

We are particularly concerned about the Krasnoyarsk radar, which is a significant violation of a central element of the ABM treaty. We have made clear to the Soviets that their failure to correct this violation by dismantling the radar in a verifiable manner that meets our criteria casts a shadow over the arms control process. We cannot conclude new strategic arms control agreements while this violation remains uncorrected. We also reserve all our rights under international law to take appropriate and proportionate responses, including the possibility of declaring a material breach.

We have discussed these violations repeatedly with the Soviet Union and have given them every opportunity to meet our concerns. If the Soviet Union is genuinely interested in a more constructive and stable long-term relationship, it will take the necessary steps to correct its violations.

This will be our last such meeting, and I must admit that I would not have predicted after first taking office that someday I would be waxing nostalgic about my meetings with Soviet leaders. But here we are for the fifth time, Mr.

And always in my mind, I go back to that first summit held in 1985 at a private villa on the shores of Lake Geneva. At the first of our fireside talks, I said to Mr. Gorbachev that ours was a unique meeting between two people who had the power to start world war III or to begin a new era for humanity. The opportunity for such a new era is there and very real.

That isn't to say, of course, that that era is already upon us. No, too many fundamental differences on matters such as human rights and regional tensions remain unsettled between East and West. But it is to say that there is the hope of an era in which the terrible nightmares of the postwar era, totalitarianism and nuclear terror, may diminish significantly and -- please God -- someday fade away. Throughout the postwar period, this has always been America's agenda: that the blessings of peace and freedom we know so well in this country will someday belong to every nation, to every people.

Toward this end, the United States and its allies have, over the last 8 years, pursued a course of public candor and military strength, but also a course of vigorous diplomatic engagement with the Soviets. And the Soviets have responded. The result has been progress on a wide series of fronts. First and most obvious, we have signed the first treaty in history reducing nuclear armaments; indeed, wiping out a whole class of U.S. and Soviet nuclear missiles. So, too, other arms negotiations are moving forward. In pursuing this cause, the Soviets must abide by past agreements. And in this regard, the Krasnoyarsk radar violation remains a significant problem.

In the area of regional conflicts, we've seen a partial Soviet withdrawal from Afghanistan and a commitment to full withdrawal by February. In Angola, U.S. mediation has led to a cease-fire and prospects for a political settlement and withdrawal of Cuban troops. In Cambodia, steps have been taken toward a withdrawal of Vietnamese troops. And in other regions, we have seen movement toward peace.

So, too, in our bilateral relations with the Soviets, there has been movement toward wider exchanges between our two peoples that bring American and Soviet citizens in closer contact and communication.

But we also are hopeful that talk of democratic reform and greater freedom for all the Warsaw Pact countries will become more than just talk. We hope, for example, for a day when the Soviet Union will permit the publication of the works of Solzhenitsyn or the day when the Berlin Wall will be no more. Yes, we want bold words of reform about political and religious expression to become more than just words.

So, for all the progress and all the hope, the journey to this final meeting between Mr. Gorbachev and me at Governor's Island has been a difficult one. And believe me, the journey toward better Soviet-American relations will remain a difficult one. Yet it is a journey that must continue beyond any single President or term of office. And that's why I'm particularly delighted that Vice President George Bush will be joining Mr. Gorbachev and me at Governor's Island next week.

I've spoken many times about Vice President Bush's foreign policy credentials and his long experience in this field. At every stage in the summit process, he has been at my side. No one is better versed in the details of Soviet-American relations or has a stronger foreign policy portfolio than our Vice President.

So, while our get-together next week will not be a working summit with a formal agenda, you can be sure I'll be telling Mr. Gorbachev that George Bush represents change, yes, but also continuity; that he stands for firmness and strength and candor in the cause of freedom; that he knows intimately the essentials of the Soviet-American relationship; and that the American people do not want treaties for the sake of treaties -- they want agreements that endure and help prevent wars as the world moves relentlessly toward a new birth of freedom for all humanity.

Well, we've already said good evening, but maybe I'll say it again. And welcome to the White House. For the past 8 years, I've had the pleasure of joining with the Kennedy Center in honoring those Americans -- 57 now -- whose contributions to our national culture have been more precious than the most precious assets and rubies. And so, this night is a time for reflection and nostalgia, as well as celebration of the five great Americans that we honor tonight.

It was my great fortune to participate in the glory years of an unparalleled form of popular art: the movies. So, I know, both as a participant and spectator, the allure and power of the performing arts. I know also how difficult it is to explain what it is that makes performing such an unforgettable experience.

There's one other thing I know about performing: Performers are judged by a more exacting standard. And those who rise to the very top know with absolute assurance that no special favor, no special help, no special anything can account for their success. No, they've made it because the world has judged them and has judged their talents and their energies and has determined in the court of public opinion that they're superior -- or better than superior, that they're great.

Sasha Schneider, the word ``great'' has been applied so often to you that it seems redundant to use it here. But as President, I guess I have a prerogative. [Laughter] As a violinist, you have performed the works of every major Western composer with your fine and delicate touch, which can move with the startling brio of the ``Flight of the Bumble Bee'' or the languorous romanticism of Schubert's ``Death and the Maiden.'' Conductor, teacher, organizer -- you have shared your peerless understanding of classical music in many, many different ways. This century would have been all the poorer without you, and we're all the richer for having listened and learned from you.

Alvin Ailey, what can I say about you that has not already been said? You brought a new vocabulary to the dance, a vocabulary of sinuous grace and astonishing rhythmic variety. And like Sasha Schneider, you were not content merely to bring your bounties before us, but also insisted on educating others and bringing them before us as well. And the world of dance has been transfigured by your part in it.

Stevens is not a performer, but literally thousands of performers owe their careers to him. As a producer, he brought hundreds of plays to the boards, delightful musical comedies and difficult modernist works alike. He helped build a national cultural center here on the banks of the Po- tomac and was the founding father of the National Endowment for the Arts. I think it's fair to say few Americans have done as much for the performing arts.

And as a performer, the lovely and mysterious Myrna Loy has always conveyed a sense of great ease and comfort, as though she were possessed of answers to questions you hadn't even thought of asking in the first place. [Laughter] She could play Nora Charles, the most sophisticated woman in New York, or she could play an oriental temptress, both with equal conviction. And she made it all look easy, which I don't need to tell all of you is perhaps the most difficult chore of all.

George, and Myrna, and Roger, and Alvin, and Sasha, this night is yours. But it's a night for all Americans to celebrate the glories that you've given us. And I can't think of a better way to conclude my ceremonial role in these festivities than to pray that God may bless you and keep you all the days of your life.

The holiday season is a most fitting time to reemphasize that driving while under the influence of alcohol or drugs is dangerous and irresponsible behavior that no one should engage in, tolerate, or permit.

Again this year, citizens across our Nation are volunteering their time and talents to take part in a week of observance to focus public attention on eliminating drunk and drugged driving. Public officials at all levels have issued proclamations, sponsored legislation, and appointed task forces; law enforcement agencies have increased enforcement efforts; public and private organizations have held safety campaigns; and citizens have sponsored programs to provide rides home from holiday parties. Actions like these bring us closer to the day when drunk and drugged drivers will no longer threaten our lives and our families.

We can take heart from the results of the comprehensive year-round activities to stop drunk driving. In 1987, the proportion of motor vehicle fatalities in which at least one driver or pedestrian was legally intoxicated was 40 percent.

We must also realize that combining drugs and alcohol adds to the risk. Studies of drivers involved in accidents reveal that many use drugs -- and that certain drugs, either alone or in combination with alcohol, contribute to crashes. We must all be aware of the safety risks of driving after taking drugs, including prescription and over-the-counter drugs that carry a warning label against driving.

We can all help improve safety on our roads and highways by refusing to tolerate drunk and drugged driving; by always wearing safety belts, even for short drives; and by insisting upon prompt and effective action against alcohol- and drug-impaired drivers.

Eighty-five years ago, above the sound of North Carolina's pounding surf, above the chattering of the sea gulls and terns, came the sound of progress; for over the sandy dunes of Kitty Hawk flew the first self-propelled, winged aero-vehicle. Hardly an imposing sight, it barely rose above the shore; and, in size, it bore little resemblance to the jumbo jets that would follow. In power, velocity, and payload, it was also but a hint of what was to come. But that aircraft, aloft for only a few moments, held promise far beyond its modest dimensions and capabilities. Eventually that promise became reality, yielding change that helped shrink the globe and bring the peoples of the world closer together. Rarely has mankind beheld an event foreshadowing such remarkable improvement for the benefit of us all. Today, we commemorate an idea that grew in the hearts and minds of the Wright Brothers, Orville and Wilbur, until it culminated in the famous flight that blazed a path into the future for America and the world.

Reading is one of the most important activities any child can engage in, and potentially one of the most enjoyable too. For all of us, and especially for youngsters, reading is a key to past, present, and future -- a path into virtually limitless treasures of knowledge and inspiration. Reading encourages wonder about the world, broadens awareness of others, and offers clues about the meaning of life. It helps transmit our cultural legacy and fosters inner resources of spirit, intellect, and imagination. Children and young adults need and deserve the gift, joy, and promise of reading, and a year of special national observance in recognition of this truth is most appropriate.

Nurturing a love of reading in children is crucial for their personal growth and well-being and for the continued health and vigor of our communities and country. Now as always, America needs a literate and knowledgeable citizenry fully conversant with and determined to defend our heritage of liberty and learning.

We can all help young readers discover the blessings and the enjoyment that reading offers. Parents can read aloud to their children. Families and schools can make reading materials a familiar part of youngsters' surroundings and can suggest regular visits to libraries. Educators and concerned citizens can redouble their efforts to ensure that students remain in school and that literacy programs for people of all ages are available in their areas. Each of us can give young people the good example of reading ourselves. We can explain the freedom we Americans enjoy to read and write and study as we like. If we do all of these things, we will go a long way toward awakening among every young reader the understanding that reading is a thrilling, lifetime journey into new worlds of adventure, history, heritage, and far frontiers. That will be an inestimable service to our Nation.

Reader. I call upon parents and educators, librarians and publishers, interested private organizations and businesses, government officials, and all Americans to observe this year with appropriate programs, ceremonies, and activities.

The President. I am delighted that later today I'll have the opportunity to welcome President Gorbachev to the United States and extend to him the hospitality and good wishes of the American people. As most of you know, our meeting today is under the gaze of Lady Liberty, and I think that's altogether appropriate. The quest for human rights and personal freedom is very much a part of the agenda of American-Soviet relations. And let me also say that, since they began in 1985, my discussions with President Gorbachev have been friendly, businesslike, and productive. And although our time together today will be brief, I welcome this opportunity for a final meeting between myself, President Gorbachev, and Vice President Bush that will demonstrate the continuity of the process we first put in place at Geneva in 1985.

The pursuit of peace is, of course, always in season. But I think it's especially appropriate that President Gorbachev should be here at this time of year, a time when the thoughts and prayers of all of us turn to the hope that someday nations and people from every part of the world will live in peace and harmony with one another. It's for this reason that I journey to New York.

The President. Well, we're pleased to hear that -- the fact that they're thinking in that term. We, too, have thought in it, and the idea of bringing conventional weapons down and achieving a symmetry between us, I think, would be another great forward step.

The President. Well, we haven't had time yet, because he held his press conference up until just a short time ago in Sweden, and we haven't had time to review what it is that he said there specifically. We're looking forward to do that.

I am pleased to note that the Cyprus intercommunal negotiating process is continuing under the auspices of U.N. Secretary General Perez de Cuellar. Numerous sessions were held in October and early November, and the Secretary General hosted a meeting in New York November 22 - 23 to review the progress of the talks. I commend the Secretary General and the leaders of the two communities for their determination in striving for a solution to the conflict.

Cyprus Coordinator M. James Wilkinson visited Cyprus from October 24 - 26 and consulted with the parties, U.N. officials, and others. Mr. Wilkinson was encouraged by the willingness of the two Cypriot leaders to engage candidly with each other in a discussion of very difficult issues and problems. The numerous meetings held in September, October, and November attest to the fact that a committed effort is being made to listen, understand, and move toward resolution of serious differences. Mr. Wilkinson also reaffirmed our strong backing for the continuation of the intercommunal dialogue.

United Nations hosted an open house in Nicosia on October 24, which brought together members of the Greek and Turkish Cypriot communities. We continue to encourage personal contact between members of the two communities, which helps to foster progress toward a lasting solution on the island.

Demonstrators on two occasions entered into the buffer zone. Such activities hinder UNFICYP's efforts to maintain the peace on the island and place the U.N. Force in a difficult position. We urge the Cypriot communities to cooperate fully with UNFICYP in the execution of its mandate from the U.N.

I would like to reiterate my admiration and appreciation for the efforts of United Nations personnel in Cyprus, particularly the United Nations Force in Cyprus (UNFICYP). The Force remains an important factor in maintaining peace in Cyprus, providing an atmosphere of calm that permits the continuation of the search for a just and lasting solution to the dispute. Regrettably, the accumulated operating deficit for UNFICYP continues to grow. The U.N. Secretary General now estimates that the shortfall will reach $167 million by the end of 1988. I join the Secretary General in urging the U.N. member nations to help reduce this deficit by contributing to the Force's operating budget.

Reagan. I think we have to go into our meeting, and I just want to say that I am looking forward to and very pleased with this fifth and final meeting between President Gorbachev and myself. We've accomplished much; there are other things still to do. And I am also extremely pleased that Vice President Bush could be here for these meetings. And now I think we'd better go.

Reagan. Well, there are going to continue to be conversations between us on that matter. But, certainly, I think that we certainly would adjust it if it would turn out that this left us with a superiority -- and we don't seek such a thing.

But as you know, I've just been to New York and back for a meeting with Mikhail Gorbachev. We were joined by Vice President Bush. Our discussions were positive and encouraging, as usual, and I was pleased by this opportunity to have a last meeting with President Gorbachev before leaving office. The discussion covered our entire four-part agenda with the Soviet Union, and we looked in particular at what had been achieved since our last meeting in Moscow and what still needed to be accomplished in the future. I expressed to President Gorbachev my confidence that the work we began together at Geneva in 1985 will continue under the Bush administration.

You will not be surprised to hear that I particularly stressed the importance of human rights in U.S.-Soviet relations. I told the President that we Americans welcomed the changes that he has initiated in the Soviet Union, and we hope that much more will be done to benefit the Soviet people and also the relations between our countries. We also reviewed progress in arms control, resolution of regional conflicts, and our bilateral relationship. I think we both expressed satisfaction in what we've achieved in recent years. But we also recognized that fundamental differences between our countries remain in many areas and that determined efforts by both sides will be necessary in the months and years ahead to overcome such differences.

About the Soviet unilateral troop reduction, I can only say that if it's carried out speedily and in full, history will regard it as important, significant. And we did see history today: an American President and Vice President meeting a President of the Soviet Union under the gaze of the Statue of Liberty. Well, it's something to remember.

Now, all of this is testimony to a process that was begun in 1985 in Geneva -- testimony, too, to the sacrifices of the people of the free world throughout the postwar era. So, while our hopes today are for a new era, let us remember if that new era is indeed upon us that there was nothing inevitable about it. It was a result of hard work and of resolve and sacrifice on the part of those who love freedom and dare to strive for it. Let us remember, too, at this critical junction our responsibilities grow more, not less, serious. We must remain strong and free of illusion. For only by doing so can we reach out and embrace this new era and transform this hope of peace and freedom for all the world into reality.

So, the meeting today was a time for reflection and for continuity. Now, let me do the same with you and consider how we've done these last 8 years and whether we've done well. And I do mean ``we.'' We have come a long way together, from the intellectual wilderness of the 1960's, through the heated intellectual battles of the 1970's, to the intellectual fruition of the 1980's.

American Enterprise Institute stands at the center of a revolution in ideas of which I, too, have been a part. Our ideas were greeted with varying degrees of scorn and hostility by what we used to call the establishment institutions. The universities, once the only real home for American scholarships, had been particularly unresponsive. And so, it became necessary to create our own research institutions as places where scholars could congregate and important studies could be produced that did not kowtow to the conventional wisdom. And your institution's remarkably distinguished body of work is testimony to the triumph of the think tank. For today, the most important American scholarship comes out of our think tanks, and no think tank has been more influential than the American Enterprise Institute.

What we wanted was a chance to try our ideas out on the world stage. We have. And, my friends, I hope you're as proud as I; because despite the naysayers and the conventional wisdom, the words of the pundits and the false prophecies of false Cassandras who proclaimed we could not succeed, we knew we were right. And I believe that, yes, we have been vindicated.

Yes, it seems to me that we've been as one these past 8 years in an effort to establish a foreign policy that stood in firm opposition to the previous decade's misguided attempt to place this country on what they used to call in the 1970's the right side of history -- by which those who used that unpleasant Marxist phrase meant we should accept the dominion of our adversaries over large parts of the world. We said no. We said we must propound and advance our national ideals abroad and once again hold high the banner for what I will, until the breath is gone from my body, continue to call the free world.

We promulgated a foreign policy whose fundamental basis was the truths all Americans hold to be self-evident: that all men are created equal; that they are endowed by their Creator with unalienable rights; that among these are life, liberty, and the pursuit of happiness. We have done this not solely because we believe it is right, but because we know it is in our national interest to do so.

A foreign policy based on our bedrock principles allows us to offer a practical solution to the suffering peoples of the world, a means of achieving prosperity and political stability that all Americans take for granted as their birthright. What we're telling them -- and their ofttimes recalcitrant leaders -- is that they cannot achieve prosperity and stability through redistribution of resources or by taking up arms against a sea of self-inflicted troubles. We've seen how that last monstrous idea was worked this decade. The war between Iran and Iraq, whose initial aim was control over an oil-rich province, has done more damage to both countries than 10 plagues.

No, we've told the world the truth we've learned from the noble tradition of Western culture, and that is that the only answer to poverty, to war, to oppression is one simple word: freedom. Now, freedom is not only a moral imperative for our foreign policy; it's also -- if I may use a word for which few in this room have much use -- supremely pragmatic. [Laughter] For if there's anything the world has learned in the 1980's, it is that, as Alan Keyes has said, freedom works.

That's a historic lesson, because until very recently many intellectuals believed to the contrary. They supported political philosophies that argued for tyranny, and more particularly Communist tyranny. The claim was that these tyrannies worked better than freedom and were more equitable. These intellectuals believed that the people of Mao's China, Ho's Vietnam, Castro's Cuba, and other Socialist utopias were actually happy to sacrifice their freedom for food and shelter and so-called literacy programs.

Tyranny fails. Freedom works. These facts, so little accepted only a decade ago, are now indisputable. There is little need here to rehearse the evidence in great detail. The tiny free-exchange experiments in the East bloc and the liberalization in the People's Republic of China are stunning evidence of the Communist world's desperate efforts to find a way out of the economic morass of state socialism. At the same time, the abject failure of the Sandinistas in Nicaragua, a nation where the standard of living has dropped precipitously since the 1979 revolution, is stark proof of communism's inherent inability to compel an enslaved population to do much of anything but suffer.

I know it's often said of me that I'm an optimist. Over the years I've been described as an inveterate optimist, an eternal optimist, a reflexive optimist -- [laughter] -- a born optimist, a canny optimist, a cagey optimist -- even as defiantly optimistic. [Laughter] It just goes to show there's no word that cannot be turned into a pejorative if the pundits work hard enough at it.

But, yes, I am perfectly happy to admit that I am an optimist, and I would like to explain why I believe -- in contrast to some of you here tonight -- that optimism is an appropriate attitude to bring to bear when thinking about our foreign policy.

The story of this century is actually two stories. It's a terrible story of world wars, totalitarian enslavement, concentration camps; but it's also the story of freedom: the fulfillment of the promise of freedom inside the United States and the triumph of democratic systems in Western Europe, Japan, Israel, El Salvador, and many other places.

Now, one may, if one chooses, take the first story as the representative tale of the 20th century. Well, I look to the second and find glorious examples of what freedom can bring. I think of how astonishing it is that Italy and Germany and Japan, three nations that engaged us in a struggle literally to the death, have in just twoscore become our brethren, our friends. The nations of Western Europe, which existed in a state you might call cold war for most of the past millennium, with periods of real war thrown into the bargain, are now the best of friends and are on the verge of creating the world's largest free market. Latin America, once a despot's paradise, is now 90 percent democratic. The brave people of El Salvador have faced down those who would still their voices by turning out to vote in great number. In the Far East, democracy has taken unprecedented strides in such countries as South Korea and the Philippines.

Freedom works, and freedom is on the march. And, yes, I am an optimist, and, yes, I believe I have every reason to be. I am an optimist because we're rapidly developing the means to neutralize the extraordinary threat of nuclear missiles through our Strategic Defense Initiative. I am an optimist because I believe we've proved with our policy of peace through strength that when we're strong, peace and freedom will prevail. This November, the electorate told us they agreed.

But while I believe that optimism is appropriate, and while I believe that freedom is on the march, I believe optimism must be tempered with prudence and its assumptions challenged every waking moment of every day. The new democracies around the world are fragile, and inattention to their fragility and their needs may result in the end of freedom there.

America, our policy of peace through strength has been undercut by a wavering Democrat-controlled Congress that seems less concerned about the threat of a consolidated Marxist-Leninist regime in Nicaragua than the possibility of scoring points against a policy so closely associated with our administration.

I'm troubled by something else as well. The 1980's have been the glory years of the NATO alliance. The Soviet deployment of intermediate-range missiles presented NATO with its greatest challenge since the construction of the Berlin Wall, and the alliance not only survived but was vindicated by the signing of the INF treaty in Washington 1 year ago tomorrow.

The NATO alliance is the best example we have to show the less fortunate peoples of the world how freedom and democracy create friendship and comity between peoples and nations. But 40 years after the North Atlantic Treaty, there are still some who question the alliance. Thus we hear, just months after the destruction of the first intermediate-range missile, that somehow the United States is being mistreated by our friends and allies. The argument they use is that our allies are not sharing the burden of their own defense equitably.

I agree that our NATO allies could be sharing the burden better. But we must also solve our economic disputes more fairly. But we must always remember the very real burden our allies bear that we never will. We must remember our allies perform a role that geography has forced upon them. They are literally on the front lines for the West. Our fortunate geography has kept the wars of the 20th century well away from the American mainland, but in Europe the memory is as fresh as the memories of a 50-year-old and the tales of a grandfather. Their soldiers, their children, their homes, their civilization itself hang in the balance every day. We cannot, we must not, forget this. And we should not give in to the temptation to transmute a small difference in a historic relationship into a major disagreement that might end up damaging the greatest foreign policy success of the postwar era.

I believe we can and will make progress on these matters as long as we hold true to our principles and do not give up the battle. Now, I would like to ask those of you in this room who consider yourselves foreign policy skeptics to do me one last favor: I want to ask you to remain vigilant. You are the people who play the vital role of reminding politicians and policymakers of many important and necessary truths we sometimes forget. It's true that sometimes you can't see the forest for the trees; indeed, sometimes you can't even see the trees for the grass that surrounds them. So, please, for George Bush's sake and for the sake of all we hold dear, please keep watching the forest.

It's a pleasure to welcome you all here as we mark Human Rights Week. Forty years ago this week, the United Nations General Assembly adopted the Universal Declaration of Human Rights. For people of good will around the world, that document is more than just words: It's a global testament of humanity, a standard by which any humble person on Earth can stand in judgment of any government on Earth.

Yes, we're here to recognize a set of ideals, our fundamental belief in the unalienable rights of man. But were it not for the people who work to uphold these ideals, then our words would be hollow and our vision without effect. So, let us record that today we're also honoring a community of people, the heroes who have dedicated their lives to these values, who work to keep the world informed, who lend their voices to those denied the right to speak for themselves, and who at times have lost their own freedom and even their lives because of their courage in speaking out for the freedom of others.

In addition, the cause of human rights has become an important factor in United States foreign policy. We have not brought these issues to the fore internationally because our own history is without blemish or sin, for it is not. Nor is our right to speak on these issues based on any claim to current perfection, because we do not make that claim. Instead, what we have said is this: that the critical moral distinction of our time is the clear difference between a philosophy of government that acknowledges wrongdoing and injustice and one that refuses to admit to such injustices and even justifies its own assaults on individual liberty in the name of a chimeric utopian vision. The moral foundation of our human rights policy requires that we maintain a single standard of justice and, above all, that our policy must be an effective instrument for improving the lives of people, not an instrument for self-righteous self-satisfaction.

Over these last 8 years and before, we've seen that representative democracy, for all its shortcomings and as imperfectly realized as it so often is, is still the best guarantor of human rights. So, our concern for human rights must be used also to encourage the success of democratic institutions. The world has not failed to notice the great improvement in human rights that is possible when countries make the transition from authoritarianism to democracy. But we've also seen the capacity for bad situations to become far, far worse: for autocratic governments to be replaced by totalitarian dungeons like Cuba, Iran, and Nicaragua. Let us as Americans set forth a simple humane principle, and any policy carried out in the name of human rights must not bring harm to those whom it was supposed to help. It should not yield slavery when what it promised was freedom.

In addition, we've seen that no totalitarian nation has ever made a peaceful transition to democracy. So, this type of transition, which has improved the level of human rights for more people in more countries than any other factor, has not brought its benevolent fruits to the Communist world. But reforms are possible and have, indeed, been occurring in Marxist-Leninist states.

At my meeting yesterday with Mr. Gorbachev, as at each previous meeting, human rights was one of the four key topics discussed. Certainly, we're not yet satisfied, but there has been real progress, which we must note and encourage.

Many political and religious prisoners have been released, and many specific cases of family reunification and the like have been resolved. Emigration, though still below the levels of 10 years ago, has increased.

But still much remains to be done to translate words into deeds -- to bring the peoples of the Soviet Union the full rights to which their government has committed itself under international agreements, including freedom of assembly, freedom of worship, national expression, and the right to leave one's country and return. Specifically, we want to see the release of all political prisoners. Dozens remain imprisoned, including two Helsinki monitors, Lev Lukyanenko and Mykola Matusevych. Well, we await permission for all long-term refuseniks to leave. For all long-term refuseniks we look forward also to the repeal of unjust laws used to jail dissenters. And I believe we learned yesterday that there is some improvement coming immediately in that regard in the one country I mentioned. We are, however, concerned by two new laws, cited by Andrei Sakharov on his recent visit. They seem to step backward, creating additional barriers to peaceful demonstrations and that would increase the suppression of independent publications.

One of the most important emerging forces of change is the information challenge to totalitarianism. Greater openness provides not just greater opportunities to exercise basic human rights but also greater protection against a state that would infringe on those rights. And in this regard, Moscow's decision to stop jamming Radio Liberty and other Western broadcasts is welcome news.

Economic freedom is also an important corollary of human rights. The time has come to recognize that the basic economic rights to own, use, and exchange property, to create and produce, free of state control, are a fundamental part of human freedom and essential components to a decent and humane world for all peoples.

Finally, human rights is inextricably linked to the issues of war and peace. Countries that violate the rights of their own citizens pose a threat to international peace. Moreover, in regarding nations that violate human rights, we should be particularly concerned about those that are expansionist and would expand the reach of tyranny and reduce the sum of freedom in the world.

We should always remember that to be silent on the violation of human rights does not advance the cause of peace; it does not improve relations or promote international stability. It does just the opposite. Silence in the face of evil is a display of weakness that invites aggression. For the free world to morally disarm itself would be the most vile form of appeasement. Our duty is to speak out, and not just 1 day a year but to make sure that every day is Human Rights Day. We owe this to the people of the world, but also we owe it to America, to the Founding Fathers whose vision of liberty we've seen [been] so immeasurably blessed by.

Universal Declaration, like our own Bill of Rights, starts from the premises that civil liberties and political freedom are the birthright of all mankind and that all of us are equal in the eyes of the law. Like our own Declaration of Independence, it also makes the inescapable connection between freedom, human rights, and government by the consent of the governed.

We are proud that the truths expressed by our Founding Fathers -- America's source of strength, stability, and authority for more than 2 centuries -- have also provided a standard for liberty and the rule of law emulated in dozens of other countries as well.

Nevertheless, many individuals and nations do not enjoy the rights enumerated in our Constitution and in the Universal Declaration. Some governments voice ringing guarantees but fall far short in practice. Some, such as Communist regimes, wrongly subordinate fundamental rights to other goals. These goals are often defined by political groups or parties that claim to know what is best for the individual and for peoples subject to their control. Fundamental goals -- free elections and due process -- are concepts not welcomed by dictators of any ideological or political stripe.

Despite this entrenched resistance of tyrants to practical guarantees of liberty, the Universal Declaration has done much to promote observance of human rights around the world. Over the past decade in particular we have seen great strides.

As we move toward the final decade of this century, we can truly say that the heroism, prayers, and sacrifices of countless heroes and heroines who have braved threats and persecution in the long struggle for human rights have produced noteworthy results. But we still have far to go. We must and will dedicate ourselves as a Nation to continue this effort, and to stand in solidarity with those who resist, until the blessings of democracy, freedom, and respect for human dignity are assured throughout the world.

Witness Whereof, I have hereunto set my hand this 8th day of December, in the year of our Lord nineteen hundred and eighty-eight, and of the Independence of the United States of America the two hundred and thirteenth.

One year ago today, on December 8, 1987, in the East Room of the White House, President Reagan and General Secretary Mikhail Gorbachev signed a historic document, the Treaty Between the United States of America and the Union of Soviet Socialist Republics on the Elimination of Their Intermediate-Range and Shorter-Range Missiles, commonly referred to as the INF treaty. Under this agreement, for the first time in history an entire class of U.S. and Soviet nuclear missiles will be eliminated, based on the zero-option proposal first put forward by President Reagan in 1981. This achievement is a direct consequence of the President's steadfast commitment to real arms reductions that strengthen U.S. and allied security rather than merely limiting increases as in previous treaties. It is also the result of allied solidarity in responding to the threat posed by Soviet deployment of SS - 20 missiles.

From the beginning of the INF negotiations, President Reagan emphasized that it would be better to have no treaty rather than one that could not be effectively verified. The INF treaty contains the most stringent verification provisions in the history of arms control, including extensive data exchanges, on-site inspections, resident inspectors at a key missile facility in each country, and prohibitions on interference with national technical means of verification.

The elimination of U.S. and Soviet INF missile systems is well underway: the Soviets have eliminated about 433 missiles, while the U.S. has eliminated about 108, in the presence of inspectors from the other side, since eliminations began in August of this year. In addition to monitoring the destruction of missiles, U.S. and Soviet inspectors have also conducted inspections at 130 Soviet facilities and 31 U.S. INF facilities, and each side has established a continuous monitoring presence at a key missile facility in the other's territory.

The signing of the INF treaty last December was a remarkable success for U.S. foreign policy and for the NATO alliance as a whole, a success made possible by allied unity and perseverance. NATO demonstrated that it has the political will to make and stand by the tough decisions necessary to ensure its security. Our common objectives were achieved: the elimination of both longer-range and shorter-range Soviet INF missiles -- limitations that are global in order to prevent transfer of the INF threat from one region to another -- and agreement that INF limits apply only to the forces of the U.S. and the USSR. The treaty also affirmed the principle of asymmetrical reductions to achieve equal U.S. and Soviet levels, an important precedent for future arms negotiations.

Since the signing of the INF treaty, the U.S. has continued its efforts to achieve a safer world, including through negotiations for deep, equitable, and verifiable reductions in strategic arsenals, a stable balance in conventional forces in Europe, an effectively verifiable global ban on chemical weapons, and effective and verifiable agreements on nuclear testing limitations. The signing of the INF treaty 1 year ago today was a good first step.

At least 2 million people in the United States receive burn injuries each year. Seventy thousand of them require some hospitalization, and more than 12,000 die from their injuries. Children, the elderly, and people with disabilities are often burn victims.

The risk of burn injury exists in our homes, cars, and workplaces. The key to reduction of death and suffering from burn injury is available to everyone; awareness is the action word. Burn awareness is how people can prevent injury to themselves, their families, and their neighbors. The use of fire/smoke detectors and safety containers for flammables, the safe use of electric power, and development of good safety habits can reduce the number of injuries.

In recent years, medical research has made major advances through improved treatments that shorten hospitalization and save lives. New products are available for fire detection, safer fabrics, and personal protection. There are organized safety programs in the office and workplace. There is more assistance to ease the psychological impact on those who suffer burn injury.

Much more can be done to make ourselves safe from burn injury. We can all cooperate with the dedicated professionals who are working to prevent burns and care for the injured. And we can all practice and promote fire safety.

Well, as most of you know, President Gorbachev has had to return to the Soviet Union due to the enormity of the tragedy in Armenia. And in a phone conversation this morning, I conveyed to him the deep sympathy of the American people and our anxiousness to provide any humanitarian assistance we possibly can.

And so we have. It was exactly 1 year ago today that an event here in this room spoke to the epoch-making nature of what has been achieved: the signing of the first treaty to eliminate an entire class of U.S. and Soviet nuclear missiles. Even in the short year since then, we've had the Moscow summit and Mr.

Gorbachev's visit here. In our negotiating agenda of regional conflicts, human rights, bilateral exchanges, and arms reductions, we've seen serious movement and even some breakthroughs. And yesterday's address to the United Nations by President Gorbachev was not only a part of this process, it was the result of this process. And I congratulate him on it.

On a personal note, Nancy and I were delighted that the Gorbachevs extended an invitation for us to visit Moscow. And as we have done before, each of us expressed the hope that they would visit us in California.

So, the path remains open, and the pace of peace continues. As I said yesterday, this means our responsibilities have grown not less but more serious. We must remain resolute and without illusion. And we must speak candidly about fundamental points of difference. We must especially maintain our military strength, but we must also continue our course of vigorous diplomatic engagement.

I cannot tonight attempt to put all these events in perspective or, still less, to claim credit for any person or administration. Let it be enough to say this: that since 1985, extraordinary things have happened, and nothing more extraordinary than the sight yesterday of a President of the United States and a future President of the United States and a President of the Soviet Union standing together in New York Harbor under the protective gaze of the Statue of Liberty.

Our hope, our prayer, remains the same as that heard on the lips of so many millions who looked up once, as we did yesterday, to see the outstretched lamp of Liberty and who felt for the first time its warmth and glow: a prayer that someday freedom will light the world and become the blessing and birthright of every people, everywhere.

The world is applauding the initiative, the new detente, that you and President Gorbachev have initiated. But on the debit side, as you leave office, the Nation is saddled with a $2.6 billion debt, an enormous deficit, caused perhaps by the tripling of military spending, tax cuts. How does all this jibe with the goals that you set 8 years ago? And I'd like to follow up.

The President. Helen, I have to tell you it is incorrect to say that all of this happened because we cut taxes and the things that have happened in these last few years. I've said many times, and pointed out, that over 58 years in which the opposing party held the House of Representatives -- 54 of those 58 years -- and in those years there were only 8 scattered years in which there was a balanced budget.

I was among a great chorus out on the hustings speaking out against this consistent and constant deficit spending. And each time the answer came back that it was necessary to maintain prosperity. And the other part of the answer was: It's meaningless because we owe it to ourselves.

Now, beginning in 1965, in the middle sixties, when President Johnson's program of the War on Poverty was put in place -- in the 15 years from then until 1980, the budget increased just about 5 times what it had been 15 years before. And the deficit increased to 58 times what it had been. So, we came in inheriting literally deficit spending built into the structure of government.

Now, with regard to the tax cuts -- yes, the rates were cut. But since 1981 our revenue from those taxes has increased by $375 billion, and our projection -- and we've been very accurate on our projections -- our projection for 1990, in the budget we're working on now, calls for another $80 billion increase in our revenues with the rates as they presently are.

If you look back beyond us to Coolidge and his tax cuts, if you look to the Kennedy tax cut in his administration -- which was very similar to the one that we later put in -- in every case, it did not reduce the Government revenues; it raised them. So, it is maintaining this and continuing to get back to a reduced spending, because while the revenue was increasing $375 billion, the spending increase was close to $100 billion more than that increase in revenues.

Mr. President, some of your former associates claim that you deliberately created a larger deficit in order to dismantle the compassionate social programs for the poor, the sick, the needy, the handicapped, the elderly, which you didn't like. Is that true?

The President. No, Helen, it is not true; and that is, I guess, political propaganda also. Actually, the reductions that we have made have not been made in the actual basic spending. I have cut the increases that were asked for, but also we have taken action to vastly improve the business management of government. When I came here, there was a program, one program -- I found out about it when I was Governor -- a program in which the administrative overhead was so great that it cost $2 to deliver $1 to a needy person. Now, this is one of the things we've been trying to correct.

There has been an ongoing increase in housing with all of the talk about the need for housing. That has been increased. And I could go on about all the other programs that they have. We've simply tried to keep the increase from being as much as was being asked for. And actually, our defense spending and what we asked for -- regardless of the cuts that were then made in it -- the ones that I asked for, the annual budgets for defense, were less than the projected budgets necessary for defense for the 5 years that President Carter had projected ahead of what was going to be needed for defense. And he projected more than we asked for.

Mr. President, Mr. Gorbachev yesterday announced a major cutback in the Soviet troop strength and talked generally about nations relying less on military might. Do you think that Mr. Gorbachev is trying to remake the Soviet Union into a less threatening country?

The President. Yes, I do. And I think he recognizes that their massive buildup has been responsible for the great economic crisis that he faces there in the Soviet Union. And, yes, he has proposed this, but even so, there still will be room for some negotiations on arms because this still leaves them with superiority in the amount of conventional weapons that they have.

The President. Well, we're still way below them in that. But we have announced our willingness to continue into -- well, before he ever made this move -- and we're very grateful for this, and I appreciate it very much -- but we have proposed that the next negotiations with regard to military -- and then between us -- should be in the area of conventional weapons.

Mr. President, George Bush has been receiving advice on all fronts, it seems, to raise taxes. I wondered if you think he can hold the line and not raise taxes for a full 4 years? And if he should cave in and raise them, would you be deeply disappointed in him?

The President. Yes, I would be deeply disappointed. And I don't think it's going to happen, because I think he is aware, as I am, that rates reduced actually increase the economic growth of the country and provide an incentive for more earnings today. The top 5 percent of earners -- when I hear these people start talking about the upper levels of income -- the top 5 percent of earners in this country at this much lower rate of taxation are paying a bigger share of the total revenue from the income tax than they were paying before at the higher rates, because there's now an incentive to go out and not look for tax shelters and so forth.

Sir, if I could follow up: Do you really feel it's possible simply to grow out of the deficit, or is it necessary -- if you're not going to raise taxes -- to cut Social Security benefits and Medicare benefits?

Social Security, and we don't have to have taxes. As I've said, we're on a line right now that is bringing the deficit down. There was no way anyone could ever pull the rug out and have the deficit solved in 1 year. But the deficit will be reduced down, under the Gramm-Rudman scale that we're following, to $100 billion, and by 1993 the budget will be balanced if we continue observing this thing.

Mr. President, this is your final news conference with us, we think. And at your first news conference, you said that the Soviets would commit any crime, would lie, would cheat, would steal to achieve their political goals. Now, tonight, you're celebrating your joint progress with President Gorbachev and celebrating a speech in which he renounced the use of force by the Soviet Union to achieve foreign policy goals. Do you think that he has really changed? And to the extent that he has changed, have you changed? What have you learned over these 8 years that may have changed your view of the Soviet system?

The President. Yes, but none of you ever thought to give the complete answer. I said, in their own words this was their philosophy, and it was in writing that there was no crime -- all of these things were not a crime if they advanced the cause of socialism. Now, I didn't make that up. That's what they said. I think there's been a change. That was four leaders back before this one. And I think there have been some changes.

The President. Well, Andrea, there were differences in these leaders. And there is a situation now where many of the things that they preached have been proven unsound, and that's why their economy is in such great trouble. But I must say I have never met with one of those leaders that was comparable to this man or had the approach that he has.

The President. I think there have been many tough things. I don't think there's anything any tougher than to have to order these magnificent young men and women in our military today -- and I think I'm prouder of them than of anything that has happened -- to have to send them into danger, to order them to go someplace where their lives are threatened and their lives are taken. That's got to be something that any President would hesitate on and have to say was the greatest burden.

The President. Well, there are a number of things to miss. I don't want to get into a lecture here. Let me just simply say on ``enjoyed the most'' is the economic recovery. When I came here, for almost half a century the debate on the Hill, in the Congress, had always been between more big spending programs, more power for the Federal Government, more intervention in private affairs by the Federal Government, as against those who were preaching less. Well, now, today -- and for a long time, the very question that was asked here about the deficit -- the argument on the Hill today is not more spending; the argument is how best can we reduce the deficit.

The President. Well, I think that, once again, here we're going to have to see whether this is still acceptable to the parties that are to be involved in the direct negotiations. Actually, we talk an international gathering or something, but the Middle East, which is still technically in a state of war -- that must be resolved between the nations of the Middle East in direct negotiations. And if we can help bring that about, then I would welcome anyone who wants to help.

The President. Oh, yes. We have long said that as soon as we once settle this issue of the START agreement -- I have said that I think our next goal must be to now engage in negotiations on reducing conventional weapons.

President-elect, and he will be the President when he takes over. But I do believe, knowing him -- and our association together for all these years -- I believe that he agrees with me that the contras are freedom fighters and they are trying to achieve democracy in their country, which is now a Communist totalitarian government.

Russian proverb: ``Trust, but verify.'' But given that verification can never be a 100-percent science, given that there are always a few percentage points where you just can't be sure, do you trust General Secretary Gorbachev for those few points?

The President. Well, as I said, right now with regard to the INF treaty, we have worked out verification provisions that are greater than anything that has ever been done before between us. And I think that there is a reasonable chance, a very reasonable chance, that we can continue to have that kind of verification.

One of the first things that I talked over with Mr. Gorbachev in Geneva when we first met was that I said to him we both didn't have great military -- how did I say it -- put it that we didn't mistrust each other because of our great military; we had our military because we mistrusted each other, and that our negotiations should be aimed at removing the causes of mistrust. And I have to say it's pretty much followed that pattern.

The President. He hasn't shown me any reason yet that I shouldn't, but again, as I've said, that's why I kept referring to Dovorey no provorey -- trust but verify. And he knows that, and neither one of us -- I don't think that he would gamble on believing that he shouldn't protect his own interests also.

Mr. President, at your meeting with Mr. Gorbachev yesterday, you toasted the things that he and Vice President Bush will accomplish. You spoke this evening about the grave economic crises that Mr. Gorbachev faces. What is the U.S. assessment of his long-term chances for political survival?

I think we all should -- that he is battling a bureaucracy; because whether it's a Russian bureaucracy or one of our own, the first rule of bureaucracy is protect the bureaucracy. And it would mean some great changes for some of the nomenclatura, as they call their bureaucracy there, if he institutes the reforms that he's talking about. But on the plus side for him, it's very evident that the people of the Soviet Union are on his side. They want this perestroika and this glasnost that he has talked about very much. And I have to believe that the nomenclatura is going to have to think twice with regard to how far they would go in trying to block him when the man in the street over there wants the things that have been seen.

Mr. President, you could help Mr. Gorbachev with a severe domestic political problem, that is, Afghanistan -- how to pull out of there with honor. He suggested at the U.N. yesterday an in-place cease-fire, a cessation of outside military aid. Some people think this could lead to a partition of Afghanistan. What's wrong with that? It would save lives and would help Mr. Gorbachev.

The President. Well, there's one thing. If we're talking about disarming the Mujahidin, remember that there is still a military force in Afghanistan that was organized by the puppet government established by the Soviet Union. And they're a force that has been fighting along with the Soviets and side by side against the Mujahidin. If you want to get around to disarming both sides -- you can't suddenly disarm the Mujahidin and leave them at the mercy of this already military management.

The President. Well, you'd have to take up with the U.N. This is something rather exceptional that he's asking on that, and I'm not sure that the U.N. would like that or that the U.N. is prepared to do such a thing.

The President. I think that we've got to recognize that if the Afghan people are going to be able to state and create the Government they want, then that puppet government has got to be ready and willing to step down, and not have some kind of a compromise thing in which it remains as a government, compromising with the others. Let's let them start from scratch and build the government they want.

Mr. President, let me bring you back to the Middle East. You've got very little time left, and Mr. Arafat of the PLO [Palestine Liberation Organization] seems to be inching towards the kinds of conditions you and Mr. Shultz have said he should. Is this perhaps not time to go the inch in his direction and start some kind of talks with Mr. Arafat rather than, as Mr. Shultz did, close the door on him?

The President. No, we've been watching very closely. And for example, we thought in the last few days that there was a statement that came out of that meeting in Sweden that appeared to be clean-cut and not with the things around the edge that then defused what seemed to be a pledge. But we had to wait until his press conference and what he said.

And I have to say that again he has left openings for himself, where he can deny that he meant this or meant that that sounded so clean-cut. It's up to him. We are willing to meet with him and talk with him, and I'm sure the Israelis would be, when once and for all it is clear-cut that he is ready to recognize Israel's right to be a nation, that he is ready to negotiate on behalf of the Palestinian people for a homeland for them, and so forth.

Now, the thing about George Shultz's decision -- I'd like to call to your attention -- there is a law passed by the Congress with regard to the conditions for granting a waiver to someone to come in and meet with the United Nations or participate in what they're doing. And there's no way under that law that Mr.

Arafat qualifies as yet. And the day that he does, and it is clear cut, then we can grant that visa. But as I say, he is barred by the terms of that law, and the only way that the -- and the Secretary of State has full power under that law. It's his decision to make. And he can only grant a waiver if an individual meets certain requirements, and Arafat doesn't.

Mr. President, in your opening statement, you made reference to our military strength. Sir, a principal element of this nation's strength is our nuclear deterrent, and during your administration, sir, numerous nuclear production plants have been allowed to decay, including plants which produce plutonium and tritium. Sir, what have you directed your aides to do about the problem, and how serious is the threat, particularly since there are plants now in Colorado and South Carolina which have not been allowed to reopen due to safety problems?

The President. And we have made it very plain that we will not allow those plants to reopen until they meet the requirements and constitute no danger to the citizens of this country. And it just has to be that -- cold turkey. Now, I don't think that we can be blamed for the deterioration that certainly began long before we were here.

President-elect Bush a tremendous financial and national security challenge not only in getting these plants back in operating order but also in devising ways that we can dispose of our nuclear waste?

The President. No, we are working on that, and we have been, and we've made more progress than I think we're given credit for on that. And he'll have to continue with doing those things. And I don't think that the problems are all money.

The President. I don't think that anyone that takes over this office is going to give in, nor did I. That is, again, one of those things I should have said to your question, Bill -- that you go to bed with every night. And we are hopeful that there can be avenues that would open. We cannot enter into negotiating in the sense of what kind of ransom to pay, or you're just encouraging more hostage-taking. But there are other channels. We're not advocating that any individual, as some have, take it upon themselves to try to get them out. But we're looking at every channel that we can find to try and get them. And I imagine that the ultimate is going to have to be somehow a negotiation with Iran, because they have control of those people.

The President. Oh, there have got to be some changes there, too. We were not negotiating with them on the so-called Iran-contra affair at all. We were heeding a plea from some individuals -- and at that time all of you were kind of heralding the day in the media that was going to come within a week that the Ayatollah would no longer be the head of government because of his health -- and these people among those who were planning ahead to have a government.

World War II. Do you see that the beginning that had been made here with you and Mr. Gorbachev resulting in a situation where we would once more count the Soviet Union as an ally and have free and open trade with them on a large-scale basis?

The President. I think that is all dependent on them -- if it can be definitely established that they no longer are following the expansionist policy that was instituted in the Communist revolution that their goal must be a one-world Communist state. Now, if that has definitely been given up, and certainly there are indications, we could anticipate bringing such a thing about. Then I do think that there is evidence that they don't like being the pariah, that they might want to join the family of nations and join them with the idea of bringing about or establishing peace.

Mr. President, if the Soviet Union makes good on it and does reduce U.S. troop strength, there's talk on Capitol Hill that perhaps the U.S. can follow suit, and in the process reduce our defense spending and make an impact on the budget deficit. Do you foresee that as a realistic possibility?

Soviet troop cuts could lead to some cuts on our own, and that this would help to reduce the deficit. People are already looking -- some Democrats -- thinking that this may help us to reduce the deficit.

The President. Well, once again, I must repeat, that can't happen with our defense spending until we have reached a parity and at which then both sides can continue the reduction of weapons and keeping it at a parity. But that is not true today. The dropping of 500,000 military personnel still leaves them with 5 million under arms. They still outnumber us in tanks and artillery weapons after they make these cuts. So, we haven't achieved parity, but at least if he goes through with that and succeeds in that, he is going to bring it down to a range where I think that he would see that we could proceed and continue then mutually reducing arms.

President and First Lady completed their annual physical and postoperative examinations at approximately 5 o'clock this afternoon at Bethesda Naval Hospital. The President's physician, Dr. John Hutton, says the President is in excellent health and there is no evidence of any cancer recurrence in the First Lady's mammogram. ``The President is in remarkable physical condition,'' Dr. Hutton said.

President's chest x-ray was clear. His urine samples were normal. There was no clinically significant change in his pulmonary condition. His colonoscopy was performed without sedation of any kind. One small piece of tissue, which resembled a small adenomatous polyp, was removed for biopsy. The tissue, taken from a point approximately 120 centimeters into the colon, and approximately 1 to 2 millimeters in size, will be tested over the weekend. It appeared to be benign. The stress test and electrocardiogram showed the President's cardiovascular system is unchanged and normal. Similarly, the CAT scan test showed no intra-abdominal abnormality.

Reagan's mammogram showed no evidence of cancer of any kind. Physical examination showed her condition was normal. This was the First Lady's second mammogram since undergoing a left modified radical mastectomy in October 1987.

Together we stood under the gaze of Lady Liberty, speaking of the prospects of peace for the peoples of our two nations and for all the world. Yes, since our first summit in Geneva 3 years ago, we've traveled a great journey that has seen remarkable progress, a journey we continue to travel together. I am pleased that the Soviet Union has accepted our offer of humanitarian aid in the wake of their devastating earthquake tragedy.

This has also been a period of important change inside the Soviet Union. The greater openness permitted by Moscow can be found in films, art, and literature. There is greater tolerance for those seeking to peacefully assemble, and the official press carries more independent opinions and factual reporting.

And just a few years ago, who would have anticipated seeing a Soviet leader stand before the world community, heralding a plan for economic restructuring and military redeployments, and promising to meet the world community's highest standards of human rights? If this vision is realized and these promises are turned into deeds, we would be witnessing a dramatic change in the Soviet system, a long-awaited break with the past, and the opening of a new era in international affairs.

But I was encouraged by the new promises of reform that Mr. Gorbachev made before the United Nations and hope to see these and past promises translated into permanent institutional changes that will signal to the peoples of the Soviet Union and the world a courageous commitment to a new path of democratization. We already see unprecedented diversity in Eastern Europe, with some countries pursuing reforms that go even beyond the Soviet example, while other countries continue to lag behind. We hope to see the day when all countries of Eastern Europe enjoy the freedom, democracy, and self-determination that their peoples have long awaited.

Just a decade ago, some intellectuals widely predicted what they called convergence: the idea that the democratic world and the Communist world would merge into one hybrid system. The main question amounted to how much freedom would democratic nations have to give up in the bargain. But instead, the free world held firm to its democratic values, cleaving to truths deeply rooted in Western culture and our Judeo-Christian tradition.

Moreover, we spoke openly of the moral superiority of our ideal of freedom. We candidly criticized the violations of human rights occurring behind the Iron Curtain. We rebuilt our defenses and with our allies worked to counter international aggression by our totalitarian adversaries. And we exhibited that scarcest of commodities: patience. And our steadfastness, our policies, our whole approach has borne fruit. Perhaps the most dramatic achievement came 1 year ago, when Mr. Gorbachev and I signed the historic INF treaty to eliminate an entire class of U.S. and Soviet nuclear missiles.

For some time now, the Soviet bloc has had overwhelming superiority in conventional forces in Europe, so we welcome the Soviet force reductions that are promised. But let's remember this: Even after these redeployments are completed in 1991, the Warsaw Pact will still have a large conventional advantage -- an edge of about 5-to-2 in tanks and artillery and some 300,000 more troops. These unilateral reductions would, however, give a long-awaited encouragement for our efforts to achieve the genuine balance in conventional forces that would assure greater security and stability in Europe.

Well, in these brightest of times, let us recall that in the darkest days of World War II, when hopes for the free world seemed most bleak, Winston Churchill rallied us to carry on, saying that ``We have not journeyed all this way because we are made of sugar candy.'' By summoning all their strength and courage, and by pulling together, the allies prevailed. The war was won.

The decades following World War II were filled with political tensions and threats to world freedom. But in recent years, we've seen hopes for a free and peaceful future restored and the chance for a new U.S.-Soviet relationship emerge. To the American people and to our allies, I would echo Churchill and say we have not come this far through lack of strength or any weakness in our resolve, nor has there been anything inevitable about what we've achieved. The unity, confidence, power, and firmness of the democracies has brought us forward, and maintaining a strong alliance will keep us moving forward.

Martin, tribal chief of the Mississippi Choctaw, said, ``We need jobs, an environment to put people to work.'' He suggested an economic council composed of private sector representatives, the Indian tribes, and the Government to create employment opportunities.

The signing of the protocol of Brazzaville this morning by the Governments of South Africa, Cuba, and Angola opens the way to peace and stability in southwestern Africa. This development fulfills President Reagan's policy determination made early in this administration to seek the removal of all foreign troops from Angola, the implementation of United Nations Resolution 435 for the independence of Namibia, and support for the UNITA [National Union for the Total Independence of Angola] freedom fighters in Angola. It was the combination of the United States steadfast support for these objectives and skillful mediation over a period of 8 years that made this breakthrough for peace possible.

American mediating team, the participating governments, and President Sassou-Nguesso of the Congo are to be congratulated for their role in this extraordinary achievement. We hope that this major diplomatic milestone in southern Africa will be followed by renewed efforts to settle the internal conflict in Angola through a process of national reconciliation and peaceful negotiation among Angolans.

Well, thank you all very much. I'm very happy to be with you today to talk about what we've accomplished these past 8 years and to look forward to what there is yet to accomplish. The Business-Government Relations Council stood with this administration as we fought the established wisdom that once ridiculed our ideas about economic growth and taxation. The companies that you represent recognize that they would not be able to succeed in the increasingly competitive world marketplace without major reforms at home. And that's why you supported us as we fought to cut taxes, eliminate unnecessary regulations, and restrain the growth of Federal spending.

That was quite a battle, but the battle was worth it, and the facts bear this out: 6 full years of uninterrupted economic growth, the longest peacetime recovery in history; an unemployment rate of 5.4 percent; and almost 19 million new jobs created since our recovery began. Today more Americans are at work than ever before in the history of this great country. And a greater percentage of the total work force is currently employed. Now, that total work force -- I had to come here to find out what they meant by that. That's everybody in the United States, male and female, 16 years and up. And 62.6 percent of them currently employed.

We understood the key to prosperity was low-inflationary growth, and we achieved it. Our other aim -- cutting the budget deficit -- was hampered by a budgetary process that can only be called insane. And so, I continue to support two measures to stop runaway Federal spending: The line-item veto and the balanced budget amendment. George Bush needs them, and I hope you will help him get them.

I know Clayton will be talking to you about the Uruguay round mid-term review in Montreal last week, but let me just say this: We've made remarkable strides during this decade toward our goal of free and fair world trade not only in the GATT but also through our passage of the U.S. - Canada free trade agreement.

There are many who said that we could not stem the tide of protectionism, that the only way to respond to unfair trading practices was to close off our own market. Well, we didn't want to succumb to this defeatist attitude. So, we launched the Uruguay round against all odds 2 years ago. And the mid-term review -- we reached agreement on a framework to move the negotiation forward in all but the two most difficult areas: agricultural and [for] intellectual property.

We remain committed to an international trading system based on the principles of freedom and fairness. And we'll continue to press for the end of agricultural subsidies and the protection of intellectual property. We're confident these aims can be achieved. And when they are, I believe the people of the world will know a prosperity of which we have only the slightest glimmering.

President Reagan met with PRC Ambassador Han Xu at the White House to convey his personal good wishes to the Chinese people on this occasion. The President noted the historically warm feelings of Americans for the Chinese people and the major contributions that Americans of Chinese descent have made, and continue to make, to the development of our country and the enrichment of our heritage.

During the meeting, the President recalled that his three predecessors, of differing parties and viewpoints, had all worked with China's leaders to bring our nations and peoples closer together. He expressed satisfaction at having been able to continue and expand on their efforts. The President looked back with pleasure on the warm hospitality he had received during his own visit to China in 1984, when he had been able to see firsthand the great strides China was making to implement reforms and better the life of its people.

In conclusion, the President expressed confidence that with our relationship firmly grounded on the three U.S.-China joint communiques of 1972, 1979, and 1982, China and the United States would be able to work together in the years ahead to forge even stronger ties and build a safer and more prosperous world.

Section 201(a) of the Implementation Act authorizes the President to proclaim such modifications or continuance of existing duties, such continuance of existing duty-free or excise treatment, and such additional duties, as the President determines are necessary or appropriate to carry out Article 401 of the Agreement (including the schedule of duty reductions with respect to goods originating in the territory of Canada set forth in Annexes 401.2 and 401.7).

Such duty does not apply to the cost of repair parts, materials, or expenses of repairs in a foreign country upon a U.S. civil aircraft, as defined in general note 3(c)(iv) to the HTS. I have determined that it is necessary or appropriate to provide for the staged reductions in the rate of duty on such equipments, or any part thereof, originating in the territory of Canada and the expenses of repairs made in the territory of Canada upon U.S.-documented vessels (except such civil aircraft), as set forth in Annex 401.2 of the Agreement.

In order to implement the duty treatment provided by the Agreement and to set forth rules for determining the country of origin of goods imported into the customs territory of the United States for purposes of the Agreement and of the Automotive Products Trade Act, general note 3 to the HTS is modified as set forth in Annex I to this Proclamation.

Except as provided in paragraph (a), this Proclamation shall be effective with respect to articles entered, or withdrawn from warehouse for consumption, on or after January 1, 1989, or, if the Agreement does not enter into force on January 1, 1989, on or after such later date as the Agreement enters into force.

Witness Whereof, I have hereunto set my hand this 14th day of December, in the year of our Lord nineteen hundred and eighty-eight, and of the Independence of the United States of America the two hundred and thirteenth.

United Nations Security Council Resolutions 242 and 338, recognized Israel's right to exist, and renounced terrorism. These have long been our conditions for a substantive dialog. They have been met. Therefore, I have authorized the State Department to enter into a substantive dialog with PLO representatives. The Palestinian Liberation Organization must live up to its statements. In particular, it must demonstrate that its renunciation of terrorism is pervasive and permanent.

The initiation of a dialog between the United States and PLO representatives is an important step in the peace process, the more so because it represents the serious evolution of Palestinian thinking towards realistic and pragmatic positions on the key issues. But the objective of the United States remains, as always, a comprehensive peace in the Middle East. In that light, we view this development as one more step toward the beginning of direct negotiations between the parties, which alone can lead to such a peace.

United States special commitment to Israel's security and well-being remains unshakable. Indeed, a major reason for our entry into this dialog is to help Israel achieve the recognition and security it deserves.

The President. Well, because the words have been spoken and the words were the words that we have been stating were necessary. But, of course, you then also -- the words must be matched by performance, and if they're not, why, we're back where we started.

President. The importance of this decision is the fact of having found someone who represents the Palestinians. This helps to work towards the solution of a delicate problem because to make peace you have to know who to make peace with and who is your counterpart. And now talks will help us understand whether conditions are there for negotiation. The decision of the American Government is very important because it has solved this problem of finding the counterpart.

These talks are part of step-by-step negotiations between the United States and the Soviet Union on the subject of nuclear testing. The first priority of the talks is agreement on effective verification measures for two existing treaties, the PNET and TTBT. Neither treaty has been ratified because they were not verifiable in their original form. During this round, the delegations have substantially finished work on the verification protocol for the PNET. They have also made progress on the verification protocol for the TTBT.

Under the terms of a U.S.-Soviet agreement negotiated in the previous round of the NTT and signed at the Moscow summit, underground nuclear explosions were conducted at the U.S. test site in Nevada in August and at the Soviet test site at Semipalatinsk in September, with observers from both sides present. The purpose of the JVE was to allow each side to demonstrate its preferred verification method for the TTBT and PNET.

Following ratification, the United States will immediately propose that we and the Soviet Union enter into negotiations on ways to implement a step-by-step parallel program -- in association with a program to reduce and ultimately eliminate all nuclear arms -- of limiting and ultimately ending nuclear testing.

For the past four decades, a strong nuclear deterrent has ensured the security of the United States and our allies. As long as we must rely on nuclear weapons, we must continue to test to ensure their safety, security, reliability, effectiveness, and survivability. In this context, the United States seeks effective and verifiable agreements with the Soviet Union on nuclear-testing limitations that would strengthen security for all nations. The substantial progress which has been made in this round of the Nuclear Testing Talks is a positive step which reflects the success of the administration's practical and measured approach to nuclear testing.

Christmas, Joe, and a very Merry Christmas to all! Nancy and I are together with you in celebration and reflection -- celebration of the great miracle nearly 2,000 years ago that brought the Christ child to us and reflection on the great gifts He has bestowed upon us.

Christmas casts its glow upon us, as it does every year. And it reminds us that we need not feel lonely because we are loved, loved with the greatest love there has ever been or ever will be. In the bustle and rush of daily life, we sometimes forget how very much we have and how much we have to thank God for providing -- for things as beautiful as a winter snow or babies who will be seeing their first Christmas, seeing the wonder of its beauty in their eyes. And, yes, from the poorest among us to the most fortunate, we are all blessed.

Americans live with bounties that those who lived at the time of the Christ child's birth could never have imagined. The bounties are material, yes, but chiefly they are spiritual. Those who would worship the birth of our Lord may do so in the church of their choosing and in the way of their choosing. Those among us who do not so celebrate the birth are free to share with us in this, our time of joy. In this day, when our freedom to worship is most precious, let us redouble our efforts to bring this and other greatest freedoms to all the peoples of the Earth.

And as we light this glorious tree, may Nancy and I offer a final wish to all Americans: that every Christmas that follows will be as full of joy as we have these past years to work in your service. May God bless you all. And now Nancy will help me light the tree. And again, a very Merry Christmas.

But you know, as I look at this remarkable university which, from its academic ideals to its magnificent grounds, is so fully the product of a single man's vision, I have to say that Thomas Jefferson would be proud of this school -- yes, proud of how far it's come, but even more for how closely it's stayed true to its traditions. In fact, I remember when Thomas Jefferson told me personally that his -- [laughter] -- that his favorite movie was ``It's a Wonderful Life.'' I know that film has become an institution here. And if it would be hard to imagine the mythical village of Bedford Falls without George Bailey, as played by my friend Jimmy Stewart, think how much harder it would be to imagine Charlottesville, much less America, if there had been no Thomas Jefferson.

To imagine that is almost beyond our grasp, but the underlying idea is very plain and also very exciting: that your life not only can but necessarily must make such a great difference in the lives of others, and in the world, that without you little would be the same. And that's never been more true than for your generation because today the rate of change is so remarkable that each one of you will be creating, literally inventing, a new future each step of the way.

This summer, when I spoke to the students at Moscow State University, I told them that the new technological or information revolution will fundamentally alter our world, shatter old assumptions, and reshape our lives. I said, we're emerging from the economy of the Industrial Revolution -- an economy confined to and limited by the Earth's physical resources -- into, as one economist titled his book, ``The Economy in Mind.'' Well, let me put it this way: I was an economics major in college, and the traditional formulation was that the three factors of production were land, labor, and capital. But in the emerging economy, land may mean little more than the limitless grains of sand used to make microchips. Labor is coming to mean the creativity of the writer of computer software. And capital has become electronic blips of credit that rocket around the globe, crossing national borders in search of opportunity at the speed of light.

This is a new economy being created, one that exists beyond material resources or centralized planning or government control. It's driven from the ground up by our new heroes, the entrepreneurs, the explorers of the modern era, who conceive, create, and produce, and in doing so discover the future one piece at a time. I dare say that it's a path to the future that Thomas Jefferson would have approved of. We know of his belief in the individual. One glance at his beloved Monticello is enough to tell us how much he loved technology and invention. And he was also a man who respected the hard evidence that the real world provides, and that evidence has been indeed hard and clear.

The fact is that in this age of entrepreneurship and innovation, our economy has been thriving as never before. Starting 8 years ago, we charted a new course that lifted America up from the worst economic crisis since the Great Depression. We did it by cutting taxes, reducing the growth in government spending, and eliminating unnecessary regulation. We got government out of the way, and we put our faith in the people so they could work their magic. The result is more Americans working than ever before and the longest peacetime economic expansion ever recorded.

And the nations of the world are following our example and initiating our policies. America is leading the world into a bright and glorious tomorrow. And today more than at any point in human history, we can truly say that the future belongs to the free. And America is the land of the free. And there have been a few voices raised here which illustrates, yes, how free America really is.

So, you can play a special part in this future. You'll be its author: Take full advantage of the wonderful life that lies in store for you. Rejoice in your freedom, sample the full richness of the opportunities that lie before you.

Help one another, trust in yourselves, and have faith in God, and you'll find more joy and happiness than you could imagine. And always remember that you are Americans, and it is your birthright to dream great dreams in this sweet and blessed land, truly the greatest, freest, strongest nation on Earth.

I have taken to collecting jokes that I can absolutely prove and establish are made up by the Russian people and told to each other, among the Russian people, which reveals they've got a great sense of humor, but also shows that they have a certain cynicism about their way of life and their way of government.

I want to ask you a question: Will you help me to reduce the Federal budget deficit and then balance the budget once and for all? No, I'm not asking you to pay more taxes. I think you already pay plenty, and those trying to tax away more of your hard-earned money should be ashamed of themselves. Instead, what I need is for you to help me fix a budget system that has broken down.

Government has run a deficit, and every dime of deficit spending over these many years has been mandated by Congress. You see, under the Constitution, only Congress can spend money; the President can't appropriate a penny. Up until 1974, the President did have one effective way to control spending: He could refuse to spend money appropriated by Congress. And this ability to impound funds was routinely used by such Presidents as Thomas Jefferson and Franklin Roosevelt. In fact, three of my predecessors -- Presidents Kennedy, Johnson, and Nixon -- used this power each year to reduce Federal spending by between 5 and 8 percent. During my Presidency, that would have reduced the deficit by billions each year, but all that changed in 1974.

In the 1974 Budget and Impoundment Control Act, Congress stripped the President of his ability to refuse to spend funds. Let me try to describe the effect of this change. Suppose the rules of hockey were changed and the goalie was removed from the game. Would you be surprised if hockey scores quadrupled? Well, since Congress changed the budget law, Federal spending has in fact quadrupled, and it has come right out of your pocket. And under the new rules, the deficit has taken off. For a quarter century, the average annual Federal deficit was just 0.7 percent of gross national product. Then in the mid-1970's Congress changed the rules, and since then the deficit has been running five times higher than before.

The verdict is in: The current system does not work. Can you imagine if a head of a household or a business were forced to spend every dime that was budgeted, even if savings were available? Well, that's the situation the President is in now.

All he can do is ask Congress to take back funds it appropriated. Since 1982 I have requested Congress to take back unneeded funds more than 460 times, and 83 percent of the time they refused. Most of the time they didn't even bring it up for a vote. They simply said: No, spend it all.

During my two terms, Congress appropriated over $100 billion more on domestic spending than I requested. But this is typical. Between 1976 and 1987 -- a period spanning three Presidencies in which we ran a deficit each year -- Congress spent an average of $30 billion per year more than the President requested. The budget system simply has no control and no internal discipline.

And that's the problem. Now, here's what must be done. To solve the deficit problem, it is essential that we restore the constitutional balance and repair the system. We need to give the President greater authority to limit spending -- that means the line-item veto, which 43 Governors have -- and also greater authority for a President to return unneeded funds to Congress. Congress must reform its faulty budget process. And we need a balanced budget amendment to the Constitution so the Federal Government does not spend more than it takes in. After I leave office next month, I will campaign for these reforms. So, today I'm asking you to join me in this vital campaign for the future by making your voice heard. If we achieve these reforms, the deficit will be ancient history in no time.

The only way to reduce the deficit is by limiting the increase in spending, and that's what my last budget will do. Without touching Social Security or raising taxes, our fiscal year 1990 budget will reduce the deficit by some $35 billion, more than meeting the Gramm-Rudman target. You see, economic growth will increase revenues by $80 billion without new taxes. Just by holding spending increases to less than $80 billion, we will reduce the deficit and put ourselves on track for a balanced budget by 1993. And with your help that will be done.

The themes of Christmas and of coming home for the holidays have long been intertwined in song and story. There is a profound irony and lesson in this, because Christmas celebrates the coming of a Savior Who was born without a home.

As we come home with gladness to family and friends this Christmas, let us also remember our neighbors who cannot go home themselves. Our compassion and concern this Christmas and all year long will mean much to the hospitalized, the homeless, the convalescent, the orphaned -- and will surely lead us on our way to the joy and peace of Bethlehem and the Christ Child Who bids us come.

In order to incorporate in the HTS the changes in tariff treatment enacted in the TMRA and to make certain technical rectifications, the HTS is further modified as set forth in Annex II to this Proclamation.

Witness Whereof, I have hereunto set my hand this 21st day of December, in the year of our Lord nineteen hundred and eighty-eight, and of the Independence of the United States of America the two hundred and thirteenth.

U.S.C. 2253(i)) with respect to the probable economic effect on the domestic industry of the termination of the import relief after 30 months. The USITC was equally divided on the question of whether the continuation of import relief would result in positive adjustments that would enhance the competitiveness of the domestic industry. On the basis of the advice that I have received, I have determined that the industry has undertaken positive adjustment efforts to improve competitiveness during the 30-month period of relief. However, the additional duties have burdened consumers and have encouraged substitution of alternative non-wood roofing materials.

Secretaries of Commerce and Labor, I have determined that recent market trends have impaired the effectiveness of import relief provided to the domestic industry. Accordingly, I have determined that it is in the national interest to accelerate the reduction of import duties.

Over the last 2 weeks, the hearts of the American people have gone out to the people of Armenia as they grappled with the earthquake disaster and its aftermath. The world wept at the terrible magnitude of the destruction and the tremendous loss of life: whole villages and cities virtually leveled. Great numbers of men, women, and children were trapped beneath fallen buildings in one of the worst earthquake disasters ever to occur. Tens of thousands were killed, countless numbers injured, and many others tragically missing.

But no sooner had we learned of the disaster and of the great need that existed than you and so many other Americans organized to help. Rescue workers and medical teams from across the country flew to the Soviet Union where you searched for the living and gave care to those who were injured. And thanks to your immediate response and special skills, precious lives were saved.

Here in Washington, the people in AID's Office of U.S. Foreign Disaster Assistance worked around the clock to coordinate the effort. And thanks to people from this country and from throughout the international community, direct assistance and desperately needed supplies were able to reach the survivors. And throughout this period, American relief organizations, churches, and the American-Armenian community have produced a great humanitarian response, which continues providing all forms of material assistance to that devastated area.

Ladies and gentlemen, thanks to people like you here today, the Armenians have not had to face this tragedy alone. And for that I want to personally thank you on behalf of every American. Those of you who answered the appeal for help, who have assisted in the relief effort, and those who flew to the Soviet Union and sifted through the rubble, searching for life against all odds, carried with you a message from America. It was a message of peace. You conveyed what was truly a universal message, one for us all to remember at this time of year: that every life is infinitely precious, a gift from God. So, whatever language we speak, whatever country we may live in, whatever our race or religious faith, we're all one people on this Earth. And in times of suffering, in the face of natural disaster, we're drawn by our common humanity to help one another, to join in a great brotherhood of man.

I am pleased to announce that Secretary of State Shultz represented the United States at a very important ceremony today in New York in which formal agreements were signed aimed at bringing peace to southwestern Africa. The foreign ministers of South Africa, Angola, and Cuba signed accords leading to the staged and complete withdrawal of Cuban military forces from Angola and for implementation of U.N. Security Council Resolution 435 leading to independence for Namibia. The United States mediated negotiations leading to these historic agreements.

The agreements signed today are the result of intense negotiations which have taken place over several years. They promise to end the cycle of violence which has plagued the Namibian-Angolan border area for more than 13 years, inflicting untold human misery and property damage. We are pleased that Namibia is to gain its long-overdue independence after being occupied by South African forces for more than 70 years. Regarding the Cuban military in Angola, the United States long has contended that the presence of Cuban combat forces was a destabilizing element in the region.

We are gratified that they will be departing the African continent. When completed in 1991, the total withdrawal of Cuban forces from Angola will end one of the major regional problems that have troubled U.S.-Soviet relations in recent years.

United States, as mediator in the negotiations, is pleased to have assisted the parties to find a peaceful formula to reconcile differences and looks forward to working with other members of the joint commission formed to monitor implementation of the agreements.

Cogan currently serves as Acting Deputy Director of the Office of Management and Budget and is on leave from his position as a senior fellow at the Hoover Institution, Stanford University. He has held several previous positions in the Reagan administration: Assistant Secretary of Labor for Policy; Associate Director for Economics and Government; and then Associate Director for Human Resources, Veterans and Labor. He has served in two senior policy positions at the Office of Management and Budget until late 1985. He has worked as a research economist at Rand Corp. and as a professor of economics at Stanford University.

I have a little statement here as Nancy and I depart for California to spend the holiday season with family and friends. I want to express our sorrow and our concern for the families and friends of those who died in the crash of the Pan American Flight 103.

There are many difficult aspects to this tragedy, but none so compelling as the anguish of those families who will not have their loved ones with them this Christmas season. Christmas is a special time for the young, for those who carry the twin promises of hopes and dreams. And on this flight were the hopes and dreams of many young people, including the tragic loss of so many students from Syracuse University. A tragedy that steals the hopes and dreams from our society magnifies the loss to our society. I know that America and the world mourn the loss of these wonderful people. And I ask that all of our citizens say a special prayer this Christmas for those who have felt the pain of those losses.

The President. I think all the precautions that could be taken were taken, with regard to warning the airline and all. But if you stop to think about it, such a public statement with nothing more to go on than an anonymous telephone call -- you'd literally have closed down the air traffic in the world.

The President. No, that, as I say, I think that would have been a virtually impossible thing to do on the basis of that telephone call. And then when, if ever, would there be a revival on all airlines?

Commissioned Corps of the United States Public Health Service celebrate a century of service to Americans and to all mankind. The rest of us can join in this celebration as well, to express our thanks and pride at their successes over the past 100 years.

Those successes have been notable. They include playing a key role in many breakthroughs in health care; battling diseases such as smallpox, tuberculosis, and pellagra; developing vaccines; performing with efficiency and courage during emergencies, epidemics, and similar situations; and working in fields such as disease control and prevention, research, environmental intervention, and health care delivery and program management.

Corps members' broad training and experience make them an effective team of medical and health experts. The Corps offers health care for American Indians, Native Alaskans, the Coast Guard, the Merchant Marine, and the Bureau of Prisons and helps provide consumer protection.

Every member of the Commissioned Corps, past and present, deserves the heartfelt congratulations of the American people for outstanding accomplishment in public health. That is a debt we should be only too happy to pay, on the centennial of the Corps and always.

We do so in memory of a man who asked to be recalled by his countrymen not for any earthly honors he had won but as ``a drum major for justice.'' That title he deemed greater than any other because earning it would mean that he had not lived his life in vain.

In a sermon on the eve of his assassination, he surely described his own mission when he asked, ``Who is it that is supposed to articulate the longings and aspirations of the people more than the preacher? Somehow the preacher must be an Amos, and say, `Let justice roll down like waters and righteousness like a mighty stream.''' Martin Luther King, Jr., did exactly that. He gave eloquent voice and powerful leadership to the long-cherished hopes of millions as he headed a crusade to end bigotry, segregation, and discrimination in our land; to foster equal opportunity; and to make universal America's promise of liberty and justice for all.

King's work is not done, but neither is his witness stilled. He urged again and again that all of us come to love and befriend one another, to live in brotherhood and reconciliation, to nourish each and every individual's dignity and self-respect. We must reaffirm in every generation the lessons of justice and charity that Dr. King taught with his unflinching determination, his complete confidence in the redeeming power of love, and his utter willingness to suffer, to sacrifice, and to serve. We must, and we can, all be drum majors for justice. That is our duty and our glory as Americans. On Martin Luther King, Jr., Day and every day let us unite in prayer and promise to be true to the American Dream he loved and renewed.

Because of the common stresses and strains of everyday life, we may be forgiven for forgetting from time to time all that God has given us. One child has a fever; another is grumpy; a third is asking why is the sky blue, and all the while there are bills to pay and a roof that leaks. Sometimes it all seems a little too much, and at these moments we look back with longing to a time when our responsibilities did not seem so large. But this season those responsibilities are revealed for what they truly are: the God-given blessings that give our lives flavor and meaning. And the more responsibilities of this kind we have, the greater are our blessings. For in this way we're indeed made in the image of our Lord: At our best, our capacity to love seems inexhaustible. We know at this time of year that all we must do is give of ourselves, and in return we shall receive all that we have given and much, much more.

We know that there are those among us for whom the holidays are painful and lonely. I know you join with me in hoping that this year they will take heart and have faith. For the message of this most joyous holiday is that we are all -- no matter what divides us -- we are all loved by a force greater than ourselves, a love that surpasseth all understanding, a love that provides all the answers for those who feel lost and alone during these remarkable days. We are not alone; we're never alone.

Now, here in our country, there are children, without homes, suffering from dire diseases, whose Christmases will be makeshift at best. But the miracle of human generosity can and does transform the holidays for them. This year, as in years past, your generosity has been breathtaking. Programs like Toys for Tots and literally tens of thousands of local initiatives are examples of this nation's determination to give all children a sense of what the Christmas spirit is and what it can mean for them.

I know all Americans have joined with me in grieving for those who perished in the Armenian earthquake. Tragedies of this nature afflict our spirit; it's hard to see why such a thing happens, what it might mean. But the Armenian people are showing us they know they are loved. They know they can renew their strength and rebuild and rededicate themselves to life.

And at a time of such terrible calamity, something happens in the world, something worth thinking about at Christmastime. For a time, the real differences that divide us -- and will continue to divide us -- fall away. Closed borders open.

Friends and enemies alike share the burden and hope to help. From Israel and war-torn Lebanon alike, supplies and aid have been sent to Soviet Armenia. And from the United States the response has been staggering: relief workers, tens of millions of dollars in private contributions, food, clothing, a cascade of good will and fellow feeling.

Armenia the birth of our Lord is not celebrated until January 6th. It is an Armenian tradition that priests travel to the homes of their flock and there make a special blessing with bread, water, and salt, representing life and substance. This season, more than ever, may the blessings of the priests over the bread and water and the salt provide the Armenian people with the strength to persevere and triumph.

This has been an historic year for Afghanistan. For the Afghan people, years of determination in the face of great adversity have been rewarded by the promise of peace. On April 14 in Geneva, the Soviet Union formally agreed to withdraw all of its troops from Afghanistan by February 15, 1989.

The agreement required that in the first stage the U.S.S.R. remove half of its forces from Afghanistan within 90 days -- a task they met. I fully expect them to honor their obligation to withdraw completely by February 15.

Nine years ago today, the Soviet Union invaded Afghanistan in a brutal attempt to prop up an unpopular and authoritarian regime. Today we all know the outcome of this tragic mistake. Rather than achieving its aim, the Soviet action resulted only in destruction and continued suffering for the Afghan people. More than 1 million people are thought to have died or been injured, while at least one-third of the population was forced to take refuge in neighboring Pakistan and Iran or to flee to the large cities of Afghanistan to escape the carnage in the countryside. Even today, as February 15 approaches, the Soviets continue offensive military operations in Afghanistan. The introduction of new weapons and the escalation in the use of Soviet warplanes in bombing raids against Afghanistan call into question the Soviet commitment to a peaceful solution.

At every turn, it is the determination of the Afghan people and the valiant freedom fighters, the Mujahidin, that stays the advance of tyranny in Afghanistan. We are proud to have supported their brave struggle to regain their freedom, and our support for this noble cause will continue as long as it is needed.

Self-determination, the right to freely choose one's own destiny, has been the central point of the Afghan struggle. The Afghan people have clearly demonstrated that they will resist any effort by outsiders to impose a leadership on them. We have held that any decision about the government in a free Afghanistan will be -- must be -- the free choice of the Afghan people alone. With the end of foreign occupation, I am confident that the Afghan people will be able to take charge of their own affairs and get on with the formidable task of rebuilding their country.

This will be my last statement as President marking the occasion of the anniversary of the Soviet invasion of Afghanistan. Nonetheless, the date will long be remembered not as yet another anniversary in a continuing occupation but, God willing, as a reminder that the Afghan people are determined to be free, regardless of the odds. The men and women of Afghanistan are an example to those anywhere in the world who would call themselves free. If liberty comes with a price, the Afghan people have more than paid it for themselves and for the future generations. In the name of the free people of the United States, I again salute the resolute people of Afghanistan and wish them Godspeed on the tasks still before them.

The territorial sea of the United States is a maritime zone extending beyond the land territory and internal waters of the United States over which the United States exercises sovereignty and jurisdiction, a sovereignty and jurisdiction that extend to the airspace over the territorial sea, as well as to its bed and subsoil.

Constitution of the United States of America, and in accordance with international law, do hereby proclaim the extension of the territorial sea of the United States of America, the Commonwealth of Puerto Rico, Guam, American Samoa, the United States Virgin Islands, the Commonwealth of the Northern Mariana Islands, and any other territory or possession over which the United States exercises sovereignty.

In accordance with international law, as reflected in the applicable provisions of the 1982 United Nations Convention on the Law of the Sea, within the territorial sea of the United States, the ships of all countries enjoy the right of innocent passage and the ships and aircraft of all countries enjoy the right of transit passage through international straits.

Procurement Sanctions. Pursuant to section 2443 of the Omnibus Trade Act and subject to the exceptions referred to in paragraph (3), departments, agencies and instrumentalities of the United States Government shall not for the three-year period beginning on the date this Order takes effect, contract with or procure products and services from Toshiba Machine Company, Kongsberg Trading Company, Toshiba Corporation or Kongsberg Vaapenfabrikk.

Import Sanctions. Pursuant to section 2443 of the Omnibus Trade Act and subject to the exceptions referred to in paragraph (3), importation into the United States, its territories and possessions, of products produced by Toshiba Machine Company or Kongsberg Trading Company is prohibited for three years from the effective date of this Order.

Exceptions. Authority to make determinations as to exceptions to sanctions and to implement exceptions by regulation or otherwise is delegated (i) to the Secretary of Defense with respect to determinations under section 2443(c)(1) regarding the procurement of defense articles or defense services, (ii) to the Secretary of the Treasury with respect to exceptions under section 2443(c)(2) regarding importation prohibited by section 2443(a)(2), and (iii) to the head of each Federal department, agency or instrumentality with respect to exceptions under section 2443(c)(2) affecting their respective contracting and procurement. All regulations implementing these exceptions provisions shall be consistent with any guidelines provided by the Office of Federal Procurement Policy, Office of Management and Budget.

Annual Report. The annual report required by section 2445, concerning estimated increases in defense expenditures arising from illegal technology transfers, shall be prepared by the Secretary of Defense, in consultation with the Secretaries of State and Commerce, for submission to the Congress by the President.

Secretary of State, who in performing such functions shall act in consultation with the Attorney General, the United States Trade Representative, the Chairman of the Securities and Exchange Commission, the Secretary of Commerce, the Secretary of the Treasury and the Director of the Office of Management and Budget.

The Office of Management and Budget shall provide to the Secretary of Commerce, in sufficient time to permit preparation of the report, a summary of the Federal base program and Fiscal Year 1990 budget initiatives in each of the technical areas of the report.

The Office of Science and Technology Policy (``OSTP'') shall provide the Secretary of Commerce with appropriate policy guidance in the technical areas of the report, including a summary of the criteria used to select research projects within an agency and among agencies, and the results of any studies conducted by OSTP, or by others if OSTP deems them to be relevant, which analyze the influence of the Federal research programs in the technical areas of the report.

Report. By February 23, 1989, the Commission shall submit a report to the President and the Congress with recommendations regarding methods of enhancing the research, development, and implementation of improved superconductor technologies in all major applications.

Competitiveness Act of 1988. The 1100 page act assigns numerous authorities and responsibilities to the President. The President's general objective in signing the Executive order was ``to ensure that the international trade policy of the United States shall be conducted and administered in a way that achieves the economic, foreign policy, and national security objectives of the United States and in a coordinated manner under the direction of the President.'' The order will enable the United States to continue effectively to work for more open world markets and strengthened international institutions.

This morning the President was informed by national security adviser Colin Powell that the British Department of Transport has determined that the crash of Pan Am Flight 103 was caused by a high explosive device. We have closely cooperated with the British investigation. We agree with the results of their investigation.

The investigation will continue to determine how the explosives were introduced into the plane. The FBI and the FAA are working closely with the British and Scottish authorities on the investigation. We are determined to find out who did it, using all available resources.

I have to say, also, that we have -- or the FAA is studying and making recommendations as to additional things we can do at airports to provide security for those who travel. And finally, the one and most important thing left to say is the sympathy that I know we all feel for those who lost loved ones in that tragedy. And I think we're all determined to do everything we can to see that we can put an end to that happening again.

Tonight we celebrate the coming of a new year, a time of expectation and promise. I believe it's going to be a very good year indeed. Our economy is healthy. Our defenses are strong. And our policy of peace through strength is paying off in spades.

In 6 weeks time, the Soviet Union is due to pull its remaining forces out of Afghanistan. I'm confident the Soviets will stick to their timetable and be out by the 15th of February, which will then be a great day for world peace.

I'm also confident about 1989 because in just 3 weeks George Bush will be sworn in as the 41st President of the United States. And a superb President he's going to be. He has handled skillfully the selection of his Cabinet, and the transition process is proceeding well and smoothly.

So, the news is good this New Year's Eve. Of course, we still reel in shock and horror from the bombing of Flight 103 over Lockerbie, Scotland, and we extend our sympathy to the bereaved. Now, if, as seems likely, our terrorists have crawled out of their hole to threaten American lives, I can promise them this: The pledge we made to seek out the truth and punish the guilty is a sacred one which George Bush shares. Indeed, President-elect Bush knows as thoroughly as anyone in the world today the nature and problem of terrorism. As chairman of this administration's task force on terrorism he oversaw a report that is the toughest statement to date on the need for strong action -- including, when warranted, military action -- against terrorists. That report ought to be giving some people sleepless nights right about now.

That crime aside, however, there is little to disturb us about the overall state of the Nation as we join together to make merry and sing ``Auld Lang Syne.'' But still, during these days, when you turn on the television or read through the newspaper, you might get the idea that what faces George Bush upon his assumption of the responsibilities of the Presidency of the United States will be nothing but a series of impossible choices, heartaches, and just general trouble. Now, I'm sure most of this talk is simply evidence that we're about to go through a change of leadership, a moment in time that does funny things to people, particularly in Washington. For some, this is a time to put in their bids on the agenda of the future. For others, this is a time for the jitters because they try to imagine what the future will bring and find it a little confusing.

These jitters have been overcome with courage and vision in both the United States and Canada as the way has been cleared for an historic new free-trade agreement to take effect tomorrow. And I want to assure you, as we do take this time together to look ahead, that there is not a single major problem facing this country today that cannot be solved when we come together to solve them. What it takes is the political will to solve them -- rather like a successful New Year's resolution.

Now, here are a few New Year's political resolutions I think could be accomplished in 1989. I think we should resolve to keep within the Gramm-Rudman targets and eliminate the deficit entirely by 1993. I'll be telling you more about our budget for the next fiscal year over the next few weeks, but let me just say that this new budget represents a serious and dedicated effort to produce a realistic plan for meeting our responsibilities to reduce the deficit, maintain our defenses, and help the needy. I've said it before, and I'll say it again: All this can be done without raising taxes. Higher taxes mean slow economic growth, and economic growth combined with budget realism is the key to eliminating the deficit. George Bush's lips have been eloquent on this subject, and it sure would be a great new year if we continue the progress we made this year, putting an end to those mammoth continuing resolutions and work with a real budget again.

We can continue to improve relations with the Soviet Union in 1989 if we remember that the key to improved relations thus far has been our strength and resolution. We must remain sober in our estimation of our negotiating partners and without illusion; we know about their goals and aims. Whether we're talking about bilateral relations with the Soviet Union or efforts to achieve a negotiated settlement in the Middle East, the lesson is the same: To achieve further reductions in international tensions, the incoming administration will need appropriate levels of defense spending, not to mention support from Congress for their foreign policy initiatives. Trust me, I know.

This section shall not apply with respect to any proposed rules related to agricultural, food, beverage, and certain related goods as defined in Chapter Seven (Agriculture) of the Free-Trade Agreement.

Having considered the relevant measures taken by Canada, along with the unanimous views and recommendations of the United States Trade Representative and interested United States Government agencies, I have determined that Canada has taken measures necessary to comply with the obligations of the United States-Canada Free-Trade Agreement (Agreement). The United States has completed necessary legal procedures in accordance with Article 2105 of the Agreement.

To further implement Chapter Nine of the Free-Trade Agreement with regard to trade in energy goods, and as indicated in Chapter Nine of the Statement of Administrative Action that I transmitted to the Congress with the Free-Trade Agreement, I also am making these findings and determinations with regard to exports of petroleum (as defined in 10 U.S.C. 7420(3)) from the Naval Petroleum Reserves, where proof is lacking that those exports are not derived from or commingled with petroleum from the Naval Petroleum Reserves.

Therefore, effective upon the entry into force of the Free-Trade Agreement for the United States, such domestic petroleum may be exported to Canada, exports of crude oil to be for consumption or use therein.

President Reagan authorized the State Department to exchange diplomatic notes with the Canadian Government, bringing the U.S.-Canada free trade agreement into effect on January 1, 1989. The Canadian Parliament's final approval of the agreement on December 30 permitted the exchange of diplomatic notes. U.S. legislation was signed into law on September 28. The free trade agreement establishes the world's largest free trade zone involving two countries. The United States and Canada are already each other's most important trading partner, with two-way trade of nearly $150 billion in 1988.

The free trade agreement will eliminate over a 10-year period all tariffs on trade between Canada and the United States and will make substantial progress on the elimination or reduction of nontariff barriers. The agreement will also enhance energy security, improve the investment climate, and significantly increase opportunities in the services sector, including financial services. While the free trade agreement will not eliminate all trade issues between our two countries, it gives us the framework to manage them and the basis for expanding our economic relations.

The free trade agreement represents a single accomplishment in the long history of U.S.-Canada relations. It will strengthen the industrial base of our two countries and will demonstrate the multilateral system that it is possible to bring down trade barriers in an equitable and mutually beneficial manner.

The Malaria Foundation International is a 501(c)(3) non profit organization that has been dedicated to the fight against malaria since 1992. The MFI's goals are to support awareness, education, training, research, and leadership programs for the immediate and long term development and application of tools to combat malaria. The MFI works in partnership with individuals and groups who have joined this cause.

MFI will be launching a new, modern website to serve as a central resource on all things Malaria in early December. In the meanwhile, please stay tuned to www.malaria.org for important announcements and information.  Resources are still available on our current website. Click here or use the tabs at the top of the page to access them.

Student Leaders Against Malaria (SLAM), initiated by Josh Gottlieb, is building a global network of students to work toward the eradication of malaria. SLAM projects strengthen the social conscience of students, and instill them with leadership qualities.

Pilot community-based projects are underway led by Joy Borra (Joy for Kids) and Christy Sattler (Nickels for Nets) to empower religious organizations and youth groups to raise funds to control malaria and also address educational and other development concerns in affected villages in Africa, and beyond.

Led by Amir Attaran, MFI successfully organized the voice of over 400 leading scientists from around the world to ensure the insecticide DDT was not banned. As a result, thousands of lives have been saved.

We seek your contribution to a novel initiative aimed at attracting attention to malaria as the persistent killer it is by collecting  short essays (details) from individuals with a variety of backgrounds. Selected essays will comprise the "Forum" section of a book to be published by Springer (book preface); other essays will be posted to this website. Once the Malaria Book is published, new essay submissions will be posted on the MFI website on a monthly basis. We look forward to hearing from students and professionals from many disciplines.

The MFI is a 501(c)(3) non profit organization, dedicated to the fight against malaria since 1992. This website was created in 1995 to provide a central source of information about this devastating disease. The MFI works in partnership with many individuals and groups who have since joined this cause. The MFI’s goals are to support awareness, education, training, research, and leadership programs for the immediate and long term development and application of tools to combat malaria. Children are most vulnerable to malaria. This disease also severely affects pregnant women and non immune individuals. There are hundreds of millions cases of malaria annually in over 90 countries, which result in several million deaths each year.

A site dedicated to malaria parasite biochemistry including: lipids, nucleotides, amino acids, carbohydrates, cofactors & other substances, redox & hemoglobin digestion, transport, cell-cell interactions, organellar functions.

In the near future, we will provide information enhanced with images. The initial information that will be presented will enable you to "Learn About Vectors", "Learn About Control", and "Learn About Vector Breeding Sites".

Information document provides further information about the global issues of malaria. These documents provide information gathered by the MFIl - with contributions from over thirty international medical and scientific experts and from the UK Dept for International Development.

The MVI was created through a grant of the Bill and Melinda Gates Foundation to PATH (Program for Appropriate Technology in Health). The objective of the MVI will be to significantly accelerate the clinical development of promising malaria vaccine candidates. The MVI is expected to lead to field trials of one or more vaccine candidates; coordinate its efforts with malaria vaccine programs at various organizations and agencies; and identify gaps in current research efforts and apply resources to advance promising malaria vaccine candidates.

The AMVTN is a non-profit network established in 1995 in Arusha, Tanzania. Its objective is to provide a forum for scientists and policy makers involved in the planning, coordination, and execution of malaria vaccination trials in Africa.

MIM is an alliance of organisations & individuals concerned with malaria. It aims to maximise the impact of scientific research against malaria in Africa, by facilitating global collaboration & coordination.

European malaria Vaccine Initiative (EMVI) The aim of EMVI is to provide a mechanism through which the development of experimental malaria vaccines can be accelerated within Europe and in developing countries.

As little of $5.00 can buy a bednet!The Malaria Foundation International aims to raise funds from public donations to develop and expand a series of innovative malaria projects started by “Malaria Project Pioneers”. Funds will be used entirely to fight malaria, to make these projects thrive, and to engage an increasing number of people in the global fight against malaria. New Malaria Project Pioneer ideas and plans are welcome. Projects can be oriented towards increased awareness and fundraising, scientific research and development, or controlling the disease through community based projects. Malaria Project Pioneers are concerned individuals who have recognized malaria is a major global problem with insufficient attention and support and who have taken a major stand in their lives to do something about it. Funds raised through the support of these projects will be used to reduce malaria immediately in affected villages and communities.

The MFI encourages individuals, companies, foundations, and governments to support its current Malaria Project Pioneers and to start new unique malaria projects. Through a growing number of Malaria Project Pioneers, the MFI will increase its capacity to function as an advocate for critically needed research, education, and the immediate application of all possible appropriate malaria control methods. MFI supported Malaria Project Pioneers have the direct aim to reduce the morbidity and mortality caused by malaria. We aim for the ultimate eradication of malaria with, in many cases, long-lasting personal relationships developing between donors and the recipient communities benefiting from the funds raised. Donors, please specify if you would like your contribution to go to a specific malaria project, or for support at the discretion of the MFI board.

In particular, we thank the over 400 doctors and scientists from 63 countries, who lent strong support last year when this issue was first brought to the attention of the scientific community. It was due only to this strong support of yourselves, voiced together with others in the public health community, that DDT was not slated for elimination along with the 11 other chemicals on the treaty.

This outcome will save many lives, and it also demonstrates the power of coherent advocacy in achieving public health goals, which is a critical function served by the Malaria Foundation International.

DDT in disease vector control as the United Nations Environment Program concluded the fifth and FINAL round of negotiations on a treaty to ban persistent organic pollutants. The official mandate of the treaty was to "reduce and/or eliminate" twelve POPs, of which DDT was one.

The outcome of the treaty is arguably better than the status quo going into the negotiations over two years ago. For the first time, there is now an insecticide which is restricted to vector control only, meaning that the selection of resistant mosquitoes will be slower than before.

Also, there is a clear procedure that endemic countries may follow to use DDT, and having done so, they have the RIGHT at international law to use DDT, without pressure from the developed countries or international institutions who have in the past threatened them against doing so.

Finally, it provides a legal understanding that rich countries should do more to research and develop alternative control measures for malaria, with the goal of "decreasing the human and economic burden of disease".

Click on the mosquito to view a beautiful new interactive module that teaches about the malaria parasite, the mosquito vector, and use of DDT for disease control. This module allows you to independently assess the probability that DDT will reduce malaria transmission based on 3 factors.

Dr. Coll-Seck has risen to the challenge to make RBM thrive and succeed, against the odds and major hurdles presented by malaria, with inadequate political will and financial resources to readily tackle this disease effectively. With Dr. Coll-Seck’s continued persistence, it is hoped that adequate financial and expert resources will be achieved so that we see the RBM partnership move increasingly in the direction of success in the fight against malaria.

Tanzanian President Benjamin Mkapa, who was on the panel. Just stand up. Just stand up. People are dying in his country today, and that is not okay with me," Stone told the delegates.  While bednets are not a total solution, they are one tool that can help protect individuals from the bites of infected mosquitoes while they are sleeping.

Lance Laifer joined the malaria advocacy movement in 2005 to help raise global awareness and support from the public (Read Interview). Mr. Laifer launched the “Hedge Funds vs. Malaria” movement in September 2005 and subsequent programs like “Dunk Malaria”, Malaria Free Zones (MFZ), and the First International Fast Day Against Malaria (IFAM) with relentless energy and passion to involve millions of people globally in the fight against malaria. He has been joined by an increasing number of partners with the shared vision that the whole world needs to know and act against this preventable and treatable disease, which need not continue to kill 3,000 children each day.

Rob Mather,  for starting and successfully running the “World Swim for Malaria”, a global grass roots malaria awareness initiative that engaged over 250,000 swimmers and sponsors by December 2005 and raised over $1 million to support the purchase and distribution of bednets in Africa, to protect individuals from bites of infected mosquitoes while sleeping.

Foundation – for establishing the first “Malaria Free Zone” village-based pilot project in Ghana in December 2005 and demonstrating the eagerness within communities to rise to the challenge of ridding their communities from malaria while also implementing sustainable development projects. Additional MFZ pilot projects have since also been established in multiple villages in Ghana and Nigeria.

African talents. The event reached an estimated 40,000 spectators and an additional audience of one billion worldwide via television, DVD, radio and CD, celebrating the continent's creative energy and bringing a message of empowerment and hope for tackling its major scourge: malaria. The concert film has since been shown at the United Nations and by PBS, and is now available in stores.

Dennis E. Kyle, with over twenty years of service to the Military Infectious Disease Research Program, at the Walter Reed Army Institute of Research (WRAIR), USA, Dennis E. Kyle has demonstrated a phenomenal record of productivity in malaria chemotherapy research.  Active at both the bench and in research management he has made novel observations on mechanisms of recrudescence and resistance to artemisinin drugs and has spearheaded rigorous optimization for malaria chemoprophylaxis. His mentorship of graduate students and junior faculty will continue in his new position as Professor of Global Health at the University of South Florida School of Public Health.

This grass roots effort is to be awarded for its initiative and effectiveness in raising funds (over $1million), creating widespread awareness and the participation of hundreds of thousands of people worldwide. The power of the WSM database for future grass roots efforts is also acknowledged. By way of example, this database was used to launch the first International Fast Day Against Malaria (IFAM) in May 2006.

Basketball Association (NBA) player, Steffond Johnson, for his commitment against malaria, demonstrated in the creation of a short film and engaging presentation to help gain attention on malaria and engender the increased support of major sports stars.

Botswana, who is educating and inspiring students to eradicate malaria. Through iEARN (International Education and Research Network) Tommie Hamaluba is working to incorporate the topic of malaria into classroom curriculums around the world.

From the Walter and Eliza Hall Institute in Australia, with current research studies aimed at understanding the underlying cause of malaria anemia, awarded as an outstanding up-and-coming scientist and for her potential as an ambassador in the fight against malaria.

Eyitayo Lambo, Nigeria, for his stance against malaria at the Africa Malaria Day 2005 Conference, and beyond, with continued dedication in 2006 to ensure the availability of effective malaria treatments and the broad distribution of knowledge about malaria prevention and treatment in Nigeria.

Emmy Award winning artist from the Walter and Eliza Hall Institute in Australia, awarded for his biomedical animations which include historical educational animated malaria images - which jump-started his career.

The CEO of the Kenya NGOs Alliance Against Malaria (KeNAAM), nominated for this dedication, team spirit and productivity as a new leader working to motivate and encourage sustained leadership among young people in the fight against malaria.

William Trager (1910-2005), who first cultured Plasmodium falciparum in the laboratory, and edited by Irwin Sherman, this book provides current scientific knowledge for unraveling and gaining insights into the molecular and cell biological nature of the malaria parasite and the Anopheline mosquito, which is important for making new drugs and vaccines and controlling malaria.

The Government of Zambia, PATH, and local and global partners are working together with initial funding from the Bill and Melinda Gates Foundation to institute the Government’s national malaria control plan, with emphasis on local successful malaria control strategies.  Malaria Control and Evaluation Partnership in Africa (MACEPA) aims to strengthen the countries health system so that these strategies can be applied across the nation of Zambia.

This campaign effectively reported that Malaria R&D global spending in 2004 was $323 million, while if malaria research were actually funded at the average rate for all medical conditions, it would receive more that $3 billion in annual R&D funding. This marketing campaign research report was developed to highlight the need for increased research support for the development and testing of new malaria drugs, vaccines and control tools.

Novartis, for pioneering the development and distribution of the first Artemisnin Combination Therapies (ACTs) for widespread use and stimulating global interest in the immediate further development, use and evaluation of such effective malaria medicines.

Africa Fighting Malaria, for its daily up-to-date reporting and analysis of malaria issues to garner increased financial support from government agencies and the appropriate use of funds for the effective control of malaria.

The Bill and Melinda Gates Foundation, for raising awareness through the financial support of  projects that advance the development of malaria drugs and vaccines, and investigate comprehensive malaria control strategies.

The author of a “Purpose Driven Life” – for empowering people to join grass roots efforts to fight malaria. Reverend Warren’s P.E.A.C.E. plan, which addresses what he calls the five major “Goliaths” of the world – spiritual emptiness, egocentric leadership, poverty, pandemic disease and illiteracy – touches on malaria prevention tactics that begin with mobilizing local churches. It has been shown, he said, that money and medicine are not enough to stop the spread of malaria.

Malaria kills at least 3,000 people each day, mostly children. People everywhere and from many professions are starting to take a stand and stress that this is ethically unacceptable. The daily devastation of our children, one child passing every 30 seconds, must be stopped. Pregnant women living in malarious regions of the world are also particularly vulnerable, with deleterious outcomes including severe anemia, low birth weight babies, stillbirths, or maternal death. Each year, at least 500 million people become clinically sick, with death being a possible outcome, despite the fact that malaria is a preventable and treatable disease. Almost half of humanity lives at risk of succumbing to malaria, caused by the bite of an infected Anopheline mosquito.

Malaria Foundation International is a 501(c)(3) non profit organization that has been dedicated to the fight against malaria since 1992.          The MFI’s goals are to support awareness, education, training, research, and leadership programs for the immediate and long term development and application of tools to combat malaria. The MFI works in partnership with individuals and groups who have  joined this cause. Donations to help fight malaria are welcome.

Why, may be part of the solution. This book looks at the present and into the future with the perspective of the last 100 years. We address how scientific knowledge and technologies have progressed, policies towards controlling the disease have evolved, how political will has waned or been revived, yet how malaria continues to spread with consistent increases in morbidity and mortality.

These contributors were asked to pin-point bottlenecks: provide personalized retrospective analyses and propose prospective strategies for malaria control in terms of scientific orientations, societal policies, programmatic strategies, health system’s needs, etc. In an attempt to develop a powerful debate that could potentially help shape future efforts, all authors were asked to be direct, outspoken, critical, and, if desired, anonymous. We sought the views of many, whose voices tend not to be heard.

We do not aim to debate what the most appropriate intervention tools might be but, rather, why new ones have not been discovered when old ones were losing efficacy and close to half of humanity has been suffering from this disease.

If the political and strategic bottlenecks were better defined and understood, the technological and public health advances could follow. The forum may help to identify possible answers to some of those “whys” from the authors’ diverse experiences. We did not want this to be simply another textbook on malaria, which in essence would be outdated as soon as it was issued. We aimed for a book that would be valuable to readers and decisions-makers for years to come.

Malaria has played a major role in human history. Invaders from the North into tropical areas died from malaria in masses, and, without the acquisition of the recipe of the Indian’s famous remedy, the cinchona bark, there would have been no colonial empires and the world would be substantially different from how it is today. Progress in modern chemistry, the discovery of cheap insecticides and synthetic quinolines, led to the eradication crusade 50 years ago in the spirit of bringing to developing countries the benefits of modern technology. Its failure left policy makers in a state of disarray and a 30-year period with decreasing action addressing the ever growing malaria problem.

In an attempt to curb this disastrous trend and re-focus attention on the disease researchers launched the Malaria Foundation in 1992. Since, several other major global initiatives were also created to tackle malaria, and the last 10 years have witnessed an upsurge of attention on this disease, though often in a disjointed if not competitive manner. Increased funds for malaria research and control efforts, advanced research technologies, and advocacy efforts have once again heightened awareness of the malaria problem and may potentially bring new solutions to this field. It can be questioned how much this revival of interest in speaking of the problem is actually truly tackling the disease; ie. will ultimately translate into the development and application of new solutions for patients (and not only benefit researchers or agencies).

Partnership for Social Sciences in Malaria Control (PSSMC) is an international alliance of individuals representing specific skills and expertise within specified institutions. The purpose of the Partnership is to improve collaborative efforts to maximise the potential contribution that social science can and should be making to research and programmatic development in malaria control in sub-Saharan Africa.

A lot of good work takes place in the world of behavioral science that is hard to keep up with, as much of it remains unpublished in meetings and technical reports. In addition, a great deal of the published data that is available is found in journals not regularly accessed by people working in malaria control. The PSSMC has generously organized many of these resources into these databases for your use. These databases will be updated approximately four times a year.

Foundation was founded in 1992 by Dr. Mary R. Galinski. With the commitment and dedication of malaria researchers and experts in a variety of professions, plans were carried forward to create a private international entity dedicated to the effective prevention, treatment, and control of malaria. The Malaria Foundation, Inc. became registered in the United States as a tax-exempt 501(c)(3) non-profit organization in 1993, and was subsequently renamed the Malaria Foundation International (MFI). Steps have since been taken to develop interactive MFI branches in other parts of the world. The MFI's organizational structure includes its Board of Trustees, International Board, Scientific Advisory Board, Executive Director, and Program Directors. Its activities are also guided and supported by its business advisors, sponsors and other supporters.

The incidence and severity of malaria was on the rise worldwide, with up to 500 million annual cases, and the availability and application of effective solutions was not immediately forthcoming. Resistance to available drugs was spreading rapidly, making them unreliable in many parts of the world, and a malaria vaccine was years away from being produced, tested, and deployed. Furthermore, social programs to curb the spread of malaria through education and community control activities were limited, and in many places were non-existent. Meanwhile, funding for malaria research and control was not only extremely limited, especially compared to the scope of the problem, but was decreasing, and no other organization existed that was dedicated specifically to addressing problems caused by this disease.

Foundation International was founded with the tenet that much more must be learned about malaria before long-lasting preventative and curative methods can be assured. The ultimate solutions will come through further research and its effective application. This will require strong political will and steadfast dedication, along with enhanced global communication and networking, long-term funding commitments, sustainable training programs, and capacity building.

Nominations are currently being welcomed to update the representation of the MFI's Scientific Advisory Board, to best advise on all areas of necessary research, control, and policy decisions pertinent for the eradication of malaria.

The original Scientific Advisory Board of the MFI is featured below. This prestigious group of outstanding scientists from many parts of the world has served the MFI well and we express our utmost gratitude for the support provided by these individuals. The Malaria Foundation welcomes the participation of scientists in all areas of malaria research and control and looks forward to the active participation on this board of many other distinguished individuals over time.

To assist with the development and coordination of networks that enhance communications, maximize exchange of views and expertise among malaria scientists and health workers, and encourage the most cost-effective use of available resources.

Malaria Awareness Campaign is a program aimed at educating people about malaria and providing opportunities to donate voluntary services or financial support. To this end, the MFI website is a central site that provides information about malaria that is relevant for a broad audience (press, teachers, students, travelers, policy makers).

Communication Center is a discussion system and Jobs Bulletin Board provided for professionals and students working with malaria. The 'Discussions' may be public (initiated by MFI or others) or private (which are controlled by the group who initiate the discussion and can be password protected).

MFI is a grassroots organization involving scientists worldwide that achieves advocacy for malaria issues through our Scientific Sounding Board function. In this capacity, we solicit views and form an evidence-based concensus on issues of importance for malaria research and control of the disease. This function has the potential for influencing policies that can save lives, an example being our successful recent effort to prevent a global ban of the production and use of DDT for malaria control.

In partnership with the Malaria Project the Malaria Foundation International successfully organised the voice of over 400 of the world's leading scientists from around the world to debate the issue of a possible global ban of the insecticide DDT, jointly sign an open letter to stop this ban, and garner the support of the press worldwide. Due to this consolidated approach, DDT will not be banned until a suitable replacement is found. The result is that many thousands of lives each year will be saved.

Thanks to the recent availability of a new, very fast and simple surveillance system of malaria drug resistance, the MFI proposes to implement a drug surveillance network in every malaria-endemic country. The MFI will collect and provide regularly updated information to national and international health authorities, scientists, and pharmaceutical industries. Dr. Pierre Druilhe (a member of the MFI's International Board) and Philippe Brasseur initiated this project and direct and implement it.

This project was initially supported by a concerted action grant from the European Commission, received support and technical assessment by the TDR Component of the World Health Organization, and is now supported by several public and private bodies. Among the supporters are the Lions and Rotary clubs who have joined their networks with that of the MFI, and they will be actively involved in all malarious countries also networked by the Roll Back Malaria initiative of WHO. To date, training of technicians has been successfully implemented in Senegal, Burkina Faso, Cameroon, Sri Lanka, Myanmar, Thailand, Cambodia, Malaysia, Vietnam, Madagascar, and Mayotte. Plans for future training include Brazil, Colombia, Zimbabwe, Mozambique, and India. A dedicated web-site where results will be available on-line (in real time) will be available in the near future. Further donations for this particular activity, including training, are most welcome. In an African country the overall cost to gather data each year is in the order of $10,000 per year.

The MFI has instituted an annual Travel Scholarship Award to allow promising young scientists to attend international conferences. This opportunity helps to establish research collaborations among scientists that, in time, bridges the gaps among countries and laboratories.

In 1998, in partnership with the MFI and MEMISA, British global explorer David Robertson launched a great challenge: to circumnavigate the globe in a four-wheel drive vehicle to draw attention to the growing danger of malaria. MFI assisted Mr. Robertson in raising public and political awareness in countries throughout Africa and Europe.

"Second Global Meet Ronald Ross Centenary" was a special conference was a special conference with a focus on malaria which was sponsored by the Indian Society of Parasitology and co-sponsored by the Malaria Foundation International. The MFI assisted with program development, fundraising, a sponsored travel award program, promotion of the meeting, and the development and management of worldwide publicity. This meeting was held in Hyderabad, India from 18-22 August 1997 to commemorate the 100th year anniversary of the landmark discovery by Ronald Ross of malaria in the mosquito. This meeting was a very strong demonstration of the commitment of scientists and public health officials to malaria research and control. Over 700 people, including malaria researchers, public health specialists, government officials and industry representatives attended from over 25 countries. Goals of the meeting included strengthening of scientist cooperation aimed at reviving public and funding agencies interest in this forgotten disease.

This was the first major MALARIA meeting of its scope and provided and unprecedented example of how attention can be drawn to the malaria problem via the media. TV, radio, and the press rallied strongly behind this meeting. Since, several new global initiatives have sprung up and followed the example of large scale public advocacy to bring attention on this disease. MFI continues to create awareness through its own programs and by facilitating the progress of the others through its role as a stakeholder where the common cause of preventing or controlling malaria is at stake.

Mutley Ball was held in 1998 in London, in memory of Vanessa Botterill, a young woman who died of malaria after being diagnosed with the disease at the end of her travels in Africa. Through this event, funds were raised to bring attention to the severity of this disease and to support the education and training of young malaria scientists from Africa.

MFI collaborated with SHARED towards a common goal to compile the most comprehensive interactive database of people, projects, and organisations related to malaria. This database is accessible to all and it allows professionals from all over the world to interact and share resources.

Upon infection by the mosquito, the malaria parasites move rapidly into the liver - within ~30 minutes - and reproduce there rapidly for 5 days or more, depending on the species (P. falciparum or P. vivax).

Stage II: The malaria parasite breaks out from the liver, enter the bloodstream, and within minutes invade red blood cells, where they grow and divide. Every 48-72 hours (time differences depend on the species) the red blood cells rupture, dispersing more parasites along with waste products/toxins into the blood stream. This step causes fever, chills and anaemia in the victim - telltale clinical signs of malaria. The released parasites then invade other red blood cells, beginning the cycle again.

If untreated, the malaria disease can progress causing a variety of serious complications. Most seriously, P.falciparum parasites cause blockage of blood vessels; cerebral malaria, coma and death can ensue.

P.vivax does not adhere to blood vessels and cause the associated complications; however, unlike P.falicparum, dormant P.vivax can burst out of the liver into the bloodstream months or several years later ready to start the vicious clinical cycle again.

Stage III: Some parasites invade red blood cells and develop into sexual forms that are ingested by uninfected biting mosquitoes, within which they mate and begin to reproduce. These parasites make their way to the salivary glands of the mosquito, ready to move on to another victim when the mosquito takes its next blood meal.

Malawi and Kenya have made an official commitment to using Fansidar but others are reluctant to follow due to perceived increased cost and/or logistics problems encountered in trying to introduce change into their health systems.

The two compounds most widely used are artemether and artesunate, mainly in Southeast Asia but not widely used in the developed world in part due to toxicity fears, licensing and logistic issues. More research data is needed for these products to meet international standards. Due to the high rate of treatment failures, artemisinins are now being combined with mefloquine.

All the above are treatments for P. falciparum or P. vivax malaria cases. Primaquine is the only treatment available for eliminating the dormant forms of P. vivax which remain in the liver. Resistance to primaquine has been noted in the past few years.

This information has been gathered by the Malaria Foundation International with contributions from over thirty international medical and scientific experts and from the UK Department for International Development.

It is a public health problem today in more than 90 countries inhabited by some 2,400 million people -- 40 percent of the world's population. Malaria is estimated to cause up to 500 million clinical cases and over one million deaths each year. Every 30 seconds, a child somewhere dies of malaria.

Drug resistance is a growing problem, chloroquine is an extremely safe and cheap drug, but in Asia and an increasing area of Africa and South America the resistance levels are high. In some areas of Asia there is resistance to all the major drugs.

Migration, climatic change and the creation of new habitats have all resulted in people who have no natural immunity to the disease being exposed. This results in much higher rates of disease and death.

There are four different species of the malaria parasite. Two are most common. Plasmodium falciparum, which is found globally but is commonest in Africa, is the most aggressive species, often killing through coma or anemia. Plasmodium vivax, which ranges widely throughout Asia, Africa, the Middle East, Oceania and the Americas (and is resurgent in Eastern Europe), can cause recurring and debilitating infection, but rarely kills.

Fever is the first symptom. Several hours later, the fever drops and chills set in. Two to four days later, the cycle repeats. More serious forms of malaria can affect the brain and the kidneys. Progression of symptoms from initial fever to death can take as little as 24 hours.

Basic health services, which have been characterized by declining levels of funding, low staff morale and inadequate drug supplies, have been unable to address the challenges of effective diagnosis and prompt treatment.

A vaccine is needed. Development of such a vaccine is complicated by the parasite ability to change its immunological identity, and thereby conceal itself from the immune responses that might otherwise be stimulated by a vaccine.

Initiative on Malaria began as a joint African-American-European project that brought together representatives from thirty-seven countries, three charities and three intergovernmental agencies in Senegal in 1997. Already it is beginning to increase to the co-ordination of research efforts.

"I propose that together we Roll Back Malaria. Not as a revamped vertical program but by developing a new health sector wide approach to combat the disease at global, regional and country and local levels.

Who said that infectious diseases were becoming yesterday's problem? The human suffering is unacceptable and so is the economic burden and impediment to progress. Time has come to respond with a new approach. Time has come to Roll Back Malaria.

Why now? Because the call is there. We have enough knowledge, skills and tools to launch a new concerted effort. Africa is responding. African leaders are committing to a renewed effort to control malaria. Africa should be spearheading the project.

I believe we should answer Africa's call and that of other regions if they choose to engage. I will invite a broad range of stakeholders to join us in this initiative, UNICEF, the World Bank, industry, foundations and all others who have a stake, a commitment and a contribution to make.

Let me stress: Roll Back Malaria will not exclude work on other diseases. To the contrary. Successful containment is no endpoint. Rolling Back Malaria is no victory unless health systems are equipped to sustain the gains.

"MALARIA which had been eliminated or effectively suppressed in many parts of the world, is undergoing a resurgence. It is a public health problem today in more than 90 countries inhabited by some 2,400 million people -- 40 percent of the world's population.

Malaria is estimated to cause up to 500 million clinical cases and 2.7 million deaths each year. Every 30 seconds, a child somewhere dies of malaria. The global effects of the disease threaten public health and productivity on a broad scale and impede the progress of many countries toward democracy and prosperity."

Africa is terribly affected, and accounts for over 90% of reported cases of malaria. About 10% of hospital admissions are for malaria, as are 20-30% of doctors' visits. As bad as that is, experts foresee as much as a 20% annual increase in Africa's rate of malaria-related illness and death. No Western disease is nearly so prevalent or growing at anything like that rate.

Children are especially vulnerable to malaria. In Africa, where 80% of malaria cases are treated at home, the disease kills one child in twenty before the age of five. Globally, the death rate is equal to seven jumbo jets, full of children, crashing every day.

Pregnant women are also especially at risk. In highly malarious parts of Africa, women are more than four times as likely to suffer clinical attacks of malaria during pregnancy than at other times; but only half as likely to survive bouts of life-threatening illness.

Expatriates and soldiers who live abroad are at even greater risk. Malaria was the number one cause of hospitalization among American troops deployed to Somalia; the number two cause among troops in Vietnam (after combat injury); and a leading cause among diplomats, missionaries and aid workers.

Each year, the world over, malaria destroys, through premature death and disability the equivalent of at least 35 million years of healthy, productive human life a figure that dwarfs the human cost of better-recognized infectious diseases such as Ebola or AIDS.

OF MALARIA has several underlying causes. Population and demographic changes have resulted in more people moving into densely populated areas, thereby increasing transmission. Human environmental changes such as road building, mining, deforestation, and new agricultural and irrigation projects...have created new breeding sites... [and] in many regions, malaria control programs have deteriorated or been abandoned."

A plague is coming back and we have only ourselves to blame. In a fight, the worst error is to misestimate a foe, and that is what we did with malaria. By failing to deal resolutely with malaria in the past, scientists and politicians have bequeathed today's children a parasite stronger than what they knew. We are now poised to perpetuate that error and be submerged, or fight back.

Insecticide resistance was the first mistake, the legacy of a scientifically naive, politically uncommitted effort to eradicate malaria in the 1950s and 1960s. Global DDT spraying to kill mosquitoes succeeded in controlling malaria for a time: in only 8 years, Sri Lanka went from a million cases of malaria a year to only seventeen.

Drug resistance was the second mistake, the legacy of foolishly overusing antimalarial drugs. Some countries even laced salt with chloroquine, the drug of choice. Errors like that, or the money-saving trick of taking a partial, rather than complete, course of drug treatment, caused the malaria parasite to evolve resistance.

Environmental changes and human mobility are a third mistake. Industrial works in the tropics, such as mining or logging, create puddles of still water that are the mosquito's dream habitat. Malaria transmission explodes just as a crop of outsiders with no immunity to the disease come into work camps. Indigenous people also suffer unprecedented onslaughts of malaria. Incidence of malaria among Yanomami Indians in the Amazon have leapt almost seventy-fold since contact with industrial works. Now, a quarter of Yanomami die of malaria, in what is reckless genocide by malaria Political ignorance and budget cuts are a fourth mistake. For the Yanomami, who have been brought disease but no outside help because malaria research and control budgets have suffered huge cuts, it may be the last mistake. International health is a sitting duck when politicians balance budgets. The creation of wars and refugees, another polticians' foible, provides conditions ideal to the aggressive spread of malaria among displaced persons.

The malaria parasite grows faster in warm areas. Even a tiny global warming will push malaria into Africa's urban centers and into temperate zones outside the tropics - places where persons have no immunity and fall easily to malaria. As recently as the early 1900s, malaria cases were 500,000 a year in the south of the US; and it was only in the 1960s that malaria was eradicated from Italy. Europe and the US still suffer a handful of cases each year.

PROPORTION of a country's population is ill with malaria for five or six months each year, sustained economic development is very difficult to achieve. Countries thus compromised cannot easily become active trading partners...nor are they positioned to decrease their dependence on foreign aid. Similarly, when child survival is threatened by malaria and other infectious diseases, family planning and environmental quality are simply not priorities."

Malaria infection can be chronic and unremitting in highly diseased parts of the world, such as Africa. Persons may receive hundreds of infectious mosquito bites a year, with the result they are perpetually weakened by the parasite.

Cash estimates of malaria's direct costs underestimate the problem because lost income is only the tip of the iceberg. If each day of malaria-related disability were valued at $1 of lost income, then malaria's annual cost is about $13 billion globally.

Attacking global diseases is a bargain. Since smallpox was eradicated in 1977, the total US total investment of $32 million is returned to the US as savings every 26 days! Every dollar spent on the measles, mumps and rubella vaccine results in a $21 savings later.

"FOR CENTURIES distancing beyond recorded history, malaria has been a pregnant ladykiller. Malaria also kills the children; in regions of intense transmission, 40 percent of the toddlers may die of acute malaria.

Malaria also kills the immunologically "unsalted" adult migrants from teeming Third World cities who pioneer new agricultural lands, soldiers of the Western world battling to save democracy in tropical nations, tourists, businessmen. In 1990 the age of rocket ships and genetic engineering 250 million people will get malaria and at least 2.5 million will die of the infection - needless deaths. Malaria is not an AIDS; the curative antimalarial drugs are available. Malaria is not like cancer; the most intimate details of malaria's causation are known. Malaria is not like the epidemic of drug addiction; given the resources, successful antimalarial campaigns can be implemented."

IS A TRICKSTER. It is not a bacterium; it is not a virus. It is a form of unicellular life as sophisticated as the cells of our bodies. It is the evil opposite of our immune cells, and that makes it a nasty foe. Passing from person to person via the bloody feasts of mosquitoes, the parasite assumes a different "disguise" with each infection, dodging the victim's immune system and whatever experience it had with malaria in the past. In brief, the parasite has perfected the trick, over millions of years and trillions of infections, of waylaying us like neophytes every single time.

There are four different species of malaria parasite that go by the collective name of Plasmodium. Two are most common. Plasmodium falciparum, which is found globally but is commonest in Africa, is the most aggressive species, often killing by coma or anemia. Plasmodium vivax, which ranges widely throughout Asia, Africa, the Middle East, Oceania and the Americas, can cause recurring and debilitating infection, but rarely kills.

Not all persons with the parasite have disease, but some are carriers without symptoms. A mosquito can draw blood from these persons, and some weeks later, transmit the parasite to another person, who may be more vulnerable. The parasite takes refuge in that persons liver, and later erupts into the blood, where it invades his or her red blood cells and begins to replicate.

Cerebral malaria is the most dreaded form of disease, and is unique to P. falciparum. Red blood cells infected by the parasite are sticky and can gum up the capillaries of the brain. The victim enters a coma, and if he is lucky enough to return, brain damage can be the result.

Death can strike in as little as 24 hours from first symptoms: or in less time than it takes to get from a village to a clinic! Thus, better access to clinics is essential to turning the tide on malaria.

Anemia is another threat. The parasite's cyclical attacks on red blood cells can result in death by blood loss. As a last-ditch effort, the victim is sometimes given a transfusion. Without a way to test the donor's blood for HIV, if the victim survives malaria, he or she will be lucky to not get AIDS.

Pregnant women are malaria's easiest prey. The normal weakening of the immune system during pregnancy makes infection more likely, and the routine anemia of pregnancy gives the parasite a deadly leg-up.

FACT is that foresight and compassion are no match for politics and profits in setting priorities for disease research. When malaria comes here, we'll seriously get to work on it. But sadly, not until then."

Africa is asking for that political will; is anyone listening? In 1997, the 53 African heads of state passed a resolution at the Organization of African Unity, to ask for help against malaria. Without scientific tools themselves, African countries must rely on developed countries to hear their plea.

In a campaign of less than a decade, 97% of cases of guinea worm were eliminated it will be driven extinct within five years. In just one day in 1997, India vaccinated 130 million children against polio. Similar "vaccination days", paid for by governments, the WHO and groups like the Rotary Club, will destroy this killer of children by the year 2000..

IS EMERGING AND SPREADING faster than new drugs can be developed...Given the speed with which parasites are becoming resistant and the length of time required to develop new drugs (even accelerated development takes 5 to 10 years from discovery to clinic), we face a looming crisis: multidrug-resistant malaria with no safe, effective alternatives for treatment. This problem exists today in Southeast Asia and will occur in most other malaria-endemic areas within the next decade."

Careless drug use has caused malaria parasites to evolve survival strategies against drugs. In most areas, malaria parasites resist at least one drug. In others, they resist all known drugs. There are no failsafe treatments a state of affairs not known since the discovery of quinine in the 17th century.

Malaria prevention is also in jeopardy. Travelers to malarious areas take antimalarial drugs to avoid getting the disease, but the parasite can resist prophylactic drugs too. There is no prescription that guarantees a traveler absolute safety from malaria.

Researchers have yet to develop a successful malaria vaccine in humans, although they have succeeded in immunizing many types of animals, from rats to monkeys. The last step is proving elusive, even though studies over 20 years ago proved that humans can be successfully immunized in the laboratory.

Although eight clinical trials are now underway globally, many other candidate vaccines are kept out of trials because research funding is so petty. US military scientists alone possesses a half dozen candidate vaccines ready for human testing, but with a budget of just $4 million a year, they cannot do the job. European, Australian and South American labs are in a similar bind.

"THE URGENT NEED is to put malaria on the scientific, media and political agenda, and in particular to identify it as a priority for research, both in the developed North and in those areas of the South where the disease is endemic... We recognize that the control of malaria in Africa will require a long-term collaboration between scientists in the North and South...[and] commitments from the industrialized countries to funding, and from African leaders to support scientist and health and research infrastructures in their countries."

SOLVE MALARIA. A disease endemic to 100 countries needs multilateral effort to conquer. Rich states must give of their funds and technological expertise; poor states must supply facilities and cooperate, especially in field research.

Initiative on Malaria (MIM) began as a joint African-American-European project that brought together representatives from thirty-seven countries, three charities and three intergovernmental agencies in Senegal in 1997. Despite a plea for joint action to save lives in Africa, countries have so far responded with token funding donations, no where near the hundred's of millions of dollars now needed and which could become available with a serious global commitment.

Taking a bite out of the mosquito. If people are taught how, they can wage war on mosquitoes: by filling ditches or covering containers where water stagnates and mosquitoes breed; by stocking ponds with fish that eat mosquito eggs; by using insecticides judiciously and in the right places; by insect-screening their homes; and by planting water-hungry trees to dry out muddy soils.

Like many diseases, malaria is less likely to kill if it is detected early and treatment is started at once. This means families must be taught to recognize the telltale signs of malaria, especially in children; and well-staffed, well-stocked clinics must be nearby to give medical care. Considering that the disease can progress in 24 hours from first symptoms to death, a dense network of caregivers and clinics throughout the countryside is a must too many children die now in the arduous journey to a clinic.

Tracking the disease, and where it will strike next. Much of malaria's bite can be mitigated if it is anticipated first. For instance, by tracking the spread of drug resistant parasites, prescriptions can be changed before people die because they are given ineffective drugs. Keeping an eye out for new environmental changes or refugee movements means preventative or curative resources can be sent to meet the disease before an epidemic begins.

Taking care of number one - Avoiding mosquito bites, is a cheap and very effective way to reduce deaths. Mosquitoes bite at night, by sleeping under a mosquito net impregnated with a natural, biodegradable insecticide derived from chrysanthemums lowers one's risk of disease greatly.

Saving children's lives for a few dollars. More than 20 studies of bednets have proven that they are effective at reducing child mortality, not only from malaria, but from other diseases too. In studies, bednets have reduced mortality by at least 20%, and as much as 63%. According to WHO, if all of Africa's children used bednets, about half a million lives a year could potentially be saved.

Bednets are so cheap, they can be given away. Nets cost $5-10, and a year's natural insecticide under $1, making bednet donation programs cheap and well within the means of governments and large companies.

The total amount spent on malaria research globally accounting for all governmental, charitable, and non-governmental sources in 1993 was about $84 million. By contrast, a single agency of the US Government will spend about $2.5 billion on cancer research this year.

Pharmaceutical companies have malaria research, though the need (and their profits) is greater than ever. Currently there is little activity by major Western pharmaceutical company's in developing new drugs for malaria.

Subsidies into lives saved: for the price of a single year's subsidies to its tobacco farmers, the European Union could support the global malaria research program until the year 2009. At present rates, 30 million people (equal to the populations of Belgium, Denmark, Greece and Ireland combined) will die of malaria between now and that date.

TO SOCIAL INTELLIGENCE as our remaining option to counter the evolutionary drives of the microbial world. That intelligence must include a profound respect for the ecological factors that enhance our vulnerability... [The] preponderant changes are the sheer expansion of our species, with high population densities, and much the worse, egregiously stratified by standards of economics, nutrition, housing and public health. At the same time we have unprecedented mixing of people: a million passengers a day cross national boundaries by air... One could hardly have concocted a better-calculated recipe for a tinderbox, as AIDS already harshly teaches. From this perspective, we have never been more vulnerable; this vulnerability must be matched against the extraordinary sophistication of the science and technology that we are, in principle, able to pit against these threats."

The costs of malaria are also enormous when measured in economic terms. Highly malarious countries are among the very poorest in the world, and typically have very low rates of economic growth; many have experienced outright declines in living standards in the past thirty years.

The evidence strongly suggests that malaria obstructs overall economic development. During the period 1965-1990, highly malarious countries suffered a growth penalty of more than one percentage point per year (compared with countries without malaria), even after taking into account the effects of economic policy and other factors that also influence economic growth.

These considerations indicate that the cost of malaria is substantially greater than economists have previously estimated. Traditional estimates have looked at some of the short-run costs of malaria without taking into account the longer-term effects of malaria on economic growth and development.

These estimates, however, neglect many other short-run costs. For instance, very few studies include the economic costs of the pain and suffering associated with the disease. Yet researchers have found that households might be willing to pay several times the direct income loss caused by malaria in order to avoid it, suggesting that the pain, suffering and uncertainty associated with the disease is very high and should certainly be included among its short-term costs.

Furthermore, these short-run costs are likely to have risen in recent years due to increasing number and complexity of cases in many countries. Moreover, the spread of drug-resistant malaria is substantially raising the costs of treatment in many cases, as well as the burdens of morbidity and mortality. Children and adults needing blood transfusions due to malaria are too often inadvertently infected with HIV, hepatitis C virus, and other infectious agents which taint the blood supply.

Households respond to this increased risk by having more children, thereby increasing the overall rate of population growth. In addition, the investments which parents of many children can afford make in the well being of each child is limited? so that average levels of health care and education per child tend to be reduced. Moreover, mothers of large numbers of children are less able to participate in the formal labor force, thereby also reducing the household income.

Individual households in malarious regions do not escape the risk of malaria infection simply by being relatively well off. In surveys of households from 22 countries in Africa, no correlation could be found between the incidence of childhood fever in households and their relative wealth.

Malaria is not a simple consequence of poverty. The wealth of the household, however, does play a substantial role in determining whether a child receives treatment for fever and influences the kind of treatment. Poor families very often lack the resources to obtain proper treatment of the disease even in complicated and life-threatening cases. Poverty alleviation strategies should therefore recognize the importance of effective antimalaria interventions, since the poor by themselves are unable to escape the burdens of the disease.

Short-term costs alone are likely to result in economic losses of several percent of GDP in a single year. Moreover, malaria hinders long-term economic growth, so that the burden of the disease increases over time as countries are deprived of the rise in living standards that they would experience if not for malaria.

No single intervention, therefore, is appropriate in all contexts. Interventions should be adapted to specific local ecological, epidemiological, economic, and social conditions. Even the goals of malaria interventions should be place-specific.

The effects of human behavior on malaria are similarly place-specific. Anthropogenic changes such as deforestation, road-construction and agricultural development generally increase the intensity of malaria transmission.

Any drug therapy strategy should be designed to minimize the threat of resistant parasites. Specific strategies, however, must be tailored to the patient, the community and the region in which they are employed. The selection of drugs and treatment protocols must be based on reliable clinical and epidemiological assessments of efficacy.

Although improved treatment in the public sector is essential, we must recognize that malaria treatment generally takes place through self-administration of drugs purchased in a variety of private outlets.

New rapid malaria tests can expand access to accurate diagnosis and should help reduce the cost of treating malaria where more expensive antimalarials (such as mefloquine) are used as a first line drug. Improved diagnosis may also improve health outcomes and potentially reduce selection pressure favoring resistance.

Addressing the problem of drug resistance requires intensive attention. Replacing an ineffective first line drug brings substantial and immediate health benefits, but strategies must be put in place to prevent resistance growing rapidly to the replacement, as there are few effective, safe and affordable antimalarials available. There are a range of implementation issues to consider, such as the effects on compliance of changing drug regimens, and the need to inform public and private providers about the new policy.

Combination therapy, which has the potential to protect new drugs from the development of resistance, is a promising new development, but needs to be introduced together with strategies to promote rational drug use in the public and private sectors.

A substantial expansion of preventive interventions is required Although insecticide-treated mosquito nets (ITNs) provide a cost-effective means of ameliorating the effects of malaria, this measure will be expensive if large human populations must be protected. Innovative mechanisms for financing and providing ITNs are needed to increase their use.

Enhanced commitment to research will improve the effectiveness of existing technology Research is essential at every level, from basic scientific studies to social science and policy analysis, in order to design, evaluate and reevaluate new and existing malaria intervention strategies.

No strategy should ever be exempt from scrutiny by the research community. Any policy has unintended consequences? ongoing program analysis is essential to identifying them and mitigating their costs. Implementation of any intervention is an adaptive process, requiring performance evaluation and operational research. This includes identifying the reasons for low compliance, and finding more efficient and cost-effective implementation strategies.

Even one of the most promising antimalaria intervention strategies, employing the use of insecticide treated nets (ITNs) will benefit from further research scrutiny. ITNs constitute a cost-effective means for ameliorating the effects of malaria. Their effectiveness in different epidemiological conditions, however, must be reassessed continually. In addition, the mechanisms of morbidity reduction by incomplete ITN coverage, and the potential for similar effects by other incomplete interventions should be explored. Most notably, the relationship between superinfection and parasite diversity requires study.

Analysis of the historical record indicates that many successful interventions employed techniques which were highly effective, but have since been abandoned, possibly due to socioeconomic upheavals and loss of interest among donors.

In certain cases, these techniques may still be useful, although research is essential to adapting them for specific contexts. Many of these approaches would require research input by epidemiologists, environmental scientists, entomologists, agronomists, and economists.

Research is also necessary in order to understand what communities are already doing on their own to defend themselves. Many residents of malarious areas buy commercial products for this purpose even in the absence of externally designed interventions. In many cases, the market in these products may be worth much more, and may save more lives, than publicly financed interventions. Researchers and policy makers must learn all they can from local communities.

There is a dire lack of extensive and comparable data about malaria. For example, there is inadequate information available on the status and trends in incidence and prevalence, epidemic outbreaks, clinical epidemiology, and interactions with other conditions (including for example other diseases, nutrition, and growth). The absence of this information is very costly to advocacy, policy design and implementation, epidemic preparedness, and resource allocation. A commitment must be made to the arduous work of collecting these data in order to replace the existing gross extrapolations, widely varying estimates, and missing information.

As research efforts begin to provide a detailed understanding of the burden of malaria, it is becoming possible to consider targeted interventions designed to produce additive or synergistic beneficial effects even beyond their direct impact on human well-being. Where important ports or centers of economic activity are malarious, for example, the economic burden of disease tends to be particularly high; interventions which target such locations are likely to improve economic conditions directly, in addition to improving individual well-being.

Similarly, malaria infection can aggravate underlying micronutrient deficiencies in children; interventions which target malnourished children are likely to improve the outcomes of simultaneous nutritional deficiencies in addition to directly protecting children from the devastating effects of malaria.

In addition to increased research into existing technologies, new antimalaria intervention tools are required. An effective vaccine, for example, could form the basis of a highly sustainable and effective intervention strategy. Interest in developing such a vaccine among private pharmaceutical and biotechnology firms, however, is limited.

One important policy initiative to spur private sector interest in this effort would be for donor governments, international organizations and private foundations to ensure a profitable market for a malaria vaccine, if one were to be developed. Such a policy would ensure that those with the most information would decide which projects are to be pursued.

These proposals should be linked together and expanded with commitments from donor governments, foundations, and international agencies into a Malaria Vaccine Purchase Fund. This fund would provide guarantees to the private sector and to the research community that any successful malaria vaccine will have a large market, thereby encouraging the necessary outlays on research and development in future years.

Even with these efforts, however, a useful vaccine may not be available for many years. In the meantime, new medicines are essential to address problems of spreading drug resistance as well as affordability.

These projects are also of little interest to firms. The dynamics of drug markets are not identical to those of vaccine markets, but enhancing private sector interest in drug development is just as essential. Any effort to spur the development of new drugs must explicitly take market dynamics into account.

Similarly, few general purpose insecticides suitable for use in entomological malaria interventions are under development now. These insecticides are essential to future antimalaria programs, due to widespread and intensifying insecticide resistance among anopheline vector populations.

Inability to diagnose malaria quickly is a contributing factor to increased mortality, prolonged morbidity, the spread of drug resistance and delayed response to emerging epidemics. Dipstick tests and other rapid, user-friendly field diagnostics are essential for addressing these challenges.

Enhanced effort should be given to producing these tests at lower cost and increasing their availability in developing countries. Private sector interest in developing new and hardier diagnostics should be encouraged. In the meantime, the use of existing rapid diagnostic technologies in malarious regions should be financed by developed country governments.

Anti-malaria programs, whether at the national, regional, or global level, suffer from a chronic lack of funding. Funding decisions have been based on dramatic underestimates of the real costs of malaria. The international community of nations, together with the multilateral agencies and private foundations, should commit to increased current expenditures for malaria interventions and research programs of at least $1 billion per year, in the coming years. This level of effort should be sustained for an indefinite period, and concentrated primarily in Sub-Saharan Africa. Today, the level of effort worldwide amounts to only a small fraction of this amount.

In addition to greatly increased current expenditures, the donor governments, foundations, and international agencies, should establish a Malaria Vaccine Purchase Fund. Such a fund would only make disburse money if an effective malaria vaccine becomes available, but its establishment now would greatly increase research and development incentives, and thereby greatly reduce the time until such a vaccine is available.

The case for the large increase in expenditures is further strengthened by taking into account the sustained growth penalty associated with malaria, which greatly multiplies the true economic burden of the disease. Taking into account the growth effects of malaria, the benefits of controlling the disease are in the dozens of billions of dollars per year after a few years of malaria control. These benefits would exceed the costs by a widening margin over time, as the program supports a sustained increase in economic growth with cumulative benefits to the level of national income (see figure 2).

The international community, working closely with the countries of Sub-Saharan Africa and other malarious regions, must immediately begin to elaborate the interventions which would make the most effective use of this additional $1 billion per year. Efforts would focus on the increased use of impregnated bednets, improved case management, enhanced vector control programs where feasible, basic research into drugs and vaccines, and ongoing massive disease surveillance and project evaluation efforts.

In addition, international cooperation in training and research in epidemiology, ecology, entomology, immunology, economics, program evaluation, and other relevant fields must be enhanced. This training and research should be designed to enhance technical capacity in developing countries, and should involve interaction between the public and private sector, and between developed and developing countries. The combination of direct interventions (e.g. bednets) with increased surveillance, project evaluation, basic research, and training constitute an integrated approach to malaria control that will be vital for a long-term, successful, and sustainable effort.

The benefits of committing substantial new economic resources to malaria will greatly exceed the costs. Furthermore, the benefits will be greatest when the new resources are deployed in an integrated and multifaceted program of anti-malaria interventions, enhanced surveillance, and greatly intensified research and training programs.

Malaria is caused by four species of parasitic protozoa that infect human red blood cells. Protozoa are one-celled organisms that are as sophisticated as a human cell. Malaria parasites feed on red blood cells for a living but .

The malaria parasite reproduces itself in the gut of the Anopheles mosquito. The malaria parasites need the mosquito to continue their life cycle. Then, the mosquito passes the malaria parasites to the human through its salivary glands.

The worst type is caused by Plasmodium falciparum. Infection with Plasmodium falciparum kills approximately 1-2% of those who come down with it. Falciparum malaria is a serious illness characterized by fever, headache, and weakness.

Complications of falciparum malaria include cerebral malaria, in which the brain is infected, severe malaria, in which the parasitic infection essentially "runs out of control," and placental malaria, in which falciparum is a grave complication of pregnancy, and coma.

The other species of malaria cause a debilitating illness characterized by spells of chills, fever and weakness. This illness generally lasts 10-14 days, and is self-limiting in nature. The malaria caused by these species is rarely fatal.

Malaria causes an estimated 2.7 million deaths per year, with most of these deaths occurring in Africa. Ninety percent of the world's malaria cases occur in Africa. Chloroquine resistance is widespread in Africa. Now, malaria outbreaks are being reported in some locations of Africa that had been previously thought to be at elevations too high for malaria transmission, such as the highlands of Kenya. Some scientists hypothesize this is due to climatic change, while others hypothesize that this is due to human migration. Also, malaria has resurged in certain locations of Africa that had previously had effective control programs, such as Madagascar, South Africa, and Zanzibar.

America and Southern Mexico: Malaria occurs in low-altitude areas of the countries of Central America including Honduras, Nicaragua, and Guatemala. Limited numbers of cases occur in Panama, Costa Rica, and southern Mexico. Active control programs are in place in several of these countries. Plasmodium vivax is the dominant species, and fortunately, remains susceptible to chloroquine.

Malaria is an ancient disease. However, environmental disturbance, malnutrition and the failure of drugs once used to control the disease have conspired to make malaria as serious a problem now as it was during the first half of the twentieth century.

Malaria has been a serious problem in SubSaharan Africa for many years. Malaria causes an estimated 2.7 million deaths per year, with most of these deaths occurring in Africa. Ninety percent of the world's malaria cases occur in Africa. Now, malaria outbreaks are being reported in some locations of Africa that had been previously thought to be at elevations too high for malaria transmission.

Some scientists hypothesize this is due to climatic change, while others hypothesize that this is due to human migration. Also, malaria has resurged in certain locations of Africa that had previously had effective control programs, such as Madagascar, South Africa, and Zanzibar.

Resistance: Drug resistance is a growing problem, Chloroquine is an extremely safe, cheap, and formerly very effective drug, but in Southeast Asia, portions of South America, and a large and increasing area of Africa chloroquine resistance levels are high. In some areas of Southeast Asia there is resistance to all the major drugs. Drug resistance is often connected with a legacy of foolishly overusing or underdosing antimalarial drugs. Some countries even laced salt with chloroquine.

Resistance to Insecticides: Malaria mosquitoes are developing resistance to the major classes of insecticides which have been used to control the disease. Portions of the effort to eradicate malaria during the 1950s and 1960s were scientifically naive and politically uncommitted. Funding for vector control was cut prematurely in areas, leading to resurgence in malaria cases and spread of insecticide-resistant vector populations. The insecticide resistance picture varies with vector species and region.

Change: Population and demographic changes have resulted in more people moving into malaria-endemic areas, thereby increasing transmission. Migration and the creation of new habitats have resulted in people who have no natural immunity to the disease being exposed. This results in epidemic malaria that is characterized by much higher rates of disease and death.

Change and Human Mobility: Human environmental changes such as road building, mining, deforestation, logging, and new agricultural and irrigation projects have created new breeding sites. Malaria transmission in newly logged or exploited areas explodes just as a crop of outsiders with no immunity to the disease come into work camps. This is particularly a problem in the Amazon in Brazil. Indigenous people also suffer unprecedented onslaughts of malaria. Incidence of malaria among Yanomami Indians in the Amazon have leapt almost seventy-fold since contact with settlers and gold miners, who are often plying their trades illegally.

Deterioration and Abandonment of Control Efforts: In many regions, including the Indian subcontinents, Madagascar, and portions of South America and Southeast Asia, malaria control programs have deteriorated or been abandoned because of political lack of commitment, and lack of willingness to see things through to completion.

Indifference and Budget Cuts: Malaria research and control budgets in many countries suffered huge cuts during the 1980s and 1990s, yet malaria was spreading, sometimes to people such as the Yanomami, who had had no previous exposure to it. Public health is often the last consideration when politicians allocate funding. The creation of wars and refugees provides conditions ideal to the aggressive spread of malaria among displaced persons.

About the Developed World? Malaria is primarily a disease characteristic of the developing world. However, portions of the southern United States and Western Europe, i.e. Italy are formerly malaria-endemic regions. The former vectors are still present in these areas. Although people's lifestyles in developed countries have changed greatly since the early 1900s, with the widespread use of screening and the advent of air conditioning, television and other reasons to stay indoors during the summer, it is a "gamble" as to when and where limited local malaria transmission could resume. Competent vectors are present, while parasitemic persons [returned travellers and persons coming from malaria endemic areas] are sometimes present in these areas.

About the Future? Although hypotheses vary about the effect of increased urbanization, population movements, and possible climatic change on malaria, one thing is certain: without the political will to control malaria on both the part of developing nations and in terms of scientific, technical and financial assistance from the resource-wealthy developed world, malaria will continue to be a very serious health problem.

Screening:Screening of Dwellings to Prevent Malaria Mosquitoes from Entering and Biting the People Inside is a positive development measure. Screening of buildings also improves people's lives in other ways, i.e. by keeping flies out of homes.

Where it's possible [i.e. buildings have four walls] to put screens on windows and screen doors on doors, it should be encouraged. Screening is a useful adjunct to use of a treated bednet or residual treatment of walls because it reduces the number of malaria mosquitoes entering and leaving the building.

Biological control: Mosquito fish reduce larval mosquito populations, and some countries have established programmes for distributing these small fish to residents. Mosquito fish are often particularly effective in small ponds, water tanks etc.

Source reduction: This is possible in some conditions but very difficult in other conditions. Source reduction is particularly useful for vector species, such as Anopheles stephensi, that often breed in man-made containers [i.e. water tanks] and at construction sites. There are several species of malaria vectors, and these species breed in many different locations. If the vector mosquitoes are breeding in water tanks, for example, it is possible to screen the tanks. However, if the malaria mosquitoes are breeding in a swamp, it is not always possible nore wise to attempt to drain the swamp. Thus, other strategies for breaking transmission may need to be used.

Drug treatment of malaria patients: People who have malaria have parasites available for malaria mosquitoes that bite them. If they are treated with appropriate drugs, the parasites disappear from their blood and are not available to the mosquitoes. This helps to reduce the transmission of malaria.

In some areas, including Africa, a very large percentage of people [over 50%] may have malaria parasites yet only some people [mostly small children and pregnant women] show the symptoms. Thus, drug treatment of patients is a helpful technique in controlling malaria, but it cannot be the only technique used.

Use of insect repellents: This is especially recommended for those who are travelling or are temporarily in malarious areas. This strategy is too expensive for many people who actually live in malarious areas.

This is a strategy that has been proven to be effective in reducing childhood morbidity and mortality in numerous studies in SubSaharan Africa. A pyrethroid insecticide [derivative of compounds found in the flower Chrysanthemum cineraraefolium] is used to treat the bednets. The mosquitoes that land on the net are prevented from biting the person sleeping under the net, and mosquitoes often avoid landing on the net altogether. The bednets need to be re-treated with insecticide at intervals of approximately 6 months.

Residual treatment of interior walls: In many instances, malaria mosquitoes rest on the walls before or after biting people. Residual treatment of the walls inside a house repels or kills the mosquitoes. This malaria control strategy is very effective where houses have four walls. An insecticide with residual activity needs to be used so that the treatment lasts for some months. Some insecticides are more expensive than others. Also, malaria mosquitoes in some places are resistant to some insecticides. Thus, a large variety of possible insecticides need to be available for this purpose.

Research needs to be done on new drugs as a "reserve weapon" for future cases of drug resistance. Unfortunately, drug resistance is more common in malaria caused by Plasmodium falciparum, the most dangerous type of malaria, than in the other three species.

Some populations of mosquitoes have developed resistance to certain insecticides. This resistance may be of varying degrees. It is important that alternative insecticides be available for breaking human-vector contact.

If the mosquitoes are breeding in water tanks, for example, it is possible to screen the tanks. However, if the malaria mosquitoes are breeding in a swamp, it is not always possible nore wise to attempt to drain the swamp. Thus, other strategies for breaking transmission may need to be used.

People who have malaria have parasites available for malaria mosquitoes that bite them. If they are treated with appropriate drugs, the parasites disappear from their blood and are not available to the mosquitoes.

How Is DDT Used? DDT is used for residual treatment of walls in dwellings in areas where malaria transmission occurs. DDT has been used in malaria control programmes since the late 1940s, often with great success. DDT is particularly useful when used in combination with improvements in housing counditions, such as screening of windows and doors. DDT is less costly than more modern chemicals used for mosquito control, such as the pyrethroids. Thus, in certain cases DDT is affordable while other compounds are not. Remember that malaria occurs in countries that are very often highly strapped for money.

How Dangerous is DDT to People? Very few (probably no) human deaths or illnesses have been conclusively linked to proper usage of DDT. On the other hand, proper usage of DDT has prevented many illnesses and deaths that would have occurred as a result of malaria.

Yes. Certain countries with high morbidity and mortality rates from malaria have trouble affording high-tech medical treatments or the latest insecticides. If DDT is effective for use against vectors in these regions it should be used to prevent premature death and disability. The preservation of human life is paramount.

These areas do not respect political or jurisdictional boundaries. Modern technologies, such as Geographic Information Systems [GIS] and Global Positioning [GPS] are highly effective tools in mapping malaria risk but are also expensive and hard to access for many developing countries.

Malaria control is different from the control of many other diseases because malaria transmission is dependent on mosquito populations. During the past 15 years, there has been a tendency to turn over malaria control from designated malaria control agencies to local primary health care centres [PHC's] that are already financially strapped and ill-prepared to conduct vector control operations.

During these same years, there has been a marked increase in malaria incidence in many regions of South America and Asia, with some increase in Africa as well. Certain aspects of malaria control, such as distribution of mosquito fish or impregnated bednets for mosquito control, or residual spraying efforts, are not closely related to the normal duties of Primary Health Care Centres. These vector control efforts have often suffered as a result of their transfer from malaria control authorities to local PHC's. These duties are better performed by designated malaria control authorities.

Many malaria-endemic countries do not have the telephone or telecommunications infrastructure that is present in the developed world. Telephone calls and internet access may be prohibitively expensive in these regions.

Support: Financial support from the developed world for malaria and communicable disease control in developing nations is often of a short-term nature. Unfortunately, often these problems are chronic in nature and are related to poor housing conditions, wars, migration and other factors that decrease the standard of living. Assistance from developed countries should be long-term and should be oriented toward improvements in overall living standards.

Problems: Unfortunately, where resources are limited, as they are often in the developing world, corruption and graft often are a problem as people within administrative structures fight over a small amount of available resources.

Unfortunately, graft and corruption have limited the effectiveness of certain malaria control programs. It is to be hoped that these influences will diminish and that the paramount importance of saving lives and promoting development and better standards of living will become apparent to administrators in developing as well as developed countries.

New communication technologies have resulted not only in new tools that are useful for epidemiology but also in a wealth explosion in the developed world. These tools should be used to their capability to integrate the developing world into the rest of the world and its affairs. The increasing availability of computer technology and the World Wide Web have enhanced communication capabilities.

The transfer of these capabilities from developed to developing countries has positive impacts on the ability of people within regions of developing countries to communicate with international agencies. These communication technologies, when implemented, are also useful for communication within countries between national administrators and regional malaria control workers. These capabilities should be installed and utilized to their full potential in the saving of lives and health.

New in the Research World? One of the most important recent advances in malaria research is the mapping of the Plasmodium falciparum genome. This is a project that involves scientists from several different institutions in collaboration. More details may be found here.

About Vector Biology and Control? Some of the most interesting recent vector biology and control research uses Geographic Information Systems [GIS] and Global Positioning System [GPS] data to analyze distribution and abundance of malaria vectors. This data can be used at both local and national levels to target malaria vector control efforts appropriately and utilize resources effectively.

Grail' of medicine. Although trials are being conducted of a few different formulations of potential malaria vaccines, none have yet proven to be both safe and effective. Existing vaccines are against viral and bacterial diseases. Because malaria is caused by a protozoan, there are some difficulties in developing an effective malaria vaccine. The immune response to malaria is somewhat different than the immune response to viral diseases such as chickenpox. Immunity to malaria is only partial, whereas immunity to some viral and bacterial diseases is complete.

What Now? For the next five to ten years, until an effective vaccine is developed, malaria control will largely be dependent on vector control measures such as improvements in housing construction, source reduction, impregnated bednets, and residual insecticide treatment.

Westerners who visit malarious countries, however briefly, are not immune! Several thousand return home from travels each year and are hospitalized with malaria. Travelers have contracted "airport malaria" while waiting on planes that were being refueled in malarious areas. Expatriates and soldiers who live abroad are at even greater risk. Malaria was the number one cause of hospitalization among American troops deployed to Somalia; the number two cause among troops in Vietnam (after combat injury); and a leading cause among diplomats, missionaries and aid workers.

The risks to travelers vary. Some parts of the world, such as southern Mexico and Central America, pose a low malaria risk while others, such as most parts of subSaharan Africa, pose a high risk. In other areas, the risk is seasonal.

The reason for the variation in risk is because different species of malaria occur in different parts of the world and because sometimes malaria is common whereas in other places malaria exists, but is not extremely common.

Malaria prevention is a medical matter and should be handled by a physician who is qualified in infectious diseases, tropical medicine, or travel health. Always consult a travel health professional such as a tropical medicine clinic or travel medicine specialist before traveling to subSaharan Africa, the Indian Subcontinent, Southeast Asia, or tropical South and Central America.

Pack a mosquito net that has been impregnated with Permethrin, which is sold as Permanone if you are travelling to an area that has malaria. Your physician or travel health clinic will be able to assist if you do not know whether the area has malaria or not.

This glossary is provided as a help to understanding some of the special terms that are used with malaria and malaria vectors.  The glossary is for the use of students and others who are interested.  The definitions will be expanded as time allows.  If you can't find a term here, try  Google.

ABER - Annual Blood Examination Rate.  Calculated as (number of slides examined/population) x 100.  WHO recommendation for malarious areas is that the number of slides examined per month should equal at least 1% of the population.  Anaemia - decrease in number of red blood cells and/or quantity of hemoglobin. Malaria causes anemia through rupture of red blood cells during merozoite release.  The anaemia caused may be extreme.  Pallor may be visible in the patient.

Oocyst - oocysts are Plasmodium cysts located in the outer stomach wall of mosquitoes, where sporozoite development takes place. When mature, the oocysts rupture and release sporozoites. Sporozoites subsequently migrate to the mosquito's salivary gland, and are injected into the host when the mosquito feeds.

Orthostatic hypotension - decrease in blood pressure occurring when an individual arises from a seated or lying position.  A small decrease in blood pressure is normal, but large decreases are abnormal, especially if accompanied by clinical manifestations such as faintness, light-headedness, dizziness, or increased pulse.  Orthostatic hypotension is a common finding in patients with malaria infections.  The patient may complain of notable tiredness after conducting light office work, etc.

Paroxysm - paroxysm - a sudden attack or increase in intensity of a symptom, usually occurring in intervals. Malaria is classically described as producing fever paroxysms; sudden severe temperature elevations accompanied by profuse sweating.  Paroxysms occurring at 48-hr intervals are typical of Plasmodium vivax infection, particularly in semi-immune persons.

Proportional case rate - The number of cases diagnosed as clinical malaria for every 100 patients attending hospitals and dispensaries [used in India]. Protozoan - A member of the Kingdom Protista.  Protozoa are single-celled organisms [eukaryotes].  The single cell performs all necessary functions of metabolism and reproduction.  Some protozoa are free-living, while others, including malaria parasites, depend on other organisms for their nutrients and life cycle.  Malaria parasites are members of the Phylum Apicomplexa.

Recurrence - a repeated attack weeks, months, or occasionally years, after initial malaria infection, also called a long-term relapse. Due to re-infection of red blood cells from malaria parasites (hypnozoites) that persisted in liver cells (hepatocytes).

Relapsing malaria - Renewed manifestation (of clinical symptoms and/or parasitemia) of malaria infection that is separated from previous manifestations of the same infection by an interval greater than any interval resulting from the normal periodicity of the paroxysms.  Refractory malaria - malaria that is not responsive to residual treatment.  The cause of the lack of response to residual treatment is usually defined to be factors other than physiological insecticide resistance.  Examples of causes of refractory malaria are vector exophily and zoophily with failure to enter houses.  An example of refractory malaria occurred in the Jordan Valley during the early 1950s.  Anopheles sergenti and Anopheles superpictus were evading residual treatment of dwellings by resting in caves and natural fissures in earth (Farid 1954).  Reproduction rate - Reproduction rates > 1.0 indicate an expansion of infections in a population while those < 1.0 indicate a decline in infections in the population.  The goal of malaria control is to decrease the reproduction rate.  This can be accomplished by altering mosquito numbers, longevity of female anophelines, biting habits, and recovery rate of gametocytemic person.  Reduction of mosquito numbers through larval control is less effective by itself than causing mosquito mortality through adult control.  The reason is that not only does adult control cause a reduction in mosquito numbers, but it also causes reduction in longevity of female anophelines [larval control doesn't do that].  The fewer gonotrophic cycles that a female mosquito has, the less likely that it is to transmit sporozoites (MacDonald 1956, p. 620).  Residual treatment - treatment of houses, animal sheds, and other buildings where people or animals spend nighttime hours with insecticide that has residual efficacy.  The goal of residual treatment is to block transmission by stopping human-vector contact.

Splenomegaly - an enlarged spleen. A common finding in malaria patients that sometimes can be detected by physical examination.  May occur in otherwise asymptomatic patients and is of use in conducting malaria surveys of a community, although it should not be the only factor considered when counting cases.

Sporozoite - the infective stage of the malaria parasite that is passed to the human host from the salivary glands of the mosquito.  Sporozoites infect liver cells, disappearing from bloodstream within 30 minutes.  The mechanism for this amazingly rapid disappearance from the bloodstream to the liver is still unknown.  Sporozoites are delicate and spindle-shaped stages that are released into the haemocoel of the mosquito when the oocyst ruptures.  Some eventually find their way to the salivary glands of the mosquito.  Sporozoite rate - The percentage of female anopheline mosquitoes of a particular species that bear sporozoites in their salivary glands.  Expressed as a percentage.  Temperature - the optimal temperature for development of P. falciparum is 30oC [86oF], while the optimal temperature for development of P. vivax is 25oC [77oF].  The time required for development of the sexual phases of the malaria parasite in the mosquito is 10-11 days at these temperatures.

Press Release: 18 November 1999 - A unique study, undertaken as part of the MIM and funded by the Wellcome Trust, includes a unique review of training opportunities provided by international funders for biomedical scientists across the developing world - revealing strengths and weaknesses in current approaches. Read full report.

In November 1996, Glaxo Wellcome announced the initiation of a controlled donation program for Malarone, a highly effective new anti-malarial, in partnership with The Task Force for Child Survival and Development. The purpose of the Malarone Donation Program (MDP) is to help combat the problem of drug resistant malaria in endemic countries where cost often limits access to new medicines.

Program of The Carter Center, through which she participated in a mission to assist the DRC with preparations for its forthcoming elections. She assisted in meetings with Congolese government officials and civil society organizations, European Union and United Nations electoral experts, as well as members of other prominent international organizations, to assess the feasibility of elections in the DRC and possible Carter Center involvement in the Congolese electoral process. Ms. Mulunda's long-term professional and personal goals include returning to the DRC to work in the public sector, and help pave the way for Congolese women to hold key government positions.

Fighting Malaria and a Resident Fellow at the American Enterprise Institute. He has a doctorate in economics from Cambridge University and has advised the South African Government on water and health policy. He has testified before both Senate and House Sub-Committees. Dr. Bate has edited and written ten books, many scholarly papers and over 500 shorter scientific/policy articles, for newspapers and magazines, including the Washington Post, Wall Street Journal, the Financial Times, and Daily Telegraph (London). Dr. Bate founded the Environment Unit at the Institute of Economic Affairs in 1993 and co-founded the European Science and Environment Forum in 1994. Dr. Bate researches water policy in developing countries; health policy and endemic diseases in developing countries (AIDS and malaria); international environmental and health agreements (industrial chemicals, climate change, and water); and the role of aid agencies and NGOs in developing countries.

Project and Advisor to United Nations Secretary-General Kofi Annan on the Millennium Development Goals, the internationally agreed goals to reduce extreme poverty, disease, and hunger by the year 2015. Sachs is internationally renowned for advising governments in Latin America, Eastern Europe, the former Soviet Union, Asia and Africa on economic reforms and for his work with international agencies to promote poverty reduction, disease control, and debt reduction of poor countries. He was recently named among the 100 most influential leaders in the world by Time Magazine. He is author of hundreds of scholarly articles and many books, including The End of Poverty. Professor Sachs was recently elected into the Institute of Medicine and is a Research Associate of the National Bureau of Economic Research. Prior to joining Columbia, Sachs spent over twenty years at Harvard University, most recently as Director of the Center for International Development. A native of Detroit, Michigan, Professor Sachs earned his B.A., M.A., and Ph.D. degrees at Harvard University.

Cindy Korir, PhD, a native of Kenya and a proteomics specialist, is currently a Postdoctoral Fellow in the Malaria Research Program at the Emory Vaccine Center, Yerkes National Primate Research Center. She also holds an adjunct faculty position at Georgia Perimeter College. Dr. Korir earned her Bachelors degree from Coe College in Cedar Rapids, Iowa and her doctorate in microbiology from the Georgia Institute of Technology, Atlanta, Georgia. Her long term goals include advancing scientific research on malaria and continuing the fight to eradicate malaria, especially through educating children. Dr. Korir serves as a project coordinator in Atlanta and as African Liaison for the "Student Leaders Against Malaria"

Ltd, a British company based in Kenya. James Finlay is owned by the SWIRE group which grows and exports tea and flowers to major distributors worldwide. Mr. Korir's management responsibilities include overseeing approximately 20,000 employees with about 55,000 dependants, in the Kenya branch. Mr. Korir has long realized that malaria has had a major impact on the lives of the employees and their families, hence the productivity of the company. Mr. Korir a graduate of Coe College in Cedar Rapids, Iowa, where he returned a few months ago to inducted into the Track Hall of Fame. Mr. Korir has become a leading supporter of the Malaria Foundation International's "Students Leaders Against Malaria" (SLAM) project along with his daughter Dr. Cindy Korir, acting as Liaison for Africa. Mr. Korir and his company's involvement are instrumental in the establishment of pilot SLAM projects with 'brother-sister' learning and working relationships developing among Kenyan and US students.

Malaria" (SLAM) project, sharing the hope that African families and communities can be freed from the scourge of Malaria. Mr. Nicolaysen earned a BS degree in Mathematics, Physics and Philosophy from Bradley University, a Masters in Mathematics from Kansas University, and completed additional graduate work at the Institute of Fluid Dynamic at the University of Maryland. He taught mathematics at Kansas and Oklahoma State Universities, worked as a research mathematician for Continental Oil Company, taught mathematics at the United States Naval Academy, and was Director of the Computer Center, Registrar, Assistant Professor of Mathematics and Assistant Track Coach at Coe College. Mr. Nicolaysen specializes in student information systems.

Sports and Entertainment Management in 1999. The O'Shea Group manages the "Beyond the Game" trademark, which acts as a marketing tool for NCAA, Cingular, Pontiac, CBS Sports, Coca Cola and Live Channel. The O'Shea Group also specializes in helping young basketball players manage the transition involved in moving from the amateur level to the professional level. Steffond recently returned from a Land O'Lakes, USAID and Hoops4Africa sponsored trip advocating for a stronger fight against HIV in Kenya. Since 2004, Mr. Johnson has become a leading advocate in support of Malaria Foundation International projects (MFI) projects and university based malaria research. Mr. Johnson is a creative individual and visionary who is always eager to encourage, challenge and inspire. He is helping to engage sports figures in the fight against global infectious diseases, especially those inflicting and killing vast numbers of individuals. Naturally, he will be an avid supporter and participant in the new "Dunk Malaria" initiative.

INTRODUCTION by Amma A. Semenya, a native of Tennessee born to Ghanaian parents, who currently is a third-year graduate student in the Immunology and Molecular Pathogenesis program of the Graduate School of Arts and Sciences at Emory University. Ms. Semenya's doctoral research in the Malaria Research Program at the Emory Vaccine Center at the Yerkes National Primate Research Center is focused on the molecular and cell biological mechanisms the malaria parasite uses to invade and grow in red blood cells. Ms. Semenya is also a global public health advocate through her volunteer activities with the recently established www.curbsideconsult.org podcast initiative and as a member of the ONE organization which is working to support the United Nation's Millenium Development Goals. Ms. Semenya's long-term professional goal is to be involved in the prevention and eradication of infectious diseases in developing nations. As a sports fan, with a special interest in basketball, she is also keenly interested in seeing major sports figures join these efforts.

Milhous is a world authority on malaria drug development, what we have, what we need, and how we can get there - with emphasis on the need to TRAIN malaria research and control leaders to develop and effectively implement the use of current and future tools. Dr. Milhous is currently acting chair of the MFI's International Board. He is a Fellow of the Academy and Diplomat of the American Board of Medical Microbiology.

Public Health, and he is planning to begin research projects in 2006 within the Malaria Branch laboratories at the Centers for Disease Control and Prevention. Dr. Garba's aspirations are to earn his doctorate and establish surveillance, protection, diagnostic and treatment programs in Niger to eliminate malaria.

OLYMPIC Games and its mission is to train elite athletes from around the world while furthering their education. Dr. Gutekunst is also currently a Visiting Scholar at Emory University's Institute of African Studies.

INTRODUCTION by Paul Driessen, JD, a senior policy advisor with the Congress of Racial Equality, Committee for a Constructive Tomorrow and other public policy institutes that focus on health, environment, energy, economics, ethics, human rights and corporate social responsibility. Dr. Driessen speaks frequently on these issues on radio talk shows and college campuses, before congressional committees and at other events in the United States, Canada and Europe. His book, Eco-Imperialism: Green Power  Black Death, is in its second printing in the United States, has been published in Argentina (Spanish) and India (English) and will soon be available in Italian, African and German editions. He also writes commentaries on these issues for websites and newspapers all over the world. Dr. Driessen earned a BA in geology and field ecology from Lawrence University and a law degree from the University of Denver, before embarking on a career that has included tenures with the United States Senate, U.S. Department of the Interior and an energy trade association. He also serves as secretary for the Kill Malarial Mosquitoes NOW! coalition.

Investment Fund Foundation (CIFF) since its inception in 2002. She works as a management consultant with clients in the health care and non-profit arena. She is currently working with CIFF on developing their strategic plan and with other non profits on issues related to orphans and children made vulnerable by HIV and AIDS. Prior to establishing her own consulting firm, she worked for The Lewin Group, a Washington, DC-based health care policy and consulting firm where she advised private sector clients on public policy issues. Phyllis worked in the public sector as the Manhattan representative for New York State Governor Mario Cuomo, advising on policy and politics in the borough. She earned her Masters in Public Policy from Harvard University's John F. Kennedy School of Government and a Bachelors of Philosophy from Miami University (Ohio).

"Those of us who have been so frustrated over the years at the lack of progress commensurate with the horrors of Malaria victims welcome this new burst of energy from Lance Laifer. This conference of veterans of the malaria wars and newcomers to this great life-saving battle will produce new stepping stones toward the implementation of effective remedies in the affected communities and the discovery of new ways to treat this widespread disease. Anyone who can distract the attention of hedge funders in the direction of malaria prevention is to be commended. I look forward to writing about this project shortly."

"It is a shame that the deaths of millions of African children from malaria every year do not elicit any outrage. But the deaths of a few hundred African giraffes would stir the world into action to save them. Historians estimate that Africa lost 10 million people through the Trans-Atlantic Slave trade that went on for nearly a century. Tragically, Africa loses more people from malaria -- particularly children -- in less than a decade."

Malaria experts, business leaders, and sports figures, as well as faculty, administrators and students from across campus were among the several hundred attendees and participants who gathered for this fast paced and personalized conference to learn the hard facts about malaria and how a diverse group of individuals can work together to fight the disease.

Malaria kills millions, mostly children, year after year, and the conference aimed to help bring this message to the forefront and help bring an end to these "quiet deaths", which minute by minute, year after year have gone largely unnoticed worldwide.

"This is the single largest health crisis in the world right now", said Mr. Lance Laifer, a Co-Founder of the Hedge Funds vs. Malaria conference series. This fact was echoed throughout the conference by many of the speakers and introducers who also gave poignant views to help stir the audience into action. To help excite the audience into action, Mr. Laifer used this opportunity to launch the first basketball "shot" for his latest initiative called Dunk Malaria, which aims to involve 99 million people in the fight against malaria by March 19th, Malaria Action Day, and he demonstrated on stage how easy it is for people of all ages to participate. "Everyone needs to be getting involved", said Mr. Lance Laifer, in his closing remarks. "All the world's children are all of our children. Let the first thing young children associate with sport be a positive thing. I want to call for a World Malaria Summit where every leader spends one day and gets going on this. The numbers are getting worse, they are not getting better. We have a responsibility. We need to get active in this. There are not enough people fighting."

Leadership conference held in New York City, September 20, 2005. The Atlantaconference represents the first conference hosted by a university and organized in partnership with the Malaria Foundation International. "This new model serves to engage people of all ages, backgrounds, and professions", said Dr. Mary Galinski, founder of the MFI and a member of the faculty at Emory University. "Malaria continues to be masked by the higher profile of other diseases and disasters, even within sophisticated university structures, while 3,000 children keep dying each and every day from this preventable and treatable disease. We need to take unique approaches and a bold stand to bring continuous attention, more intellectual capacity and financial support to this problem. That is what this conference is about."

Emory's campus became involved and many helped by motivating their friends, colleagues and family members. Dr. Jeffery Koplan, Vice President for Academic Health Affairs stressed how this conference was particularly important in the context of Emory University's focus on global health initiatives and how malaria is germane particularly to this university. Professor Abdullahi Ahmed An-Na'im, from the School of Law, introduced economist Professor Jeffery Sachs, but first described the profound impact of malaria in his home country Sudan and stressed the need for political will and a sense of urgency to eradicate the disease. Dr. Holli Semetko, Vice Provost for International Affairs, emphasized Emory's particular concern for fighting malaria and global health problems of poor countries, as she introduced IBM's Ann Wilson Cramer. Dr. Jeff Rosenzweig, an Associate Professor of International Business and Finance, expressed his enthusiasm that Goizueta Business School students were getting involved in a follow-up MFI sponsored meeting to learn how they can apply their business training and skills to help with this malaria battle. He then introduced Phyllis Kurlander Costanza, a Trustee of the Children's Investment Fund Foundation.

The conference organizers reached out to involve business, foundation and government leaders, recognizing this as the first step of a constant process that will continue towards involving an increasing number of business executives including Hedge Fund managers from Atlanta – and beyond. "We want all companies to ask how they can participate, and especially those carrying out business in the affected countries," said Dr. Cindy Korir, a malaria research scientist from Emory University and a Kenyan national who serves as a Project Coordinator and African Liaison for the MFI.

Many of the attendees and participants represented various countries throughout Africa, South America and Asia, which are among the 90 to 100 countries afflicted by the disease. All speakers had clear strong messages, a number with first hand experiences with malaria, and each aiming to both educate and draw in supporters in the fight of this deadly yet completely preventable and treatable disease.

The webcast is both educational and moving, involving malaria fighting experts like Professor Wen Kilama of Tanzania and other charismatic champions who can relate to the masses. Among them, retired NBA basketball player Steffond Johnson emphasized the need to care and for high profile sports figures to become involved.

Malaria" campaign in Africa and relayed how everyone's combined efforts are all about saving the children. The webcast will serve the purpose of sharing this event with many audiences around the globe and garnering increasing support against this disease from new and diverse sources. The conference succeeded in initiating a new university-based momentum to help raise the awareness and consciousness of individuals in the United States. It also promoted projects such as "Student Leaders Against Malaria", "Drive Against Malaria" and "Dunk Malaria", which can involve students and adults of all ages. The main goal shared by the Hedge Fund leaders and the MFI is for everyone in the United States to be aware that millions of children die of malaria, literally thousands each and every day, and that this is unbelievable and undeniably unacceptable.

In closing, Dr. Galinski encouraged everyone to frequent the MFI website to learn more about current malaria awareness and fundraising, education, research and control projects, which will benefit from both financial and volunteer support.

Funds vs. Malaria" Business Leadership Conference in partnership with the Malaria Foundation International. With a sense of urgency, given the enormous global toll malaria has on communities worldwide (over 500 million estimated cases annually and several million deaths each year), this awareness raising and fundraising conference has been scheduled a mere month after the first galvanizing inaugural "Hedge Funds vs. Malaria" event held 20 September 2005 at the New York Marriott Marquis. The New York event was attended by over two hundred people and marked the First Annual New York "Hedge Funds vs. Malaria" Leadership Conference.

Adopting a similar template, the Atlanta conference will be held on Tuesday, 6 December from 3-7pm, at Emory University's Law School. The conference will bring together a distinguished group of business, medical, advocacy, and theological leaders to present their insights on Africa, business, leadership, and malaria. Guest speakers will be hosted and introduced by leaders of the Hedge Fund community, including Mr. Lance Laifer, one of the co-founders of the "Hedge Funds vs. Malaria" concept. A main aim is to engender an unprecedented interest in this disease, which ravishes millions, yet by and large goes unnoticed.

"We and others have been raising awareness and support to fight malaria, but we now need to escalate and expedite our efforts", Dr. Galinski said. "The Hedge Fund community has the means to help make this happen, bringing superb business, investing, and marketing skills. We have welcomed the opportunity to step up to the plate as partners with the Hedge Fund community and ask others to similarly join us in this fight."

Foundation International's mission is to facilitate the development and implementation of solutions to the health, economic and social problems caused by malaria. The Foundation's goals are to support awareness, education, training, research, and leadership programs for the immediate and long term development and application of tools to combat malaria. The MFI established the first malaria website at www.malaria.org in 1995 and the first major global media attention on malaria in 1997. The organization has worked in partnership with many individuals and groups who have since joined this cause.

Funds totaling over $200,000 raised at the inaugural "Hedge Funds vs. Malaria" conference are being used to establish Malaria Free Zones (MFZ's) - pilot projects in Ghana, Kenya, and Nigeria. The "Hedge Funds vs. Malaria" plans entail the proper combination of current methods, with professional monitoring and oversight, and with sustainability being a goal. "We believe that malaria represents the tipping point social issue for Africa.

We believe that an African child's life is worth protecting with the same vigor, intensity, and passion we summon up to fight wars and elect presidents (or cheer for our favorite college and pro sports teams), " says Mr.

Funds raised at the Atlanta conference will support Malaria Foundation International projects aimed at heightening awareness to an unprecedented level and expanding the number of people involved in raising funds and working to tackle this disease. The projects will involve professionals from all walks of life, as well as engage student leaders in the U.S. working in partnership with African students. A goal of the conference will also be to involve large U.S. corporations in the logistical planning of the fight against malaria. The Atlanta conference will immediately lead to the announcement and planning of a subsequent "Hedge Funds vs. Malaria" conference. Before long, everyone in the United States will know that malaria is an ongoing disaster that can no longer be ignored.

The Atlanta conference will mark the first "Hedge Funds vs. Malaria" conference to be held at a University. Emory University is hosting this event with the support of the University's President James Wagner. "We are pleased to host this event which will engage new leadres to help make malaria a disease of the past", said President Wagner. "Disease research and outreach initiatives are in line with Emory's strategic plan and commitment to global health concerns."

Between one to three million children worldwide die from malaria each year (more than AIDS and cancer combined) even though malaria is a completely preventable disease. Pregnant women and non-immune individuals are also especially vulnerable. Non-immune individuals, if not treated with effective medications, can succumb to the disease in a matter of days from the time of first symptoms, which include chills, fever, nausea and headache.

Malaria, earth's largest killer ever, is the worst positioned and marketed disease in world history. Over 95% of the people surveyed about malaria were unaware that millions of children are dying from malaria. There is no malaria lobby in Washington. There is no organized malaria PR effort. There are few relevant charitable efforts focused exclusively on malaria. There are few malaria education efforts in the United States. Governmental spending on malaria control initiatives worldwide is difficult to audit. These problems are exacerbated by the fact that malaria is normally subsumed under the overall banner of world poverty and global health.

Hundreds of volunteers are needed to help lead the effort to raise awareness of the malaria emergency that is currently taking place, especially in Africa (It is estimated that 90% of malaria deaths worldwide occur in Africa and that 90% of malaria deaths occur in children under the age of five). We are encouraging everyone interested in volunteering to contact us at vs.malaria@gmail.com Please also follow developments and opportunities for your participation by accessing information being posted regularly at www.malaria.org.

We are a group of scientists and doctors who are writing you on account of your participation in the ongoing treaty negotiations of the United Nations Environment Program (UNEP) aimed at eliminating Persistent Organic Pollutants, or POPs.

As people who have dedicated our careers to health in the developing world, we wish your country to carefully scrutinize any treaty proposal which could aggravate the burden of malaria upon your citizens. Although we entirely agree that DDT should one day be eliminated because of its known environmental effects, we also believe that human life must not be endangered in reaching that goal.

In our view, setting a deadline for the elimination of DDT -- whether that deadline is in 2007 or some other date -- unacceptably endangers health in countries with malaria. We simply cannot be sure when DDT will no longer be necessary for malaria control. Yet to act ethically, we must know, with the greatest of certainty, that DDT is unnecessary before we ban it.

To be satisfactory, these alternatives must be: (1) equally effective, (2) equally inexpensive, and (3) able to replace DDT wherever it is now used or may be needed in the future for malaria control. This will require scientific and technical resources that developing countries lack, but which Western countries can offer.

Phase two would extend the ban to public health uses of DDT, but ONLY if Western countries research and successfully implement effective, affordable alternatives to replace DDT. This two-phase plan, we emphasize, does NOT rule out a DDT ban, but makes it contingent on Western countries funding global efforts to research, develop and deliver satisfactory alternatives to control malaria.

As a negotiator of the POPs Treaty, we believe it is helpful for you to understand the science and politics of DDT and malaria. In this letter, we explain why we believe DDT is a legitimate tool of malaria control, and why a two-phase ban is justified. It is our wish that you find this information useful in pressuring developed states to negotiate a POPs Treaty that respects both the environment and human health.

Malaria is responsible for about 500 million clinical cases of disease and about 2.7 million deaths a year, mostly those of children under five and pregnant women. In Sub-Saharan Africa alone, malaria destroys 70% more years of life than do all cancers in all developed countries combined. It therefore follows that even a tiny loss in the efficiency of a national malaria control program, occasioned by the loss of DDT or otherwise, would result in a tremendous number of additional deaths from the disease.

Malaria is a serious infection of Plasmodium parasites, which are spread by the bite of Anopheles mosquitoes. For this reason, nearly all malaria control strategies target either the parasite or the mosquito in some way. This is easier said than done. There are no fewer than four species of Plasmodium that infect people, each with thousands of genetic variants, and about thirty-five different species of malaria-transmitting mosquitoes. It is the complex diversity of the parasites, the mosquitoes, the local ecologies, socio-economic conditions, and human responses to disease that conspire to make malaria notoriously hard to control. As a result, there is no single prescription, not even DDT, which can successfully control malaria in all locales.

Yet DDT is still a very useful tool for malaria control in some places. Once or twice a year, DDT is applied to the interior walls only of a house. No spraying is done outdoors. Wall spraying is sufficient because mosquitoes tend to feed at night, when people are also indoors. If a mosquito is "DDT sensitive", the small amount of DDT it absorbs through its feet when it lands on a sprayed wall will kill it within a few minutes. If a mosquito is "DDT resistant", it will not die, but will be irritated by the DDT and fly outside. This irritant effect means that DDT continues to be moderately effective even in locales where DDT resistance is considered widespread. In either case, whether DDT kills or irritates the mosquito, the opportunity for the mosquito to bite a person with malaria and carry the infection to another person is lost.

World Health Organization scientists have called indoor house spraying "the most easily applicable large-scale transmission control measure" for malaria. DDT is often the insecticide of choice because it is both very cheap and effective. Data from the Pan-American Health Organization show that where South American countries stopped spraying houses with DDT, their rates of malaria increased, often dramatically.

But leaving aside its effectiveness, what makes DDT attractive is its very low cost. Although exact data on cost per life saved are lacking, there is no doubt that indoor house spraying is among the most cost-effective malaria control strategies. For countries with small health budgets and worsening malaria problems, there may be few, if any, practical alternatives, which may be a reason to immediately increase rather than eliminate DDT use. Thus, any treaty to ban DDT must be weighed very carefully, as against the uncertain cost of other strategies to control malaria, and the loss of human lives if these strategies are too expensive to be implemented.

This is inappropriate, because the relevant question is not whether DDT can pose health risks (it can), but whether these risks outweigh the tremendous public health benefits of DDT for malaria control (they do not).

"possibly carcinogenic", we emphasize that this risk must be balanced against the public health benefits. It is only if the health risks of DDT outweigh the benefits of DDT for malaria control that we should consider not using it. Balancing health risks and benefits like this is not unusual.

For instance, several prescription drugs are classified by the IARC as "possibly carcinogenic", "probably carcinogenic", and even "carcinogenic in humans"  but these drugs are still used to treat life-threatening diseases because the health benefits of a cure far outweigh the cancer risk . The same is true of DDT.

Another possible risk of DDT is that it may shorten the duration of lactation in women. This is the view of one group of scientists who found that DDE (a product of DDT decay in the environment) reduced lactation time in Mexican women. As of today, this conclusion has yet to be confirmed by a second or third group of scientists, as is necessary to have confidence in this result. This is especially so because experiments in rats contradict the human studies, and fail to show that DDE affects lactation time.

But even if DDT shortens lactation time, this too must balanced against the benefits of DDT for malaria control. The same scientists who found reduced lactation in Mexican women also noted an "absence of any apparent effect on the health of the children"

Wildlife Fund (WWF), suggest that DDT may disrupt hormones in the human body and adversely affect our immune and nervous systems. But the scientific evidence of such harm is scanty, if there is any harm at all. WWF itself admits that "the magnitude of immune suppression...is largely unknown", and that "direct effects to humans [nervous system] are difficult to assess".

It would be ironic indeed if in running from the bogeyman of these speculative health risks, we banned DDT and ran directly into the familiar and deadly hands of malaria. Wisdom demands that one first study and prove that risks of hormonal disruption outweigh the benefits of malaria control. Until this is done, the only sensible conclusion is that all the health risks of DDT are outweighed by the concrete, demonstrable health benefits of DDT use in malaria control.

WWF also misleads by concealing the fact that a much greater number of studies contradict its position than support it, and that study after study finds no risk of breast cancer associated with DDT or DDE exposure. WWF cites only a single negative study, but at least five studies reached this conclusion in 1997 alone.

In summary, we would advise developing countries to be skeptical of claims that DDT is destroying the health of their people. Sweeping aside the unfortunate scientific misrepresentations, at worst there are small health risks, and very large health benefits to DDT house spraying. We therefore have no doubt that it would be a terrible error to eliminate DDT, which probably saves hundreds of thousands of lives a year from malaria.

It cannot be seriously disputed that DDT has devastated some wildlife populations, such as birds of prey. The effects of agricultural DDT overuse in the 1950s and 1960s on these populations are reversing only now. We agree this is a good reason to eventually eliminate DDT. However, the urgency with which DDT is eliminated in public health uses must not be an overreaction to the mistakes of agriculture, given the small amount of DDT that indoor house spraying requires.

The environmental impact of DDT use in agriculture and malaria control are not at all comparable. Indoor house spraying needs 2 g/m2 of DDT once or twice a year, or about 470 g for a large house. Quite a lot of this DDT will remain indoors and never enter the environment. By contrast, a single 40 hectare field of cotton requires 795 kg of DDT per growing season  as much as 1700 times as much DDT, sprayed directly into the environment. Spraying all the high-risk houses in a small country like Guyana is estimated to require only as much DDT as for a 4 km2 cotton field.

There is far less urgency in banning public health uses of DDT. Although this should eventually be done, we can safely postpone doing so until satisfactory alternatives to DDT are found and implemented. To do otherwise, or to tie DDT elimination to an deadline that may pass without implementation of alternatives, is to endanger the health of the developing world for an environmental goal.

Of course, we would want to reject unsafe alternatives. We would also want alternatives to prevent the same number of deadly or disabling malaria cases per dollar spent. In short, we would want safe alternatives that are equally cost-effective as DDT. Cost-effectiveness is supremely critical to developing countries that have very little money to spend on malaria control.

Leaving aside DDT, there are three families of insecticides used in malaria control: the carbamates, the organophosphates, and the pyrethroids. The first two are dangerous to handle and require special protective equipment that is not widely available in developing countries, so they are not practical alternatives. That leaves only the pyrethroids to substitute for DDT, although some worry that they are hazardous to health as well.

At this time, there is reason to be enthusiastic about the pyrethroids. Like DDT, pyrethroids require little protective equipment and are safe in ordinary use. There is, however, controversy as to their cost-effectiveness.

Although pyrethroids cost very much more per kilo than DDT, one uses less of them to spray a house. Taking this into account, a recent World Health Organization study estimated pyrethroids cost over three times as much as DDT in actual use. On the other hand, one study from Brazil suggests that pyrethroids can equal or surpass DDT for cost-effectiveness in house spraying.

Scientists have tried hanging pyrethroid-dipped cloths over doors and windows, or soaking mosquito bednets in pyrethroids. Sometimes these strategies are comparably cost-effective as DDT house spraying. But again, success depends on the local ecology, mosquitoes, and socio-economic factors. Take pyrethroid-dipped bednets: these can dramatically reduce childhood deaths from malaria. But how can nets ever work in areas where people are too poor to buy nets (at $5-10 each); how can a net help where the local climate makes it unbearably hot to sleep under a net?

While we believe the pyrethroids could one day largely substitute for DDT, we are not prepared to gamble with human lives by abandoning DDT outright. The diversity of malaria demands that we maintain an equal diversity of control strategies to fight the disease.

If the world banned DDT today and later found that pyrethroids were sometimes, but not always, equally cost-effective or useful, the cost of this "mistake" in human lives would be too awful to contemplate.

Insecticides are not the only way to control malaria. Drugs, vaccines and environmental modifications can work to varying degrees. As always, which strategies work best depends on the local features of the disease.

Technology has a very long way to go before vaccines are practical tools of malaria control, and at the current, poor level of research funding, developed countries are barely advancing vaccine technology. Even if scientists tomorrow discovered a cheap, effective vaccine that gave lifelong protection (a huge "if") on past experience it would take a decade, or decades, to vaccinate people worldwide.

Finally, there is environmental control for malaria. World Wildlife Fund advocates planting trees to dry out wet areas, and introducing fish that eat mosquitoes, among other ideas. Environmental controls are probably best suited to areas where malaria transmission is moderate -- but much of Africa, Asia and South America is not like this. Where people receive hundreds of infected mosquito bites yearly, or the wet season brings great monsoons, environmental controls are likely to be overwhelmed. And even where they work, environmental controls can be very expensive. Thus, while environmental controls deserve more research, they cannot presently substitute for DDT.

Today, there are no alternatives that can substitute for DDT in all cases. This is because of the diversity of the disease. There is no doubt that some alternatives can substitute in some areas, or even improve on DDT in other areas, but we cannot be sure that if we ban DDT there will always be an effective and affordable alternative. Yet there are good environmental reasons to eliminate DDT as soon as possible. The essential matter, therefore, is to test and implement alternatives before a DDT ban comes into force. Otherwise, we are gambling with human lives.

For the price of only a single Stealth Bomber (the United States has twenty), the global malaria research budget could be sustained for two decades -- an interval in which over 50 million people will die from the disease. Other Western countries are equally guilty of neglecting malaria research.

The comparison remains extreme even if one assumes a population density typical of a nation like Tanzania (33 persons per square kilometer). In that case, 13.2 persons would occupy the same 40 hectares of this cotton field, making up perhaps three families in three homes. Spraying those homes would require about 1.4 kilos of DDT; the cotton field still requires 560 times as much.

While DDT is manufactured in developing countries, pyrethroids are made only by multinational chemical companies. Pyrethroids therefore sell at higher prices, which could readily explain why Western chemical companies -- and their governments -- favour a DDT ban.

Scientist discovered Anopheles funestus mosquitoes during a recent survey in northern Kwazulu-Natal.  This particular species was absent from South Africa for the past four decades while Anopheles arabiensis (or gambiensis)(An. arabiensis - sic) was present in summer months after normal rain. An. funestus is much more dangerous than its summer counterpart as it breeds all over in swamps, wetlands and water resources even during cooler winter months. It is also a better vector or transmitter of malaria than A. gambiensis.

DDT that was used all over the malaria areas until 1996 exterminated An. funestus but the termination of DDT use in KZN appeared to have opened the doors for A. funestus again. This mosquito is completely resistant to the new, softer pyrethroid insecticides that were introduced by the National Department of Health (NDH). Pyrethroids are effective against A. gambiensis (An. arabiensis - sic)and will be continued as the primary malaria vector control products in South Africa.

South Africa and will never be allowed for any other purposes that malaria vector control. It is still registered as a malaria vector control agent but only by the NDH. It is a serious criminal offence to acquire, distribute, sell or apply DDT for any other purpose.

The Poison Working Group believes that all South Africans carry traces of DDT, DDD and DDE in their systems this proves that the products is a bio-accumulative product, but also that it does not pose a threat to the lives of people.

Snow who is the field officer of the Poison Working Group in KZN has already trained the spray teams about the correct and responsible application of DDT.  We have also drafted a protocol for the circulation of all rinse water and other contaminated materials to prevent any DDT entering the environment.  The Poison Working Group is monitoring the process in KZN closely and will act relentlessly if protocols are not strictly adhered to.

Globally, numbers of malaria cases are increasing and the rate of increase is accelerating. This pattern is illustrated by multifold increases in malaria rates since 1979 in South America1 accompanied by a rise in the proportions of populations at high to moderate risk of the disease. For example, populations at high to moderate risk more than doubled in Colombia and Peru from 1996 to 1997.2,3 Malaria is reappearing in urban areas and in countries that previously eradicated the disease (eg, urban areas of the Amazon Basin,4 South and North Korea,5 Armenia, Azerbaijan, and Tajikistan6). The frequency of imported malaria has also increased in industrialised countries (US and Europe6). Additionally, the increase in cases and the altered geographical distribution of malaria is underestimated because accurate information on global incidence is difficult to obtain and reports are generally fragmentary and irregular. Although many factors contribute to increasing malaria, the strongest correlation is with decreasing numbers of houses sprayed with dichlorodiphenyltrichloroethane (DDT).1,7,8 Recognition of this link and the start of negotiations by the United Nations Environment Programme (UNEP) for global elimination of DDT9 has fuelled an intense debate.10 The position of many scientists concerned about increasing malaria was described in an open letter10 that was subsequently signed by over 380 scientists, including three Nobel laureates in medicine, representing 57 countries. The letter supports continued use of DDT and residual spraying of houses for malaria control.

Even in the earliest field studies, DDT showed spectacular repellent, irritant, and toxic actions that worked against malaria vector mosquitoes.10 When DDT was sprayed on house walls (2 g/m2) it exerted powerful control over indoor transmission of malaria.11 As a consequence, house spraying produced excellent and rapid results in 1943 in the Mississippi Valley, USA, then in Italy, Venezuela, Guyana, India, and several other countries. House-spraying programmes functioned as national malaria-eradication services. The strategy encompassed vector control and case-treatment campaigns during the attack phase (3-5 years), followed by case treatment to eliminate the remaining parasites during consolidation and maintenance phases. As such, it was a multifaceted approach to disease control. Most countries adopted the malaria-eradication strategy that was formulated and coordinated by WHO. Colonial Africa was left out of the "global" programme because of the lack of national structure and expertise. Even so, some African countries (South Africa, Zimbabwe, and Swaziland) developed successful national eradication programmes. Although malaria transmission could not be stopped by DDT in some areas such as the wet savannas of West Africa,12 the overall effect of vertically structured programmes for applying DDT to house walls was an almost complete reduction or elimination of malaria.11,13,14. For example, malaria was eradicated from most of North America and Europe, and strong decreases in prevalence were seen in the Mediterranean Basin, the Middle East, the Far East, and even in southern Africa.

Claims of risks of DDT to human health and the environment have not been confirmed by replicated scientific inquiry. This is all the more remarkable given that DDT has been used for malaria control for almost 55 years. According to Curtis and Lines,17 toxicity of DDT in human beings and effects on the environment are questionable and require further investigation.

Since the early 1970s, DDT has been banned in industrialised countries and the interdiction was gradually extended to malarious countries. The bans occurred in response to continuous international and national pressures to eliminate DDT because of environmental concerns. Global trends of decreasing numbers of sprayed houses started with changing strategy from the vector-control approach to malaria control. Despite objections by notable malariologists18 (also Arnoldo Gabaldon19), the move away from spraying houses was progressively strengthened by WHO's malaria control strategies of 1969, 1979, and 1992. These strategies were adopted even though published WHO documents and committee reports have consistently and accurately characterised DDT-sprayed houses as the most cost effective and safe approach to malaria control.12,20-22 Changing the emphasis on house spraying was further strengthened by a WHO plan, first introduced by the Director General of WHO in 1979,23 to decentralise malaria-control programmes. This plan was adopted in World Health Assembly Resolution 38.24 in 1985.24 From then on, for countries to qualify for foreign or international assistance, they were expected to comply with WHO guidance on house spraying and to incorporate malaria control programmes into primary health-care systems. Additionally, assistance from industrialised countries was often specifically contingent on not using DDT.

Other mechanisms also have been used by environmental advocates to stop use of DDT for malaria control. A recent example is the agreement of the North American Commission for Environmental Cooperation (CEC) that forced Mexico to stop producing and using DDT for malaria control.25 This agreement also eliminated a rare source of DDT for malaria control in other countries in South America. Claims by environmental advocates26 that Mexico is "now" a test-bed for a new model of "malaria control without DDT" ignores the simple fact that Mexico is a developed country (ie, it is one of the richest of malaria-endemic countries). Consequently, years from now, the outcome for Mexico will show how a scientifically and economically rich country can or cannot control malaria without DDT. Even if Mexico is successful in maintaining control of malaria without use of DDT,27 this success will not be relevant for countries with serious malaria problems and the methods used may not be useful or affordable in more needy and scientifically impoverished countries.

On a landscape scale, a sprayed house will only have a very small amount of DDT enclosed in the walls. Nevertheless, environmentalists are still seeking a global ban26,28,29 arguing that if DDT is produced for use in improving public health, it will also be used for agriculture and lead to global pollution of the environment.26,27 This instance of environmental advocacy seems to have won approval of powerful pesticide companies because it allows them to sell their more expensive insecticides. The replacement of DDT by organophosphate, carbamate, or pyrethroid insecticides is commonly proposed even though price, efficacy, duration of effectiveness, and side-effects (eg, unpleasant smell), are major barriers to their use in poor countries. High costs and downward trends in foreign assistance discourage many countries that cannot afford the switch to DDT alternatives. Although arguments can be mounted on both sides of the issues of cost-effectiveness, duration of activity, and safety of alternative insecticides, there should be no confusion about what happens to public health when use of DDT is banned.

WHO's Global Malaria Control Strategy (GMCS)30 of 1992 and the current Roll Back Malaria31 initiative emphasise treatment of cases and protection of people with impregnated bednets. The failure to include DDT house spraying results from antagonism between the horizontal medical structures and the vertical ones that are needed to restart house-spraying programmes. In other words, more is involved than some undefined opposition to use of DDT. Additionally, some sponsors make the banning of DDT a condition of their support and also require that malaria control be done within a primary health-care system. Because of these multiple factors, the GMCS or Roll Back Malaria initiative, as formulated, will not stop progression of the ongoing global resurgence of malaria.

There is no ideal solution to the problems of malaria control, and DDT house spraying has its limitations. However, DDT remains a remarkably effective tool that should still be used. There is a continuing need for operational research to improve the cost-effectiveness of this approach. It is an astonishing fact that WHO guidance for spraying houses is the same today as it was in the eradication era (2 g of DDT/m2 of wall surface every 6 months). New and improved approaches to malaria control should have evolved from the wreckage of the eradication programme. For example, a yearly cycle instead of the standard 6-month spray cycle might have produced adequate amounts of control in many environments32,33 (eg, Madagascar8,12). If effective, this change alone could have reduced amount of insecticide used in some control programmes by 50%. Partial spraying of houses might have produced control comparable to complete wall coverage.34 Improved methods for prioritising spray operations by risk factors could have further increased the cost-effectiveness of limited malaria-control resources.35-37 Indeed, even today, small investments along these lines of applied research could produce large cost savings and reductions in insecticide usage.

We recommend that the global response to burgeoning malaria rates should allow for DDT residual house spraying where it is known to be effective and necessary. For this to happen, it might be necessary to create new or rehabilitate the old organisational structures.38 Regulations and policies of industrialised countries and international agencies that block financial assistance to countries that use DDT for malaria control should be eliminated. One organisation should be created with the ability to manufacture and distribute DDT to public-health organisations in countries that need it. This centralised system will help guarantee that DDT is used for public-health purposes only. In addition, the necessary quantity of DDT for vector control will be so low that even if diverted, it will not be enough to pollute the environment.

Each Party that produces and or uses DDT shall restrict such production and/or use for vector control in accordance with the World Health Organisation (WHO) recommendations and guidelines on the use of DDT and when locally safe, effective and affordable alternatives are not available to a specific party.

In the event that a Party not listed in the DDT Registry determines that it requires DDT for disease vector control, it shall notify the secretariat and WHO as soon as possible to be immediately added to the DDT Registry.

The Parties, within their capabilities shall promote research and development of safe alternative chemical and non-chemical products, methods and strategies for Parties using DDT, relevant to the conditions of those countries and with the goal of decreasing the human and economic burden of disease. Factors to be promoted when considering alternatives or combinations of alternatives shall include human health risks and environmental implications of such alternatives.

Malaria is one of the world's most serious tropical diseases and imposes very significant economic costs on some of the poorest nations on earth. This study estimates the direct and indirect costs of malaria to South Africa and examines the issues surrounding the use of DDT as an anti-malaria insecticide.

Early records of malaria cases by Europeans in the late 19th and early 20th centuries show that malaria was a severe inhibitor of economic development and caused large economic costs. The current malarial areas in South Africa today are about one fifth of the size they were at the beginning of the 20th century. The historical success in controlling malaria is due in very large part to the use of DDT in malaria vector control.

For a number of reasons, DDT is being phased out of the malaria control programmes in South Africa. Numerous environmentalist organisations have lobbied strongly for the banning of DDT, despite the success of the insecticide in saving lives and preventing disease in developing countries. While DDT is not an ideal insecticide, it does have numerous advantages over the alternative insecticides and has a proven track record. Although DDT is currently used by a number of Southern African countries in malaria control programmes, the UNEP Governing Council is pressing for the banning of DDT and eleven other persistent organic pollutants (POPs).

The potential banning of DDT highlights a trend whereby environmental pressure from mostly developed countries imposes standards on developing countries where they are neither accepted nor appropriate. While there are alternatives to DDT, these are all more expensive and frequently more complicated to use than DDT. The banning of DDT would not only remove an important anti-malaria weapon, but will result in countless deaths and very significant economic costs (perhaps as much as US$480 million) on countries that can ill afford it.

As will be shown later, DDT elimination has been an important goal of certain environmental groups and in the foreign policies of developed countries and in the politics of many UN organisations. The result of these policies and politics is that many developing countries have already been forced to abandon their public health use of DDT. Almost without exception, where this has occurred, malaria rates have increased (Figure 1). Today, if UNEP negotiations are successful in the unconditional banning of DDT, which is the intent; even more millions will suffer increased death and disease from malaria.

As stated by Heppner and Ballou (1998), "More cases of malaria are expected to occur in 1998 than in 1958.." This is a sobering assessment of our backward march to the pre-DDT era of rampant, uncontrolled malaria. The re-emergence of this highly preventable disease speaks to the limited role of poor countries and poor people in international politics. Even the fact that this disease has been allowed to re-emerge with limited international notice attests to the political invisibility of threatened populations.

Although most knowledgeable people are concerned about environment issues, when the environmental agenda eliminates a critical public health tool, it is time to ask a number of questions, to include how large a public health price and who pays? Of the world's estimated 6.8 billion people, 4.4 billion live in developing countries. Within developing countries, 2.64 billion have no access to basic sanitation and 1.45 billion are without safe drinking water (United Nations Human Development Report of 1998). Unfortunately, a large proportion of these poor and disadvantaged people live in malaria endemic countries. The price for DDT elimination is already enormous and it is being paid in daily instalments of lost health and lost lives for hundreds of millions of the world's poorest and most disadvantaged people.

Yet, since 1979, WHO strategies have specifically de-emphasised use of house spraying for malaria control (Roberts et al . 1997). Discussions with malariologists in developed and developing countries alike and publications of prominent health workers suggest that a scientific explanation of the global strategies does not exist. Likewise there appears to be no consensus of support for WHO's de-emphasis of house spray programmes (Farid 1991 and Mouchet et al 1997).

In 1969, the great Venezuelan malariologist, Dr. Arnoldo Gabaldon, argued for establishing a WHO strategy that emphasised residual spraying of houses to maintain the successes of the eradication programme.

International assistance and political acceptability of malaria control programmes are generally contingent on compliance with WHO's global strategies. In other words, if a developing country wants external assistance, its proposal should comply with the WHO strategy and this means that vector control must be de-emphasised. Beyond this, assistance is often contingent on the specific non-use of DDT. For example, the US Agency for International Development (USAID) has invoked sections of the Foreign Assistance Act and USAID Regulation 16, published at 22 Code of Federal Regulations, Part 216 and USAID's pesticide procedures in section 216.3(b) for making decisions about foreign assistance to programmes in developing countries that used DDT for malaria control. The rationale is that DDT is not registered by the Environmental Protection Agency (EPA) for use in the US, consequently foreign assistance is not available to programmes that use DDT. This registration issue ignores the fact that DDT would not be registered by EPA because malaria is not a problem in the US. Also this interpretation ignores WHO's ruling that DDT is safe and effective for use in malaria control. Similar restrictions are employed by other industrialised countries to prevent continued use of DDT in developing countries.

We should note that the early (pre-eradication) patterns of malaria response to house spray programmes in the Americas did not change during the eradication era. Where DDT had shown an ability to stop transmission, disease was eradicated, e.g., southern Brazil; but where transmission was not stopped, only variable levels of control were achieved, e.g., some countries of Central America and regions of the Amazon Basin.

We should also note that, just as the patterns of malaria response to DDT-sprayed houses did not change during the eradication programme, the same patterns held steady after eradication. So as house spray programmes declined, malaria rates increased and transmission reappeared in areas previously cleared of malaria. We should further note that these occurrences reflect a failure to use the chemical, not a failure of the chemical itself. During this time of increasing malaria, Mexico, Ecuador and Belize still used DDT to exert spectacular control over burgeoning malaria rates (Roberts et al 1997). Control was achieved in Mexico despite problems of vector resistance to DDT.

One might argue that change has occurred; so now it is time to get on with the job of making WHO's global strategy a success. Unfortunately, the global strategy includes no broadly applicable and cost-effective preventive measures, so success is simply not possible. Emphasis on case treatment (the core tenet of the global strategy and the new 'roll back malaria' initiative) is laudable; but case treatment is basically curative, not preventive. Without doubt, de-emphasis of preventive measures has allowed the numbers of cases to increase in many rural and even urban environments.

The dichotomy of WHO's Malaria Expert Committee's consistent support for use of DDT versus WHO strategies that worked against use of house spray programmes suggest that global strategies have been political formulations unrelated to the opinions of malariologists or to health interests of people living in malaria endemic countries. In the international arena, defence of DDT for public health use is a WHO/PAHO responsibility. Overall, it is disappointing to examine how these organisations fulfil their responsibilities.

In summation, there is hope for more cost-effective uses of DDT and other insecticides for malaria control. However, we are presently confronted by a global environmental agenda that opposes a major public health need. On the environmental side there is a clearly defined plan for DDT elimination through UNEP negotiations. On the public health side, there is no operable plan for controlling the current global epidemic of malaria or for controlling malaria once DDT is eliminated. So today, with malaria control positioned in organisational structures that are not compatible with vector control programmes; guided by strategies that de-emphasise vector control measures; pressured economically and politically by environmental groups and developed countries to eliminate use of DDT; combined with the political force of ongoing UNEP negotiations, the malaria endemic countries are experiencing an unmitigated disaster as numbers of malaria cases increase at unprecedented rates.

Public health advocacy is needed to bring about an open debate of the DDT and malaria control issues. The outcome of such a debate is critical to hundreds of millions of people in malaria endemic countries. Public health professionals should not accede these issues to the exclusive domain of UN organisations, environmental groups and foreign policies of industrialised countries.

Malaria is one of the most serious tropical diseases in the world and has been a health risk to humanity for many generations. Diseases referred to as deadly fevers, likely to be malaria, have been documented for thousands of years. Malaria was a very widespread disease, covering many areas of Europe, North America, South America, Asia and Africa.

It was only in 1897 that Dr. Ronald Ross of the British army, discovered the complex life cycle of the malaria parasite. Ross proved the link between the parasite of the genus Plasmodium that causes malaria and the Anopheles mosquito. Prevention of malaria had until this time concentrated mainly on the treatment of malaria patients, usually with the quinine. The discovery of the role that the Anopheles mosquito plays in the lifecycle of the malaria parasite led to arguably the most effective way of dealing with the disease - attacking the malaria vector, the Anopheles mosquito.

Vector control programmes began in earnest in the 1950s and saw the eradication of malaria in Europe and North America and dramatically reduced the incidence of malaria in many tropical countries in Asia, Africa and South America. These vector control programmes relied mainly on the pesticide, DDT, which proved to be remarkably effective in controlling the disease. In 1969 however, WHO abandoned its attempts to eradicate malaria globally, leaving many developing countries, particularly those in Sub-Saharan Africa with considerable problems associated with the disease.

An outbreak of malaria carries with it two categories of costs or damages. The first category consists of morbidity and mortality costs, which are made up of productivity losses through lost time and in the case of death, lost future earnings. The second category consists of the costs associated with taking action to avert and to treat the illness. This paper will attempt to measure each of these categories of costs in order to arrive at an estimate of the economic costs of an outbreak of malaria.

Perhaps the most rigorous economic method of valuing the economic costs of an illness is to measure the willingness to pay (WTP) to avoid illness, or the willingness to accept compensation (WTAC) as a result of the illness. Social benefits, or social welfare is made up of the sum of individual's willingness to pay for (or to avoid) change. Illness affects social welfare through the individual's inability to work and to contribute to social welfare. The impact of lost work affects not only the individual, but also the employer, the customers and the rest of society.

To estimate the different impacts on employers, individuals and customers would be extremely complicated, therefore it will be assumed that the interests of the individual are identical to that of the employer and customer. It will be assumed that each malaria sufferer is self-employed and therefore the losses in pre-tax income will be an adequate estimation of the social value of lost work.

Evaluating individuals' preferences towards illness may be a more rigorous approach to establishing the economic costs of a disease, however it relies on detailed information and primary data collection. Because of the time limits to this paper, no attempt will be made to estimate the WTP or WTAC to avoid disease. Rather a cost of illness (COI) approach will be adopted. This will estimate the social losses through lost work and the cost of treating malaria.

Nineteenth century European pioneers and travellers into the Northern Province, Mpumalanga and northern Kwazulu Natal soon recognised the threat and serious impact that malaria could have. Little data is available on the incidence of malaria at this time, however specific studies into the disease in the early twentieth century has shown the devastating effect that the disease had on the economy.

In South Africa, malaria is now only found in the low altitude areas of the Northern Province, Mpumalanga and the north east of Kwazulu Natal Province. The fact that the disease is contained to these areas is due in large part to the vector control programmes, which began in earnest after the Second World War. Prior to this, malaria occurred in much of the North West Province, areas of Gauteng (including Pretoria), much of Kwazulu Natal and even in the Northern Cape - an area five times larger than the area of its present distribution.

In 1905 a malaria epidemic in Durban alone resulted in 4 177 cases and 42 deaths and subsequent epidemics in Kwazulu-Natal and the lowveld (low altitude areas) of the Northern Province and Mpumalanga frequently brought economic activities to a standstill. Because of the changing socio-economic conditions of the country at the time, the impact of malaria was extremely severe. At this time, many labourers were brought into malarial areas to work on railway lines and to develop agricultural areas. Many of these labourers came from non-malarial areas and therefore had no immunity to the disease.

Since the advent of the use of DDT in the vector control programmes (to be described in more detail below) after the Second World War, outbreaks of malaria have not been as serious, nor have they led to the number of deaths as witnessed prior to this period. The combination of agricultural and industrial development in the malarious areas during the 1960s and 70s with the increased concentrations of people in the homeland areas caused a general increase in the number of malaria cases.

Specific data for the number of cases and deaths as a result of malaria have only been kept since 1971 and are presented below. Of the approximate 40 million population of South Africa, 10%, or 4 million people live in a malaria risk area.

There has been a noticeable increase in the number of cases of, and deaths from malaria in recent years. Heavy rains have been experienced throughout South Africa and particularly in the low altitude malarial areas in the last three years. A study performed in the malarial areas showed that for one research station, Makatini, the rainfall and malaria cases were well correlated (r = 0.913, P<0.001), however the relationship for another research station, Ndumu, was far less well correlated (r = 0.643, P>0.05). (Sharp B. et al, 1988). While anecdotal evidence would suggest that the incidence of malaria and rainfall are very closely correlated, research suggests that this relationship is more complex.

Sharp et al, 1988 estimated that for the period between 1976 and 1985, imported malaria cases (mostly from Mozambique) accounted for 19% of the total cases. With the democratic changes in South Africa and the more relaxed policy towards border control, imported cases could account for a significant proportion of the total number of cases. Geographic Information Systems (GIS) for Kwazulu-Natal show markedly increased levels of malaria along the main corridors travelled by Mozambicans through Kwazulu-Natal from the southern border of Mozambique. (pers. comm. Jotham Mthembu, Kwazulu Natal Dept. of Health) Migration from other Southern African countries, such as Zimbabwe, Botswana and Malawi could account for some of the increase in malaria cases in recent years.

In order to accurately estimate the economic impacts of malaria, it is important to know the age groups of malaria sufferers. If malaria occurs mainly in the working population (between the ages of 15 and 65) the disease is likely to incur far higher economic costs than if the disease affects only small children or only the elderly.

This age breakdown of malaria cases closely corresponds to the demographic data for the province detailed in Table 3, which gives a age breakdown of the total populations of the three malaria provinces based on the 1996 census. Of the three provinces, approximately 40% of total residents were below the age of 15 and approximately 4.5% of residents were over the age of 65. About 55% of the provinces' residents were between the ages of 15 and 65. This demonstrates how closely the ages of malaria patients correspond to the general age profile of the provinces. It is important to note that the malarial areas form only a part of the total provinces, however there is no reason to believe that the general age breakdown of the malarial areas will differ significantly from the age profile of the provinces as wholes.

From the census data presented in table 4, it is possible to estimate the relative risks faced by residents in each of the three malarial provinces. By dividing the number of malaria cases in each province by the population (as measured in 1996) an incidence risk for each province is arrived at.

From table 5 it is clear that the risk of infection in Mpumalanga is between 2.6 and 3.4 times higher than in the Northern Province and between 1.6 and 3.4 times higher than Kwazulu-Natal. The higher risk in Mpumalanga could be due to a number of factors, such as climatic differences, or perhaps because of different approaches in the malaria control programme adopted in each of the provinces.

Malaria has never been known to affect either gender more severely and therefore it is assumed that the parasite attacks males and females equally. (pers. comm. Dr. Frank Hansford, Northern Province Dept. of Health) Data from Mpumalanga province shows that the number of cases in males and females is fairly evenly divided, with 44% of cases occurring in females and 55% in males in 1997. The breakdown is more equal in 1998, with 52% female cases and 48% male cases. Traditionally, the role of women in rural areas would have been to care for children and to produce agricultural produce from small household plots or tribal land. With general economic changes and particularly the increased importance of the tourism industry in the malarial areas, women are now playing a more active role in the formal economy. Because of this, no distinction is made between the genders of malaria patients with regard to lost productivity.

The provincial departments of health record two broad types of malaria cases, namely active cases and passive cases. Malaria control personnel, who regularly visit households in malarial areas in order to detect cases, record active cases. This active detection of cases involves inquiring about residents with illnesses resembling malaria and taking blood smears from them. Active detection is essential in identifying uncomplicated or mild malaria, particularly in areas where curative health services are not available. Those suffering from uncomplicated malaria are often treated immediately and if someone is found to be suffering from severe or complicated malaria, arrangements are made to transport them to clinics or hospitals.

The proportion of active to passive cases appears to vary between the three malaria provinces. In the Northern Province, for 1996 and 1997, passive cases made up approximately 80% of the total number of cases, while in Kwazulu-Natal, the number of passive cases appear to be of the order of 30%. In Mpumalanga, passive cases made up 65% of the total number of cases in 1995/96, however were much lower (approximately 30% for previous years.) This difference could be due to different levels of effort on behalf of malaria control personnel in the different provinces in finding active cases, or it could be due to different levels of tolerance to the disease in different areas.

The data presented in Table 6 includes data for Mpumalanga, Northern Province and only northern Kwazulu-Natal. The data does not include those cases found outside the three malaria provinces or in other areas of Kwazulu-Natal because of data inconsistencies (Medical Research Council).

South Africa's malaria control programme requires that all malaria cases within the three malaria provinces are confirmed and logged. The number of cases is monitored at both a local and national level. There is no requirement however for malaria cases outside these areas to be logged or tracked. A significant number of cases are recorded outside the malaria areas and can be attributed to migrant workers, who are infected in one of the malarial areas and then return to work in a non-malarial area, such as Gauteng. Tourists who visit the malarial areas would also contribute the number of cases outside the three malaria provinces. The total number of reported malaria cases outside the three malaria provinces were 1 097 in 1996, 1 259 in 1997 and 902 in 1998. These cases range between 3% and 5% of the total number of reported cases. It is likely that cases are among the economically active in the major industrial centres of South Africa. It can therefore be assumed that the economic impact, through lost productivity of these cases will be significant and should therefore be taken into account.

The first malaria control programmes in South Africa began in the 1920s with larval control. Antimalarial committees were set up in Kwazulu-Natal and in the then Transvaal in order to co-ordinate preventative measures. The identification of larval sites was a vital part of this programme, which also encouraged the use of house screens and bed nets.

A report by Professor Swellengrebel, who visited the Kwazulu-Natal in 1930, recommended intensive anti-malarial measures and the principles of species sanitation contained in his report have been followed ever since. (Sharp B, et al. 1998). Certain areas, such as the Ingwavuma, Ubombo and Hlabisa districts of northern Kwazulu-Natal were not considered suitable for anti-malaria programmes because it was feared the natural immunity of the local population would decrease. Oil and Paris Green were used in larval control in the 1930s and continued to be the main method of control until 1946. During this period, many larval sites were drained and frequently eucalyptus trees were planted in order to remove permanently any malaria breeding sites. The South African Railways was extremely pro-active in malaria control, particularly through larval control near its stations. Between 1932 and 1938, the number of malaria infections among railway personnel fell from 1 021 to 57.

The spraying of households with pyrethrums was extended to "native" areas (original wording) in the 1930s whereas before this it was restricted to white rural populations. Where larvicides and pyrethrums were used together, such as in the Springbok flats, which now fall in the Northern Province, the incidence of malaria was greatly reduced.

Malaria continued to be a severe problem while larval control was practised and while pyrethrum house spraying was implemented. It was not until DDT replaced pyrethroids that the vector control programme led to the radical and long-term reduction of malaria cases. In Kwazulu-Natal, the use of DDT began in 1946 and during the next five years, the number of adult vectors caught annually during routine check sprays decreased from 4 621 to 322 (Nethercott, 1974, reported in Dept. of Health, 1997).

DDT is widely acknowledged as the most successful insecticide in malaria control and its use allowed for the economic development of many areas that previously had been restricted because of malaria. After the introduction of DDT in the vector control programme in 1946, the number of cases of malaria in the then Transvaal declined to about one tenth of those reported in 1942/43. In some areas, DDT spraying was reduced and sometimes stopped because of the success it had in vector control. It was only required again after periods of heavy rains when malaria cases tended to rise.

DDT is highly specific and is still considered to be one of the most effective insecticides for several reasons. (Kemm, K. 1999) First, it is affordable and therefore available to many of the poorly developed and under-funded rural areas of South Africa. Second it is easy to mix and apply and therefore relatively little supervision and quality control is needed. When DDT is sprayed onto walls, it leaves a white powdery residue that allows the sprayer to check easily the parts that have been left out. Lastly no immunity of mosquitoes to DDT has been found in South Africa.

Data from the Development Bank of Southern Africa (DBSA) for 1994 gives a breakdown of the economic activities in the various malarial areas of South Africa. The economies of the three areas where malaria is prevalent are somewhat different. In Kwazulu-Natal and Mpumalanga, agriculture, manufacture, trade and catering and community services are the most important sectors of the economy. In the Northern Province, the mining sector contributes the most in terms of gross geographic product (GGP) with almost a 50% contribution, followed by community services, trade and catering and finance and real estate.

Tourism plays an important part of the economies of most of the malarial areas. The Kruger National Park and the private game reserves that border it comprise the majority of the land area within the malarial areas of the Northern Province and Mpumalanga. There are a number of smaller game reserves and private lodges in northern Kwazulu-Natal, both inland and along the coast. In recent years many cattle ranches in this area have moved over to game farming, either for hunting or game viewing. The Lubombo Spatial Development Initiative (SDI), which is fundamentally a development plan for eastern Swaziland, southern Mozambique and north-eastern Kwazulu-Natal has tourism as its main focus and the basis for future development in the area. The trend towards tourism is therefore likely to continue and to become an even more important sector of the local economy.

In most of the malarial areas, unemployment is very high and frequently is above 40%. Malaria occurs in many areas that lie in the previous homeland areas, which are generally economically depressed and reliant on small-scale agriculture. Industrial and urban centres such as Gauteng and Durban draw much of its labour from many of these areas and there has been an historic and ongoing pattern of migration from rural areas to urban centres. There are however a number of industries in or surrounding these old homeland areas which provide employment opportunities. Examples of these are Nelspruit in Mpumalanga and Richards Bay in Kwazulu-Natal, which are within malarial areas of intermediate risk.

The informal sector plays an important part in the local economies in the malarial areas, with on average 12% of the total labour force active in this sector. Small scale agriculture and the production of arts and crafts for the tourist market are important sources of income for many households. Because of the nature of this sector, it is however impossible to know what it contributes to the GGP of the area or what the value of lost earnings through illness might be.

Tables 7, 8 and 9 give economic data based on 1994 figures and it is assumed that the basic structure of the economies is unchanged. A number of economic and social changes have taken place in South Africa since 1994, however current data at magisterial district level is unavailable. The figures presented in tables 7, 8 and 9 do not purport to give a complete picture of the local economies. They should however give broad indications of the kinds of economic activities and the employment situation so that a more accurate assessment of the losses in productivity through malaria can be made.

The National Productivity Institute (NPI) produces productivity statistics for a number of different sectors of the South African economy. Wage data for the main economic sectors in the malarial areas are summarised below in table 10. In order to determine an accurate average wage rate for the malarial areas, a weighted average, based on the levels of employment in the various sectors within the malarial areas is calculated.

Based on the above wage data and the percentages of the labour force in the malarial areas, weighted average wages have been calculated for 1996, 1997 and 1998. An 8 hour working day has been assumed in order to calculate the hourly wage rate.

The economic costs of malaria can be divided into two broad groups, direct costs and indirect costs. Direct costs include the costs to individuals and to the health services of treating and preventing malaria. Indirect costs are the costs to the economy of lost productivity due to malaria, the costs of lost future earnings in the case of death from malaria and costs incurred through days lost in education.

In general, two types of malaria cases are treated in South Africa, complicated (or severe) malaria and uncomplicated (or mild) malaria. As their names would suggest, complicated malaria requires more intensive treatment and usually hospitalisation. Uncomplicated malaria symptoms are similar to flu symptoms, with fevers, sweats, body pains and headaches. The symptoms of complicated or severe malaria can include convulsions, severe anaemia, hypoglycaemia, renal failure, sepsis, pneumonia, adult respiratory distress, hyperparasitaemia, hypothermia or circulatory shock. Cerebral malaria can also develop in complicated cases and as with the other symptoms, is life threatening.

Uncomplicated malaria cases are usually treated with drugs in tablet form and more often than not are sent home. All pregnant mothers and children under the age of five are treated in hospital whether they have complicated or uncomplicated malaria. There is a far higher risk of complications developing in these two categories of patients.

Neither the Department of Health, nor regional hospitals and clinics keep accurate data on the number of complicated and uncomplicated cases. The regional malaria control programme offices however do have data on the number of active and passive cases within their regions. As explained above, an active case is one where the malaria control personnel have actively gone into the community and have sought out malaria cases. Active cases usually do not exhibit any severe symptoms of malaria and have not chosen to seek medical attention. Passive cases are those which have actively sought medical attention by coming into clinics or hospitals. These cases are likely to be severe or complicated malaria and are treated with fansidar and chloroquine. Not all passive cases are admitted to hospitals and in fact many are usually sent home to complete the course of treatment.

In order to estimate the economic costs of malaria, it is assumed that all the active cases are treated at home and do not receive any hospital treatment save the drugs given to them by the malaria control personnel. Of the passive cases, 55 percent are assumed to be treated as outpatients and 45 percent are assumed to be admitted to hospital. Of those admitted to hospital, some of the cases will be treated orally with chloroquine and fancidar and some more severe cases will be treated with IV quinine. Those less severe cases will generally be in hospital for 4 days, while the IV quinine patients will be hospitalised for 7 days. (pers. comm. Dr. Ian Cooper, Medical Superintendent, Manguzi Hospital) No accurate data exists on the number of orally treated patients and those IV treated patients, therefore it is assumed that of the total number of cases, 40 percent are treated orally and 5 percent are IV quinine treated.

Direct costs are made up of the time of medical personnel, cost of drugs to treat malaria victims and the cost of testing for malaria. Every malaria case is different and will require different amounts of attention from medical personnel and different types and quantities of drugs to treat the disease. It has not been possible to collect primary data on the costs incurred in treating malaria cases. The data used are largely estimates from medical practitioners and medical researchers in the field and should be seen as averages and are based on their estimates.

In clinics within malarial areas, it is unusual to find medical personnel who are solely dedicated to the treatment of malaria, however in many cases, malaria takes up a significant amount of time. This imposes a direct cost on the health service, as these personnel are no longer available to perform other duties.

The time costs are based on the average wages of medical personnel for Shongwe Hospital in Mpumalanga for 1997. (pers. comm. Justin Wilkins, Dept. of Pharmacology, UCT ) It is assumed that these wage costs are applicable in all parts of the country as this hospital is a fair example of the hospitals and treatment centres in all the malarial areas. The average annual cost of employment for medical personnel includes annual fringe benefits and is based on a full range of personnel. The average nursing wages for example take into account the cost of employment of nursing assistants, staff nurses, professional nurses, senior professional nurses and assistant directors. The medical cost of employment is averaged between the cost of employing medical officers and superintendents.

All active and passive malaria cases are given rapid malaria tests, which take approximately five minutes to complete. These rapid tests or parasite F tests only test for Plasmodium falciparum malaria, which makes up approximately 90% of the malaria cases in South Africa. Rapid tests cannot be used to confirm whether or not a malaria patient is free of the parasite after treatment, as the rapid test can remain falsely positive for up to two weeks after treatment. Rapid tests on average cost R10 per test and can normally be completed in five minutes.

Malaria cases are usually tested after treatment, using a smear test, which has to be performed in a laboratory. While the equipment for smear tests is cheaper than the rapid tests, they are far more time consuming and on average take approximately forty minutes to complete. The smears need to be dried and stained - a process that can take up to two hours to complete. The smears are however done in large batches so as to save time. It takes approximately five minutes to view the smear and confirm the results, however the process per slide can take approximately forty minutes to completion. Time is the greatest expense with smear tests, however there are costs of consumables, which are estimated to be R3 per test.

As with the cost of medical personnel, the cost of laboratory technologists is taken from Shongwe Hospital in Mpumalanga for 1997. It is again assumed that the cost of laboratory personnel is equivalent in all malarial areas. The daily and hourly rates are calculated in the same way as with the medical and nursing costs.

The costs involved in keeping a patient in hospital are often very significant. Costs are incurred in feeding patients, changing and cleaning bed linen, cleaning and disinfecting floors and walls, swabs and in the use of needles and drips. It is estimated that for the 1997/98 financial year it cost on average R300 per day to keep a patient in Manguzi hospital in Kwazulu-Natal of which R70.32 per day is attributed to medical personnel. The cost of accommodating a patient in hospital, not including medical personnel is therefore R229.77 (pers. comm. Dr. Ian Cooper, Medical Superintedent, Manguzi Hospital). The cost of keeping a patient in hospital per day in most rural hospitals is very similar and it is therefore assumed that it costs R230 per hospitalised patient per day throughout South Africa.

Certain costs are not included in this estimate, such as the cost of transporting emergency malaria cases to larger and more sophisticated hospitals. Anecdotal evidence from Manguzi hospital suggests that a number of malaria patients are transported from this hospital in northern Kwazulu-Natal to larger hospitals in Durban or Richards Bay either by ambulance or helicopter. (pers. comm. Dr. Ian Cooper, Medical Superintendent, Manguzi Hospital) These costs are borne by the hospital (in the case of ambulances) or by the provincial department of health (in the case of helicopters). Due to a lack of data on these costs, they have been omitted from the analysis.

A large proportion of the costs incurred in detecting and treating malaria cases is in the active malaria control programmes. Malaria control personnel actively locate and treat malaria cases and take rapid tests and smear tests. The budget for the malaria control programme also includes the costs of spraying households with insecticides as part of the vector control programme. Estimates of the expenditure on the national malaria control programme are given below. It must be stated that these figures are estimates of the programme costs done at the beginning of the financial year. No figures are available from the three malaria provinces of the actual amounts spent, which could well be in excess of the figures given here.

Indirect economic costs of malaria are those that do not entail an immediate cash cost to an organisation, such as the Department of Health. Indirect costs are those costs incurred on the wider economy through, for example, productivity losses through the inability to work. Indirect costs are more difficult to estimate than direct costs, as assumptions have to be made about productivity of malaria victims. Estimates have to be made of mortality costs as well as morbidity costs, which involves estimating the present cost of lost future earnings.

Wages have been determined according to the published average wages per sector and then weighted according to the levels of employment in those sectors within the malarial areas. The unemployment rate in the areas will have to be taken into account, however it cannot be assumed that those malaria patients that are unemployed will not cause productivity losses. In most rural areas, most household members are involved in some productive activity, be it herding cattle or goats, or working on communal or private land in order to produce agricultural products that are either consumed by the household or sold at market.

Many women are involved in caring for children other than their own (grandchildren, nieces, nephews etc.) which allows women to leave the home and seek employment elsewhere. The illness or death of a child carer can therefore have devastating effects on the employment of such a mother.

As has been shown by the breakdown of the ages of malaria cases and the gender breakdown, malaria is not selective, as the cases closely resemble the demographic pattern of the malarial areas. The age breakdown of malaria cases for 1996, 1997 and 1998 (given in table 6 above) is applied to both active and passive malaria cases. This gives at the number of cases below the age of 15, the number of cases between the age of 15 and 65 and the number of cases over 65.

The malaria cases within the economically active age range (15 to 64) are further divided into those employed, those unemployed and those active the informal sector based on DBSA data (table 8 above). It is assumed that those in formal employment earn the weighted average wage rate as detailed above. It is further assumed that the unemployed earn a basic agricultural wage as they produce agricultural goods on household land and herd cattle and goats. As it is difficult accurately to determine appropriate wage levels for the informal sector, it is assumed that those active in this sector also earn a basic agricultural wage.

Because of the nature of active malaria cases it is assumed that they lose 1 day of productive work. Passive cases that are treated as out patients will usually lose about 4 days of work, as will passive cases that are treated with chloroquine and fancidar in hospital. IV quinine patients who suffer from more severe malaria will lose approximately 7 days work.

It is usual for a member of a household to take time off to care for children with malaria. (pers. comm. Dr. Ian Cooper, Medical Superintendent, Manguzi Hospital) As mentioned above, all children under the age of 5 are automatically hospitalised and it is assumed that on average the length of stay in hospital will again be 4 days. During this time, it is further assumed that one adult will lose an equivalent amount of productive time. For those children between the ages of 6 and 15 that are treated as outpatients, it is likely that an adult will be able to perform some of the usual productive activities, therefore 2 days of lost productivity are assumed. Because of the supportive extended family in most rural areas of South Africa, it is assumed that carers are not formally employed, but are members of the immediate or extended family who are able to afford the time to care. The productivity losses are therefore estimated at agricultural wages.

Anecdotal evidence from residents in the Jozini area of Kwazulu-Natal suggests that in certain clinics and hospitals, family members are required to care for malaria patients of all ages due to a shortage of nursing staff. (pers. comm. Mr. J. Gumede, Jozini resident) As this has not been officially confirmed, these potential lost productive days have not been included.

A number of studies have associated malaria with poor cognitive development, anaemia, epileptic convulsions and faltering growth in the first three years of life (Chima et al, 1999). Schiff et al. (1996) (reported in Chima et al. 1999) showed that children who were not protected by impregnated bed nets grew less in a 5 month period and were twice as likely to be anaemic as protected children. Strong evidence has been shown between iron deficiency anaemia and poor performance in infant development scales, IQ and learning tasks in pre-school children and educational achievement among school-age children. (Pollitt 1993; Pollitt 1997; Soewondo et al. 1989 - reported in Chima et al. 1999).

Malaria is reported to be the single most important cause of epileptic seizures in early childhood, with 31.3% of seizures attributed to malaria in Kenya while in Zimbabwe the figure is lower, at 16% (Chima et al, 1999). The impact of epileptic seizures on the cognitive ability of children is serious and can cause serious learning disabilities and reduced school attendance. (Chima et al. 1999).

The losses in school days, impaired cognitive abilities and the ability to reason could affect future productivity and earnings. No direct evidence is however available to support this assertion (Chima et al, 1999) and more research is necessary before any estimate of these costs can be estimated.

For every malaria patient that dies, costs are incurred to the economy due to lost future productivity. An estimate of these mortality cost will entail calculating the present value of future earnings. A real discount rate of approximately 10% is used in this calculation, based on real interest rates of 20% and an inflation rate of 9%.

No data is available on a national basis of the ages of malaria deaths, however limited data for the province of Mpumalanga is available for 1997 and 1998. This data (contained in table 16 below) gives the number of deaths from malaria in the province for these 2 years, within 5 yearly intervals.

It is assumed that each death occurs in the median year of each age group and on this basis, the average age of death for 1997 was 30.3 years and for 1998 was 35.6 years. It is assumed that the retirement age is 65, which results in 34.7 years of lost productivity for 1997 and 29.4 years of lost productivity for 1998. As no data for the country as a whole is available, the estimated average age of death for Mpumalanga is used for both years for the whole country. In addition, in order to estimate mortality costs for 1996, the 1997 average age of death is assumed for this year.

For every death however there are costs, which could be borne by the government that are saved. These costs could include future health costs, pension costs and general welfare payments. No estimate is made of these cost savings, which could be considerable, however they should be borne in mind.

Frequently visitors to malarial areas return home, or in the case of migrant workers, to their place of work, and only then do they show the symptoms of malaria. As pointed out above, because the non-malaria provinces are outside the malaria control programme, the reporting on these cases is less systematic. For the purposes of this study, it is assumed that all the cases of malaria outside the malaria provinces are treated in hospital for 4 days, using chloroquine and fancidar treatment. The costs of treatment are assumed to be the same as in the malaria provinces, however this could be an underestimation as usually the costs of treatment in urban centres is higher than in rural areas.

In order to estimate lost productivity, the same average wage rate as in the malaria provinces is used. As there is no data giving the location of the malaria patients outside the malarial areas, it is not possible to adjust the wage rate accordingly. It is also assumed that no family care is necessary for those patients outside the malaria provinces.

A number of additional economic costs are incurred by malaria that have not been quantified in this analysis. One cost for example is the lost productivity incurred through the attendance of funerals of malaria victims. In South Africa funerals are usually attended by most or all of the extended family and by large numbers of neighbours and friends. While funerals are usually held on weekends, costs will be incurred by family members travelling from urban centres to rural areas and will frequently be required to take time off work. In many farms and factories, the whole workforce will take time off to attend funerals, which can disrupt production and therefore incur costs.

Malaria could have an impact on the tourism industry, especially as tourists have recently become more aware of the high levels of malaria and the danger that it poses. Tourists are usually required to take antimalarial drugs, such as chloroquine (trade names: Anoclor, Daramal, Nivaquine, Plasmoquine or Promal) and proguanil (trade name: Paludrine). An alternative drug is mefloquine (trade name Lariam) which should be prescribed by a doctor. Some of these drugs can cause serious side effects, such as nausea, vomiting and diarrhoea in the case of chloroquine and proguanil. Lariam can cause more serious side effects to the nervous system and has been known to cause hallucinations and trembling of the body. It is because of these serious side effects to the nervous system that Lariam can only be prescribed by a doctor. The danger of contracting malaria and the side effects from the antimalarial drugs are likely to deter a number of tourists from visiting malarial areas. It is interesting to note that many of the non-malarial tourist areas in South Africa, such as the Waterberg nature areas in the Northern Province prominently promote the fact that they are non-malarial.

While these economic costs have been calculated in order to reflect the local economic conditions as closely as possible, a number of assumptions (as detailed above) have had to be made. The economic costs are only estimates that rely on secondary data and information and do not purport to be the full economic costs of the disease. Because of time constraints no primary data collection from malaria patients has been done in order to verify the results. No attempt has been made to quantify the social costs of malaria in terms of inconvenience, pain and the reduction in quality of life of malaria patients and their families. These costs should therefore be viewed cautiously, as conservative estimates of the partial economic cost of malaria in South Africa.

The World Health Organisation has estimated that malaria causes over a million deaths a year mainly in African children and is responsible for between 300 and 500 million cases of acute illness globally, including Asia and the Americas. Accurate data on the actual number of cases and deaths specifically resulting from malaria are however not available.

Between countries, there are differences in the methods of defining malaria cases and therefore it is difficult to interpret the number of cases from other African countries with those from South Africa.

In most Southern African countries, malaria cases are only confirmed with blood smear tests once patients are admitted to hospital. The total number of cases reported includes all cases that are classified as malaria based on the symptoms of the patient. Because of this, the number of cases could be exaggerated because of the fact that other diseases with malaria-like symptoms could be classified as malaria. By the same token, the number of cases in South Africa could be underestimated, as only cases that are confirmed by quick F tests or blood smear tests are included.

Table 18 gives the number of estimated malaria cases for certain Southern African countries for 1998, based on data held by malaria control personnel in those countries. This data must be viewed with caution for the reasons given above and should only be seen as estimates. No data is available from Botswana and no clinical reports of malaria cases are available for Mozambique.

Certain other African countries, such as Zambia, do not have malaria control programmes as in South Africa. A strategy of increasing the resistance to malaria in endemic areas is rather pursued and a programme that eradicates the malaria vector could disrupt this process. Because of this, no malaria control programme costs are included. Costs of treatment are assumed to be similar to South Africa as are the number of days spent incapacitated.

No age breakdown of the above cases is available and it is likely that a large proportion of the cases comprise children under the age of 15. As in South Africa, family members will be required to care for malaria patients, particularly children. Due to financial limitations, the health services in Southern African countries (other than South Africa) are likely to be highly dependent on family members to care for malaria patients that are admitted to hospital. Because of this, for every malaria case it is assumed that one adult days work is lost. Not all malaria cases in Southern Africa will be treated with Fancidar and Chloroquine, while others will receive no medical attention at all. Due to a lack of accurate data, the cost of treating patients will be restricted to the cost of a treatment of Chloroquine (R 0.98/treatment). No cost data on hospital costs are available, therefore these costs are omitted.

On this basis, the total economic cost of malaria in other Southern African countries is estimated to be approximately R 5 900 million, or US$ 967 million. These figures should be viewed with caution because of inaccuracies in the reported number of cases and because of the assumptions wages and medical costs. While the figures presented here could exaggerate the real economic cost of malaria in Southern Africa, they are within reasonably close limits to the estimate of US$ 791 million estimated by Shepard et al (reported in Chima et al, 1999) for the whole of Africa in 1987.

The economic cost of malaria to Southern Africa is extremely high and while there are likely to be inconsistencies and inaccuracies in the way in which costs have been calculated, the costs are high and could be as much as 4 % of the region's combined GDP. Given that most of the Southern African countries featured are heavily reliant on agriculture and other relatively labour intensive economic activities, the impact of malaria on the economy is likely to be very severe.

As mentioned above, DDT is widely recognised as being the most effective insecticide in malaria vector control. To date no studies have been performed in South Africa that analyse the relationship between the incidence of malaria and the use of DDT. Anecdotal evidence however from a number of specialist researchers, health workers and malaria control personnel confirm that DDT has been the single most important and effective factor in controlling malaria in the past.

While DDT may be a highly effective weapon against malaria in Africa, South America and Asia, evidence does exist showing certain negative biophysical impacts and certain negative implications for human health. These potential impacts are discussed in turn.

A number of recent studies have been performed in South Africa, mainly in the Kwazulu-Natal region which have attempted to assess the impact of DDT on plant and animal life. The area in which the studies were performed is very rich in biodiversity and has unique topographic, geologic and climatic features. It is also an area that has extremely high incidences of malaria and that has been the focus of DDT vector control for approximately 50 years.

In a study (Bouwmann et al. 1990) on the health implications on fish in the Pongola Flood plain in northern Kwazulu-Natal, the levels of p,p'-DDT and its metabolites, p,p'DDE and p,p'DDD were tested in three species piscivorous fish, the tigerfish (Hydrocynus vittatus), the blue kurper (Oreochromis mossamibicus) and the butter catfish (Eutropius depressirostris). The tigerfish is the major piscivorous fish in the system, while the other two species are more omnivorous, eating plant matter, diatoms and algae, insects, young fish and shrimp. Importantly all three species are utilised by the local populations and in many cases represent the major form of protein.

At the time, DDT was applied in house spraying between January and March every year as part of the malaria control programme. DDT was used as an agricultural pesticide in the area, however this use was ceased when the pesticide was banned as an agricultural pesticide in 1974. Tests were performed on the fish species before and after the use of DDT in the area.

The results of this study show that the levels of DDT contamination in the major piscivorous fish are approximately three times higher than the level of contamination in other fish species. This would seem to support the theory of bioaccumulation, in other words that DDT accumulates in higher concentrations in higher order species. Caution however must be exercised with this result as the low number of tigerfish tested prevents meaningful statistical analysis. It is important to note that the levels of DDT found in the study on tigerfish and the other fish species do not pose any threat to human health.

The highest concentrations of DDT and its metabolites DDE and DDD were found in pan closest to the malaria control camp, where DDT was stored and mixed. It is likely that DDT containers were washed out in this pan, leading to higher than normal levels. Simple changes to the way the camp is managed would however prevent future contamination.

As mentioned above, tigerfish are used by local populations and are also preyed upon by the African fish eagle and possibly the Nile crocodile. The implications of the higher levels of DDT in higher order species can only be inferred. No studies have been performed in South Africa that has looked at the effect of species population as a result of DDT use. Some studies in Zimbabwe have shown that levels of DDT in crocodile eggs are at levels that would point to bioaccumulation at levels higher than the tigerfish.

Many of the studies into the effects of DDT in South Africa have been piecemeal and so the potential impacts on higher order species can only be inferred from other studies, in South Africa and abroad. Levels of DDT have been found an egg of the African fish eagle from Kariba Island in Zimbabwe (Tannock et al, 1983 reported in Bouwman et al, 1990) which affect the reproductive ability of the raptor (this conclusion is however based on the study of only one egg). The African fish eagle is however known to be a strong reproducer and in actuality no direct impact on its population has been found. (pers. comm. Dr. Henk. Bouwman, Head, Unit for Pesticide Impact, ARC ).

Unlike the United States and Europe, the highest levels of DDT have not been found in predatory birds, rather in insectivorous birds. The reason for this is most probably because many insectivorous birds feed and nest near human habitation, where there are higher insect populations. With household DDT spraying, the levels of DDT are therefore likely to accumulate in insectivorous birds via insects.

A study done in Kwazulu-Natal has shown that for infants, the mean intake of DDT was between 20 and 75 times higher than the allowable daily intake for adults. (Bouwman et al.1992). The impacts of this have not been adequately researched, however the dosages may result in detrimental effects, such as hypo-reflexia.

Many studies have been performed examining the possible carcinogenic impact of DDT on humans, however there is no evidence that elevated levels of DDT in body fat either caused cancer, or were caused by cancer. A study by Tomatis (reported in Smit et al. 1992) on the carcinogenic risk of chemicals to humans listed 17 chemicals as having carcinogenicity, however not one of these was a pesticide.

Currently in South Africa, DDT is used only in vector control only in the Northern Province and there only existing stocks are being run down with no plans to replace them. DDT has been withdrawn from the vector control programme for a number of reasons.

Firstly, environmental pressure, both nationally and internationally has forced the Department of Health to reassess the use of DDT. Environmental pressure against DDT began in earnest in the 1960s in the United States and led to the banning of DDT in agricultural use in 1974. Although many of the arguments put forward by environmentalist groups were not based on fact, the ban was upheld. (Kemm K., 1999) The US has continued to put pressure on other countries to ban the substance by threatening not to import agricultural produce and related goods if DDT was not banned.

In South Africa, it has been reported that a major consideration for ceasing to use DDT in malaria vector control is so as not to deter foreign tourists. (pers. comm. Jotham Mthembu, Kwazulu-Natal Dept. of Health) As has been explained above, most of the malarial areas in South Africa fall within the major tourist destinations where there are game and nature reserves. The knowledge that DDT is used in this environment could potentially turn tourists away who had preconceived ideas of a pristine natural environment. (pers. comm. Jotham Mthembu, Kwazulu-Natal Dept. of Health) This is despite the fact that malaria itself poses a serious danger to tourists who have no immunity to the disease and who are required to take prophylactic drugs which frequently have unpleasant side effects.

Lastly, DDT stains walls white and although this makes quality control of spraying extremely easy, some householders find the staining unacceptable and tend to re-plaster after the malaria control personnel have left. The re-plastering covers over the DDT residue and therefore leaves it ineffective.

After taking the above factors into consideration, the South African Department of Health has sought alternatives to DDT, which, as explained below, may have some advantages, however their unqualified superiority over DDT is questionable.

DDT is not the only pesticide that can be used in vector control, indeed deltamethryn, a synthetic pyrethroid, is currently being used in vector control in South Africa. Like DDT, deltamethryn is highly toxic to insects and has a low toxicity to humans, however it is biodegradable and should not bioaccumulate as does DDT. Deltamethryn does not leave any stains on walls and therefore should be more acceptable to householders who found the DDT staining unacceptable.

Deltamethryn does not appear to irritate bed bugs and therefore increase their activity and it can also be used on modern painted walls, were DDT cannot. There are however a number of drawbacks to the use of deltamethryn.

While a number of international studies have been performed to assess the potential biophysical and human health impacts of synthetic pyrethroids, no studies have been performed in South Africa. Because of the different climatic conditions in South Africa, neither the rate of breakdown, nor the impact on the environment of the insecticides is known. Evidence has shown that synthetic pyrethroids have an effect on the neuro-transmitters of animals and there is potential for synergism between DDT and pyrethroids.(pers. comm. Dr. Henk Bouwman, Head, Unit for Pesticide Impact, ARC). Synergism occurs when two agents react and produce an effect that is greater than the additive effect of the two agents. For example, if the effect of agent A is 1 and the effect of agent B is 1, the additive effect is 2. The synergistic effect on the other hand would, for example, be 3. Synergism has been found between DDT and synthetic pyrethroids, however the clinical significance of this synergism has not been studied. (pers. comm. Dr. Henk Bouwman Head, Unit for Pesticide Impact, ARC).

Synthetic pyrethroids are currently used in agriculture, particularly on cotton and in small scale farming. It is possible that Anopheles mosquitoes will develop resistance to the insecticide. If this occurs, there could be a return to the use of DDT in vector control, however there is a danger that resistance to synthetic pyrethroids could instigate cross-resistance to DDT, depending on the genes that are affected.

The two main focuses of this strategy are in disease management, which entails detecting, diagnosing and treating malaria cases and disease prevention, which includes vector control, parasite control and the protection of individuals. The vector control programme concentrates on identifying high risk areas and spraying structures with residual insecticides. Parasite control involves identifying and treating people that are infected with the parasite in order to disrupt the parasite's lifecycle and reduce the rate of transmission. Protecting individuals by preventing malaria bites is recommended and various trials testing the feasibility of insecticide impregnated bed nets are underway in South Africa. Chemoprophylaxis is an option available for the protection of individuals, however due to their high cost and the fact that they are not 100% effective, they should only be used after considering the risk benefit ratio.

Table 20 below gives the quantities of insecticide used for indoor spraying for the three provinces during the 1997/98 season. The table also shows the expenditure on each insecticide, based on the published prices at the time of spraying. It is interesting to note that the only province to still use DDT, the Northern Province, managed to spray 3.6 times the number of dwellings as Kwazulu-Natal and almost 7 times the number of dwellings as Mpumalanga. Not only did it spray more dwellings, but it managed to do so at a lower cost per household. These costs do not take into account the fact that synthetic pyrethroids could require more quality control than DDT and thereby increasing the cost of application still further.

During this season, the number of malaria cases in the Northern Province was well below that of either of the other provinces and was in fact consistently lower than the other provinces for the two preceding seasons.

It is impossible to say how important DDT has been in ensuring that the Northern Province maintains the lowest levels of malaria as numerous factors contribute to malaria incidence. The fact however that over 900 000 structures were sprayed (not only with DDT) would tend to suggest that it does play an important role.

Insecticide spraying only occurs in those malarial countries where malaria is unstable and highly seasonal, such as South Africa, Namibia, Swaziland and Zimbabwe. The use of insecticide spraying does not feature prominently in the RBM vector control policy, despite the success of the insecticide use in the past.

It is vital that the development of affordable and effective chemoprophylaxes and vaccines in the long term is a vital part of the anti malaria programme, caution should be exercised in promoting anti-malarial measure that are not appropriate to developing countries. R & D of new insecticides that specifically target mosquitoes and that are not adapted from agricultural insecticides could also be an important part of the anti-malaria programme.

The United Nations Environment Programme Governing Council at its 19th session in February 1997 concluded that action was needed to develop legally binding international agreements to reduce the risks to human health and the environment resulting from the release of DDT and 11 other persistent organic pollutants (POPs). The impact of the effective ban could have far reaching implications for many developing countries.

While there are undoubtedly sound reasons for the banning of a number of the POPs, the valuable role that DDT plays in saving lives and reducing economic costs in many developing countries should be taken into account. While it is not possible to put an accurate figure on the potential economic cost to developing countries of a banning of DDT, it will undoubtedly have very significant negative economic impacts.

South Africa is moving away from the use of DDT in its vector control programmes for a number of reasons of which local and international environmental pressures are only one. The ban however will limit the number of 'weapons' in South Africa's anti-malaria arsenal if the use of synthetic pyrethroids do not have the desired effects. What is of even more importance is the fact that DDT is currently used by a number of Southern African (Namibia, Botswana and Swaziland) countries against malaria and is saving lives and economic costs.

The banning of DDT is perhaps part of a wider debate in which the pressure put on many developing countries in the South to conform to the environmental and health standards of developed countries in the North. Frequently institutions and individuals that do not encounter the life threatening diseases and health problems faced by many millions in the developing world, bring about these economically costly pressures. Not only do many developing countries have to contend with serious environmental and health problems, but they are striving to create jobs and improve the standards of living for their citizens. Legally binding international agreements will frequently hamper their ability to do this and ensure that they will never attain the standards of living of developed countries that benefited from substances such as DDT in the past.

It has been reported that the use of DDT in Mexico could be responsible for DDT contamination in areas of the Arctic Circle. (pers. comm Dr. Henk Bouwman Head, Unit for Pesticide Impact, ARC) Where there is clear evidence of this and it can be demonstrated that actual harm is being done, the intervention of international bodies such as the UNEP could be justified. The possibility that DDT use in vector control in Southern Africa affecting those outside the region is remote. In the case of Southern Africa, the decision of whether or not to use DDT are best based on local conditions and considerations and not on imposed and inappropriate environmental and health standards of the developed world.

Should alternatives to DDT, such as a malaria vaccine, become available to developing countries at affordable costs, DDT will no longer be necessary. A long-standing problem though is that the development of anti-malaria drugs, insecticides and vaccines is not as commercially profitable as research and development into the prevention of other diseases. Malaria control programmes are normally required to use insecticides that have been developed for the agricultural sector and not to fight malaria.

No research has been done which determines the relationship between the number of malaria cases and the use of DDT in malaria vector control and therefore it is difficult to determine accurately the economic cost of a ban of DDT. However, based on the efficiency of the insecticide in malaria control in the past, the removal of DDT from vector control programmes is however likely to impose costs on Southern African countries. If DDT is used and can reduce the number of malaria cases in Southern Africa by only 10%, it could result in a saving of around US$ 96 million. The success of DDT in the past could mean that a ban of the insecticide could result in costs of as much as US$ 480 million.

This study has shown that malaria imposes very significant economic costs on South Africa and most other Southern African countries, both directly through health costs and indirectly through losses in productivity.

The use of DDT in South Africa pushed the area affected by malaria back to one fifth of its original size. This allowed for the development of land and the economic advancement of many people. At the same time, DDT was being used internationally (particularly in many developed countries) for a number of uses, to great effect and economic gain. DDT became the focus of a concerted attack from many environmentalist groups, however many of the claims made by these groups are unfounded.

While most developed countries no longer need to use DDT and can afford the numerous alternative insecticides, some developing countries rely on DDT to fight malaria and to save lives. DDT is not a panacea and there are environmental and health considerations that should be taken into account. However, banning DDT will not only impose significant economic costs on developing countries, but many of the environmental and health considerations on which the ban is based are not appropriate to developing countries.

DDT still has an important role to play in saving lives and reducing the burden of malaria in some of the world's poorest countries, states the World Health Organisation (WHO) as the international community considers phasing it out.

WHO has been working in collaboration with the United Nations Environment Programme (UNEP) to provide treaty negotiators with information on the health and environmental issues associated with DDT as well as the current use of DDT in malaria control.

Although DDT has been banned from agricultural use in most countries since the 1970s due to its damaging effects on the environment, it continues to be used in limited quantities for public health purposes. For many malaria-affected countries, responsible DDT use is a vital strategy for preventing malaria transmission and controlling epidemics. Countries continue to use DDT primarily because they cannot afford reliable alternatives or do not have the capacity to develop them.

In order to ensure that treaty restriction on DDT will not result in an increase in malaria deaths, WHO and the Roll Back Malaria partnership (RBM) are encouraging the negotiators to support time-limited exemptions for the public health use of DDT. In addition WHO is calling for new financial resources to aid in the development of and orderly transition to cost-effective alternatives to DDT for malaria vector control.

According to Dr David Heymann, WHO Executive Director for Communicable Diseases: "Time limited exemptions are critically important to the ultimate success of this treaty. Countries that are currently using DDT for malaria vector control need the time and the resources to identify and implement the alternatives that work for them."

"WHO recommends that DDT should be used only for indoor residual spraying and every step must be taken to prevent DDT from being diverted to agricultural uses," says Dr Heymann. "Projections suggest that the amounts of DDT needed for malaria control are a very small fraction of what has been used in the past for agricultural purposes."

WHO is working with malaria-affected countries and other Roll Back Malaria partners to develop a systematic approach to reducing reliance on DDT while assuring that people continue to be protected from malaria.

WHO states that reducing reliance on DDT needs to be part of an overall strategy of strengthening malaria control. There is a need building robust capacity for malaria control at country level that supports the development and utilization of a range of methods to prevent malaria transmission that are cost-effective, sustainable and rely less on chemicals in general.

In addition to the issue of exemptions, negotiators in Johannesburg will be discussing the financial and technical resources required to implement the treaty. According to Dr Heymann, "The countries that rely on DDT are some of the poorest in the world. Without additional resources they will be unable to make much progress in reducing reliance on DDT. We hope that the treaty will result in significant new funding in the coming years, in the meantime we must look to all available sources."

For rich people, malaria is not much of a problem. The Anopheles mosquito, which spreads the disease, was eradicated from Europe and North America half a century ago, largely through the use of pesticides such as DDT. Having employed the stuff to such great effect, however, rich countries then banned it because of its environmental consequences (it accumulates in animals that eat insects, slowly poisoning them).

That is fair enough. But with a convert's zeal, many rich countries have tried to impose their decision on the poor world, where about 300m people suffer from malaria every year, and more than a million die. Sick people find it hard to work, so the disease helps to keep poor countries poor. Jeffrey Sachs, a development economist at Harvard University, estimates that sub-Saharan Africa would be almost a third richer today had the disease been eradicated in 1965.

The most cost-effective way of fighting malaria is to spray the insides of houses with DDT. This either kills the mosquitoes, or drives them away. The recommended alternatives, pyrethroids, are four times as expensive as DDT and also less effective.

In the early 1990s, for example, the United States Agency for International Development stopped the governments of Bolivia and Belize from using DDT. In Madagascar, the United Nations Development Programme tried to persuade the government to replace DDT with Propoxur, a less effective pesticide. To its credit, Madagascar refused. In Mozambique, both NORAD, the Norwegian development agency, and SIDA, its Swedish counterpart, said that they could not support the use of DDT, as it was banned in their own countries. That the problems of a desperately poor malarial country in Africa might be somewhat different from those of wealthy, non-malarial Scandinavia seems not to have occurred to them.

Mozambique's DDT-spraying operation, disrupted by civil war in the 1980s, was duly squashed before it could get going again after peace returned in the 1990s. Samuel Mabunda, the head of the country's malaria-control programme, concedes that the evidence now suggests that DDT-spraying would be cheap and effective, but says that the government has no definite plans to start spraying again.

Environmentalists argue that DDT-spraying causes harm to humans, but no replicated, peer-reviewed study has ever demonstrated this. Nor is it likely that the tiny quantities used in house-spraying have any serious effect on the environment. Amir Attaran, another Harvard academic, estimates that the volume of DDT used to protect the entire high-risk population of Guyana for a year is equivalent to what a farmer might spray on to a single field of cotton.

This may not sound onerous, but in places such as Mozambique, where the annual budget for fighting malaria is less than 30 cents a person, any additional bureaucracy could prove to be a big drain on resources. Concern for the environment is generally an admirable thing. Obsession, at the cost of human lives, is of more questionable value.

Malaria kills over one million people, mainly children, in the tropics each year, and DDT remains one of the few affordable, effective tools against the mosquitoes that transmit the disease. Attaran et al. explain that the scientific literature on the need to withdraw DDT is unpersuasive, and the benefits of DDT in saving lives from malaria are well worth the risks.

However, DDT remains one of the few affordable, effective tools against the mosquitoes that transmit malaria, a plague that sickens at least 300 million and kills over one million, mainly children, in economically underdeveloped areas of the tropics each year. Such a toll is scarcely comprehensible. To visualize it, imagine filling seven Boeing 747s with children, and then crashing them, every day.Until now, developed countries have grudgingly tolerated the use of DDT against malaria in poor tropical countries; at least 23 countries do so1. However, this may now be ending. Led by the United Nations Environment Programme, more than 110 countries are negotiating a treaty to "reduce and/or eliminate...the emissions and discharges" of 12 persistent organic pollutants, citing their "unreasonable and otherwise unmanageable risks to human health and the environment."2 If it becomes law, the treaty will likely end DDT manufacture, or at least make the supply scarce and unaffordable to tropical countries.This, in our view and that of nearly 400 colleagues who have signed an open letter to the diplomats negotiating the treaty, is simply dangerous3. The scientific literature is unpersuasive of the need to withdraw DDT; on the contrary, it is clear that doing so risks making malaria control ineffective, unaffordable, or both.Ecological effects DDT became emblematic of the toxics movement because of its effects on the non-human environment. Ecological studies have demonstrated that bioaccumulated DDT could cause thinning of eggshells and reproductive failure in birds of prey. The fault for this lies in the massive agricultural use of DDT. Dusting a single 100-hectare cotton field, for example, can require more than 1,100 kg of DDT over 4 weeks4.In contrast, DDT spraying for malaria control is less intensive, less frequent and far more contained. The current practice is to spray the interior surfaces only of houses at risk, leaving a residue of DDT at a concentration of 2 g/m 2 on the walls, ceiling and eaves, once or twice a year. Half a kilogram can treat a large house and protect all its inhabitants. Doubtless some fraction of this escapes to the outdoors, but even assuming it all did, the environmental effect is just 0.04% of the effect of spraying the cotton field. Guyana's entire high-risk population for malaria can be protected with the DDT that might otherwise be sprayed on 0.4 km2 of cotton in a season5. Compared with its agriculture uses, public health uses of DDT are too trivial to merit banning with any urgency.

Environment aside, health considerations arise, and with them the dilemma that one man's benefit is another man's risk. Environmentalists in rich, developed countries gain nothing from DDT, and thus small risks felt at home loom larger than health benefits for the poor tropics. More than 200 environmental groups, including Greenpeace, Physicians for Social Responsibility and the World Wildlife Fund, actively condemn DDT for being "a current source of significant injury to...humans."6 But five decades of experience with DDT shows that it is highly effective and safe when deployed in house spraying7.Reliance on DDT reached its zenith, and malaria, its nadir, with a campaign to eradicate malaria from large parts of the world in the 1950s and 1960s.

This inverse correlation is readily understandable because it is so biologically plausible. For mosquitoes, DDT is a toxin, irritant and repellant all rolled into one chemical. All three properties decrease the odds of being bitten by mosquitoes, and toxicity particularly reduces the odds that parasite-bearing mosquitoes will survive to infect others. Lowering these odds slows disease propagation by second- or higher-order relationships and therefore is very important13, 14. Indeed, renewing the spraying of houses with DDT, as Ecuador did in the early 1990s, rapidly decreases case rates5.This body of evidence is so indisputable that even environmental groups such as Physicians for Social Responsibility concede that DDT is "highly effective" in malaria control15. Campaigning for a DDT ban given this benefit would seem politically difficult unless one alleged even greater health risks associated with its use, which is precisely what environmentalists do. Recent bulletins from Physicians for Social Responsibility and the World Wildlife Fund cite animal studies indicating involvement of DDT in neurological and immune deficits, and epidemiological studies linking DDT to human cancers and endocrine-disrupting effects, such as reduced lactation15, 16.In this kind of 'balance of risks' paradigm, the evidence must be scrupulously weighed. Although the International Agency for Research on Cancer rates DDT as a possible human carcinogen (along with, notably, several pharmaceutical drugs), not one case-control study of DDT's human carcinogenicity has been affirmatively replicated. Breast cancer furnishes the clearest example: the first study to correlate DDT exposure with statistically elevated risk17 has now failed to be replicated at least 8 times18-25, and of these later studies, some found exposure to significantly reduce risk24, 25. Much the same can be said of studies indicating involvement of DDT in multiple myeloma, hepatic cancer and non-Hodgkin lymphoma26, 27.

With such weak evidence of harm to human health, one must decide whether to set policy as a precaution and ban DDT based on animal studies. Ordinarily, this makes sense (given the alternative of experimenting on humans with toxins), but not for the spraying of houses with DDT. Acting with precaution because there are risks in animals, and thus denying people the known health benefits of malaria control, is very unethical: house spraying exposes millions of people to DDT, any of whose health can be studied, making extrapolations from animal studies unnecessary. Proper case-control studies should be done before policy is cast in treaty law.Indeed, if precaution is relevant, it favors spraying houses with DDT, because it is affordable or effective where other interventions may not be.

House spraying also has the advantage that it protects whole families, which is sometimes overlooked in comparing it with insecticide-treated bed-nets, which protect only one or two people at a time30. Simply put, there are too few economic studies to determine with certainty whether bed-nets are more or less cost-effective than DDT house spraying31. However, the fact that spraying houses with DDT can lower the prevalence of malaria parasitemia in highly endemic African communities to levels below that achieved by bed-nets (less than 5%) indicates that it is careless to treat them interchangeably8.

How then to reconcile DDT's 'Janus-faced' character? Its benefit in alleviating the suffering of malaria, at a reasonable cost, outweighs any reasonable speculation of its health risks. Living with this may not be easy; changing it is harder still.Above all, rich countries must allow, and even facilitate, poor tropical countries to make choices about DDT freely, and with informed consent. African countries in particular lack the resources to dispatch health experts to the treaty negotiations, and although it provides financial assistance, the United Nations Environment Programme has declined to assist with this, or even to provide a translator when French- and English-speaking diplomats meet to discuss DDT. The resulting lack of knowledge suffocates debate. At worst, threats are used, as Belize learned when the US Agency for International Development demanded that it stop using DDT.Such arm-twisting is as lamentable as it is effective. Highly indebted poor countries must of necessity rank poverty reduction over environmental orthodoxy, and stimulating growth and foreign investment will require nearly eliminating malaria from economically productive zones. This is essential for development in sub-Saharan Africa, where malaria subtracts more than one percentage point off the gross domestic product growth rate, for a compounded loss (since 1965) now reaching up to $100 billion a year in foregone income32.Seen in this way, the insistence to do without DDT is 'eco-colonialism' that can impoverish no less than the imperial colonialism of the past did.

Sub-Saharan Africa, which never experienced much spraying of houses with DDT, should consider starting this. South Africa, Swaziland and Madagascar, among others, run successful DDT-spraying programs and prove it can be done1, 33.At present, the United Nations Environment Programme mandate to "reduce and/or eliminate" DDT probably cannot be accomplished safely, without causing extra disease. As 'preachers of precaution', environmental groups and rich country governments should start by committing at least $1 billion annually to roll back malaria in Africa. That is the sum requested by African leaders at their first-ever Malaria Summit earlier this year34. Meeting this request is a small price to pay for respecting the lives of the poor, and will bring us much closer to no longer needing DDT.

Grieco, J.P. et al.  A comparison of house entering and exiting behavior of Anopheles vestitipennis using experimental huts sprayed with DDT or deltamethrin in the southern district of Toledo, Belize. J. Vector Ecol.

The views expressed are those of the authors and do not reflect the official policy or position of the Uniformed Services University of the Health Sciences, the Department of Defense or the United States Government.

The pesticide DDT has a long and checkered history. Today, it evokes particularly contentious argument. Though environmentalists have come to demand this poison's elimination from the face of the Earth, some tropical-disease specialists laud DDT as an irreplaceable weapon in their fight against malaria. Which view prevails may be a life-and-death matter for nearly a half-billion people.

Its unqualified success came at a price, however, as Rachel Carson chillingly documented in Silent Spring, her 1962 landmark book. Biologists linked DDT's increasingly indiscriminate use to the disappearance of songbirds and raptors. By then, the chemical had permeated the bodies of fish, livestock, and house pets. Health officials indicted the pesticide for causing cancers in people who had applied it recklessly.

Few nations argue against elimination of the other persistent organic pollutants (POPs) on this list, such as chlordane, dieldrin, and polychlorinated biphenyls. Debate over DDT, however, has complicated the drafting of the so-called POPs treaty. In many parts of the world, this long-lived toxicant remains the best hope for reining in malaria.

Deaths occur most often among malnourished people in countries that can't afford adequate treatment. WHO has joined several other UN agencies and health organizations in advocating the retention of DDT for malaria control.

Whether malaria is fatal depends on both the initial health of a person and the Plasmodium parasite. "Plasmodium falciparum causes the most deadly form of malaria," observes John Paul Clark with WHO's Roll Back Malaria program in Geneva.

P. falciparum's predominance in sub-Saharan Africa, he says, "is one reason that 90 percent of malaria deaths occur there." Another is that this region is home to some of the better carriers of the parasite.

Consider South Africa. About 5 years ago, its malaria-control program abandoned DDT for less toxic pyrethroids, notes Rajendra Maharaj of the Department of Health in Pretoria. In recent months, however, evidence has emerged that some malarial mosquitoes in the country have become resistant to these insecticides.

WWF intended the deadline "to serve as a motivator" to prod the scientific community into developing less toxic alternatives, according to Richard Liroff, director of the group's Alternatives to DDT Project in Washington, D.C.

In support of the campaign, WWF offered case studies of new malaria-control strategies. Noting that several malaria hotspots had weaned themselves from DDT, WWF contended that other areas should be able to do the same.

United Nations officials expect the POPs treaty to be finalized by the end of this year and in force by 2004. Even if it permits DDT use for disease control, many areas with serious malaria problems may lose access to the compound, Clark says.

Unable to find a backup source, Belize has turned to deltamethrin, a pyrethroid that costs three to four times as much as DDT, Polanco reports. Purchases of the alternative insecticide now eat up 89 percent of the country's budget for malaria control, he says, leaving little for surveillance, eradication of mosquito breeding grounds, or malaria treatment.

Although foreign investors have lined up $800 million to double the plant's capacity, Tren says, backers are reluctant to release the money until the region's endemic malaria is controlled. Many of the foreign staff recruited to engineer the plant's construction have contracted malaria, and several have died. Local antimalaria programs, however, have been barred from using DDT by European aid donors and, in turn, the Mozambique government. Instead, the programs use pyrethroids. However, some local A. funestus mosquitoes are exhibiting resistance to them.

In hopes of resolving the stalemate, Tren says, Mozambique officials indicated in May that they were considering carbamate pesticides, a second major family of DDT alternatives. These are vastly more expensive than DDT and pyrethroids, Tren says. Even more troubling, he adds, preliminary studies indicate that the malaria-carrying mosquitoes in neighboring South Africa are developing resistance to carbamates.

Malaria control is complicated by an area's terrain and ecology; the mosquito species present; the housing, habits, and beliefs of local people; and the area's economy. In some parts of the world, DDT has not proved necessary or even useful in fighting malaria.

In many other regions, however, the insecticide has performed dependably, with no sign of mosquitoes developing resistance, observes Donald R. Roberts of the Uniformed Services University of the Health Sciences in Bethesda, Md. Moreover, antimalaria programs contribute relatively little to environmental problems, he asserts.

Still, WHO and other international organizations have been arguing that malaria-control programs should integrate a host of mosquito-control strategies. These include fostering natural predators (including fish and bats), eliminating mosquito breeding areas, and finding bacteria and other pathogens that attack parasite-carrying mosquitoes.   Yet to date, Roberts notes, no country has ever implemented an integrated mosquito-management program, much less tested how well it works. Perhaps more disappointing, notes this tropical-diseases specialist, there have been almost no studies to examine whether any alternative works as well as DDT in the places where DDT has proved useful.

In and around a trio of dirt-floor, thatched huts in southern Belize, Grieco monitored the behavior of the malaria-carrying mosquito Anopheles vestitipennis. Mosquitoes entered an untreated hut at dusk and left at sunrise. After the interior walls of a second hut were sprayed with deltamethrin, the mosquitoes entered at dusk but left by midnight. As expected, Roberts notes, "the whole time they were inside, the mosquitoes were biting [us]."

However, DDT sprayed inside the third hut repelled the flying bloodhounds. Only 3 percent as many mosquitoes entered the DDT-sprayed hut as the other two. Of those few mosquitoes that did venture in, most exited without biting.

Throughout the tropical Americas, malaria is undergoing a massive resurgence. Roberts argues that the reason is largely that control programs have been abandoning DDT. He'd like to see more use of the chemical, not less. If the plant in Mexico chooses not to reopen, he says, countries should consider setting up their own facilities to make DDT.

Indeed, "it would be really stupid of us to rely on a single tool" to fight malaria, Clark says. "You need a host of alternatives, because what works in one country won't necessarily translate to the next."

The "precautionary principle" has become an established argument in debates on the environment and health. There are various definitions, one of the most frequently used being: "When an activity raises threats of harm to the environment or human health, precautionary measures should be taken even if some cause and effect relationships are not established scientifically". Environmentalists liken the principle to medicine's caveat primum non nocere, and the principle has become an increasingly powerful tool for the environmental lobby to garner political and public support. The principle is now inscribed in various international treaties and agreements, notably the 1992 Rio Declaration on Environment and Development, which states that: "Where there are threats of serious or irreversible damage, lack of full scientific certainty shall not be used as a reason for postponing cost-effective measures to prevent environmental degradation".

The precautionary principle has been invoked several times in the name of protecting the public's health, notably in the various moratoria that were set up to prevent the development and use of genetically modified (GM) organisms. Yet only last week came reports that there are now moves to end the de facto moratorium  imposed by the European Commission on GM foods, arguably because of fears that Europe could lose financially and scientifically to the USA if development of GM products continues to be hindered. This change of stance has led to criticisms that the Commission is sacrificing protection of public health to the marketplace (see p 320).

By contrast, in this week's issue, Donald R Roberts and colleagues  give an example of how the precautionary principle is being employed, they argue, to the detriment of health. A global and legally binding convention for the elimination of persistent organic pollutants, including the pesticide DDT, is being negotiated under the auspices of the United Nations Environment Programme, as a result of the 1992 Rio Declaration. Roberts and colleagues argue that global elimination of DDT would be a disaster for developing countries already struggling with the burden of re-emerging malaria. They state that such countries need to retain the right to use small amounts of DDT for indoor spraying.

They are not alone in their fears. Earlier this year, almost 400 scientists signed an open letter advocating the continued use of DDT for house spraying. More pertinently, concern was expressed at a February meeting of African countries that are being asked to reduce their reliance on DDT for malaria control. While supporting the elimination of agricultural use of DDT, delegates stressed that indoor residual spraying of DDT continues to play an important part in malaria control in their countries. The delegates also pointed out the responsibility of the global community to provide the financial assistance necessary if their countries are forced to switch to more expensive insecticides. And WHO, delegates said, "should advocate and highlight, at any relevant and appropriate forum, the deep concerns of the participating member states on the possible economic and health implications of any restriction made on DDT use for malaria control". Indeed, the 20th WHO Expert Committee on Malaria report this year reaffirmed the role of DDT house spraying in vector control.

Despite these objections, at the fourth round of negotiations on a global treaty on persistent organic pollutants  in March the consensus was to continue to favour elimination of production and use of DDT, but to employ a public-health exemption while countries adopt strategies to reduce reliance on DDT for vector control. Proponents of the ban, mainly environmental protection agencies, have invoked the precautionary principle to push for this global ban on health grounds, despite the fact that, as A G Smith points out  on p 267, at likely exposure levels the effects on human beings seem to be very slight.

Whose health is being protected by this invocation of the precautionary principle? And who will benefit if and when malaria-endemic countries are forced to switch to newer, more expensive insecticides? The answer seems to be that the health of people in poorer countries is being put at a very real risk to protect the citizens of wealthier nations from a theoretical risk. The only player guaranteed to benefit if DDT is banned outright seems to be the chemical-manufacturing industry.

DDT is prohibited in many industrialised countries, and the United Nations Environmental Programme is starting negotiations for a global ban. In today's Lancet D R Roberts and colleagues  argue for the continued use of DDT, on grounds of its value for malaria control and its safety.

The early toxicological information on DDT was very reassuring; it seemed that acute risks to health were small. If the huge amounts of DDT used are taken into account, the safety record for human beings is extremely good. In the 1940s many people were deliberately exposed to high concentrations of DDT through dusting programmes or impregnation of clothes, without any apparent ill effect.3 There are probably few other chemicals that have been studied in as much depth as has DDT, experimentally or in human beings.3 It quickly became clear that the dermal toxicity of dry DDT was very low, but even the oral toxicity depended on the composition of the diet. By contrast dieldrin caused poisoning of sprayers in many malaria-control programmes2 and is equally toxic by oral and dermal routes, the acute toxicity to rats being more than three times that of DDT.3 Ingestion of DDT, even when repeated, by volunteers or people attempting suicide has indicated low lethality, and large acute exposures can lead to vomiting, with ejection of the chemical. The earliest symptoms are hyperaesthesia of the mouth, followed by paraesthesia of the tongue, dizziness, tremors, and vomiting. Few toxicological effects due to inhalation of DDT have been reported. Some deaths attributed to DDT have been due to mixtures with other chemicals or solvents.3 Dermatitis in workers exposed to DDT was also probably due to solvents. Thus with acute or high-level exposure, DDT is probably safer than many other chemicals.

What concerns most people is chronic exposure to DDT. Evidence for any paraesthesia, headaches or dizziness, or changes in liver-function tests in workers who worked with or used DDT are very rare despite the presence of significantly raised serum concentrations of DDT or DDE.3 Many of those workers investigated have been sprayers in antimalarial programmes. As exemplified by malaria control in Natal,4-6 serum DDT has been significantly higher in  sprayers and members of sprayed households than in control populations, and the chemical may be passed in the milk to infants, but associated toxicity has not been proven.

Although there is little evidence that chronic low-level exposure to DDT produces serious deleterious effects, the current debate on potential "endocrine disruptors" has brought up the possibility of other potential toxicological effects. DDE has been found to be an antiandrogen11 and,  in addition to its proposed link to breast cancer, DDT is commonly cited as having oestrogenic effects. In one study of the most heavily exposed workers in a DDT factory, there seemed to be no effect on their ability to father children.3 In interpreting possible toxic hormonal effects of DDT, it should be noted that in-vitro studies often employ the o,p-isomer of DDT, which does have weak oestrogenicity in vivo but has constituted only a tiny percentage of the total DDT used. Nevertheless there has been a proposal that exposure of mice to very low concentrations of DDT in utero or at certain perinatal stages could have subtle developmental influences.12 This idea or its applicability to human beings would be very difficult to disprove completely.

In summary, DDT can cause many toxicological effects but the effects on human beings at likely exposure levels seem to be very slight. However, the perceived rather than the calculated risks from DDT use are an important consideration in maintaining public confidence. Thus it would seem prudent that if its use was continued for antimalarial campaigns and the benefits of use outweigh the risks, tight control should continue and the effects of spraying DDT should be closely monitored. What has not been discussed here, though, is the environmental issue of any detrimental effect on wildlife.

The editorial below from The Lancet makes the much needed point that failure of Roll Back Malaria caused by withdrawal of donor support and focus on "political correctness" must be avoided. Donor support must be forthcoming not only monetarily but also in terms of support for operations with methods that actually work to reduce incidence of malaria and for support for research on parasites, vectors and malaria epidemiological situations, which are quite diverse and often necessitate strategies individually tailored to the local situation.

A valid point to make about the first sentence in this article is that the definition of the term "failure" as it applies to malaria control has changed greatly during the 35 years from 1965-2000. In the 1960's, a "failure" was any sort of sustained transmission of malaria, even at a low level. Eradication efforts were deemed to be "failures" even when they had reduced cases to a small number of P. vivax cases and had eliminated P. falciparum. During the 1980's and 1990's, the term, "failure," came to be used much less, even when describing situations in which malaria case numbers have increased exponentially to hundreds of thousands of cases in regions that had merely a few thousand cases during active control efforts. Few have described the widespread cessation of active case detection (replaced by passive case detection that is capable of detecting many fewer cases) during the late 1980's and the 1990's as a "failure." Why? It seems odd that the term "failure" is rarely used to describe resurgence of malaria involving many thousands of cases, and sometimes renewed P. falciparum transmission, under decentralization and emphasis on case treatment, whereas some writers, often the proponents of decentralization and reduced emphasis on vector control, were only all too happy to describe low levels of malaria cases under active control efforts as "failure." Charts and information about cessation of vector control and the results thereof are available for Peru, Sri Lanka, and Colombia.

Can the new campaign succeed? It has, at least, gained much support. A key feature of RBM is that it is a partnership--of four core partners (WHO, UNICEF, the World Bank, and UNDP) and national governments, other UN bodies, non-governmental organisations, and the private sector. By the third global RBM meeting in March this year, there were 93 partners. The overall aim is to halve the burden of malaria by the year 2010 through four critical actions: enabling everyone at risk to sleep in a mosquito-free environment, mainly through use of insecticide-treated bednets; prompt diagnosis and treatment (within or near the home, as reported in today's Lancet on p 550, for example); antimalarial therapy for all pregnant women at risk of malaria; and early identification and effective response to epidemics. Programmes are to be country specific and implemented through existing systems.

The G8 countries have also pledged support for malaria control. With such encouraging starts, why should there be concern now about the likelihood of failure? Epidemiology, entomology, genetics, health-care delivery, and a range of other operational issues all contribute to the technical complexity of malaria control, which partners seem not to appreciate.  Why, for example, has UNICEF proposed support for chloroquine for Burmese towns along the Thai border?

It is time for RBM to switch focus from the campaigning to implementation of malaria-control activities. Things must be done right this time, which means first knowing what is right and operationally feasible. A recommendation was made at a meeting of malaria scientists in June at the Center for International Development at Harvard University for all projects to first pass scientific and operational scrutiny by an external multidisciplinary expert review panel, who would assess projects according to scientific norms. Proposals for projects would still come from the field, so there is no danger of detracting from local ownership or partnerships, a concern that led to vehement dissent by UNICEF about having a review panel. That organisation has yet to approve the consensus document for guiding RBM drawn up at Harvard.

The RBM partnership is in principle well founded, but partners must realise that for the programme to succeed money cannot be squandered on flawed projects. Scientific rigour of projects should not take second place to their political correctness.

"However, the great unexpected additional bounty of the antimalaria spray program was its effect on kala azar.  Considering the natural history of _Phlebotomus argentipes_ it is only natural that DDT would be as effective, or more so, against the sandfly as against the mosquito.  _Phlebotomus argentipes_ is a domestic creature...The sandfly is not a strong flyer...And they rested on the walls inside the house, usually not above six feet from the floor." - pg. 64.

"When the spraymen came to kill the malaria-transmitting anopheline mosquitoes, the kala azar-transmitting phlebotomine sandflies got a dose of DDT, too.  The DDT was especially effective against them because they tended to rest on the wall mroe often for longer perooids and at more accessible heights than the anophelines.  They were also (and still are) exquisitely sensitive to DDT, being killed by concentrations that would be too low to affect the mosquito." - pg. 65.

The Treaty aims to see a significant reduction in the use of DDT, if not its virtual elimination. The current draft of the Treaty includes exemptions which would allow countries to continue using the pesticide for public health purposes, as well as provisions for technical and financial support to DDT dependent countries to help them reduce their reliance on this persistent organic pollutant.

WHO believes that these exemptions and provisions are essential to reaching the ultimate goal. Nabarro adds: "A premature shift to less effective or more costly alternatives to DDT is likely to be unsustainable. Countries need time and resources to evaluate and select alternatives that are locally appropriate and sustainable. In the meantime, they require the reassurance that DDT can be used, if needed, to protect human lives. This is simply good planning, and good planning needs time and cash."

Extensive use of DDT for agricultural purposes has resulted in serious damage to the global environment. Although the pesticide is now banned from agricultural use, it continues to be used in limited quantities for public health purposes. WHO projections suggest that the amounts of DDT needed for malaria control are a small fraction of what has been used for agricultural purposes.

Further reductions are possible. Environmentally safer alternatives to DDT do exist and more are under development. At present these alternatives are either significantly more expensive, or are useful only in more limited circumstances than DDT.

For many malaria-affected countries, responsible DDT use is a vital strategy in situations where alternatives are not available and where the potential loss of human life associated with unstable malaria transmission and epidemics is greatest.

"At present, issues around the continued use of DDT are emotive and complex," states Nabarro. "Countries affected by malaria are asking for help in making informed decisions towards reducing their use of DDT. They will try to eliminate its use, but to do this they want help to ensure that there are minimal adverse health consequences as a result the of their decisions."

"From our consultations with WHO member states and regional experts, it is clear that one of the highest priorities is the need for solid scientific and programme based information on the costs, effectiveness and safety of potential alternatives to DDT. This will require significant new investment by the global community in research and capacity building. This is one of the key reasons for supporting a time limited exemption on DDT use. To obtain this critical information will take several years," Nabarro says.

In our countries malaria is a significant cause of morbidity and mortality and an impediment to economic development. Indoor residual spraying of DDT continues to be an important tool in efforts to control malaria in areas of unstable transmission and to prevent or respond to epidemics.

We note the presence of a general exemption on DDT production and use limited to vector control in the present draft convention text included in the report of INC-3 and unanimously support the inclusion of this exemption in the future Treaty.

We further support proposed mechanisms within the Treaty (i.e. Articles J and K) to assure that technical assistance and adequate financial resources are available to countries for action to reduce and/or eliminate reliance on DDT.

Technical assistance and capacity building is needed for strengthening countries' abilities to develop surveillance systems for epidemiological monitoring, epidemic forecasting, and detection of insecticide resistance so as to target and selectively apply insecticides for indoor residual spraying purposes.

Countries recognize that reducing reliance on DDT involves a complex set of activities over a potentially long time frame. Strategies and interventions must be developed and/or adapted to country specific scenarios and will require sustained mobilization of financial and technical resources.

Decisions to replace DDT with potential alternatives should be based on a complete assessment of the costs, effectiveness, feasibility, and environmental and health impacts of DDT and alternatives under local conditions.

Evaluation of alternatives to DDT must include assessment of technical characteristics, acceptability by communities and health workers, potential sustainability in terms of cost, effectiveness and the potential for resistance development (e.g. extent of concomitant use in agriculture), availability, environmental impact and human safety.

These strategies include, but are not limited to, the reduction or elimination of taxes and tariffs on public health commodities, and the transfer of technology to promote development of endemic country and/or regional production of these tools.

All activities to reduce reliance on DDT for malaria vector control (including planning, operational research, implementation, monitoring and evaluation) as well as national efforts to strengthen malaria control and health systems should be an integral component of health systems development.

Assessments" that describe the current epidemiological situation, disease control and health care practices and the national health infrastructure are required for planning and strengthening malaria control activities.

Inter-sectoral and regional collaboration should strengthen surveillance, research and planning activities and linkages should be established between health, environment, agriculture, and other sectors.

The global community, through both existing mechanisms and new mechanisms to be established under a future POPs treaty, should ensure that financial and technical assistance required to reduce reliance on DDT without compromising effective malaria control is available to countries for immediate and longer term action.

Delegates to this consultative meeting should inform the INC negotiators of their respective countries participating in the next INC meetings of the technical, economic, health and environmental issues in the use of DDT and potential alternatives for malaria control in preparation for the forthcoming INC meetings.

WHO should advocate and highlight, at any relevant and appropriate forum, the deep concerns of the participating member states on the possible economic and health implications of any restriction made on DDT use for malaria control.

WHO, in collaboration with partners, should ensure that the necessary technical and financial support is available to member states for implementation of integrated, evidence based and cost effective vector control programs to ensure sustainable reduction of malaria burden.

WHO, with its partners, should support investments in research to develop new affordable, cost-effective and sustainable vector control methods including effective and affordable alternative insecticides.

DDT may therefore be used for vector control, provided that all the following conditions are met: it is used only for indoor spraying; it is effective; the material is manufactured to the specifications issued by WHO (5); the necessary safety precautions are taken in its use and disposal.

KwaZulu-Natal - While DDT has become a profanity amongst environmentalists because of the toxin's tendency to remain in the environment for a considerable timespan, KwaZulu-Natal's health department has taken the unusual step of once again utilising DDT in combating malaria.

The insect was the reason the Letsitle valley had been known as the valley of death. In northern KwaZulu-Natal these mosquitoes spread malaria to an area bisecting Eshowe and possibly even as far south as Durban.

With the advent of malaria eradication programmes utilising DDT had completely [Webmaster's Note:the proper words are _'temporarily eliminated_'] eradicated the species in South Africa. However, in areas such as Mozambique the mosquito survived.

In 1996 however, a policy decision was taken and DDT was taken out of use in eradicating malaria. The programme switched to a group of poisons called pyrethroids, generally accepted as being more environmentally-friendly.

But with the huge upswing in cases of malaria the situation was reviewed.  A provincial health department entomologist, Keith Hargreaves, who himself is now a malaria carrier [Webmaster's Note:P. falciparum infection clears completely after effective medicinal treatment.  P. falciparum, the malaria species found in South Africa, does not relapse.], found An. funestus specimens inside homes sprayed with pyrethroids during a study.

The results were described by McGlew as a "catch-22" situation. On the one hand there was the option to return to the effective poison with the bad name: DDT. On the other hand a human tragedy was in the making with more and more people dying of malaria.

Verdoorn added that DDT's worst attribute is its longevity. If a kilogram of the poison was left somewhere in the environment today, half of it will still be left in 11.5 years from now. After another 11.5 years, a quarter would still be "alive".

The poison is mainly lethal to insects, although birds and animals will die if large quantities are consumed. However, what does happen is that deposits build-up in the food chain, causing the thinning of egg shells in raptors such as vultures and fish eagles at the top end of the food chain. The birds lay healthy eggs, but the shells are so thin that they soon crack - causing a disruption in the birds' reproductive mechanisms.

The sober facts, however, are that DDT is the only poison on the market that will effectively eradicate [Webmaster's Note: proper word is _eliminate_ ] An. funestus - and the present malaria epidemic. Which was why the poison task group agreed to the use of DDT.

There are however, very specific conditions in using DDT. It is only permitted to be sprayed inside homes, under eaves and sheds. Poison task group inspectors are permitted to do unannounced inspections at any time.

Task group member Tim Snow is in the process of training people on the correct ways of spraying, to the extent of preventing the water they use to clean their equipment from flowing back into the ecosystem.

While controlled and limited use of DDT is still an option, Verdoorn has set his hopes on a new product under development by pharmaceutical company Bayer which may successfully eradicate An. funestus and have a much shorter viability in the environment.

Meanwhile he'll continue the battle against DDT. There is a general perception that it was banned worldwide, however it has only been banned in agricultural areas in some countries. The poison task group is campaigning to have it banned in all areas, with the exception of inside homes.

A study conducted by Professor Donald Roberts and colleagues of the University of Health Sciences in Bethesda, Maryland found that the incidence of malaria increased considerably in South American countries where the use of DDT had been banned.

They suggest that DDT was the cheapest way of efficiently [Webmaster's Note: proper word is _controlling_ ] eradicating malaria, adding that it should only be manufactured for use by governments in their malaria eradication programmes.

It has been 27 years since the United States banned the pesticide DDT, and the payoff is undeniable. The peregrine falcon, once pushed to the brink of extinction, came off the endangered species list this month, and the bald eagle may soon follow. Brown pelicans are flourishing in Florida. On the shores of Long Island, the ospreys are back.

Now the United Nations is drafting a treaty that may lead to a worldwide ban on DDT. But the negotiations, set to resume in Geneva next month, are drawing opposition from an unlikely quarter: public health professionals, who say DDT is necessary to stop the spread of malaria, a disease that kills as many as 2.7 million people each year, mostly children in undeveloped countries.

Dr. Wirth is among more than 370 medical researchers in 57 countries who are urging that the treaty allow DDT to be sprayed in small quantities on the interior walls of homes, where it acts as a repellent to the disease-carrying insects. The scientists argue that if the pesticide, which is cheap and effective, must be eliminated, it should be phased out gradually, and only if Western countries conduct research on the more expensive alternatives and help pay for them.

Willis, director of chemicals for the United Nations Environmental Program, which is sponsoring the talks. But the specifics are engendering intense acrimony between the public health experts and environmentalists, and have created some friction in the Federal Government, as it tries to formulate its policy for the negotiations.

"This poses an unusual dilemma," said a State Department official involved in the talks. "Usually the dynamic is protection versus economics. There, it is very easy for one side to paint the other as the black hat. But here there is a peculiar tradeoff between health and the environment."

The DDT dilemma stems from a United Nations plan to eliminate, or greatly reduce, the use of 12 toxic chemicals classified as persistent organic pollutants. The group -- "the dirty dozen" to environmentalists -- consists of eight pesticides, including DDT, as well as chemical byproducts and industrial chemicals. All accumulate in the food chain and can travel thousands of miles through air, water and bird migration, causing lasting contamination.

The treaty negotiations on the group of pollutants began in 1998 and are scheduled to conclude by the end of next year. The Geneva meeting, which runs from Sept. 6 to 11, is the third of five scheduled sessions, but the first to examine each chemical in detail. Mr. Willis of the United Nations predicted "a rather thorough discussion of the DDT issue."

Physicians for Social Responsibility, a doctors' group concerned with environmental health. They argue that even small amounts of DDT sprayed inside homes are harmful to the environment and cite studies suggesting that the pesticide turns up in the breast milk of nursing mothers and has other "subtle effects on human health."

Taking its cue from Mexico, the wildlife fund is pressing for a ban on DDT by 2007. But the idea of a specific date is extremely contentious, and the State Department official said the United States would not ask for on On the other side are two scientists' groups, the tropical medicine society, and the Malaria Foundation International, a nonprofit organization dedicated to promoting research. Several months ago, at the behest, curiously enough, of a Vancouver environmental lawyer and cell biologist, Amir Attaran, the foundation posted a letter about the negotiations on its Web site, arguing that "setting a firm deadline to ban DDT places an unethical burden on the world's poorest countries."

The debate is occurring as malaria is making a deadly comeback, re-emerging in regions where it was once under control and killing many more people than it did decades ago, at least partly because of a reduction in DDT use. The World Health Organization estimates that there are 300 million to 500 million new cases of the disease each year, and last year started a project called Roll Back Malaria to combat it.

There are drugs to treat malaria, but some patients cannot afford them and drug resistance is an increasing problem. So the best means of prevention is to keep mosquitoes from biting people. At least one expert, Dr. Donald R. Roberts of the Uniformed Services University of the Health Sciences in Bethesda, Md., argues that "DDT is the best insecticide we have today for controlling malaria."

In the late 1970's, Dr. Roberts, a medical zoologist, traveled to Brazil to conduct experiments in malaria control. He built two houses and sprayed the inside of one with DDT. Hundreds of mosquitoes entered the unsprayed house, he said. None entered the sprayed house.

Others, including Dr. Galinski, say they have no problem eliminating the pesticide, so long as alternatives are in place. But that is a frightening thought to Dr. Wen Kilama, a Tanzanian entomologist who in June presided over an expert panel, convened by the World Health Organization, to debate the future of the pesticide in malaria prevention.

Dr. Kilama says that getting rid of DDT would be a mistake. "The mosquitoes are very complex and one should not rely on one measure alone, particularly one type of insecticide," he said in a telephone interview last week.

Tanzania no longer uses DDT; the country cannot afford it, Dr. Kilama said. But with the economy improving, he added, "I can see a lot of hope coming up" that Government-sponsored spraying might resume. In the meantime, some Tanzanians sleep under nets soaked in pyrethroids, another chemical. But the nets cost $4 to $5 apiece, too high a sum for many villagers, and Dr. Kilama said they work only by "mass effect," which means entire neighborhoods must use them.

Further south, in Botswana, health officials have also abandoned DDT, but for a different reason. Only three countries -- China, India and Mexico -- still manufacture the pesticide, and Thandie Phindela, a malaria control officer in Botswana's Ministry of Health, said the country could not get a reliable supply this year. "The environmentalists are trying to put pressure on the use of DDT," she said. "We had to resort to pyrethroids."

That is the World Wildlife Fund's view: its contaminants expert, Richard Liroff, urges "more creative thinking about moving away from DDT." He points to an experiment in India, where gambusia -- a larvae-eating fish -- were deposited in bodies of water where mosquitoes breed. But Dr. Kilama, of Tanzania, said such steps are not practical in a country where a hippopotamus footprint after a heavy rain can create an instant breeding ground.

As the debate continues, the World Health Organization is drafting its own plan to help countries cut back on DDT. But the organization has no idea how much the effort will cost; the price tag will vary from nation to nation. As to who will pay, said Jenny Pronczuk, a chemical safety expert, "Well, that's a problem."

More than 350 of the world's leading experts in malaria have signed an open letter of protest against plans for a global ban on the pesticide DDT, which they say will lead to millions more people dying in the developing world from the disease.

DDT, sprayed on the interior of homes, is a cheap and effective deterrent to the mosquito whose bite spreads the infection. Nothing yet developed works as well or is so easy to use, say the experts who signed the letter.

WWF of overstating the dangers to humans. While pesticide residues are found in breast milk, only one study - not two as WWF states on its website - has claimed DDT may be carcinogenic. The other six found no evidence DDT was implicated in breast cancer.

"While it is true that we don't know every last risk of using DDT, we know very well what the risk of malaria is - and on balance malaria is far, far more deadly than the worst that one could imagine about DDT," said Amir Attaran, director of the Malaria Project in Washington.

"If western countries like the US or UK want the environ mental benefit of a DDT ban, let them pay for it. Africa, Asia and South America have neither the technology nor money to research and implement alternatives to DDT. The rich countries do. For them to advocate a DDT ban while holding tight the purse-strings for those alternatives is obscene."

Among the eminent tropical medicine and public health specialists who have signed is Joshua Lederberg, a Nobel laureate in medicine who 30 years ago supported a ban on DDT but feels the threat of malaria today outweighs the evil of the pesticide. Two other Nobel laureates in medicine, Peter Doherty and Ferid Murad, and Wallace Peters, King Faisal International Prize laureate, a malariologist at the London School of Hygiene and Tropical Medicine, have also signed.

In their letter, the doctors and scientists say that although they agree DDT must one day be phased out, "we also believe that human life must not be endangered in reaching that goal. In our view, setting a deadline for the elimination of DDT - whether that deadline is in 2007 or some other date - unacceptably endangers health in countries with malaria".

Prof Kilama, based in Tanzania, says that although DDT is cheap it is still not cheap enough for much of sub-Saharan Africa, where malaria is most deadly. The chances of the developed world investing more money to find other means of controlling malaria are slight, he feels.

Chris Curtis, a medical entomologist at the London School of Hygiene and Tropical Medicine, said: "DDT is the cheapest insecticide and what I feel will happen is - as has happened several times already - if they can't use DDT they won't feel they can afford to replace it, so they will simply cut down on the total area that gets vector [mosquito] control."

WWF insists there is no risk of lives being lost if the global ban by 2007 is agreed. Clifton Curtis, director of its global toxic chemicals initiative, said: "We set an end-date as a motivational target. In our view, if you don't set a target you don't get decision-makers to focus on putting the money into the alternatives that are needed."

A few decades ago, world health specialists talked of eradicating malaria. Now they talk only of trying to regain control. Malaria is endemic in more than half the world's countries. In the time it takes to name the disease, 10 children will contract it and begin fighting for their lives. One child in four who dies in Africa has succumbed to malaria.

DDT has a bad name. It is a pesticide that damages the environment and has been widely used in agriculture. Since Rachel Carson exposed its depredations in her book Silent Spring in 1962, environmentalists have campaigned to curb its use. In the west they have been successful.

But in the developing world it has saved millions of lives. Sprayed inside houses, it kills or more often repels the mosquitoes whose bite transmits malaria, and it is cheap. Specialists argue that it does not migrate out of doors, and if we lose it through a global ban in 2007 millions who could have been protected will die.

It is a head-on clash between first world environmentalists, who insist that DDT must go for the health of the planet and that alternatives will and must be found, and the malaria specialists, who say that until alternatives are in place that are as cheap and effective it would be catastrophic to ban it.

What will happen is clear, say the doctors. Under pressure from the west, which has no malaria, and amid worries about damage to human health from DDT, some developing nations have stopped or cut down on its use.

The World Wide Fund for Nature, at the forefront of the campaign to ban DDT, talks about environmental management and biological control instead of pesticides, citing examples in India, Tanzania, Mexico and the Philippines.

This sort of alternative might be acceptable to all, but pyrethroids are up to three times more expensive than DDT, although on bed nets they are used in smaller quantities, and projects to provide sprayed nets for large numbers of people are inevitably more complex than spraying house walls.

Two years ago, in the journal Emerging Infectious Diseases, he showed that Ecuador, which increased its DDT spraying while others cut down, was the only one of 11 malaria-endemic South American countries to have reduced its detection rate. With organised DDT house spraying, malaria in urban areas of the Amazon basin largely disappeared, but it is again becoming a big health problem.

Roger Bate, director of the European Science and Environment Forum and a fellow of the Institute of Economic Affairs, pointed to areas of South Africa where malaria is once more on the rise since other pesticides were substituted for DDT. "It has gone from a couple of hundred cases a year to 15,000 in South Africa as a whole." Restricting DDT use was not the only factor, but it was part of the equation.

These numbers are tiny compared with the malaria toll in other parts of Africa. But South Africa once had it firmly under control. A paper by a consultant to the government there, Roger Tren, to be released by the IEA at the UN pesticides meeting next week, traces the virtual eradication of the disease in most parts after DDT's arrival. Measures to stop mosquitoes from breeding and then weekly spraying with pyrethroids reduced cases, but malaria was still a serious problem.

"After the introduction of DDT in the vector [mosquito] control programme in 1946, the number of cases in the then Transvaal declined to about one tenth of those reported in 1942-43," Tren writes. "In some areas DDT spraying was reduced and sometimes stopped because of the success it had in vector control."

Province and Mpumalanga. Yet Tren's report (on http://www.iea.org.uk/env/malaria.htm) calculates that the cost of malaria to the economy in terms of people unable to work and needing hospital and home care is 4% of gross domestic product.

Bate said: "If the cost is so great to South Africa, where malaria is not endemic in 50-60% of the country, what is it like for the rest of Africa? Yet people I have spoken to involved in mosquito control in Botswana and Zimbabwe, where there are much higher levels of malaria, have no knowledge that this convention [on banning DDT] is taking place.

These pesticides are less toxic to wildlife and biodegrade far more efficiently than DDT. They are used to spray the inside of houses, like DDT, or more successfully to impregnate bed nets, which protect populations from malarial mosquito bites at night. They are three times as expensive as DDT, but less needs to be used in bed net spraying.

There are suggestions that malarial mosquitoes are becoming resistant to pyrethroids. WWF is not completely happy with them as an alternative to DDT and is calling for research on the "possible hazards" of pyrethroids to health.

Predators that eat mosquito larvae, such as fish like guppies or carp, are introduced to waters where mosquitoes breed. Other possibilities are parasitic wasps and natural bacteria. This method can pose a threat to biodiversity if the predator attacks indigenous wildlife, such as other fish or tadpoles.

Spring", exposed the dangers of DDT. She horrified Americans by showing that some pesticides are transmitted through the food chain until they can destroy the reproductive systems of such birds as the robin and the bald eagle. Her book proved a clarion call for the modern environmental movement in America. It also seemed to sound the death-knell for DDT: in the years since, every country in the developed world has banned the stuff. Not all pesticides are equally harmful; and there is even evidence that some birds know how to avoid them (see article). However, there is little doubt about the nasty effects, on humans as well as on wildlife, of such persistent organic pollutants as DDT and dioxins. These accumulate in the body over time, and have been linked to cancer, endocrine disruption and other ills.

Now, the United Nations Environment Programme (UNEP) is co-ordinating negotiations for a new international treaty to curb the use of 12 of the worst pollutants. But even before officials meet next week in Geneva to work on a first draft of such an accord, a bitter row has broken out over, guess what: DDT. For it so happens that this notorious pesticide is used by two dozen poor countries to fight malaria.

DDT are so clear, it should be banned worldwide by 2007. Public-health officials retort that this would condemn millions to misery or death from a preventable disease. The health argument is the stronger. The greens' impulse to ban this thoroughly nasty pesticide is well-intentioned, but malaria still plagues hundreds of millions of the world's poorest people; and worse, it is on the rise. Malaria exacts a heavy economic price, in lost productivity, and it means sure death for several million children every year. And the only effective defence many have against it is to spray DDT inside their homes.

There are, however, three useful steps against DDT that the treaty negotiators could agree on. For a start, rich countries should concede that they will not push for a complete ban, even if it is dressed up with "exceptions" for emergencies, unless and until malaria is no longer a menace.

Achieving that could take many years, for it will require technological advances in drugs and pesticides, as well as a development of public-health infrastructure in poor countries. Such a move would help win over poorer countries, whose co-operation is essential for the second step: a complete ban on the use of DDT outside the home, notably in farming. Although many countries already have such a ban in theory, poor enforcement means that it often leaks into agriculture. UNEP reckons that as much as half of the DDT used today is for purposes other than fighting malaria inside homes.

The third and hardest step is for rich countries to put some cash on the table. Some should be used to boost incentives for firms in the rich world to look for malaria vaccines, therapeutic drugs or alternative pesticides to DDT. That will take time. Meanwhile, though, more money would help agencies such as the World Health Organisation to expand the use of non-chemical measures against malaria, such as draining swamps or biological control, that would reduce DDT use.

These three measures will not satisfy all those who lie awake at night worrying about bald eagles. But they would tilt the scales toward compassion for the avoidable suffering of the world's poorest people. And they could produce something that will benefit both the world's haves and its have-nots: a widely observed treaty to phase out some of the worst pollutants that man has ever invented.

The headache starts in the morning, a blinding pain that cripples Bonisiwe Mathenjwa as she tackles the routine tasks of a poor single mother with three children at her river bank hut in northern KwaZulu-Natal. She doesn't need the body pains, fever and flushes, dizziness and diarrhoea that follow to know she's down with malaria - for the third time in eight months.

At first Mathenjwa, 28, avoids the local clinic, not wanting to leave the kids with their elderly grandmother and hoping that this time her body will thwart the disease. But she's desperately ill by the time she's rushed by ambulance to Mosvold Hospital in Ingwavuma, a small rural town tucked in a corner near Swaziland and Mozambique. It is three days later and a stream of lifesaving quinine drips into her veins as she lies exhausted, shaky and sweaty in a tatty pink nightdress on a bed she shares with a woman and baby in a crowded isolation ward. "I feel a bit better so I'm not frightened anymore," she whispers. "This time I thought I was going to die."

There are 20 women and children packed into a ward built for half their number in the years before the current malaria epidemic. South Africa has not seen the disease on this scale since the 1930s. Northern KwaZulu-Natal (KZN) is in the grip of a malaria scourge moving down from heavily infested southern Mozambique and the surrounding regions, where some areas report 70 percent infection rates.

The parasite is running rampant along the border and is on the march south towards Durban. Earlier this year, two-year-old Craig Paul from Sea Cow Lake died of malaria - the first death of someone who contracted the disease in Durban in half a century. Health authorities were sure that Craig was infected locally, most likely by a mosquito brought in by a traveller in their luggage.

Thousands more South Africans will perish if the blood-red splashes warning against malaria continue to seep down African maps which are becoming eerily reminiscent of those of the mid-1900s, the darkest days of the disease. If the epidemic were allowed to spread totally unchecked, we could possibly find ourselves back at the level of malaria fatalities of November 1931 to June 1932, when more than 22000 people died in KZN, says Dr Brian Sharp, director of the National Malaria Research Programme (NMRP) of the Medical Research Council. But he is optimistic that the tide will be turned. "All the right policies are in place and we are confident that next season will see an arrest in the number of cases and a reduction in the geographical distribution of malaria." To try to turn the tide, the authorities in KZN have had to resort to a huge house-spraying programme with one of the most controversial pesticides in history - DDT.

The hut in sweltering Ndumu is empty. Mathenjwa's meagre possessions are piled outside, to avoid being contaminated by the clouds of DDT. A masked man in blue overalls is spraying DDT through a fan nozzle onto the hut's inside walls, thatch ceiling and eves. There, the insecticide will last for some nine months and repel the mosquitoes that have nearly claimed her life three times. "I want the spray," Mathenjwa tells me. "I don't want to be sick again and I'm worried about my children." The programme began in February, four years after DDT was withdrawn under pressure from environmental groups.

It was discovered last December that malaria-bearing Anopheles mosquitoes had become resistant to the more environmentally-friendly insecticides that had been sprayed since 1996. The consequent resurgence of mosquitoes included even the virulent Anopheles funestus, which was eliminated 50 years ago.    South Africa, which in the 1940s was one of the first countries in the world to use DDT against malaria, is now among the first to re-introduce it. Experts and the government will resist attempts by northern countries, which have money and medicine but not malaria, to stop the anti-malarial use of DDT at the UN Environmental Programme treaty meeting this month in Johannesburg.

"DDT is extremely effective and cheap. The case for it being a medical hazard is unproven, and should have little environmental impact in the small quantities we are using it." Returning to DDT was controversial but essential, agrees Dave McGlew, a provincial health department spokesman. "Given the deteriorating malaria situation and the growing threat to human life, we had little choice but to opt for the most effective way of combating the disease." Sharp concurs.

"DDT is the best we have available, but it is only an interim measure until a better solution is found." The health department has gone to a great deal of trouble to minimise the toxic effects of DDT, consulting with environmental bodies, scientists and poison experts to ascertain how, where and what concentrations to spray inside homes. Strict procedures are followed to avoid environmental contamination. "There is a very small chance of harming people or animals," says McGlew. Since February, KZN's malaria control unit has sprayed 241020 structures (mostly one-room homesteads). Already surveys show a reduction in the number of mosquitoes inside homes. DDT spraying is being supported by other methods, says Jotham Mthembu, malaria co-ordinator for KZN. One is a natural oily solution applied to still waters to kill off mosquito larvae.

Almost immediately, this semitropical region along the Indian Ocean saw a dramatic increase in the number of cases of malaria, which is transmitted by mosquitoes. There are now nearly 10 times as many cases as in 1995. There were no malaria deaths five years ago. This year, the disease has killed more than 300 people in the province.

"We have to use it. People are dying," said Bheki Qwabe, an environmental health officer who supervises 17 DDT- spraying teams that resumed work in May in northern KwaZulu-Natal. South Africa's experience with DDT was a main reason the pesticide received a reprieve under an international treaty negotiated this month to ban 12 toxic chemicals.

The treaty, scheduled to take effect in about five years, would immediately ban the production of nine of the "dirty dozen" chemicals that biodegrade slowly and have been linked to cancer, birth defects and other disorders. They include chlordane, dieldrin and hexachlorobenzene.

But DDT, whose perils were the subject of Rachel Carson's 1962 book, "Silent Spring", which catalyzed the modern environmental movement, was regarded as too useful in the fight against malaria to ban outright.

About 25 countries, including South Africa, would be allowed to use DDT under strict controls until a safer solution is found. DDT, which stands for dichlorodiphenyltrichloroethane, is produced only in Mexico, India and China.

DDT's image has metamorphosed since health officials began raising alarms about a worldwide resurgence in malaria, which kills more people than any communicable disease except tuberculosis. The World Health Organization estimates that from 300 million to 500 million people are afflicted with malaria each year, and more than a million die, mostly children in rural Africa.

Health officials in South Africa emphasize that they use DDT judiciously, only spraying the chemical on residential structures where humans are vulnerable to mosquitoes at night, when the species that carries the malaria parasite prefers to feed on warm- blooded creatures.

South Africa, where thousands of tons of DDT were introduced into the environment by airplane crop-dusters, long ago banned agricultural use of the compound. In the United States, such campaigns to eradicate insects led to the near extermination of several species of birds of prey, including the bald eagle and the peregrine falcon.

The work crews, wearing blue overalls and protective paper masks, applied the sweet-smelling aerosol [note: DDT for malaria control is applied as a wettable powder mixed in ordinary water in a compressed air sprayer, not as an aerosol.  The compressed air sprayer uses a mechanism similar to a bicycle air pump to create the pressure] from hand-pumped tanks on the mud-and-stick walls and grass roofs of the traditional Zulu dwellings. The crews apply about 2 grams of pesticide per square yard, which leaves a light white coating. It is effective for up to a year.

"When they spray, the mosquitoes go away," said Muzi Tembe, a retired woman in her 60s. She and her family sat on the ground, surrounded by their chickens and their possessions, which they had removed from their huts to make way for the spray.

Last year, health officials noted that malaria cases failed to decline in June during the onset of the southern hemisphere winter. Then entomologists in KwaZulu identified the Anopheles funestus mosquito, a species adept at carrying malaria parasites that had been eradicated in South Africa in the 1950s. It was resistant to pyrethroids.

Malaria cases have been on the rise since and one malaria carrying mosquito which was eradicated in South Africa after 50 years of house spraying with DDT has returned. It has proven to be resistant to pyrethroid.

Delegates at the conference said there was a growing consensus that DDT and PCBs needed to be placed under an annex calling for restrictive use while most or all of the other 10 POPs under discussion will likely be slated for elimination.

Traveldoctor.info is a new service about travel health. It provides country specific advice depending on the lenght of the trip. Amongst others there are a section about outbrakes and?"Ask the Doctor".

I believed that societies can be changed and that poverty can be fought. That people working together can achieve impressive results. This I still think and know. We can harness the resources. We can mobilize the will. We can inspire the extra effort.

We need political guidelines from this Assembly. We depend on how members states follow up at home. We depend on how they live up to the imperative of equity and social justice, expressed in health for all.

The 20th century gave the world more health advances than in the entire previous history of mankind. Still we are faced with daunting challenges. Above all they are linked to the persistence of poverty. The imbalances are striking. People in developing countries carry over 90 per cent of the disease burden, yet have access to only 10 per cent of the resources used for health. This is unacceptable. This has to change.

Wealthier countries will benefit by contributing and they have the moral obligation. Governments in poorer countries must acknowledge their responsibility, they have a moral obligation to give priority to health and to equitable distribution of health services.

I hear some say that infectious disease is becoming yesterday's problem. But is that correct? I don't believe so. There is an unfinished agenda of eradication and rolling back diseases. No one should underestimate childhood infections, HIV/AIDS, TB, malaria, polio and the other new and emerging diseases. They may hit us all in this small world - but above all they keep ravaging the lives of the poor.

WHO must be an enduring advocate in the fight against infectious diseases. And WHO must help governments face the daunting challenge from the new epidemic of non-communicable diseases, now spreading in the low- and middle-income countries.

Globalization is opening up new opportunities for growth and progress. But the benefits are not adequately distributed. Globalization has also brought new and critical threats to health and the environment.

We have to reach out to new arenas critical for the health of billions. The next century may well be one of great environmental crises. But it need not be. We still have the opportunity to make timely decisions before we have to pay the bills of overburdening the capacity of the planet, its resources and most importantly - the health of its people.

Our constitution provides us with a broad and impressive mandate. But a mandate is no roadmap. It must be made according to the needs - of the people, the communities and the nations we are meant to serve. We need to focus our work.

I see our role as being the moral voice and the technical leader in improving the health of the people of the world. Ready and able to give advice - not on every issue - but on the key issues that can unleash development and alleviate suffering. I see our purpose to be combating disease and ill-health - promoting sustainable and equitable health systems in all countries.

What should be our motivation? My answer is short: Making a difference. We should measure our work in full transparency - sharing and learning from successes and failures - our own and those of others.

One road leads to our work on the ground. We must combat disease, premature death and disability. We must give advice on best practices to achieve equity and quality, set standards and norms. We must encourage, support and trigger the best research and development.

We must speak out for health in development,  bringing health to the core of the development agenda. That is where it belongs, as the key to poverty reduction and development underpinned by the values of equity, human dignity and human rights.

I wish to organize our programmes and activities around key functions that tell a clear story of what business we are in. I wish to concentrate our resources in a way which enables us to do fully what we decide to do - and to let go what we decide not to do - either because others do it better or because we simply can't do all.

WHO will help countries build sustainable health systems that can help reach equity targets and render quality services to all, with a particular emphasis on the situation of women and mothers who are so critical for giving children a safe and healthy start in life.

Not two - meaning one financed by the regular budget and one financed by extrabudgetary funds. Not seven - meaning Geneva and the six regional offices. Not more than fifty - meaning the individual programmes.

WHO must be one: Setting its priorities as one, raising additional financial resources as one, speaking out as one. And then - but only then - can we act effectively in our decentralized diversity through skilled presence at the country level, through regional guidance by the regional offices and through global direction by the headquarters and the governing bodies.

With this structure and spirit in place WHO will be the lead agency in world health. But we need a change in attitude. We cannot point to our Constitution and say: We have the right to be the lead agency. We must earn our leadership. We must demonstrate through the way we plan, structure and carry out our work that we make a difference that we and others can measure.

We need to improve our work at the country level, especially in developing countries - in cooperation with national authorities but also by drawing on and expanding the contact with collaborating centers. Technical cooperation must be relevant and address the needs.

We will need a much stronger focus on how health sectors are tailored to sustain activities that secure the quality and distribution of services. I will propose that health sector development becomes an integral part of all our activities. Each of our disease control units will have to identify sectoral issues where they can contribute and capacities that must be strengthened for them to do their jobs. We should not engage unless our work can make a direct contribution to the overriding purpose of building and strengthening the health sector.

One obvious area is to lend full support to UNAIDS together with the other patrons of that programme. The regions most ravaged with AIDS are coming close to what most of Europe faced during the plagues of the 14th century.

We must make an extra effort in the crucial combat against the HIV/AIDS pandemic, especially in the most vulnerable countries. We must help the health systems to cope. We must help make the scientific advances available also to the developing world.

Our voice is needed to remind both governments and financial institutions that budget cuts should not be in critical sectors such as health and that the long term expenses of disengaging in public health will go beyond the short term budgetary gains.

Where would the battle against leprosy, TB or blindness have been without the NGOs? I will convene a conference with the NGO community to draw up new guidelines for our cooperation to establish new mechanisms for interaction with civil society in member states.

Governments should ensure universal coverage of health services. We have seen evidence that growing reliance on private financing mechanisms, including private voluntary insurance, risks massive cost escalation. A key role for public finance of universal coverage results in greater equity but, also, in reduced waste and inefficiency.

The private sector has an important role to play both in technology development and the provision of services. We need open and constructive relations with the private sector and industry, knowing where our roles differ and where they may complement each other. I invite industry to join in a dialogue on the key issues facing us. To this end I will propose the creation of a WHO-industry roundtable and convene a first meeting before the end of the year.

For WHO to be the leading advocate for health we need to know the relevant facts, not only have the conviction that health is essential. Health is not only a moral obligation and a basic human right. Health is pure and sound economics.

Reaching goals based on values are also measurable. We need to know the burden of disease and how health policy can contribute to change. We need to know the cost-effectiveness of intervention and we need to define our priorities accordingly.

To be the leading advocate for health we need to take that evidence to decision makers around the world. We will report on the news of fact. And the fact is that healthy people help build healthy economies.

Ministers and Finance Ministers that they are truly health ministers themselves, key to the well being of their people. Health investments are sound investments for poverty reduction and economic growth.

I said that WHO is my priority. Don't expect to see me constantly traveling to the four corners of the world in this first phase. I look forward to attending the meetings of the Regional Committees in September. Beyond that I will devote my attention to the running of the organization.

A first task will be to suggest certain amendments to the current budget built on the directions that I have already indicated. A next task will be to take these directions into the preparation of the 2000-2001 budget and to present my orientation for our next program of work.

I strongly believe that WHO can say more with fewer volumes of documents, fewer reiterations of what we all agree and more focus on what we are here to do. I also believe we can do with a flatter structure and fewer layers. Information and communication must flow.

Directors, inviting them to take part in the management of the whole organization. We will take advantage of new technologies which will allow us to meet on the information highway securing the unity of purpose that this organization needs.   I wish to establish more direct links to the country representatives seeing to it that they have a clear understanding of our priorities and their evidence base, and that we get their feed back.

I wish to see WHO attract the best expertise there is - inviting people to come - not all to spend a life long career with us - but to share their knowledge and expertise and then move on with what they have learned.

Staff is WHOs prime resource. We should do more to offer staff opportunities to develop and refine their knowledge and expertise. In July I will propose a staff development package including training opportunities - not for the fortunate few - but for the many. And I will invite the Staff Associations into a structured dialogue on working conditions and arrangements.

I wish to increase the number of women in the organization. There is a long way to go to reach the targets set by the World Health Assembly and the Executive Board. But I will take targets seriously and I intend to make sure that we reach them.

I wish to strengthen our programmes. Not as independent units separated from each other. Not as separate fund raising bodies sending different signals about our priorities,  but as centers of excellence. Some times co-sponsored by others, but always open to the rest of the organization and to each other. Not overwhelmed by administrative functions, but encouraged and supported to bring our shared knowledge further.

I believe there is a lot to gain from organizing part of our activities into projects. Not too many, but easy to define, easy to identify, open for our partners to co-sponsor - and transparent for donors to lend their financial support to.

I propose that together we Roll Back Malaria. Not as a revamped vertical program but by developing a new health sector wide approach to combat the disease at global, regional and country and local levels.

That means connecting the services with the primary location for action; the family - the home - and the mother.  Efforts against all infectious diseases will benefit. Drawing upon what we learn we will be ready for a fast track on a future Roll Back TB - and a reinvigorated action against HIV/AIDS and the tropical diseases.

My second emphasis is in the field on non-communicable diseases. We need to address a major cause of premature death which is dramatically increasing - killing 4 million people this year - and - if we let it go on without action - 10 million people in 2030 - half of them dying in middle age - not old age. The major focus of the epidemic is now shifting to the developing countries.

I  envisage a world where solidarity binds the fortunate with those less favored. Where our collective efforts will help roll back all the diseases of the poor. Where our collective efforts assure universal access to compassionate and competent health care.

Honigsbaum has been a prominent journalist for the last eighteen years, his work appearing in the Observer, the Guardian, the Evening Standard, the Sunday Times, GQ and Vogue. In 2000 he was bitten by the travel bug and left England to retrace the routes of three Victorian explorers who were despatched to South America in 1860 to obtain seeds and plants of the Cinchona tree - the source of quinine. Venturing deep into the Venezuelan Amazon and over the volcano Chimborazo, in Ecuador, he suffered dysentry and altitude sickness, and was attacked by mosquitoes so many times he lost count. Thankfully, however, he did not contract malaria.

Affairs, Princeton University says: "Plague Legends is a fascinating contribution to the history of medicine.... Litsios' profiles and interpretations of the 18th and 19th century outbreaks of bubonic plague, smallpox, tuberculosis, yellow fever, cholera, and malaria are masterful."

Wahlgren & P. Perlmann, Eds. (Harwood Academic Publishers 1999) This multiauthored text covers the important areas of malaria research, particularly focusing on those sectors which are of clinical importance for the understanding of the disease, the parasite, and its vector.

"Bugs in Armor" takes the reader on a historical journey of military expeditions and their encounters with a relentless bug - the malaria parasite. It is also a story of how this confrontation fuelled research that gave the world a better understanding of the nature of malaria, its treatment and prevention.

A research effort led by scientists at the National Institute of Allergy and Infectious Diseases (NIAID) has produced the first high-resolution genetic map of Plasmodium falciparum, the deadliest malaria parasite. The map along with a report describing its construction appears in the journal Science.

The annual loss of growth from malaria is estimated to range as high as 1.3 percentage points per year. If this loss is compounded for fifteen years, the GNP level in the fifteenth year is reduced by nearly a fifth, and the toll continues to mount with time, as losses from malaria retard development.

Center for International Development at Harvard University is working with Roll Back Malaria and has a developing website devoted to malaria that will discuss an upcoming book The Economics of Malaria.

RBM's strength lies in its ability to from effective partnerships both globally and nationally. Key players from the world of finance and commerce, government, development agencies, non-governmental organisations are working together.

However, it has accomplished a good deal of the large-scale planning. RBM is working on prompt drug treatment of cases coupled with use of vector control measures, such as bednets to block malaria transmission expecially among children and the elderly, the most vulnerable groups. During the African Summit on RBM, debt relief for the most impoverished countries was discussed as a way to financially speed up malaria work. We anticipate many exciting developments to come from RBM, and will keep these posted at this site.

RBM launched its website on 24 April 2000. The site has many resources, including progress reports, maps of malaria risk for individual countries, RBM and WHO documents in PDF and MS Word forms and news releases. The site also has an individualized interface that allows users to register and select their country and field of interest.

The Multilateral Initiative on Malaria [MIM] is an effort to increase international collaboration on malaria. MIM is accomplishing many of its goals, including promotion of communication on the public health importance of malaria, promotion of scientific collaboration, genome sequencing work, and interaction between scientists and the development community. A summary of malaria research news is available, as is a developing resource library.

Under the auspices of a newly formed partnership with the Malaria Vaccine Initiative(MVI) at PATH (Program for Appropriate Technology in Health), the Emory University Vaccine Research Center has begun the first of a series of malaria vaccine trials that researchers hope will significantly advance progress toward an effective vaccine.

Coordinating Committee (FMVCC) is an interagency working group composed of representatives of agencies of the U.S. Federal Government that have an interest in and commitment to the global prevention and control of malaria. Because vaccines have proven to be cost-effective means of disease control, representatives of these agencies desire to promote the development, evaluation, production and widespread deployment of safe and effective malaria vaccines, either alone or in combination with other malaria control measures. In recognition of the diverse activities, expertise and resources that such a process requires, participating representatives agree to facilitate all phases of the process through sharing information and expertise, identifying, developing, and communicating priorities, and collaborating actively and assisting in coordinated efforts with each other and other agencies.

Insecticides break the contact between vectors and people, thus breaking the cycle of malaria transmission. Random trials in the Gambia, Kenya, Ghana and Burkina Faso show that 30% of child deaths could be avoided if children slept under bednets regularly treated with recommended insecticides, such as pyrethroids that are relatives of an extract from chrysanthemum plants. Insecticides are thus a useful tool in malaria control, in addition to source reduction and drug treatment. As the vectors of malaria are quite different in their behavior and resistance status, different insecticides are useful in different malaria transmission situations. It is dangerous to totally ban compounds that are relatively safe when used indoors and that can save lives.

The American Council on Science and Health is an organization composed of scientists and engineers who work to present balanced, scientifically sound analyses of current health topics, even where controversy is involved. Commentary on malaria situation in Mozambique and Southern Africa.

This will be as a result of an enormous global movement from lots of organizations' work together in partnership and it's a result of you, David and the Drive Against Malaria group sponsored by MEMISA and the Malaria Foundation International that will make this possible.

Chromosome 1 is in the later stages of gap filling. There are currently 3 almost overlapped YACs being used, and it appears that the centromere has been identified. Chromosome 4 is also in the later stages of gap filling.

Chromosome 14 is currently in closure. There were about 39 physical gaps remaining to be closed at the last assembly. Using PCR products, this has been reduced to about 15 gaps. The remaining few have been significantly challenging.

Ross Coppel, David Roos and Chris Newbold have been laying the groundwork for proposing an integrated plasmodium genome database and presented their recommendations. The database aims to be "usercentric", with outreach efforts and proactive planning in place to make the bench scientist more at ease in the database environment. Meeting participants, both from the sequencing centers and from the general malaria community responded positively to the database plans and offered feedback. A proposal to allow further development will be submitted to BWF for review. Further information about the database planning will be available after submission of the database proposal.

Before the meeting, the question "If another plasmodium were to be sequenced, which should it be?" was raised. It was proposed that low level sequencing be done of 4 models, P. knowelsi, P. yoelii, P. chabaudi, and P. bergei. Steve Hoffman discussed 3x or 6x sequencing of P. vivax using funding from DoD.

The group left the meeting with the charge to investigate the costs of 3 x and 6x sequencing of a group of organisms: a second strain of falciparum, vivax, knowelsi, bergei, yoelii, chabaudi, and galanaceum. It was generally agreed that obtaining sequence from this wide group was preferable to investing in finished sequence from a single species.

David Schwartz will also identify the cost of doing optical maps across these species. GST projects currently underway in vivax and bergei will interface well with these "lighter" sequencing projects.

As the sequencing of the P. falciparum genome progresses there is an increasingly urgent need to ensure that mechanisms (both technical, information sharing and funding) are in place to exploit the information obtained, for health care benefit. The Seventh Genome Sequencing meeting was convened with a focus on the post-genomic era and participants included experts from fields other than malaria research, who shared their experience in areas such as database development and proteomics.

TIGR/NMRC and Stanford) presented reports on the P. falciparum sequencing effort. Excellent progress is being made at all three centres and the Sanger team was congratulated on the completion of chromosome 3, to be published in Nature in August.

There was an open discussion about the new 96 well format capillary sequencing machines (ABI 3700). It was generally agreed that these machines, although not as efficient as the manufacturers first suggested appeared to be showing promise and with the correct technical support could increase throughput to 5 runs per day with ~500 bp reads.

Reagent Resource center) described how the repository had been set up in 1998 under the management of ATCC and with contract funding from NIAID, to provide reagents for the malaria research community. Dr. Cypess described the operation and management of the MR4. Reagents are issued in reference amounts with researchers paying only shipping costs. MR4 has an international advisory group with 14 members who meet twice each year. There is a webpage (www.malaria.MR4.org), and a newsletter detailing reagents currently available and describing opportunities for workshops. Printed and CD ROM versions of the reagent catalog are anticipated in the near future. MR4 is funded to run 2 workshops per year; these could be on any relevant topic, for example, parasite culturing, bioinformatics.

Although it is expected that investigators will freely deposit reagents to the MR4, in some cases funds will be made available for the production of reagents that are deemed valuable to a large number of malaria investigators.

In this section there were four presentations which provided insight into key techniques which will be important for the post genomic era of malaria research. Michael Ashburner talked about the FLYbase database, originally set up for the Drosophila research community but now widely used and linked to other organism databases. This was followed by a discussion of proteomics (Philip Cash), metabolomics (Alan Fairlamb) and reporter protein systems (Alan Cowman).

Ways in which sequence information might be exploited in vaccine and drug design were considered by three speakers. Steve Hoffman highlighted ways in which the genome sequence data could be used to screen novel antigens as potential vaccine candidates, but pointed out that this requires the development of high throughput screening methods. Paul Sims and David Roos demonstrated how sequence information can help identify pathways specific to parasites which are potential drug targets and provide a clearer understanding of resistance mechanisms.

Delegates were split into five groups with a breadth of expertise within each group. In the first breakout each group was asked to discuss what information we would hope to access from a malaria specific database, possible topics for workshops which should be set up to develop expertise in key areas and what the malaria repository should provide. In the second break out session, the focus for discussion was the prerequisites for drug and vaccine development.

It was generally agreed that the database should be managed by an international committee comprised of malariologists, sequencing experts and representatives from other pathogen communities, probably with a single person responsible for curation.

There is an urgent short term need to provide sequence information in a more usable form for the general community. In the longer term the ideal would be a comprehensive database which will provide a one stop shop for the malaria community.

There are already several model organism databases which meet, at least in part, the needs identified above. It was therefore agreed that the first step in developing a malaria database must be to examine the options already available and decide which (if any) would be the best model for malaria. It would be important to identify one or two individuals with the time and motivation to drive development of the database forward quickly.

In order to ensure the transfer of enabling technologies to the wider research community, it will be important to run training courses and workshops in areas such as microarray technologies, bioinformatics, comparative studies and molecular epidemiology. Some courses already exist and new courses should link into these if possible. There is also a clear need for transferring transfection technologies to a larger number of malaria investigators, although due to the length of time required to generate transfectants, it was felt that a short course would not provide the necessary conditions to transfer the technology. In this case, a mechanism should be available to fund visits to expert labs with costs for travel and consumables provided. By doing so more foci of expertise would develop relieving pressure on the few labs currently expert in these methods.

When the complete genome sequence is available it will be theoretically possible to knock-out all genes systematically. However, this may not be the most efficient or effective strategy to identify key genes involved in pathogenesis and most participants favoured a thematic approach to generating knockouts, based on invasion, cytoadherence etc. In any event, progress will be dependent on setting up consortia of groups with relevant expertise.

Now that the sequencing of the P falciparum genome is almost complete it is possible to analyse polymorphic regions within the genome using other P. f alciparum isolates and to compare the sequence with that of other Plasmodium species. It was generally accepted that there are arguments for doing a 3-4X coverage of at least one rodent malaria strain.

Suggestions of reagents for the repository are to be forward to Raymond Cypess at MR4 and researchers with reagents which could be included in the repository are invited to deposit them. Dr Cypess is to explore possible ways of simplifying the procedure for obtaining and distributing reagents.

The Department of Defense is now in the second year of a five year funding cycle. They are spending about $1M per year for sequencing at TIGR (with NMRC) and are also investing a smaller amount in projects related to sequencing at NMRC. The Wellcome Trust has committed A 7M to the project including investments in some equipment at Sanger that is also being used for other genome projects. The Trust is organizing a small workshop on malaria postgenomics for the European and Australian malaria research communities on February 12, 1999.

Three meetings focusing on expression technologies, database development and development of genetic tools were held in late 1998 and early 1999 as an initial step toward considering how the malaria community can best make use of the genome data. Steve Hoffman will plan a similar meeting on vaccine development in 1999. Summaries of this series of meetings have been distributed by on the malaria genome mailing list.

Report of a workshop held on 23 November 1998 at the Wellcome Trust, London For subsequent meeting reports please refer to MFI's Malaria Genome Database page at www.malaria.org/genome.html Background and Introduction This was the second of several workshops to discuss how to maximize the usage of the genomic information arising from the P. falciparum sequencing project.

The aim of this meeting, which was jointly chaired by Ross Coppel (Monash) and Chris Newbold (Oxford), was to make recommendations on database development for the project. The 19 participants included representatives from the three sequencing centres, various malaria research labs involved in the project, the EBI, the NCBI, scientists involved in other genome projects and funders.

Dan Carucci (NMRI) gave a brief summary of the workshop on functional analysis of the malaria genome, held at TIGR on 9-10 November 1998. At this meeting the bioinformatics issues associated with the generation of large amounts of data from expression analysis had been highlighted.

The replies obtained gave a snapshot of the current situation. Although a minority of scientists experienced no problems accessing the data, over 70 percent reported difficulties either with access to the data, problems in analysis or with the available software. The survey identified a wide range of user needs at various levels, and many of the problems are not specific to the malaria genome project; for example, the need for sequence information to be in the right format to be useful, and a lack of bioinformatics expertise among biological scientists. Ross Coppel announced that he planned to include the malaria genome data in the next release of the WHO Sequence Database mailout.

He requested some form of agreement from the three sequencing centres authorising him to copy and distribute the data in this way. Funding for this will initially be provided by WHO and Monash University in 1999.

NCBI are currently revamping their navigational system. Mention was made of the need to ensure that use of sequencing data observed the convention of avoiding chromosome-wide analysis until the responsible sequencing group had a chance to report the data.

The group agreed that access to blastable data needs to be improved and that acceptable procedures for annotation of data available via the web need to be clearly defined (see data release policy below).

Centre) described the development of the Malpep database of malarial proteins, which currently consists of 542 predicted ORFs from chromosomes 1, 2, and 3. Additional data from chromosomes 4 and 13 will be added soon. Search tools for gene finding are being developed.

Eula Fung (Stanford) reported that Stanford intend to include the research community in annotation of chromosome 12 by using a submission form, and a discussion of various tools (eg Java, Diana, Ace) for annotation by researchers ensued.

In the next 12 months the majority of the genome sequence will be available in unfinished form and Dan Lawson considered that this will cause problems because many groups will want to publish results derived from the unfinished data.

Sanger releases them as they are assembled. Stanford releases contigs by bins - about 100-200kb in size. TIGR had not released any contigs for chromosome 14 at the time of the workshop but contigs and shotgun reads have since been released on the web. Several members considered that unauthorized annotation of the early released data with publication (either on a website or in press) prior to publication by the sequencing centers would be unethical.

In subsequent discussion it was agreed that the current data release policy statement for the malaria genome project should not be altered, and that it should be displayed more prominently on the websites of the sequencing centres.

It was also agreed that there should be more interaction between the sequencing centres and research community concerning the use of unfinished sequence data and that the sequencing centres should communicate frequently to discuss common issues concerned with data release.

Both set-up funding and ongoing funding for curatorship would be needed. Opinions on the cost of curation of a malaria database varied, but possibly one postdoctoral assistant with computing skills, funded for 1 year, would be needed to set the database up. The group agreed that long-term curatorship would require 2-3 biologists, located in the research community, and one computer expert, possibly located at the EBI or NCBI. A commitment for at least 5 years funding is needed, with realistic estimates for development and long-term maintenance costs.

Training - Participants agreed that more bioinformatics training is needed to enable the community to use the genome data, and recognized the current shortage of good bioinformaticists in academia. NCBI and ICPEB in Trieste run basic courses in bioinformatics and an advanced course at Cold Spring Harbour is planned. There will be training for 2 people from each of the WHO genome projects course at Hinxton, 27 March-1 April 1999, and 2 malaria people could be included. In addition, it was agreed that for developing countries web and CD-ROM-based tutorials and regional training are required. Martin Aslett has produced a tutorial on bioinformatics and Mark Blaxter agreed to arrange for it to be put onto CD-ROM for distribution to workers in developing countries.

Newbold agreed to draw up a draft proposal for a malaria genome database, which will include specifications and rough costings. It will be circulated to the group for input before consideration by the funders at the next meeting of the malaria genome project in Chantilly on 29 January 1999.

The Plasmodium falciparum genome project is a coordinated effort by funding agencies, sequencing centres and malariologists to achieve the complete sequencing of the P. falciparum genome (clone 3D7) and to promote its use in developing new strategies to control malaria, including diagnostics, vaccines, and drugs.

US Dept of Defense funds allocated to Plasmodium vivax will be refocussed into the P. falciparum effort, including bioinformatics . The Dept of Defense has allocated funds for the sequencing efforts at TIGR in collaboration with support from NIAID and the Burroughs Wellcome Fund.

Cathy Fletcher (Wellcome Trust) reported that the Trust funds sequencing of up to half the P. falciparum genome (Chromosomes 1,3,4, 5-9, and 13) and currently coordinates the Multilateral Initiative in Malaria, which gives high priority to ensuring that knowledge from sequencing the Plasmodium genome is applied to the discovery of new drugs and vaccines. Recently the Trust established Beowulf Genomics, which is funding the sequencing of various pathogen genomes and pilot projects on Trypanosoma brucei and Leishmania major.

Rob Ridley (WHO) reported that although WHO does not fund the P. falciparum genome project, its TDR programme is interested in promoting the use of genomic information for strategic research for drug and vaccine development. WHO-TDR does provide catalytic funding for sequencing of other parasites relevant to its mission, and promotes links between agencies.

Herve Tettelin described the progress on chromosome 2. Efforts since the Orlando meeting had been directed at closing the A-T rich sequence gaps. The sequence is now completely annotated and edited, and a manuscript had been submitted to Science four days before the meeting. Two small sequence gaps still remain in the chromosome, at 10 kb from either end.

The 945kb chromosome contains a total of 209 genes, of which 36 percent are genes for the cell envelope and 27 percent are for hypothetical proteins. There was 4.3 percent difference between expected sequence fragments and the optical map constructed by David Schwartz.

Herve Tettelin presented his analysis of the predicted ORFs on chromosome 2 and compared the distribution of some gene families with those on yeast chromosome 3. (e.g. those for secreted proteins, integral membrane proteins). He described some prominent features of the chromosome 2 genes. The success of the chromosome 2 effort was attributed to improved methodology for high-throughput sequencing, development of optimal chemistry, modifications to TIGR assembler software, use of optical mapping, and development of Glimmer M software ( a program for gene prediction).

Eugene Koonin (NCBI) presented his analysis which suggests that many of the predicted proteins encoded by chromosome 2 contain large nonglobular domains, to a much greater degree than in yeast. He speculated they may have accumulated due to positive selection by the immune system.

He estimated the gene complement for the whole P f alciparum genome at 5,500 to 6,000, and emphasized that completely different genes can be located very close together. The largest number of introns predicted to be in a single gene was about 7, although most genes appear to have 1 or 2 . He considered there were 4 families of subtelomeric genes and estimated that about 40-50 var genes are present in the whole genome.

Richard proposed an experiment in annotation at Stanford whereby open annotation by anyone would be invited, to be edited by himself. The name and affiliation of the annotator would be submitted to Genbank.

SESSION II Updates on technology and mapping projects Dyann Wirth (Harvard) described progress at Harvard in identifying E coli strains defective in DNA repair that may be suitable for stable cloning of P falciparum DNA. By screening about 200 strains they have identified the SRB strain as suitable. This is commercially available from Stratagene and is very similar to the SURE strain, which is claimed to differ only in lack of the recB gene. Its tranfection frequency is quite low.

David Kemp ( Darwin) reported that his lab has mapped about 3/4 of the total genome. They have located a gene coding for cytoadherence at the right-hand end of chromosome 9, and designated it Clag (Cytoadherence linked asexual gene). Clag is expressed in blood stages, probably as a membrane protein. Tansfection of 3D7 P. falciparum with an antisense construct gave increased cytoadherence to melanoma cells.

Note: David Kemp will send sequence of Clag to TIGR and Sanger to identify David Schwartz (NY University) described the optical mapping technique in which fluorescence intensity of DNA molecules cut with restriction enzymes is related to base composition.

The optical map of P. falciparum chromosome 2 has given quite a good match with the sequence, and helped reduce finishing time. A whole-genome map of P f alciparum is currently under construction. Using BamH1 twelve whole chromosome contigs have been assembled out of 14; using Nhe1 thirteen whole chromosome contigs are currently assembled.

Michael Ferdig (NIH) described the construction of a genetic linkage map of P falciparum using a Pf Hb3 x Dd12 cross. By using genetic linkage analysis genes involved in transmission, drug resistance, pathogenesis, immunity, development etc can be identified.

Steve Oliver (UMIST) described the EUROFAN Saccharomyces cerevisiae sequencing project funded by the European Commission , and pointed out similarities to P falciparum in terms of real or apparent high redundancy. In phase I of EUROFAN ( 4 years ) about 200 labs were involved. Phase II of the programme involves an international consortium which has divided up the yeast genome between labs worldwide to undertake a systematic functional analysis. The first step is making tagged deletions, then the mutants will be characterised phenotypically.

These included the complex life cycle and the problem of obtaining sufficient parasite material for some stages (e.g. sporozoites). He described a pilot project at NMRI/TIGR using highly synchronized blood-stage P falciparum.

A single site should be established to include BLAST data EST/GST data shotgun data known genes with databank Site should be mirrored for others, with email servers Site should have links to other Apicomplexan databases. Develop searching/comparative methods Long-term curatorship is needed. Initially one person is needed, expert in bioinformatics. Possibly more people needed later.

Eugene Koonin described experiences of other microbial genomes, including data on protein fold recognition patterns, and development of systems that allow functional characterization Martin Aslett described his work at EBI curating Brugia malayi, Schistosome, and Trypanosoma cruzi genome projects . He identified needs to maintain analysis once the sequencing centres had finished, to liaise with major bioinformatics centres, and to put a dedicated person in place early on in the project.

Many aspects had been covered in the previous two sessions, but points were made that it would be useful to be able to track publications relevant to the malaria genome in NCBI tools such as Medline. Journal editors should require authors to quote accession numbers .

Malcolm Gardner put a brief case for doing a second-generation shotgun on P. vivax, assuming that cost reductions and higher throughput may become available as a result of the new generation of sequencing equipment.

The meeting reconvened after lunch to discuss the workshop proposal and it was generally felt that workshops or focus groups on the first three topics would be useful. A workshop on drug discovery and vaccine developmnet was felt to be premature.

Note : Funders will draft letters of invitation to individuals identified by them (in a follow-up conference call) as likely members of the focus groups. BWF to initiate arrangements for next meeting to be held at Hilton Head. Wellcome Trust to  book Hinxton Conference Centre for July 1999.

A meeting was held on 11-12 December 1997 in Orlando, Florida to discuss progress in the malaria genome project, develop consensus on policy issues, and identify needs for future activities that will translate the knowledge gained from sequencing the genome into new knowledge about the disease.

Wellcome Fund's ongoing support of Malaria. The Fund has earmarked $4 million dollars for malaria genomics, and approximately $2.9 million of this has been spent. Approximately $3 million has also been given for malaria research through the Fund's regular award programs.

US Department of Defense's efforts in this area. DoD began working on malaria genomics two years ago and met with TIGR in January of 1996 to begin looking for ways to fund a malaria genome project. The DoD's objectives are to finish and annotate the complete sequence of the P. falciparum genome and to produce significant quantities of genomic sequence from P. vivax. DoD's budget for sequencing in malaria is projected to be $8 million during the next 5 years, with $1.425 million to be spent directly on the project in FY98. The majority of the funds are allocated to the TIGR/NMRI team with additional funds going to WRAIR for P. vivax cloning and development of bioinformatics expertise for use of the sequence data for malaria drug development.

The database will provide "one stop shopping" for users and aims to be comprehensible to researchers, making access to genomic information easy and intuitive. Although the database will be centralized in terms of bringing data from the project, the data can be physically dispersed at sites around the world. Information now at the site includes EST data from John Dame's group; mapping, marker and sequencing data from Tom Wellems' group; and data at the web sites of the three large scale sequencing groups.

Ross Coppell talked about the need for a next generation of archiving. His work with databases started well before the malaria genome project with a WHO-sponsored database giving researchers in endemic areas access to a copy of available malaria sequences.

The Stanford group has also been doing comparative sequencing using dye primer and dye terminator chemistries to compare the costs of the two technologies. So far the sequence data and mapping data is largely in agreement. They hope in the next 6 months to a year to finish the shotgun sequencing phase of the project.

The Sanger group is waiting for DNA from chromosome 13 from which to make a library, and libraries have been prepared for 2 fractions of the blob. Dan Carucci from NMRI agreed to send the chromosome 13 material. A small number of shotgun reads of sequences from the blob have been generated.

Daniel Lawson will be working full time on the malaria project starting in January. For chromosome 1, analysis has predicted 185 orfs, and there is an estimated gene density of 1 gene/4.5 kb, or a total of 200-250 genes on the chromosome. If this density is typical for the organism, then approximately 6500 genes are predicted for the whole organism. 26% of the genes identified are spliced, mostly edited with small splices at their 5' ends.

Steve Hoffman pointed out how much has been learned from the intensive effort that has gone into the assembly and closure phase of the chromosome 2 project after the end of the random sequencing phase. He also touched on how critical it will be to utilize this experience to develop the most efficient methods for assembling and closing the entire genome, since this level of effort my be impossible to sustain for the entire project.

Chromosome 2 has 80.2% AT as determined by sequence. At the time of the meeting there were 6 large contigs, 5 sequence gaps, and 3 physical gaps. There was 949 kb assembled, and closure was anticipated for January. The coverage criteria for TIGR is that there will be at least double clone coverage at every base pair, and that sequencing of each base pair will either be in both directions or by two chemistries.

Dyann Wirth discussed cloning strategies worked out by her lab. They have been developing methods for cloning P. falciparum DNA in E. coli, and have found that large fragments are unstable in E. coli. This has been more problematic with DNA from P. falciparum than from the other plasmodia. Traditional phage and cosmid libraries made with P. falciparum DNA are not representative of the entire genome.

Wirth's lab has looked at a large number of different E. coli rec mutations and found that regardless of the genotype of the host, there is a great deal of rearrangement of falciparum DNA. These sequences are not inherently unstable in E. coli- rather, they are unstable in cloning: they have to be closed circular DNA to be stable when cloned. After searching through strains deficient in recombination and DNA repair, the SRB strain from Stratagene has been identified as a good host for cloning. SRB is very different from the newer cloning host strain SURE, which is now being advertised as a good host for cloning unstable DNA. The only difference in the advertised genotypes of SURE and SRB is that SURE is recB- and SRB is recB+, but the advertised genotypes may not be complete and the strains may differ in other ways.

David Schwartz gave the group an overview of how his optical mapping technique works. Briefly, DNA is applied to a charged microscope slide, where it adheres. It is then is treated with restriction enzymes, which cleave the DNA on the slide surface without displacing the fragments from each other or from the slide. Quantitative fluorescence allows determination of the length of the resulting fragments.

David Kemp was not able to attend the meeting, but sent along a letter that was read to the group.In it he asked whether the community feels the completion of the chromosome 13 map would still be useful.. The status of the YAC mapping project was shown to the group. There are two chromosomes that don't have YACs- chromosomes 10 and 11, and chromosomes 6 and 7 haven't had much work done. Since the availability of optical mapping may change the project's need for other kinds of physical mapping, consideration of the necessity for completion of the chromosome 13 map has been put on hold for the moment.

They are trying to make the best use they can of the chromosome 2 YACs in assembling the sequence. Daniel Lawson said that Sanger also looks for multiple clones over regions. Richard Hyman said Stanford looks for multiple clones or confirmation by two chemistries. Hyman pointed out that with all the groups using the same techniques, it is possible that there is systematic error that won't be detected.

Discussion revealed that the data usage/acknowledgment statement circulated before the meeting was still not right, as it left doubt about when data could be used and what constituted fair use. Concern was expressed that those who are working hard to finish chromosomes could miss out on the chance to use the data that they have generated. The evolving data release policy represents a balance between recognition of the genome centers' need to publish fully annotated sequence and the need to bring the genomic data rapidly to the greater malaria research community. It was agreed that there were no fundamental and insoluble disagreements- rather, the objections to the statement could be solved by "better wordsmithing". It was agreed that another pass at the statement should be made, and Michael Gottlieb took responsibility for circulating a reworded statement.

Wirth also suggested developing fellowships for getting endemic country scientists involved in the genome project. ICCBNet, an international bioinformatics network for the third world, is a UN-sponsored project being handled by the Weizmann Institute.

Michael Gottlieb talked about the Malaria Repository: NIAID has made a commitment for 1 year (this year) and put out a request for proposals for a 7 year contract to build and maintain a malaria repository. The repository will offer reference standards for the community: strains, antigens, etc. In the future, it might be expanded to include things like the DNA microarray technology. Within the first year there won't be any live materials, but the initial repository will have field samples, dot blots, and other non-living samples.

Make full length cDNAs of everything Making full length cDNAs of chromosome 14 is to be funded as a 2 yr project Verification/validation- checking whole chromosome vs. known sequences Develop the database- ultimately will be, effectively, the encyclopedia of malaria Develop better sequence tools for the biologist- something up, running, and ready to be played with.

Discussions for the establishment of a global repository(ies) for malaria research material and reagents continue. Initial funding for such a resource is being obligated by the US-NIAID/NIH. Further, a NIAID planning meeting with malaria researchers is scheduled for November 24-25 to obtain advice and set priorities for initiating the development of this resource.

Strong interest has been expressed for the development of a very practical user-friendly centralized database for analyzing and utilizing malaria genome sequence information. Discussions continue to determine how best to make this a reality.

Sanger Centre will complete chromosome 3 and TIGR was to initiate sequencing of chromosome 2. Since that meeting, these sequencing centers and a group at Stanford have agreed upon dividing the remaining chromosomes among themselves.

Discussion should be held within the broader malaria community on additional malaria genome projects that would advance research and would lead to development of diagnostics, drugs and vaccines. Issues under consideration included which other malaria species (P. vivax and/or rodent malaria, other) should be sequenced either as full scale sequencing or more limited EST or GST projects; also, are there other projects which would complement the large scale sequencing effort underway for P. falciparum?

Thought should be given to mechanisms by which the information derived from the genome project would be made available to the entire malaria community in a manner that would promote its optimal utilization.

At the request of the Burroughs Wellcome Fund, the Malaria Foundation convened the Malaria Genome Focus Group, which was held on April 7, 1997 in Rockville, Maryland, USA. This group (participants listed below), came to a general consensus on the following points up for discussion. Additional considerations provided by other members of the scientific community, also listed below, have since been condensed and incorporated as summarized commentaries.

Networking and the sharing of information and resources are crucial, and the malaria genome discussions should be kept open in the broad scientific community, particularly since the output should reflect the wishes of the research community. There is a strong desire for others to enter the discussions that have begun, and to broaden the forum for debating the management and use of information obtained from the malaria genome sequencing projects.

It was further stressed that this is a global project. Although the sequencing collaboration described has been largely a US/UK venture, it is important that these efforts are not seen as exclusive. Other groups currently play facilitating roles, and attention on the efficient dissemination and use of this information worldwide was considered crucial. Additionally, the importance of involving scientists from malaria endemic countries was stressed, with special emphasis on their need to be able to electronically access malaria genome information from databases.

Overall this was viewed as a thorough listing of key biological questions to be addressed. An additional point made was that the information from a single genome would be only a starting point for understanding the antigenic repertoire for vaccine development. However, once one P. falciparum genome is sequenced, high throughput sequencing will not be required to determine the antigenic repertoire for most vaccine candidates. On the other hand, analysis of the var gene repertoire, if to be accomplished, will require sequencing of large amounts of DNA of the order of 0.5-1.5 Mb per isolate, and would require the involvement of a number of laboratories.

Several individuals mentioned funding concerns, and it was stressed that basic funding to maintain many productive laboratories is already limited. Several contributors also indicated that while this document is quite comprehensive and well thought out, it lacks emphasis and direction (short and long term) regarding how best to accomplish objectives of utilizing genome information to answer biological questions, especially in a cost-effective manner. Follow-up discussions should address these issues, and it was suggested that a list of action items specifying what is being done by whom, and, perhaps, how and by when, be included in this and subsequent reports on malaria genome projects.

Much discussion was raised about another genome. Several people emphasized that P. falciparum is the first priority, and that given the current funding situation additional sequencing efforts may be difficult to consider at this point. If another genome project were to begin, support was for the EST/GST sequencing approach, rather than whole genome sequencing. Obtaining ESTs/GSTs is relatively inexpensive, and they provide good "seed data" even though the corresponding sequences are not complete. Although the importance of P. vivax as a human parasite and the value of P. vivax ESTs/GSTs was emphasized, several individuals stressed the greater accessibility of rodent malaria to the broad malaria community (i.e. many more laboratories can work on rodent malaria) and the usefulness of these models to approach important biological questions such as cytoadherence. For these reasons, if entire genome sequencing were to proceed for one additional Plasmodium species, support for a rodent parasite outweighed that for P. vivax. Although rodent malaria models continue to be generally recognized as more amenable to biological studies by a larger number of laboratories, hope was expressed among those working with P. vivax that continued development and support of a P. vivax network would overcome several of the existing difficulties for a number of groups to study P. vivax. Recent advances in culturing P. vivax may also facilitate future studies on this parasite.

It was noted that, ideally, one should consider the availability of the life cycle, the ability to transfect the parasite, the availability of data on cytoadherence, the availability of antigenically diverse isolates, and whether or not one better represents a biological model for P. falciparum especially with regards to pathogenesis. Several researchers provided support for the consideration of P. chabaudi, with the argument that it provides a more suitable biological model for P. falciparum than the others and provides a model for understanding questions on antigenic variation and sequestration. It was also noted that transfection vectors are available for P. chabaudi, but whether or not P. chabaudi transfection has been achieved was not mentioned. A number of additional characteristics were highlighted "for P. chabaudi," which may be best as part of a full paper on the subject, comparing and contrasting the different models. It was also noted that one priority should be to determine if transfection experiments have been or could be performed with rodent malarias other than P. berghei. P. berghei was supported because it has the advantage of an in-vitro system and has been transfected, but the limitation of an apparent lack of genetically diverse isolates was noted.

Other support was expressed for P. yoelii as a model for vaccine development utilizing sporozoite challenge. Some additional discussion has followed on the possibility of obtaining EST/GST information from more than one rodent parasite. It could be extremely useful for researchers working with the different rodent malaria models to meet and elaborate on the pros and cons of each of their systems.

Additional comments were made about the potential need to sequence more than one isolate of P. falciparum, at least for targeted regions of the genome, to understand about sequence diversity especially for particular biological questions such as agglutination or cytoadherence.

What tools/reagents will facilitate full utilization of Plasmodium genomic information that is generated? What complementary projects should be initiated now to maximize the use of incoming malaria genome information?

DNA sequences in E. coli, as well as the presence of frequent very long stretches of A or T sequences, are likely to be significant problems in the derivation of the complete and accurate P. falciparum genomic sequence. Hence, it is recommended that a systematic effort be undertaken to explore various strategies to overcome this problem. These could include identifying alternative host-vector systems, or identifying E. coli mutants in which large fragments of P. falciparum DNA can be stably maintained.

One immediate application of sequence information will be in the area of molecular genetic analysis. Several necessary molecular tools now exist, but improvements in their application and efficiency of use are of high priority.

Basic genetic manipulation of malaria parasites should be further developed and improved. This will require the identification and utilization of additional selectable markers, the enhancement of transfection efficiency, as well as the identification of promoter/regulatory regions for differential and stage-specific expression.

Complementation analysis capabilities should be developed, which could include the use of heterologous systems such as yeast and Toxoplasma gondii, as well as the malaria parasite itself. This will be facilitated by the identification of centromeres for chromosomal complementation and the development of Plasmodium artificial chromosomes.

Information and materials from currently recorded laboratory genetic crosses is extremely valuable and should be made generally available to the malaria research community. The development and analysis of additional laboratory genetic crosses, as well as studies aimed at comparatively analyzing natural crosses, should also be given consideration.

It was noted that the need to develop means of stably cloning large fragments of P. falciparum is critical for utilization of the genome information, and more resources should be dedicated to solve this problem; stability is initially important for obtaining reliable sequence, but will also be important for conducting biological studies. It was also noted that mapping of EST/GST sequences to YACs would provide valuable landmarks for assembling and ordering sequence. Additionally, the problem of low transfection efficiency was emphasized as a barrier to full utilization of the sequence information; thus, investigations to improve transfection efficiency should be a priority.

Complementation of heterologous systems clearly should be exploited, but whether a large effort on P. falciparum artificial chromosomes should be a priority was questioned. Overall, the suggestion for the development of new genetic tools is a good one, but new funding sources will need to be developed to turn this into reality.

Many comments addressed the establishment of a repository or repositories, how they might be set up, and how they would be funded. It was emphasized that a mechanism(s) for long-term funding was especially critical. In addition to items mentioned in the text above, it was indicated that parasite lines should be standardized by a set of internationally agreed upon criteria, and that the culture history of each line from whichever sentinel stock is used should be known. Well characterized, strictly defined and representative libraries could be useful in some cases for P. falciparum (ideally 3D7), P. vivax and rodent malarias; however, in many cases defined primer pairs and PCR protocols could replace the need for DNA libraries. A desire for YAC libraries, yeast for growing and expanding YAC libraries, plasmids which are used for sequencing, and bacterial strains which people have found good for malaria DNA stability, was also expressed. It was also noted that stage-specific and organelle-specific markers (e.g. specific antibodies) for P. falciparum, P. vivax and rodent malarias would be valuable in a repository. Support for the development of a catalogue/database directory of reagents with their sources and properties was also expressed by several individuals. The issue of corporate rights to certain reagents was also mentioned as a barrier to the availability of some reagents, and that up-front discussions with companies, before products are produced, might enable the development of mechanisms to place future products in repositories.

It was also noted that the assembly and dissemination of reliable protocols would be very valuable especially for scientists beginning to evaluate genomic information in developing countries. Basic protocols, not involving the use of expensive kits, could include standardized methods for the isolation of DNA and RNA from parasitized blood samples, and PCR and rtPCR conditions for analyses involving specific genes or gene regions. These would facilitate the widespread use of the genome information.

What is the best way to facilitate access to information generated in malaria genome projects for the broader scientific community? How can the current databases be linked and the information be shared in a common format?

There is clear frustration with the currently available genomic DNA databases, as it is difficult for a biologist/malariologist to readily obtain much useful information from them. Besides, it was noted that simply handing our needs over to Genbank personnel would be a mistake, as they have no particular expertise in genome information as opposed to sequence information and, additionally, have no particular expertise in malaria.

Very strong support was expressed for the development of a database that would allow easy access to information and would allow biological questions to be approached directly (and without the need to rely on the aid of a bioinformatician, which for many groups is not even available on-site). For example, it could be useful if one could ask for the sequence of all genes with a putative signal or anchor sequences or GPI attachment signals. It was suggested (wished) that an integrated and fully annotated "malaria information resource" database be developed that covers not only genome information, but immunochemistry, localization, monoclonal antibody data, protection studies, variant sequences, etc. A dedicated knowledgeable malariologist would be required to annotate it and keep it current. Importantly, the malaria research user community should be actively consulted throughout the development process to ensure that this resource best meets their needs. In fact, the point was made that people will want to be involved in the process of putting together information to make an effective database. The availability of links to appropriate literature was also suggested, especially to facilitate entry of newcomers into malaria research. The presence of mirror sites in different countries was also deemed important.

How can comparative genomic approaches facilitate our understanding of malaria genome information? How can "genomics" be used to obtain information beyond that which can be obtained from "pre-genomic" approaches?

Genomics as a science is relatively new and there is clearly a lot to be learned from the many genome projects being conducted today, which could assist investigators in understanding the information contained in malaria genomes.

Information from malaria genome project efforts should be linked with information derived from other microbial genome projects. These links should be made to the public sector and to the private or industrial sector.

It could be very useful if a few people working on other genome projects were invited as guest speakers to the biannual malaria genome meeting. On the other hand, it was noted that "given the parlous state of malaria funding, we will be hard pressed to exploit the possibilities generated by the coding regions alone, without bothering with nebulous concepts of genomics."

The current effort is a multilateral initiative supported by international funding agencies from Europe, the United States, plus the World Health Organisation, to strengthen malaria research capability and control in Africa. What was unique about the Durban conference however, is that more than 50 percent of the delegates were highly trained African scientists, technocrats, public health experts, clinicians and other health professionals committed to the control and perhaps eradication of a neglected disease, that has brought the continent to its knees. The high quality presentations by these African professionals, working both inside and outside Africa, rekindled the hope that "Africa has come of age, and is, no longer, a dark continent".

In Durban, we were told that there is "no magic bullet" for controlling malaria. An effective vaccine against the disease may not be realised for the next 20 years or more. The available drugs of choice, especially chloroquine, are becoming less effective, because the malaria germs are becoming resistant to them. Control efforts through the use of insecticides and treated bednets is becoming problematic, as the mosquitoes that transmit the germs are developing thick skins for the insecticides. There is urgent need therefore to evolve new strategies for combating the disease. This was the major theme at the African Malaria Conference. There was a strong advocacy for an integrated approach, involving the use of drugs, prompt diagnosis, insecticide sprays and treated bednets, proper case management, and proper environmental management geared towards vector control, plus a continuous search for an efficacious vaccine.

African governments. The onus of responsibility lies in their hands to ensure that these efforts are maximised towards alleviating the burden of malaria on the continent. One way forward is to actively involve the Ministries of Health in Africa, in this global effort through an improved primary health care schemes directed towards disease prevention and control.

Prevention they say is better, and in fact cheaper than cure. Most African countries have a national malaria and vector control program that could be restructured to meet the current needs. To generate adequate information on disease prevalence, clinical cases, mortality and morbidity, surveillance of drug treatment failures that would be useful in policy changes. They would be responsible for public awareness, for instance, educate the people on how to minimise man-mosquito contact and thus, reduce malaria transmission.

Developmental projects like construction of dams and urban planning should involve health professionals to avoid environmental degradation that gives rise to new breeding sites for mosquitoes. Health care services should be taken to the grassroots at community levels, where the disease is prevalent.

Increased funding for malaria research in the national medical research institutes and universities. Non-governmental organisations (NGOs) and private-sector industries, especially the pharmaceuticals with a stake on national health should be encouraged by sound health policies to participate in disease prevention and control. Hospitals, especially university teaching hospitals and general hospitals should be properly equipped for prompt and adequate diagnosis, monitoring and surveillance of drug resistance.

Malaria drug therapy may soon be changing to a multiple drug regimen, as in the treatment of TB, due to widespread resistance, but such decisions must be based on scientific evidence, to avoid expensive and un-affordable prescriptions in health centres, and drug policies that may increase the prevalence of resistant malaria in the community. African governments should support vaccine research, training of high quality personnel, collection of malaria baseline data in endemic communities towards an eventual vaccine trial in sites located in Africa. National Malaria & Vector Control programs should augment and co-ordinate the activities of the various NGOs and international organisation involved in malaria control in Africa. This author observed with satisfaction the presence of officials of the Ministries of Health from most African countries at the conference, for take-home messages to their administration. Africa with its vast human and material resources should take up the challenge in this people-oriented initiative.

It is worthy of mention that international organisations like WHO, UNICEF and UNDP are bringing their many years of expertise in managing human health and resources world-wide, to bear on the disease.

The World Bank president, James Wolfensohn, noted that "making significant, sustained inroads in the battle against malaria urgently requires a co-ordinated, focused initiative, and that governments, international organisations, the research community and the pharmaceutical industry must all play a major role". Nigeria's Professor Ayo Oduola gave an excellent treatise on the deplorable malaria situation in Africa and the objectives of the initiative. He solicited for support from the rich industrialised nations and funding agencies. African governments should complement and support this timely initiative to reduce the burden of malaria on the continent.

The meeting in Durban was also used as the site to launch the Drive Against Malaria (DAM) in Africa, in partnership with the Malaria Foundation International (MFI) and Memisa. British global explorer Dave Robertson is attempting to set a record driving around the world - and South Africa is the 27th country he has visited. Dave is using this journey to spread awareness of the devastation caused by malaria and to raise funds and political support for education and malaria control efforts.

On a lighter mood, it was not all malaria talk-show throughout the conference, the participants took time off to play tourist, and indulge in culinary adventures, sampling the different foods and wines, representing the diverse culture of South Africa. There was also an opportunity to teach our American and European colleagues how to dance to typical African rhythms. This was in one of the many relaxation joints dotting the beaches around the city of Durban, with its well-laid out streets, gardens and parks. On the other extreme, this author also visited our African brothers and sisters, the Zulus, in their "homeland", one of the relics of the old political dispensation in that country. The Multilateral Initiative on Malaria in Africa has been started and nurtured by the developed world, where malaria is non-existent, it is the duty of Africans to maintain the momentum of this international effort, for its immense benefits, which according to Roll-Back Malaria includes a drastic reduction in the malaria burden in Africa, reduction in poverty and an appreciable human resource development. We all stand to loose, if this initiative is not supported, and allowed to fissile out, as the disease will continue to undermine Africa's economic development.

He is also interested in bridging the gap between scientists and policy-makers in Africa, and in encouraging the most effective use of available resources for malaria control on the continent. He is a Fellow of the Royal Society of Tropical Medicine & Hygiene, London.

The problem of emerging antimalarial drug resistance in Africa has been prioritised for concerted action under the Multilateral Initiative on Malaria (see MIM meeting reports, Papers 3 & 4). The immense implications of this problem for malaria control efforts has stimulated considerable activity by a range of sponsoring organisations. These various agencies have different contributions to make towards addressing the overall problem and it has become evident that there would be considerable benefit to be derived from promoting increased integration of their activities, and developing clear plans for concerted action to address outstanding needs.

As the nominated co-ordinator of the MIM for this year, the Wellcome Trust has agreed to convene a meeting to bring together relevant agencies in order to work towards greater integration of the full range of research, policy and implementation activities relating to antimalarial drug usage, and to identify any critical gaps not encompassed by current programmes. The meeting will also provide a forum to explore research-development interactions on a broader basis.

The focus of the meeting will be on the interface between research and implementation, including the processes for a) maximising the impact of current research, and b) defining further research necessary to formulate policies for antimalarial drug usage, and to develop standardised, effective methods for monitoring drug resistance. To this end, the meeting will include representation from a range of different organisations involved in malaria research and control activities.

The meeting will aim to summarise in broad terms the research and implementation programmes supported by different organisations that are of critical importance to developing and applying a rational approach to deal with the challenge of emerging antimalarial drug resistance. This overview of activities will allow identification of areas of overlapping interest between agencies, gaps in activities and constraints. It will also form a basis for considering opportunities for more effective harmonisation of activities. In this context, discussions will explore mechanisms for review of scientific advances and for policy development; communications links between research communities, policy makers and implementors; and mechanisms for orientating research agendas to on-the-ground needs in malaria endemic countries. The type of issues considered to fall within the remit of the meeting are set out in Paper 2.

The meeting has been constituted to focus on broad programmatic issues, such as the contributions and responsibilities of the different players in the transition from research through to policies and implementation, and the integration of these activities. It will not be a forum to prioritise specific research questions or to formulate policies and recommendations for deployment and use of antimalarials. However, it is anticipated that further workshops or meetings will be organised to tackle specific research or policy development issues in depth, where they are not adequately being addressed by existing activities.

The meeting will also contribute towards addressing a further agreed priority of the Multilateral Initiative on Malaria: to promote creative interactions between the research and development communities.

Developing research capacity in Africa, increasing international co-operation and communication at all levels, and ensuring that research findings are actually applied to malaria treatment and control are central objectives of the MIM initiative. By promoting co-ordination between the range of agencies and individuals concerned with malaria, the MIM aims to maximise impact of global activities against malaria. The initiative arose out of preliminary discussions between a number of organisations supporting malaria research activities. The outlook was subsequently broadened with the recognition that the full benefit of research could not be realised without the close involvement of the communities responsible for implementation of public health activities and for the commercial development of tools for malaria control and treatment.

The fifty participants at the two day meeting held at the Wellcome Trust on November 10/11 1997 were mainly representatives of governmental, non-governmental and international agencies supporting malaria research or control activities, together with a number of senior malaria researchers.

These participants were clearly committed to the principles of a concerted effort against malaria. The primary role of the meeting was to build upon progress made at earlier meetings, by defining more clearly the specific priority areas impacting upon the problem of malaria in Africa, that would benefit from concerted action by funding agencies, and by identifying the initial steps required to address these areas.

At the previous meeting in the Hague it had become evident that the differing remits and funding mechanisms of the range of organisations sponsoring malaria research presented substantial barriers to the establishment of a common fund for MIM-related activities. It was therefore acknowledged that any joint activities must allow individual agencies to operate within the constraints of their particular mandates. As a consequence, the MIM has taken the form of a loose alliance of organisations and individuals concerned with malaria research and control activities, as opposed to a defined body with a formalised administrative structure.

It has been agreed that, as far as possible, activities prioritised by MIM should be supported through existing mechanisms offered by the range of participating organisations, in order to avoid unnecessary creation of new levels of administration and to fully utilise the diversity of established funding mechanisms. However, where required, concerted action will be taken by MIM agencies to establish new initiatives to fulfil specific identified needs. For example, the new scheme for Malaria Research Capability Strengthening in Africa was established through the WHO Special Programme for Research and Training in Tropical Diseases with funding from a variety of sources.

Current malaria research activities and new initiatives established since Dakar were summarised at the meeting in London; this information being an essential basis for integrating ongoing activities, minimising duplication of effort and optimising further investment of resources.

The above list was not intended to exclude other specific priorities, but represented areas that required immediate concerted action by sponsoring organisations. It was agreed that agencies participating in MIM should nominate representatives to act as a contact group that would further progress the general aims of MIM, while sub-groups of these agencies should take forward the separate initiatives identified above, according to their individual mandates and expertises. The Wellcome Trust accepted the nomination to serve an overall co-ordinating role for MIM-related activities for the first year.

The Multilateral Initiative on Malaria (MIM) is a newly developed forum for researchers, governmental and non-governmental agencies concerned about malaria. Its role is to facilitate a globally coordinated response to malaria in Africa where 90% of cases occur. Following previous meetings at Dakar and the Hague, a 2-day meeting of the funding agencies involved in the MIM met at the Wellcome Trust in London on 10 and 11 November 1997.

To support a working group to explore ways of maximising creative interaction between the communities involved in malaria research and malaria control in order to optimise the use of available methods for control and treatment of malaria, including the scientific and economic evaluation of intervention trials.

To create an inventory of the infrastructure which exists within African malaria research centres to assess the capacity for activities relating to research and control with the objective of maximising and improving the technical and human resource within centres.

To create a working group to address issues relating to policy on the use of antimalarial drugs and on mechanisms for surveillance of resistance of those drugs within Africa, this working group to be established in collaboration with the World Health Organisation.

To establish an MIM Contact Group to coordinate the further progress of these separate initiatives and the general aims of MIM. The Wellcome Trust will serve this coordinating role for the first year.

The meeting in The Hague was meant to discuss the practical consequences of the recommendations made in Dakar and what was needed to realise co-ordinated investment into broad malaria research activities, such as proposed in the Letters of Interest. To that end the meeting brought together 60 participants from 17 countries (mostly donor countries) and international bodies, such as WHO, the EC, The World Bank and UNESCO .Most participants were senior administrators in their respective agencies.

An immediate role :To facilitate Collaborative Efforts between scientists and control workers and therefore also between supporting agencies and thereby providing a context and a suitable environment for training and capacity building of young scientists from developing countries.

A potential long-term goal: To serve as a Global Forum for malaria-related discussions and political awareness and a political context for co-ordinated action of traditionally separated bodies, such as research and development agencies.

The long-term goal is of much wider implication, involving all possible players as much as possible. This aspect was discussed mainly at day two of the meeting. Day 1 concentrated on the practical possibilities of national and international research agencies to work more closely together (related to a).

It was decided to attempt to achieve the MIM objectives initially within existing research funding mechanisms and to achieve the desired added value mainly through co-ordination and synergistic action. Especially in the field of Research Capacity Strengthening (RCS), immediate and common actions could be envisaged.

The short term aim of MIM is to foster international and mutually beneficial scientific partnership between (more) African Scientists and their colleagues in the North working on malaria-related aspects.

In case the operational phase reveals the need for additional mechanisms, specific working groups may develop proposals for adapted procedures acceptable for all participating agencies in close consultation.

Where needed, the agencies will jointly take responsibility for providing necessary funds for proposal-development workshops. This could be of specific interest for those areas where the letters revealed an obvious need for synthesising different proposed activities and weeding out of unnecessary overlap.

The signatories of the Letters of Interest will receive the matrix analysis of the Letters and the full list of addresses of signatories. This will allow them to efficiently get together a group of interested scientists working on related topics. Proposals can be developed in workshops for which funding can be provided on a competitive basis by one or more of the participating agencies.

The Dakar conference put such a clear emphasis on communication and exchange that the agencies will already now take a specific initiative in a co-ordinated fashion to get this aspect started as soon as possible.

These parties, potentially complemented by others, comprise most of the high quality expertise needed to try and solve the technical problems associated with more effective communication between scientists, notably in Africa, but will need to be provided with the operational funds to make it happen.

At the second day a broader picture was discussed, which stretched beyond what research agencies alone can do within their mandates. The organizers of the DAKAR conference had realised that important other sources of support to the malaria research and control community are needed for the MIM to have an impact beyond more efficient use of existing research resources.

The Development Agencies have their focus more on downstream issues of research and on the control aspects of diseases. RCS and implementation projects as well as application-oriented and operational research are therefore more likely to fall in their area of interest. It became clear that there is an increasing awareness all around the globe that science is an important instrument for development. Therefore, we witness a growing interest from the side of the development agencies to co-ordinate their efforts with the research agencies. The research agencies in turn recognise more and more that supporting high quality and relevant research in Africa is not enough in the long term. There must be a context for growth of the research opportunities and the implementation of research results. It became very clear from the discussions, that this continuum can only be created if the research and the development agencies co-ordinate with the governments of the African States and develop a coherent research and implementation policy.

Evaluation of candidate drugs and vaccines up to the phase where they become attractive to industry should be taken up by the public sector, and the support to governments of endemic countries could finance the market. The latter aspect would be crucial if we talk about either a vaccine designed for use in Africa or drugs that have no use as a travellers prophylactic.

The entire range from basic research to control and development issues related to malaria should be viewed as a continuum and the role of each player in that process should be identified to facilitate co-ordination.

Assuring a reasonable market in a context of cost-effectiveness can be a major contribution of Development Agencies to promote the involvement of Industry in the development of new and improved tools.

Demonstration of feasibility to a much higher extent than up to now could be a valuable contribution of the public sector research to promote the industrial development of drugs, vaccines and diagnostics.

Both NIH and the EC have developed plans for concerted activities in the field of malaria vaccine development- and evaluation The Wellcome Trust, WHO, the World Bank and others are involved in a consortium approach towards the development of new drugs.

The comparative advantage of the MIM vis a vis this big challenge should be spelled out clearly, to result in concerted efforts where scientifically feasible and to generate a significant increase in resources invested in malaria.

Overarching goal The original overarching goal of MIM was "to strengthen and sustain, through collaborative research and training, the capability of malaria endemic countries in Africa to carry out research required to develop and improve tools for malaria control."

However, co-ordination of research activities in isolation was recognised to be insufficient to ensure that research findings yield practical health benefits and the remit of the MIM has been broadened to encompass strengthening of the research-development interface.

Further development of human resources and institutional capacity in Africa is essential to enhance the ability of African countries to address their own health problems. MIM aims to publicise existing training opportunities and further develop research capacity by facilitating effective scientific partnerships across Africa, and between African researchers and colleagues internationally.

To ensure research findings are applied to malaria treatment and control and to translate practical problems into manageable research questions. MIM aims to stimulate and facilitate dialogues among scientists, public health professionals, policy makers and industry.

An alliance of organisations and individuals concerned with malaria research and control, including donor organizations (governmental, non-governmental, international agencies and private foundations), scientists, health professionals, and industry.

Catalyses concerted efforts to address specific identified scientific problems and needs to ensure full exploitation of scientific opportunities. This may involve collective or individual action by organisations or scientists to organise meetings or workshops, and establish new initiatives.

Wellcome Trust is acting as the nominated co-ordinator of MIM activities during 1998, and has allocated staff and funds specifically for this purpose in recognition of the importance and responsibility of this role. [List of organisations involved in MIM].

MIM originated in discussions between a number of organisations supporting malaria research. As such, the priority focus of MIM is to promote and facilitate communication and collaboration in the research community, and strengthen research capacity in Africa, while advancing critical areas of malaria research.

A major objective of MIM, however, is to ensure that practical health benefits arise from research and close liaison with the control community and pharmaceutical industry is therefore critical. MIM is fully committed to integrating its activities with the major new malaria control initiatives (WHO/World Bank African Malaria Control Initiative, and Roll Back Malaria) to ensure that research findings are actively fed into these programmes and that research necessary to underpin policy decisions is carried out.

Despite the severe impact of malaria in Africa, through morbidity, mortality and socio-economic loss [Disease figures], international public and private investment in malaria research has historically been low relative to the burden of disease [Wellcome Trust Report, 1996. Malaria Research: An Audit of International Activity].

A limited repertoire of tools is available for treatment and control of malaria, but more effective application of these tools is required, together with the development of novel approaches to tackle the disease.

Recent technological and scientific developments have advanced our knowledge of the malaria parasite and mosquito, but the impact of these advances on the malaria burden faced by endemic countries has been low. MIM recognises the importance of developing collaboration and co-ordination not only within the scientific community, but also at the research/public health interface.

The fact that most laboratory malaria research is carried out in the USA and Europe, whilst control must be implemented in malarious regions, means that effective communication among scientific, medical and public health communities across these regions is critical to the effective translation of research findings into practical benefits.

With the worsening of the malaria situation world-wide, governments and donor organisations recognised the need to formulate a new multilateral response to the problem of malaria, including increased financial inputs. A range of different activities concerned with the problem of malaria in Africa is ongoing independently, but there is a need for a formal mechanism by which these activities can be orchestrated into a more cohesive global effort.

The following list represents activities that have been established during 1997 and 1998 following the MIM meeting in Dakar. Some are investigator-driven initiatives while others represent proactive responses of particular donor organisations to address the research priorities identified in Dakar and other identified needs. The list includes activities stimulated directly as a result of the MIM, and also other activities developed within the current climate.

Publicity and advocacy are required to increase awareness of the public health significance of malaria, to raise the status of malaria on political agendas, to mobilise resources and to stimulate action.

A MIM newsletter will be produced and circulated to all MIM members every two months and will provide up-to-date information on all the latest developments at MIM. The newsletter is intended to serve as a forum where all participants and other interested parties can share their news, views and information, particularly those without electronic access to the web pages.

Malaria Network has been developed by WHO/CTD in collaboration with the World Bank to provide easily accessible support for malaria programme managers. The global network will function through an Internet web site and aims to provide information on operational issues in the management of malaria control programmes. It will collect and make accessible information relevant to malaria control activities in the field and will also function as a forum for discussion for participating managers and senior health workers both among themselves and with WHO/World Bank.

A proposed plan for a public-private alliance for development of antimalarial drugs (with the goals of producing one registered product every five years and of becoming financially self-sustaining in the medium term) was not supported by industrial partners in November 1997. Discussions on an alternative format for the initiative are continuing.

For Monitoring Antimalarial Therapy A regional network established in 1998, between Kenya, Tanzania and Uganda to monitor antimalarial drug resistance in the region Towards a global surveillance network of anti-malarial drug-resistance (EC supported concerted action) has the objective of improving the monitoring of anti-malarial drug resistance and establishing a system for rapid dissemination of information in order to guide treatment and prophylaxis policies. The co-ordinator can be contacted at University of Rouen, France (philippe.brasseur@wanadoo.fr).

African nations suffer from a shortage of health scientists and the further development of human resources and institutional capacity in Africa is essential for enhancing the ability of countries to address their own health problems.

Co-ordinated by TDR; formed directly in response to priorities identified at Dakar. The objective is to develop and strengthen core African research groups, promote technology transfer and local training through research activities involving partnerships between African and non-African groups. At the first meeting of the task Force in February 1998, fifteen full proposals (budget US$2.5 million) were recommended for funding. These covered several aspects of malaria research including; clinical and molecular basis of drug resistance, chemoprophylaxis in pregnancy, drug policy, epidemiology of immune response, epidemiology of parasite diversity, home-based malaria management, and vector biology. Additional support was recommended for 12 proposals for further improvements and collection of preliminary data.

Inventory of Current Infrastructure and Malaria Research Capacity in Africa (Wellcome Trust/PRISM) represents a first step towards the identification of requirements for further development of human and infrastructure resources in Africa and training requirements.

International Center and the National Library of Medicine of the National Institutes of Health have launched a new International Training Programme in Medical Informatics. The program will provide opportunities to advance research, including malaria through training in informatics and related disciplines.

A request for proposals was issued and award of the repository contract is expected before the end of 1998. The full repository will improve access to research materials (including Plasmodium parasites and vector reagents) for malaria investigators worldwide.

These have been established to provide an opportunity for local, regional or international research training for junior postdoctoral basic scientists or medical graduates who are nationals of developing countries. The Wellcome Trust offers a range of schemes through the Tropical Medicine Programme that aims to specifically promote clinical and non-clinical research in the field of tropical medicine.

South Africa, will be a MIM meeting to promote discussion and interaction between scientists and public health workers across Africa. The MIM AMC will extend the existing biennial Southern African Malaria Conference to create an all Africa conference. The last Southern African Malaria Conference, held in May 1997 in Maputo, Mozambique, was initiated and organised from within Africa, attracting over 200 delegates from 16 countries in Southern and Eastern Africa. The objective of bringing together malaria health personnel and research scientists coincides with the MIM priority of promoting integration of the research and development communities.

The MIM AMC will include African delegates from both public health and research, together with a number of key malaria scientists from outside Africa. To maintain regional cohesion, the meeting might have embedded within it parallel sessions to discuss regional malaria control issues.

Joint sessions will be organised to address critical, pan-African issues such as antimalarial drug resistance and malaria economics. The meeting will also provide an opportunity to track the progress of MIM initiatives.

Collaboration on malaria vaccine development (NIAID); Research to determine in vitro correlates of protection for an MSP-1 based vaccine for future clinical trials, through a collaborative initiative between intramural and extramural investigators.

An understanding of malaria epidemiology underlies control programmes. Relationships between transmission, infection, disease and death; impact of environmental change on malaria, and malaria surveillance for guiding health services are all important aspects of malaria epidemiology requiring further investigation.

The development of PCR techniques has enabled researchers to investigate the molecular epidemiology and population genetics of malaria parasites and the interaction of host, parasite and vector genetic diversities on malaria epidemiology.

Understanding the mechanisms of malaria morbidity and mortality will provide opportunities for new methods of disease prevention and treatment. Africa wide capacity for pathogenesis research needs to be developed, with research in specific areas, such as malaria anaemia, parasite cytoadherence, stimulated.

Malaria in African Children (supported by NIAID) - a collaborative network of clinical centres for the study of severe and complicated malaria in African children, capable of conducting multi-centre clinical trials and validating prognostic features identified in a single site.

Meeting, Hinxton, UK, 30th June- 1st July 1998. The agenda was expanded to include consideration of the mechanisms required to optimally exploit sequence information for identification of novel drugs and vaccines.

Investment in malaria research Provisional funding figures indicate that thre has been a substantial increase in investment in malaria research. Over US$100 million was invested in malaria research in 1997, compared to approximately US$85 million in 1995. During this period, NIAID increased its expenditure by 50% and the Wellcome Trust doubled its expenditure. The overall level of funding still remains low relative to the burden of the disease.

MIM recognises the importance of developing collaboration and co-ordination not only within the scientific community, but also at the research/public health interface. Historically, a clear source of funding for research at the interface with control programmes and health care provision (e.g. large-scale intervention trials, home management of malaria) has been lacking. There is a need to change the perceptions of funding agencies to ensure that mechanisms are in place to allow for operational research to be supported. MIM is working to promote constructive interactions between the research and development communities, and to address the problem of funding for intervention trials, health services research and operational research.

MIM has selected the problem of antimalarial drug usage and policy development to explore in greater depth the mechanisms required to stimulate stronger links between laboratory and field research, promote wider dissemination of research results relevant to country programmes and ensure that research agendas are orientated to provide essential information to underpin policies.

The recent MIM antimalarial drug resistance and policies for drug usage meeting in Geneva brought together individuals from 20 organisations encompassing malaria control programmes, through policy formulation, clinical and epidemiological research, and basic laboratory research. The meeting provided a forum for examining on a broader basis options for enhancing the dovetailing of research and development activities.

We are writing to you as malariologists and members of the International Board of the Malaria Foundation International (MFI), to ask for your support in endorsing an "open letter" about an impending global ban on DDT.

While we understand that DDT can harm the environment, we believe that protecting human lives from malaria demands special care. We support an eventual ban on DDT use, but ONLY on the condition that Western countries increase their funding to research and subsidize the costlier alternatives for malaria control.

In our view, setting a firm deadline to ban DDT places an unethical burden on world's poorest countries. Tropical countries simply can not afford the more expensive alternatives to DDT. Rather, the burden should be on rich Western countries to end their shameful neglect of malaria: to research and implement alternatives to DDT that both vanquish malaria and protect the environment.

ANY scientist, doctor or other person working in biology or public health is welcome to sign (no students please). You have already read a summary of the open letter above, but if you wish to read the full document (11 pages), links are at the bottom of this page for French and English versions - plain text and pdf files.

Publishing Trust for Development (EPT) supports the electronic distribution of research generated in developing countries and published in peer-reviewed journals, thus increasing visibility and closing the South to North knowledge gap.

"In recent times, there has been a strong advocacy for an integrated approach for malaria control. This involves the use of drugs, prompt diagnosis, insecticide sprays and insecticide-treated bednets, improved community-based systems, proper case management, improved health information systems, and proper environmental management geared towards vector control, plus a continuous search for an effective vaccine. This article highlights these components of a multilateral approach to malaria control, and is particularly aimed at drawing the attention of healthcare providers and indeed the policy-makers in Africa where the disease has had a devastating effect"

In this paper, we explore the determinants of cross-country differences in malaria morbidity, and examine the linkage between malaria and economic growth. Using a classification rule analysis, we confirm the dominant role of climate in accounting for cross-country differences in malaria morbidity. The data, however, do not suggest that tropical location is destiny: controlling for climate, we find that access to rural healthcare and income equality influence malaria morbidity. In a cross-section growth framework, we find a significant negative association between higher malaria morbidity and the growth rate of GDP per capita which is robust to a number of modifications, including controlling for reverse causation. The estimated absolute growth impact of malaria differs sharply across countries; it exceeds a quarter percent per annum in a quarter of the sample countries. Most of these are located in Sub-Saharan Africa (with an estimated average annual growth reduction of 0.55 percent.

Welcome to this discussion board!  This document gives you the basic knowledge that you need to use this board effectively.  If you experience any difficulties with the board, contact one of the moderators listed under the Contact link from the Main Menu.

Anyone with WWW access can read discussions on this board.  To read discussions, navigate to the discussion of interest by single clicking on the links from the list of topics and subtopics.  You can navigate backwards using the navigation bars at the top of each page.

To post a message to an existing discussion, fill in the "Add a Message" box at the bottom of the page.  You may use formatting codes or basic HTML tags to improve the appearance of your post.  At the discretion of the moderators, the discussion may allow public posting or may require a user account (username and password). Follow the instructions on the form to supply the necessary credentials for posting.

Where available, you may click on a "Create New Conversation" button to start a new discussion.  This will add a subtopic with the subject you specify and start a conversation with the initial message that you specify.  After filling in the subject line, post a message as described above.

This discussion board can be searched by time of post (New Messages search) or by matching text (Keyword Search).  Each of these searching mechanisms provide convenient methods to locate discussions of interest.

To search for new messages, click the New Messages link from the Main Menu.  If you have an account with a valid username and password, fill in your username and password in the appropriate boxes to search for messages since your last check.  If you do not have an account, you can still search for new messages posted since a given date.  The Last Day and Last Week options on the Main Menu are equivalent to searching for messages posted within the last day and messages posted within the last seven days, respectively.

To search the board by keywords, click the Keyword Search link from the Main Menu.  You can then specify the words that will be used in the search.  Additional instructions for using the Keyword Search option are displayed on the search screen itself.

To get a user account, first click the Edit Profile link from the Main Menu of this board and see if "Instant Registration" is available.  If not, e-mail one of the moderators listed on the Contact page and request a user account.  Be sure to include your e-mail address, full name, and desired username if you e-mail a moderator.

For additional information on using this system, read the Formatting document and the Troubleshooting document, available from the Main Menu.  If you have additional questions or concerns, post them to an appropriate area on the discussion forum, or contact one of the moderators or the board administrator from the Contact page.

When writing your messages, please use the same courtesy that you would show when speaking face-to-face with someone. Flames, insults, and personal attacks will not be tolerated.  It's fine to disagree strongly with opinions, ideas, and facts, but always with respect for the other person. Great minds do not always think alike, and that's where the fun is! Also, note that messages express the thoughts of the writers, not the board or its moderators.

A powerful formatting language developed specifically for this application allows you to format your posts without knowledge of HTML.  This formatting language is easy for both HTML users and non-HTML users to learn quickly.  There are examples after each major section.

The code is a keyword to invoke the desired formatting (for example, green to produce green text and b to produce bold text).  Formatting tags are case sensitive.  Formatting tags may be nested within other tags.  A comprehensive list of available formatting tags is available in this document (although the system administrator can turn off certain tags).

To use formatting, enter the appropriate code(s) in the text of your message or subject line.  When you preview your post, your formatting will be displayed so you can verify that you have entered your tags properly.

The "Symbol" font, supported on Windows platforms, allows the incorporation of Greek characters which is especially useful for mathematical notation in many scientific disciplines.  The following table gives available Greek characters in groups of 5.

If you wish to use these characters as text within a tag, you must "escape" them as with a backslash. Additionally, when you are using a tag that requires 2 or more arguments and you want to include a comma within the arguments (and not have it interpreted as a separator), you must escape it with a backslash.  See the examples.

You can hand-enter tables or you can paste in tables directly from a tab-delimited spreadsheet (such as Microsoft Excel).  See the "Pasting Tables" instructions if you are pasting a table directly from Excel.

If you use the browser's back button several times after posting a message,  you are looking at the page as it was before you posted the message.  Clicking links from the Navigation Bar avoids this problem.

Internet Explorer:  Click on View, then on Options..., then on the Advanced tab, and then on the Settings... button under "Temporary Internet files."  Under "Check for newer versions of stored pages," select "Every visit to the page."  Then click on OK to exit the settings dialog box, and finally on OK to exit the options dialog box.

This is because the browser reloads the entire document (the one shown in the "Location" line) when the reload button is clicked.  This document contains the code that sets up the frames -- and hence it reloads the top page into the frame on the right side.  If you want to reload only the frame,  use the "Refresh" command (in Netscape,  access the browser's View menu and select "Reload Frame"; in Internet Explorer, right-click in the frame and select "Refresh").

This appears to be a feature (or a bug) with Internet Explorer.  Most screens in the user interface preserve the user's input even if an error occurs.  In general, you do not need to use the back button when you are presented with a form to correct your mistake.

Moderators can set up links that appear as subtopics but really link to a page that is outside of the discussion board.  Likewise,  anyone posting a message can include links.  If links are entered incorrectly or change,  you will get an error message.  If you get an error message,  contact the moderator (be sure to specify where the bad link was).  The moderator can then fix or remove the bad link.

Because the discussion board supports image upload and clipart,  images are permitted on pages.  If your browser has automatic loading of images turned off,  you will see boxes where images are supposed to be displayed.

Depending on your browser and operating system, some special characters and formatting will not be displayed correctly.  This is especially noticable with browsers below Netscape Navigator 3.0 and below Microsoft Internet Explorer 3.0.  Some fonts are specific to the Windows operating system and will not be displayed correctly on other platforms.

Netscape Communicator 4 appears to have a bug that prevents text entry boxes from showing up correctly in some cases.  If you click the mouse under the "Add a Message" line, where you think the text entry box would normally be, you get a cursor.  Otherwise, try using the NavBar to go back one page and then return to the page on which the text entry box does not show up.

This small light blue paperback, unassuming in appearance, is a surprisingly potent and captivating account of malaria history and programmes aimed at malaria eradication or control. It is replete with tidbits of information, whether for the historian, scientist, public health specialist, or politician, and is a fine starting point for further study of this field. Key players and stories are featured as Litsios painstakingly brings forth the viewpoints and decisions that have driven malaria programmes from one decade to the next. Meanwhile, his underlying wish is that a greater understanding and appreciation of the past will be realized and bring new hope for the people of tomorrow.

This book provides glimpses into the thinking of the times since the malaria parasite was first discovered by Charles L. A. Laveran in 1880, through landmark meetings including the League of Nation's Conference on Rural Hygiene (Bandoeng, 1937) and a series of World Health Organization (WHO) Expert Committee Meetings that convened between 1946 and 1986. This is a whirlwind tour of the malaria situation and challenges faced by several generations. Litsios frequently recaptures quotes from the past and cleverly employs irony to bring attention to major decisions which seemed to have been made with a disregard for available knowledge, with irrational thinking, or with political motivations. This style makes for amusing reading, but, importantly, it succeeds in bringing emphasis to elements of the history of malaria that ought to be revisited, and nudges current generations to critically assess the logic behind important decisions today.

Strategic plans for malaria control shifted dramatically from a broad public health and social approach prior to World War II, where malaria research in areas such as immunity and epidemiology were also deemed relevant, to the WHO's militant-like eradication campaign between 1955 and 1969, where DDT elimination of Anopheline mosquitoes became the dominant goal. Now, with reference to the changing politics of the post Cold War Era, Litsios conveys the message that it is an opportune time to tackle malaria with renewed recognition of knowledge and studies from the past, and where "human development" is also a focus. With this in mind, he carefully scrutinizes directions taken especially by the WHO as the world's leader of malaria eradication and control programmes for almost 50 years. His critical analysis points to conflicting viewpoints that have existed with regards to philosophical approaches, strategic planning, and methodologies.

Litsios points out examples where knowledge of the times was overlooked as the WHO's global eradication campaign was designed and implemented; in some cases a sense of urgency overruled practicality; or, Cold War politics dictated its direction.

Later, Litsios discusses one of the WHO's current focuses as a primary supporter and patent holder of the widely publicized candidate malaria vaccine known as Spf66. Litsios notes that once the results are available for the latest in a series of large scale trials - conducted in Thailand - that the future of this vaccine candidate "will be reviewed and decided upon."

Litsios' critical accounts are meant to be instructive. He takes his readers through periods of high hopes, confidence, despair, and wonder, as history shows that massive efforts have helped little to avenge malaria - the "King of Diseases," which, as he notes, it was dubbed long ago in ancient Indian literature.

The Tomorrow of Malaria is very timely as the 100th anniversary of the August 1897 discovery in Secunderabad, India of malaria in mosquitoes approaches. The past 100 years of discovery, both scientific and personal, are leading to a special period of reflection. Socrates Litsios, who is currently a Senior Scientist with the WHO Division of Control of Tropical Diseases, writes with a sense of optimism as he refers to the WHO's current Global Malaria Control Strategy, a product of the Ministerial Conference on Malaria (Amsterdam, 1992), and the end of neglect noting that this plan is "beginning to yield tangible results." He has hope in "the tomorrow of malaria" as he beckons his readers to be knowledgeable, logical, and responsible when deciding upon the present and future of malaria.

I especially recommend this penetrating little book to anyone working in any area of malaria research or control. This literary work may very well mark a reemergence of malaria scholars and help these fields flourish with accomplished malariologists.

"Every 30 seconds, a child somewhere dies of Malaria. It kills indiscriminately, it puts an enormous strain on health services, and prevents the developing world from escaping from grinding poverty. The Roll Back Malaria initiative presents a huge opportunity to make a difference."

Plans for a major new international campaign to curb tile alarming spread of malaria - the Roll Back Malaria initiative announced by Dr. Gro Harlem Brundtland, Director General Elect of WHO at The World Health Assembly on May 13 1998 - received an important boost today when it won a promise of support from leaders of the G8 countries. This initiative will allow effective co-ordination of the research and implementation initiatives recently taken by a variety of agencies faced with the explosive situation in malaria.

The Roll Back Malaria initiative takes up the challenge, setting itself the ambitious target of halving malaria deaths by 2010 and again by 2015, through the extensive, co-ordinated, and improved use of existing tools and the development of new ones.

Speaking as chairman of the G8 conference, UK Prime Minister Tony Blair expressed his pride in the foresight shown in the development of the Roll Back Malaria initiative. He said malaria was clearly a major escalating problem which requires the co-ordinated attention of the developed world in genuine partnership with the malaria endemic countries. Mr. Blair praised the campaign for its strength, inspired by the unique partnership of governments, the World Health Organization, the World Bank and the private sector, and its focus on simple measures which, if met, will transform poverty induced health issues for the developing world.

Foundation DR Mary Galinski said "The entire malaria community has stressed the need for a co-ordinated international campaign to help control malaria for several years and it is now clear that the decision makers are taking up the challenge. The pledge of support from the G8 nations is enormously encouraging. We only hope it will translate into a real increase in the financial commitment for malaria not only from all G8 countries, but from many more countries around the world, especially the affected countries. If not the world faces a looming crisis.

Furthermore we welcome the renewed interest of the pharmaceutical industry worldwide in malaria and we believe that this public initiative will provide a strong context for the private sector to re-establish their commitment to research and development for malaria control tools. The partnership between the public sector, the WHO, the World Bank and other interested parties will enable us to make a very serious impact on this killing and debilitating disease.

After congratulatory speeches delivered by the five Vice-presidents of the World Health Assembly representing five of the six WHO Regions, plus a representative of the Eastern Mediterranean Region, Dr Brundtland took the oath of office and addressed the Assembly.

She immediately affirmed her conviction that societies can be changed and that poverty can be fought. "The challenges go to all of us. WHO can and must change. It must become more effective, more accountable, more transparent and more receptive to a changing world", Dr Brundtland said.  Referring to the complex processes of transition that WHO must cope with, the new Director-General said:  "The transition from one century to another sees changes which will be faster and more dramatic from an economic, social and health perspective".

As regards the transition from the communicable diseases to the noncommunicable diseases, Dr Brundtland noted that: "They cannot be seen as competing tasks. They are complementary. We need to fight both. The burden of disease is the burden of unfulfilled human development".

Dr Brundtland also expressed the view that "there is a lot to gain from organizing part of our activities into projects". Not too many, but easy to define, easy to identify, open to our partners to cosponsor - and transparent for donors to lend their financial support to." Among the first priorities for such projects she proposed to "Roll Back Malaria, by developing a new health sector-wide approach to combat the disease at global, regional and country levels". "Why now?" she asked. "Because the call is there. We have enough knowledge, skills and tools to launch a new concerted effort. Africa is responding. African leaders are committing to a renewed effort to control malaria. Africa should be spearheading  the project", Dr Brundtland answered.

Making a difference - being able to make an effort - being one of many dedicated people working together for what we believe in. I envisage a world where solidarity binds the fortunate with those less favoured.

Where our collective efforts will help roll back all the diseases of the poor. Where our collective efforts assure universal access to compassionate and competent health care. Bringing the world one step closer to that goal is our call for action."

Thank you for your letter of March 22 on infectious diseases, which arrived only a couple of days after your address of March 24 in Mukono, Uganda, in which you spoke of the tragic malaria problem in Africa and announced a further $1 million for the West African Malaria Center in Mali.

While this is a welcome, first step toward a reinvigorated American malaria effort, I must concur with your sentiment that "this should be only the beginning of our efforts to attack this problem" of infectious diseases of the developing world.

I am encouraged by your statement in Uganda that, as a nation, "we want to do more.  "The timing of this is fortuitous: America's global partners also want to do more at the moment.  I am, accordingly, writing on this occasion to suggest how your Administration may, through unilateral and multilateral action, renew America"s commitment to controlling the scourge of malaria.

The malaria epidemic is worse than ever, particularly in Sub-Saharan Africa.  Since the failure of malaria eradication efforts in the 1960s, the disease has regained the upper hand.  Sri Lanka, which had only eighteen malaria cases in 1963, today has over one million annually1.  In Senegal, the final stop of your African tour, French scientists reported a seven-fold increase in malaria deaths over the last five years2.  Every year, almost half a billion people are diagnosed with malaria and 2.7 million human beings lose their lives to the disease3.  As you noted in Uganda, malaria takes a far greater toll of African lives than does AIDS.  About as many Africans will die of malaria in 1998 alone, as have died of AIDS in the last fifteen years4.

In Uganda, you were correct to warn that Americans cannot ignore the malaria problem - that "with increasing globalization we are all at risk."  Every year, about 1500 Americans returning home from foreign travels are hospitalized with malaria, after spending as little as one day abroad5.  For those who reside overseas, such as American military forces or Peace Corps workers, the risks are even more severe.  Malaria was the leading cause of hospitalization among troops who served in Somalia6, and caused over 1600 cases of serious illness among Peace Corps workers in West Africa in the late 1980s alone7.  Even persons who do not travel may contract malaria from contaminated blood transfusions: two Americans died last year in just this way8.

Although the United States contributes half of the world's malaria research budget, the overall numbers are far too low.  A research audit by the Wellcome Trust in 1996 found the malaria research budgets of all nations, charities, drug companies, and the WHO total under $90 million annually - about as much as the budget of a single, modestly-sized hospital in the United States.

To redress the neglect of malaria, your Administration needs a two-track approach.  As a matter of domestic policy, America must fortify its research commitment through inter-agency cooperation and a real increase in appropriations.  As a matter of foreign policy, America must put malaria research and control squarely onto the diplomatic agenda, where it already has the support of our international partners.  The following are my specific recommendations.

Your Administration should take two steps to bring the malaria agenda under one strategic umbrella.  First, the recommendation of the NAS-IOM panels, for "the establishment of a national advisory body on malaria", should be acted on at once.  Such a body would coordinate, monitor and report on the progress of malaria research and control13.  In these ways, it would emulate other inter-agency bodies that were pivotal in fighting diseases: the Polio Vaccine Committee and the National Task Force on AIDS Drug Development are two examples14.  Seven years after the first NAS-IOM recommendation, it is high time the American government formally coordinate its malaria research and control effort.

Since 1997, the global community has become much more aware of malaria, and a number of multilateral and diplomatic initiatives have been or will soon be taken against the disease.  Diplomatic action and multilateralism are part of your June 1996 Presidential Decision Directive, which called for a the U.S. to collaborate with other nations and international bodies on emerging infectious diseases.  In that spirit, your Administration should pay especially close attention to the following three developments.

At Dakar, the MIM partners identified areas in which they agree that research is acutely needed.  The CDC, DoD, NIH and USAID all have research plans aimed at these areas, but most are inactive for want of funding.  For example, the DoD is sitting on about fifteen drug and vaccine candidates suitable for testing, and NIH has a vaccine plan that would test another thirty vaccine candidates within a decade15.  The limitations are not technical, so much as financial.  Your Administration ought to seek special appropriations, in this Congress, so that these and other research plans may proceed.  Also, OMB must be instructed to consult with the above agencies, to ensure that their malaria research plans are accommodated in the forthcoming budget.

In deciding to make available more funding for malaria research, history lends a helpful perspective.  The last time the United States seriously grappled with malaria was in the years from 1958-63.  Back then, Congress gave its bipartisan support to a global malaria eradication program which cost the equivalent of billions of today's dollars16.  President Eisenhower called for the "unconditional surrender" of the disease; and Senator John F. Kennedy predicted that children would be born into a world naive of this scourge.  Unfortunately, in the end malaria eradication failed, but this is hardly surprising: the eradication plan was proposed just one year after scientists deciphered the structure of a mysterious thing called "DNA".  Four decades later, our expertise in vaccinology, pharmacology and genetics is beyond the imaginations of the architects of that program, and the technical barriers are no longer so daunting.  There is no doubt that today we can, for a fraction of the cost of that program, develop effective drugs or vaccines17.

United States scientific and aid agencies both contribute to and receive funds from TDR.  In recent years, U.S. projects have in fact received more money from TDR than they have contributed18.  Your Administration ought to watch Dr. Brundtland's Roll Back Malaria plan with the greatest of interest, and strengthen the involvement of American scientists and development specialists in TDR research as a means of supporting this very noble plan.

In preparation for the upcoming G-8 summit of leaders this month, Japan and Britain are calling for concerted action on malaria research and control, and this will be raised in the G-8 session and discussions on "global economic issues".  The rationale for treating malaria under this rubric is inescapable: as the G-8 economies grow increasingly connected to developing country markets, the health of people in those countries becomes a matter of global economic and political security.  You alluded to this linkage when, in Uganda, you commented that, "By weakening as well as killing people, malaria contributes to poverty and undermines economic growth."

Your growing recognition of the global malaria crisis is a first step toward committing the seriously increased budgetary resources that are needed to banish this scourge.  I look forward to being of assistance as your Administration turns to further action on this problem.

During your recent State of the Union address, you called for a substantial increase in Federal spending for basic biomedical research in the forthcoming budget.  As you are aware, enhancing biomedical research funding and the budget of the National Institutes of Health has bipartisan support in Congress.

While the United States prepares to invest more heavily in research and technologies for public health, I am writing to ask that the needs of the world's poor, who suffer greatly from infectious diseases, be given special attention in the funding process.  As Vice-President Gore, speaking before the National Council for International Health in 1996, recognized, emerging infectious diseases are among "the most significant health and security challenges facing the global community".  Yet, despite the importance of this challenge to America, our commitment, both before and after Mr. Gore's onetime priority call, to researching the vicious, re-emergent scourges of the developing world remains embarrassingly low.

Numbers like these are so alien to American experience that they are hard to comprehend.  To envision the number of children killed by malaria annually, imagine seven jumbo jets, full of children, crashing every day.  To get a sense of malaria's ubiquity in the tropical world, consider that if Americans, rather than Africans, were malaria's victims, every American would be hospitalized on average once a year.  Many would be hospitalized twice.

What is to be done?  Government must take the lead.  The pharmaceutical industry is economically unwilling or unable to recoup an investment in malaria research, for the simple reason that the prospective market for antimalaria products is not sufficiently affluent.13  The Institute of Medicine of the National Academy of Sciences notes that "not a single major Western pharmaceutical company is now developing new drugs for malaria"14, and the number of companies working on malaria vaccine technologies can be counted on a single hand.  But as with other areas of technology where Federal funding led the way, to the benefit of America as a whole, malaria research too promotes our national self interest.  There are at least four reasons for this.

First, although malaria is no longer endemic to the United States (it was very common in the early part of this century), the disease still afflicts Americans.  Every business traveler, soldier or vacationer returning home from a malarious area is at risk of the disease, no matter how brief their sojourn abroad.  About 1500 American travellers each year are hospitalized in the US with this sort of "imported" malaria.15  And as international travel grows, especially business travel to newly-industrializing countries, some of which harbour multidrug-resistance, the incidence of malaria among Americans is certain to rise.

Second, the global burden of malaria has serious economic implications for developing countries, and by extension, implications for American foreign policy.  Malaria is a perennial plague, and works like a "disease tax" in Africa: limiting inward capital investment, squelching development, damping trade in goods and services, and generally depressing the standard of living.

Just as public support for space science in the 1960s, or particle physics today, are seen as valuable to the cultivation of American scientific advances, malaria vaccine research presents an unequalled opportunity to give rise to technologies that would help us combat other diseases endemic to America.  These could be parasitic diseases, such as cryptosporidiosis, which caused 400,000 illnesses in Milwaukee in 199423; or they could be terrible scourges such as AIDS.  Needless to say, the commercial significance of these technologies for American industry is certain to be enduring.

Lastly, malaria research can help promote America's stature in the developing world, which is wise foreign policy, while at the same time promoting Americans' traditional values of helping the weakest help themselves.  Last year, at the instigation of Dr. Harold Varmus, Director of the National Institutes of Health, the malaria research community met in Dakar to create the Multilateral Initiative on Malaria (MIM).  The objective of the MIM is to create networks of American, European and African laboratories to work in collaboration on malaria research.24  For a modest investment in the MIM, the United States can build scientific capacity in Africa, promote contacts between American researchers and their European colleagues, and work toward conquering a devastating disease -- all of which makes for excellent scientific diplomacy.

I cannot stress enough, Mr. President, that biomedical research on malaria is not about traditional, third-world aid: it is about basic science, done largely in American laboratories, that has the potential to help the least fortunate countries of the world throw off the yoke of disease that stifles their life expectancy and material progress.  There is no "cycle of dependency" in funding malaria research.  There is only Americans' goodwill to stop the pointless death of children; to support the health of women; and to foster economic security for all people of the globe.

Malaria deserves serious attention from your Administration.  I would recommend that the White House become involved by convening the best experts the field has to offer, to design and steer a renewed American research effort, backed by a funding committment equal to the scientific challenge.  An early, initiatory gathering of these knowledgeable persons with you at the White House would demonstrate the priority given this scourge by your Presidency.

This is a discussion that concerns a topic of public interest. The moderators anticipate an excellent discussion. Summaries of the discussion will be released to the press, as there is much interest in this issue and it is felt that the best answers will come from a consensus garnered from the scientific community at large. Questions will be posted to this board periodically. The answers to some of the questions may be rather extensive. Please give your answers careful consideration. You may wish to write your answer off-line and copy/paste to this site. Participants are asked to utilize references in their discussions where applicable. References are preferably written publications. Web pages may be used as supplementary references. A good reference format to follow is that of the ESA or JAMCA. (An example is: Fontenille, D. and I. Rakotoarivony.

Recently, articles have been published in the New York Times and in the Guardian of London concerning DDT and malaria control. The articles are available from this site. Please give an initial opinion regarding the future need for DDT in malaria control. This may be very brief [one sentence or a small paragraph], as we will go into this more deeply in the discussion.

Malaria is one of the key health issues affecting developing countries, particularly in sub-Saharan Africa and Asia. With increasing drug resistance and high cost of pharmaceutical drugs, the use of herbal antimalarials is popular.

Organisation. The programme of research that was drafted from the initial meetings on malaria in Dakar, Senegal, in 1997 included research into herbal antimalarials. However, while research has progressed in other areas of malaria control, research into herbal antimalarials has yielded few - if any - results that can be implemented by malaria control programmes.

Methods (RITAM) was designed to develop a strategy for more effective, evidence-based use of traditional medicines that can also inform malaria control policy decisions. The aim of this meeting was to bring together experts on research and policy on herbal medicines for malaria, to formulate a research strategy that will make a significant contribution to malaria control programmes. It will be followed by a natural products chemistry meeting at WHO in Geneva in the Spring of 2000.

The purpose of RITAM is to facilitate exchange and collaboration among those studying and using plants in the control of malaria with a view to developing a coordinated strategy for more effective, evidence-based use of traditional antimalarial methods.

Utilization of traditional medicine is widespread in non-industrialised countries. The efficacy of many traditional treatments have been well documented, including in the area of skin disorders and allied fields, malaria and other parasitic disorders. Currently, modern pharmaceuticals are not available in constant supply in those areas most affected by malaria - particularly in sub-Saharan Africa and in South and SE Asia.

Herbal Antimalarial Methods: Developing a research and policy agenda Malaria is one of the key health issues affecting developing countries, particularly in sub-Saharan Africa, but also in Asia. Malaria causes many deaths, much suffering, and delay in economic development. At present, the cheapest drugs for the treatment of malaria are becoming ineffective as malaria parasites evolve mechanisms to resist them. Alternative drugs are often too expensive for the poor to afford, so in some areas the use of herbal remedies is popular.

The two most effective drugs for malaria originate from plants: quinine from bark of the Peruvian cinchona tree, and artemisinin from the Chinese antipyretic Artemisia annua. It is probable that other plants contain as yet undiscovered antimalarial substances. Much research has focussed on trying to isolate and purify these from plants. However, there has been almost no research into the clinical effectiveness of herbal remedies as they are used in real life. National malaria control programmes have largely ignored the potential of traditional healers, even though they are more numerous and culturally accepted than conventional health care workers.

The conference was attended by biological and social scientists, clinicians, traditional healers, and policy makers, with a wide range of scientific and professional experience. From Africa, there were 28 delegates from 11 countries. There were 16 delegates from eight European, Asian and American countries. Delegates were invited because of their work or interest in plant-based means of controlling malaria.

The meeting consisted of seven sessions on different topics. Each session had 40-60 minutes of plenary talks, which were brief summaries of work so far, and key issues to consider in discussions about future research.

The meeting was structured according to sets of objectives developed for a range of themes on research, policy and product development. The purpose of focussing presentations in this way was to generate a coherent action agenda by the end of the meeting.

Look for other traditional medicines / treatments for malaria not involving plants Confirm what is known, add what is incomplete and correct what is distorted Assess feasibility of wider cultivation of Artemisia annua and other antimalarial plants Develop guidelines on the integration of traditional and orthodox medicine to inform government policy.

To evaluate remedies reputed to potentiate existing drugs or act as resistance reversers To standardise the crude extracts produced by healers To prioritise development of drugs against the pathogenic erythrocytic stages, but also look for anti-hepatocytic drugs, which would act as a useful prophylactic for the individual.

In vitro and in vivo (in rodents infected with sporozoites) safety and toxicology tests should precede human trials Query usefulness of WHO microtest kit for rapid assessment of herbal medicines activity against malaria.

Developing a database of existing research (ethnobotanical, pharmacological, phytochemical, toxicological, chemical, epidemiological), and disseminating information on traditional medicine  looking at weaknesses of the current system, and how messages can get into the right system.

Identification of plant species and families to be prioritised in research on traditional antimalarials; this may eventually lead to endorsement of traditional medicines when sufficient evidence becomes available.

Executive Board, consisting of the chair of each specialist group, and other members as appropriate, including heads of national/regional networks. Dr. Gerard Bodeker was elected Chair of the RITAM Executive Board for an initial three year period.

The establishment of a structure for RITAM, with definition of its roles, activities and management was a major step forward. The specialist group on "Policy, Advocacy and Funding" will continue this work.

Tuberculosis causes more deaths than any other infectious disease, killing 3 million people annually. One hundred thousand children die from TB each year. The World Health Organization estimates that between now and 2020, `nearly one billion more people will be newly infected, 200 million people will get sick, and 70 million will die from tuberculosis, if control is not strengthened. Tuberculosis is not just an issue for some faraway countries; in the United States, more than 19,000 cases of tuberculosis are reported annually and increasingly we are seeing drug-resistant strains of tuberculosis in this country but especially in the states of the former Soviet Union where, according to one CDC doctor, an epidemic is taking place of `the worst situation for multidrug resistant tuberculosis ever documented in the world.' Other areas of the world, such as central India, Bangladesh, Latvia, Congo, Uganda, Peru are also experiencing near-epidemic tuberculosis crises.

According to the World Health Organization, malaria kills more than 2 million people every year, and the disease is an important public health problem in 90 countries inhabited by almost half of the world's population. Each year, one million children under the age of five die from complications associated with malaria.

While AIDS is entirely preventable in this country and abroad, and while behavioral interventions for HIV have proven effective at reducing infection rates, many factors, including political obstacles, insufficient prevention funding, forced sexual encounters, and the difficulty of maintaining safe behavior over a lifetime, mean that a vaccine will be required for control of this worldwide epidemic.

And, yet, Mr. President, biotechnology and pharmaceutical companies in the United States, the home of the most innovative research and development in the world, are not working on vaccines to the world's largest killers. Market disincentives--especially the lack of a viable, cash-rich market--play against investment into these vaccines. Private-sector scientists and chief executive officers have a difficult time justifying to their boards an investment in developmental research toward these vaccines as long as other pharmaceutical research and development into products appealing to the developed world, like anti-depressants or Viagra, present more attractive investments.

This market failure and the need for incentives is shown most dramatically by last year's survey by the Pharmaceutical Research and Manufacturers of America. Of the 43 vaccine projects found to be in development by the survey not one was for HIV, malaria or tuberculosis. To find vaccines for the biggest infectious disease killers in the world, both the private and public sectors must be engaged in a bolder, more creative and dramatic way.

Mr. President, with that in mind, we are introducing the Lifesaving Vaccine Technology Act, which establishes an income tax credit for 30 percent of the qualified expenses for medical research related to the development of vaccines against widespread diseases like malaria, HIV and tuberculosis, which according to the World Health Organization, cause more than one million deaths annually.

This bill also declares that it is the sense of Congress that if the vaccine research credit is allowed to any corporation or shareholder of a corporation, the corporation should certify to the Secretary of the Treasury that, within one year after that vaccine is first licensed, the corporation will establish a good faith plan to maximize international access to high quality and affordable vaccines. In addition, the bill expresses the sense of Congress that the President and Federal agencies (including the Departments of State, Health and Human Services, and the Treasury) should work together in vigorous support of the creation and funding of a multi-lateral, international effort, such as a vaccine purchase fund, to accelerate the introduction of vaccines to which the vaccine research credit applies and of other priority vaccines into the poorest countries of the world. Lastly, the bill expresses the sense of Congress that flexible or differential pricing for vaccines, providing lowered prices for the poorest countries, is one of several valid strategies to accelerate the introduction of vaccines in developing countries.

This bill is highly targeted: it will cost relatively little to implement but would have a profound impact on America's response to international public health needs. And it would complement--certainly not supplant--current federal efforts at USAID, the NIH and other federal agencies to assist developing countries and to bolster vaccine research.

Mr. President, this legislation is a companion to a bipartisan bill introduced in the other body by my friend and colleague from San Francisco, Congresswoman Nancy Pelosi, and 36 co-sponsors. Over the years, I have had the honor to work with the distinguished Congresswoman on various pieces of legislation. The nation is in her debt for her tenacity and her overwhelming sense of duty to country. Her constituents benefit daily from her leadership, and I am pleased to be associated with her again today.

Pelosi has found in the other body is replicated in the Senate and that our colleagues join the Senator from Illinois, Senator Durbin, and I in passing the Lifesaving Vaccine Technology Act as quickly as possible.

Mr. President, I ask unanimous consent that the Nyhan column, an article which appeared in the Albany Times-Union about the market difficulties of developing an AIDS vaccine, and a Congressional Research Service study of the bill be printed in the Record.

RBM Initiative.The newspaper features articles highlighting ideas, successes and challenges of those involved in malaria control. By emphasising the elements of the RBM strategy, the newspaper also helps increase awareness and understanding of the strategy as a whole.

Anyone with a story, no matter how small, that illustrates the many ways in which RBM movement is progressing towards its goals is invited to submit their story. (Corresponents are encouraged to use the RBM Reporter Form described below.) We are looking for articles, editorials, and letters to the editor that feature your country's activities in malaria control, as well as examples of the successes and innovations you have discovered in your community. By sharing your experiences and useful ideas readers will be able to utilise innovations and avoid pitfalls that have already been encountered, thus leading to more effective malaria control programmes.

We encourage you to use the RBM Reporter Form which saves time and guarantees that the information we need is included in your story. The Reporter form is a pdf file (read only) that you may print, fill out, and send in.

In addition, if you would like to submit an article: Use a conversational rather than academic tone. Strive to tell the story from the human/personal perspective, noting specifically how a family, a community or a country has been impacted.

Included in this release is all the data, sequence and otherwise, normally found at the WHO web site together with genome data kindly made available by the three malaria sequencing centres at Sanger, TIGR and Stanford University. There are over 300 Mb of various sorts of data on the CD.

Clearly the data will only include that available at the time of pressing and more recent data can be accessed via the web at the relevant URLs. Please note that all unfinished genome sequence is provisional only and governed by the release policy of the individual sequence centres. The CD-ROMs will appear 2-3 times a year and will be developed into a more comprehensive information resource. All suggestions for inclusions or improvements will be gratefully sought.

Arriving in South Africa today, David Robertson, a disabled Briton, is on course to smash the world record for the most countries driven through in a single vehicle in the cause of combating malaria. Robertson's arrival coincides with the African Malaria Conference in Durban organised by the Medical Research Council of South Africa and the Wellcome Trust on behalf of the Multilateral Initiative on Malaria (MIM).

In the spirit of Jules Verne, crusader, David Robertson, in his Land Rover left Rotterdam on 6th September with the ambition of gaining a place in the Guinness Book of Records with a record-breaking 300,000 mile drive that will take him across six continents over the next five years. With one leg and one arm missing the handicapped man is undertaking the endeavour to raise awareness and funds for malaria, a forgotten disease that still kills over 1 million people annually, most of them young children.

The campaign to raise awareness for the fight against malaria which began at the World Harbour Festival in Rotterdam, is being carried out in collaboration with Memisa Medicus Mundi, one of Europe's largest Non-Governmental organisations for Healthcare in Developing Countries and the Malaria Foundation International (MFI), a bottom-up organisation of malaria researchers and other professionals, with a main aim to raise global awareness and promote effective communication and global networking against malaria worldwide.

David will visit many areas affected by malaria, as well as hospitals and research institutes where Memisa-doctors and MFI affiliated-scientists work on malaria projects. On his trip he will distribute information being provided by the Malaria Foundation International and its partners engaged in the Roll Back Malaria (RBM) initiative being coordinated by the World Health Organisation (WHO) in Geneva. People in remote areas will be able to 'speak to the world about malaria' using David's state of the art communication's equipment.

The proceeds of the Drive Against Malaria will be donated to various malaria programmes agreed by David Robertson and his partners to help combat the disease. Anyone wishing to follow David's journey 'live' can log into the 'Drive Against Malaria' interactive Web-site (www.driveagainstmalaria.org).

This site has a live "chat-room", route maps, facts on malaria, information on countries already visited, a shop to buy and donate bed-nets and medicines, and a question and answer page. The site is regularly up-dated by David himself.

Year-old global explorer David Robertson lost his right leg and right arm in a serious motorbike accident in 1977. It did not stop him from seeking adventure and travelling round the world. He has since travelled through 67 countries on expeditions including Trans World 88-91 (crossing 44-countries and three continents-the longest ever Range Rover journey), and the Great South American Geographical Expedition. Robertson's past expeditions have taken him through 6 continents over the past 12 years. David Robertson knows what it is to fight for ones health, during his journey through Kenya, he nearly died after being infected with malaria. He recalls "Around me I saw the misery this disease causes, the many victims, especially young children. While recovering I decided to raise money for health, education and medicines." says Robertson. He will be the sole driver for the entire duration of the expedition, but will be accompanied for up to four weeks at a time by assistants who will navigate and help with video filming and photographic work, as well as with writing a journal and updating the DAM web-site.

Mother and child health care gets a great deal of attention. Production and distribution of affordable medicines are also supported. Memisa always co-operates with local organisations. Wherever necessary, the work of partner organisations is supported by Memisa doctors, nurses, and paramedic staff. If necessary, Memisa renders medical emergency relief. However, this is only done in close collaboration with the local partners. After the first emercency has been alleviated, repair of the health care structure is started.

Malaria Foundation International (MFI) is a bottom-up organisation of malaria researchers and other professionals, with a main aim to raise global awareness and promote effective communication and global networking against malaria worldwide. The MFI stands up for effective communication on malaria among researchers, health workers and the general public in both malaria endemic countries and in industrialised countries where people sometimes believe that malaria is a disease of the past.

Memisa and MFI are complementary organisations. While Memisa mostly focuses on direct assistance to health care programmes, MFI aims to support research efforts and translate the latest scientific insights into better malaria control strategies. Both are badly needed. Importantly, Memisa and MFI feel that with this campaign they will raise public and political awareness about the disease as the new international plans for malaria under the Roll Back Malaria (RBM) Initiative gets underway. In addition, Drive Against Malaria supported by Memisa and MFI will assist in this new programme and the established Multilateral Initiative on Malaria (MIM) by encouraging the general public to support malaria action initiatives. In the long run, this is crucial for their success. The MFI has been officially recognised by both the MIM and RBM initiatives as a central communicator of information, and MFI's role as a partner of the Drive Against Malaria initiative was recently endorsed by the WHO.

He has two primary goals. The first is to visit more than 150 countries by jeep and break the world record set by a German couple who visited 117. The second purpose of his journey is to help the fight against one of the world's biggest killers - Malaria.

Reagent Repository. NIAID's contract facility will provide a versatile resource to the international malaria research community. The repository will acquire and distribute, to qualified investigators throughout the world, malaria-related reagents, materials and protocols which satisfy quality assurance standards. The Malaria Reagent Repository will collect information about malaria-related reagents and standards and disseminate this information through print publications, World Wide Web sites, and workshops. Additionally, the Malaria Reagent Repository will enhance technology transfer through development and publication of methods, will facilitate the commercial development of reagents through proactive communication with biotechnology and pharmaceutical companies, and will participate as a Collaborating Center of the World Health Organization.

In its initial phase, the repository will acquire and distribute relevant monoclonal and polyclonal antibodies, recombinant malaria proteins and antigens as well as gene libraries, molecular probes and constructs. Future plans include the acquisition, maintenance and distribution of parasites, mosquito vectors and human samples.

Johannesburg - Fighting malaria is among Unicef's top priorities. This formidable tropical parasitic disease kills at least one million people annually - three quarters of them children, according to the Unicef website .

This disease, which is spread through Anopheline mosquito bites, is a serious public health problem affecting between 300-500 million people a year in some 100 countries inhabited by 40% of the world's population.

According to Unicef, malaria contributes to severe anaemia in children, is a leading cause of low birth weight among infants, is a most common cause of school absenteeism, causes severe anaemia, miscarriages, and still births among pregnant women and contributes to high rates of maternal deaths.

Secondly, providing mosquito nets empowers families in poorer communities to do something to protect pregnant women and especially children from contracting malaria, he told SABC radio. The nets can prevent malaria deaths by as much as 25%, according to the Unicef spokesperson.

"One of the things we have been asking governments is to ensure that nets are made available to families, and this is done by reducing taxation and tariffs on mosquito nets and treat them like an essential health item. This can reduce the price of the nets to about R12 to R18," he says.

DDT has a role to play in the control of malaria, but Unicef and its partners are looking at less toxic insecticides, he says. In areas where malaria is seasonal, spraying with DDT can save lives, he told SABC radio, adding that there are still concerns about complications for the environment.

The problem was complicated by malaria strains that were resistant to chloroquine, the most inexpensive and widely used antimalarial drug and some strains of malaria have also developed a resistance to other antimalarial drugs.

Also contributing to the resurgence of malaria are: the displacement of populations, global warming, roads being built, commercial tree cropping and deforestation, creation of dams, and the opening up of new mining areas.

The summit, attended by 39 countries, including 20 African leaders and senior officials of major UN agencies and NGOS, also called for one billion dollars to be made available yearly to roll back the mosquito-borne tropical disease, which kills some two million people world-wide, 90 percent of them in Africa.

The 13-page declaration also stressed the need for an investment of additional resources to stimulate the development of malaria vaccines appropriate for Africa and provide similar incentives for anti-malaria technology.

According to an expert report to the summit, much of the 500 million annual malaria global attacks cost Africa up to 12 billion dollars a year, while the region lost some 1.3 percent annual growth to the debilitating disease.

Its goals include halving the high mortality rate in Africa by 2010, while 60 percent of sufferers, mainly children under five and women of childbearing age, are expected to be provided with prompt access to and the use of correct and affordable treatment within 24 hours.

The pledge was made during a malaria summit for African heads of state in Abuja, Nigeria, on Tuesday, according to a press release from the Ministry of Health. The African leaders, who attended the summit, signed a declaration to reduce malaria deaths by half every year. The Minister of Health, Dr. Crispus Kiyonga, signed on behalf of President Museveni.

They asked the donors to commit an additional US $1 Billion towards controlling malaria and invest more resources towards vaccine development. They agreed to observe May 25 every year as World Malaria Day.

Addressing African government leaders attending the worlds first-ever summit on malaria in Nigeria last Tuesday, Bellamy said theres now effective, affordable and durable interventions to prevent and cure malaria.

According to a UNICEF statement, Bellamy further appealed to governments to abolish taxes and import duties on mosquito nets to make them affordable for poor families. She said priority should focus on providing every child and pregnant             woman in Africa with mosquito nets as they remained the most venerable to the disease.

According to the report, malaria slows economic growth in Africa by up to 1.3% each year. This slowdown in economic growth due to malaria is over and above the more readily observed short run costs of the disease. Since sub-Saharan Africa's GDP is around $300 billion, the short-term benefits of malaria control can reasonably be estimated at between $3 billion and $12 billion per year.

"Malaria is hurting the living standards of Africans today and is also preventing the improvement of living standards for future generations," said Dr Gro Harlem Brundtland, Director General of the World Health Organization. "This is an unnecessary and preventable handicap on the continent's economic development."

Malaria-free countries average three times higher GDP per person than malarious countries, even after controlling for government policy, geographical location, and other factors which impact on economic well-being.

One healthy year of life is gained for every $1 to $8 spent on effectively treating malaria cases, which makes the malaria treatment as cost-effective a public health investment as measles vaccinations. This analysis, carried out by Dr Ann Mills, LSHTM, demonstrates that malaria control tools and intervention strategies provide good value for money.

"Malaria is taking costly bites out of Africa," said Dr David Nabarro, executive director at WHO. "It is feasting on the health and development of African children and it is draining the life out of African economies."

The report recommends that $1 billion annually be devoted to malaria prevention and control and that most of this expenditure be focused in Africa. This is many times greater than the amount which is currently being spent. It argues that spending this amount is economically justifiable as the short-term benefits of malaria control can reasonably be estimated at between $3 billion and $12 billion per year.

Malaria accounts for nearly one million deaths each year in Africa; an estimated 700,000 of these deaths are among children. Research has found that the wider availability and use of insecticide treated bednets would result in 50 percent less malaria illness among children. Yet presently, only 2% of African children are protected at night with a treated bednet.

"Roll Back Malaria aims to help African families create a mosquito free zone in the home through the use of nets, drapes, or bednets treated with insecticide," said Dr Awash Teklehaimanot, acting project manager for Roll Back Malaria. "Our goal is to ensure that every person at risk of malaria in Africa is protected with an insecticide-treated bednet within the next five years."

Malaria is also working to provide greater access to rapid diagnosis and quick treatment with the appropriate therapies -- ideally in the home; preventing malaria illness during pregnancy; and detecting and responding to epidemics quickly.

Gro Harlem Brundtland, Director-General of WHO. "We have the tools. We have the economic justification. We now need leaders from both the public and private sectors stepping forward to make this happen."

They said that malaria slows economic growth in Africa by up to 1.3 percent each year. This slowdown in growth due to malaria is over and above the more readily observed short run costs of the disease.

In return, the developing countries promised to spend more on health, AIDS prevention and education. Many of them currently spend more on their debt than on social and medical programs. As NPR's Brenda Wilson reports, international economists and health workers say global economic development is suffering because of disease and poverty.

It's a vicious cycle of poverty undermining health and poor health hampering development. Right now, malaria is one of the biggest killers in sub-Saharan Africa, where more than a million people die of the disease each year. Nor is death the only toll. Dr. Nils Daulaire of the Global Health Council says there are other often overlooked costs.

Dr. NILS DAULAIRE (Global Health Council): Each person who gets infected gets sick. They get sick for a period of several weeks. You don't work, you don't take care of your family, you just try to live through it. This has huge economic consequences. Those countries that have high levels of endemic malaria and other tropical diseases have much slower economic growth than countries that are largely free of them.

WILSON: With the investment of just $ 4 per person, much of the billions of dollars spent each year treating malaria could be saved. Something as simple as bed nets sprayed with insecticide reduces mosquito bites, and this would slow the spread of the disease. And poor countries often have to contend with several diseases at once. The World Health Organization estimates 13 million people, many of them children, die each year from malaria, AIDS, tuberculosis, measles and pneumonia.

Organization a year ago, she has promoted health care as essential to economic development, in part, she says, because there can be no progress until the stranglehold of disease is loosened and health improves. The AIDS pandemic has magnified the problem. The disease is depriving many sub-Saharan countries of a generation of young, educated professionals, the teachers and health workers who were counted on to build economies.

WILSON: A catastrophe compounded by fragile economies that were already in trouble even before the AIDS epidemic. Revenues and resources not sunk in ambitious building projects were soaked up by huge bureaucracies or mismanaged and siphoned off by corrupt officials. Attempts by the World Bank, the International Monetary Fund and international donors to push reform forced governments to shrink the civil services and to cut budgets across the board. In most instances, the reforms worsened the economic situation, making it more difficult to pay off debts.

Mozambique's prime minister, Pascoal Mocumbi, says that repaying a $ 5 billion loan from the World Bank consumed more than a third of his country's gross domestic product, leaving little for health or education.

Mozambique, and all our population was excluded, practically, from access to health services. When we took over the responsibility of running our own state, we decided this was the priority, taking care of education and health for all.

Mozambique qualifies for a new relief package that will reduce debt payments to a tenth of current revenues. But for Mozambique, like many poor countries, there are so many problems, it's hard to know where to begin.

Dr. DAULAIRE: They're now starting to bounce back. If they had not had a foundation of reasonable health and with the large majority of their population able to make their own decisions in terms of family size, it would be a much, much slower recovery process.

WILSON: Such as immunization and nutrition and good maternal and child health care. But even that requires the commitment of political leaders in developing countries, many of whom are only beginning to acknowledge that business development, military security and infrastructure have suffered because large sectors of the population are ailing. For years, the responsibility of health care has been left to international foundations and Western governments.

WILSON: To ensure that savings under the new debt plan are actually spent on social priorities, countries have to commit to spending on basic health care, AIDS prevention and education. But some doubt such a commitment can be enforced.

Abuja, Nigeria (PANA) - Nigerian President Olusegun Obasanjo Tuesday said that the fight against malaria would not succeed if African countries continue to spend their meagre resources on debt servicing.

Officially opening of the African Summit on malaria in Abuja, he called for complete forgiveness of all African debts, saying the gravity of the malaria problem with all its ramifications provided a strong case for the forgiveness of all African debts.

"The stranglehold of debt obligations on our developmental priorities is such that no realistic anti-malaria efforts - or indeed any development strategy - is conceivable to be meaningful with these debts hanging around our necks," he told the summit,                    attended by some 20 African leaders and representatives of international and bilateral development agencies.

Obasanjo, who described the summit on Roll Back Malaria as "a life and death issue for the continent of Africa," expressed the hope that the summit would mark the beginning of the end of malaria in Africa.

Obasanjo urged the summit to include in its plan of action the aim to put in every African home anti-malaria first aid kit fitted with equipment for simple diagnostic tests and affordable drugs for early treatment.

The World Health Organization today plans to announce an ambitious new program to fight malaria among children in Third World countries by distributing special mosquito-net bedding dipped in insecticide.

WHO wants to help provide 60 million African families with these insecticide-treated mosquito nets over the next five years as part of a WHO initiative called Roll Back Malaria that started last year, said the project manager, Dr. David Nabarro.

Malaria, spread through mosquito bites between dusk and dawn, kills 1.1 million people worldwide each year, and about 1 million of them are in Africa. One of every four childhood deaths in Africa is from malaria, resulting in 700,000 children in Africa, most of them under 5 years old.

Two years ago, studies showed that insecticide-treated nets could reduce malaria deaths by 25 percent. The nets were dipped in synthetic pyrethroids, a substance derived from a plant common in East Africa that has a long safety history and is environmentally friendly. The insecticide creates an invisible chemical wall that keeps the bugs away.

Nils Daulaire, president and chief executive of Global Health Council, a membership alliance of improving health worldwide, said: "It is clear that we have the technology, and it can have a huge effect now on child deaths with malaria. Nobody leaves from the hospital anymore without a child car seat in the US, but that doesn't make more than a 5 percent difference in our child death rate. With malaria, no mother in Africa should leave the hospital without a bednet."

Between 1991 and 1996, Vietnam launched use of a new antimalaria drug and distributed insecticide-treated bednets on a massive scale and was able to reduce the malaria incidence by more than 95 percent, said Dr. Kamini Mendis, a WHO malaria specialist in Geneva. Mendis said that a trial of treated bednets in the southern part of Sri Lanka reduced the number of malaria infections by 80 percent over 18 months.

Tanzania, are discussing strategies to increase the availability of bednets, working with manufacturers to bring down the cost, and promoting the need to retreat the bednets every six months with the insecticide. "It will reduce the reliance on DDT," said Nabarro.

The World Bank, one of the partners in the Roll Back Malaria initiative, is supporting a loan program allowing countries to begin to provide bednets and trying to reduce the tax and tariffs on bednets.

In some countries, bednets are still categorized as a luxury or higher-tariff good, not a public-health good like pharmaceuticals, said Julie McLaughlin, health specialist for the World Bank. In some places, a net could cost $20, although Nabarro said he hopes that they can eventually get the cost down to $3.50.

Johns Hopkins School of Hygiene and Public Health. "The time people need nets and antimalaria drug treatments the most is in the rainy season, but that is also when people don't have the money, because the harvests haven't come in yet and roads are impassable because of the rain."

In Africa, more than 550 million people, almost the entire population estimated at just above 700 million people, is now at risk of contracting malaria. In sub-Sahara  Africa, malaria causes more than one million deaths every year, most of the victims being children aged below five years. Its occurrence is 90 percent in Africa alone.

"The social and economical consequences of malaria in our region are very grave.  It is a major contributory factor to poverty, it keeps many adults from work and many children away from school. It affects the poor primarily thereby exacerbating inequities in health and impeding development," says Dr Ebrahim Samba, the WHO Regional Director for Africa.

Recently, heads of government from Africa, leaders of the industrialised countries  (G8) and various international development agencies gathered in Abuja, Nigeria, to deliberate on the issue of malaria.

The main focus was to target the spread of malaria in Africa but devising collective  strategies. The conclusive resolution of the summit was that simple environmental control tools should be used to minimise the breeding of mosquitoes hence  achieve the envisaged objectives.

Other simple tools that delegates resolved to use are: DDT spraying of houses; use of insecticide-impregnated nets to minimise contact between human beings  and mosquitoes; early treatment within 24 hours of cases involving vulnerable groups such as children under five years of age, pregnant women and tourists.

Immediate measures to be taken, according to Samba, will be at the political level.   Here, the WHO has requested each country's Ministry of Finance to ensure easy  availability of the bednets by removing customs duty on them entirely.

Governments would be expected to announce malaria related preventive measures through the national radio and television stations while the Ministry of Agriculture should ensure the extension workers add malaria control to their schedule of activities.

Local production of bednets should be increased to bring down the costs, that all tariffs on bednets and insecticides should be removed and that public and private donors should be encouraged to subsidise the provision of bednets for those who cannot afford them.

The economic costs of malaria are enormous. According to WHO, health economists estimate that in 1997 alone, African region lost more than US $ 2 billion because of malaria and malaria related diseases. The amount of loss is projected at US $ 3.6 billion this year.

WASHINGTON: An experimental malaria vaccine achieved limited success in a field trial in West Africa, researchers say, fueling cautious hopes that people can one day be inoculated against one of the planet's most prolific killers.

The vaccine briefly reduced malaria cases by almost two-thirds in a group of volunteers in Gambia last year, researchers said. Scientists disclosed the results last week at a meeting of the American Society of Tropical Medicine and Hygiene in Washington.

Scientists recruited 306 men in six rural villaged in Gambia, a nation about 200 miles long and about 12 miles wide, lying inside Senegal. After two months, almost two-thirds were protected, but that rate fell to just 16 percent after 15 weeks. It was too short a time for a practical vaccine.

But researchers were heartened about the results. The vaccine, developed by the Walter Reed Army Institute of Research and SmithKline Beecham, protected about half of volunteers in a series of small-scale trials in the institute's Washington labs over the past three years. But the African trial tested the vaccine against different strains of the malaria parasite in an area of intense transmission.

The vaccine consists of a piece of the malaria parasite linked to a piece of the hepatitis B virus, and mixed with a cocktail of compounds called adjuvants, meant to boost the response of the immune system. Like all vaccines, the Walter Reed-SmithKline product is designed to teach the immune system to respond quickly and aggressively to a particular microbe.

Institute says he plans in January to use RTS,S to "boost" a vaccine developed in his labs. Hoffman's vaccine works by inserting malaria genes into the DNA of human muscle cells, causing those cells to make chemical structures normally made only by the parasite. Released into the bloodstream, those chemical structures stimulate the immune system, preparing it for combat with the parasite itself.

Malaria is common throughout the tropics. It ranks with tuberculosis and AIDS as one of the biggest killers among infectious diseases. The World Health Organization estimates that each year the mosquito-borne parasite causes a half-billion cases of clinical illness and 1 million to 2 million deaths.

The world's largest pharmaceutical companies are eager to spend billions of dollars to develop better treatments for heart disease, depression, and other high-priority diseases of wealthy nations, but they are far less enthusiastic about putting resources toward malaria, tuberculosis, and HIV, which kill millions of people in developing countries.

Call them cruel or heartless, but they are simply following the rules by which nearly every US company operates: they don't invest in areas in which they cannot make a profit, and selling drugs to developing nations is not profitable.

Two Harvard University economists have come up with a novel way to circumvent the problem: give private companies financial incentives - from a pool of public and foundation funds - to produce products for the developing world.

"genius" grant, and Jeffrey Sachs, a noted expert on debt relief who directs Harvard's Center for International Development, want wealthier nations to direct dollars to pharmaceutical research that would otherwise go toward direct loans to impoverished nations.

Sachs, a well-known advocate for the world's poor, believes that when governments fail to meet the basic health needs of their people, they destroy the base for future economic growth. But because creating new drugs and vaccines is a technology-intensive business that largely occurs in the developed world, the Third World is dependent on the good graces of industrialized nations.

The private and government donors would promise the money upfront, but wouldn't have to spend it unless and until a successful malaria vaccine was ready for market. "It's not standard foreign aid; it's conditional," Sachs said.

"Such a fund would both create incentives for vaccine research and ensure that if vaccines were developed, they would reach people in developing countries," said Kremer. Companies understandably shy away from researching drugs that would be targeted mainly to developing nations, he said, because as it is, only one in 10,000 drugs makes it from the laboratory to pharmacy shelves.

Before a drug can meet approval by the US Food and Drug Administration, it must go through a lengthy series of clincal trials to establish its safety and efficacy, and the FDA must review and pass judgment on tens of thousands of documents that constitute the application for marketing approval. Today, it costs about $500 million to develop a drug, and can it take more than a dozen years.

"Paying for vaccines, rather than funding research expenditures, gives pharmaceutical firms and scientists strong incentives to self-select only those research projects that have a reasonable chance of leading to a vaccine," said Kremer. "With pull programs, the public pays only if a vaccine is actually developed."

For the past three years, Leahy has spearheaded allocations of $175 million in foreign aid to address infectious diseases worldwide, with funds being used to expand programs at USAID, the Centers for Disease Control and Prevention, and the World Health Organization. "We can get more and we will get more," Leahy said.

The enemy - malaria - is devious. The battlefield is worldwide, from Wirth's office at the Harvard School of Public Health to the refugee camps where Lee, an East Boston physician, has worked in Africa. Last week the international group through which Lee donates his time, Doctors Without Borders, was awarded the Nobel Peace Prize for its humanitarian work in areas of the world where disaster, be it war, famine or epidemic, strikes.

The old weapons against malaria are failing; the parasite is increasingly resistant to insecticides and to the major drugs used to fight it, including the once reliable chloroquine. The disease has shown a remarkable capacity for variation and mutation, making it difficult to treat and control. While a single case of measles grants the sufferer lifelong immunity from the disease, even multiple bouts of malaria produce only partial immunity.

Malaria is transmitted by the Anopheles mosquito. The insect carries the parasite, Plasmodium, from one person to another; the disease reproduces in the liver and then invades red blood cells. In mild cases, malaria causes recurrent fever and chills; in severe ones, it causes anemia, weakness, coma or death.

Many pharmaceutical companies have dropped out of tropical disease research because there is little chance of recouping their investment in impoverished countries, where people are too poor to buy the drugs without government assistance.

The best approach to eradicating or limiting malaria is a vaccine, say experts, but few companies have an incentive to invest in one. Wirth, director of the Harvard Malaria Initiative at the Harvard School of Public Health, believes "there has to be a new paradigm of governments getting involved" in providing incentives for companies to work on drug or vaccine development.

Roll Back Malaria campaign, begun last year, which is attacking the disease on several fronts. Earlier this month, WHO said it would help provide 60 million African families with insecticide-treated mosquito nets over the next five years. Studies have shown that the treated nets can reduce malaria deaths by 25 percent.

The Roll Back Malaria campaign is unique in the realm of disease control, say experts, both for its global scale and for the diversity of partners engaged in a single coordinated effort. The campaign brings together academic researchers, pharmaceutical companies, government and private donors, international agencies, health officials from developing countries, and humanitarian relief groups.

Somali refugee camps of eastern Kenya for Doctors Without Borders. The most common diseases he treated were diarrhea, respiratory tract infections, and malaria. Many people had deadly combinations of malnutrition and parasitic infections.

"We needed a wider arsenal of weapons," he recalls. Like other relief workers, he lived with "a kind of contradiction" that is emblematic of malaria generally: he was protected by prophylactic medications, bed nets treated with insecticide, and an adequate diet, none of which the refugees have access to in their daily lives.

She surveyed 20 major pharmaceutical companies and found only two involved in malaria research: one had an anti-malarial medicine in the final stages of development and another was working on a vaccine and combinations of existing drugs.

Malaria kills about 1.1 million people worldwide each year, about 1 million of them in Africa. The overwhelming majority of them are children under five; indeed, one of every four childhood deaths in African is due to malaria.

People living in malarial areas may endure an infectious bite every night; they may have chronic anemia, immune system suppression, and vulnerability to countless other maladies. Children may suffer 10 to 20 bouts of malaria before the age of five; if they survive into adulthood, they often gain partial immunity that reduces the severity of the disease but does not prevent subsequent infections.

Kamini Mendis, a WHO malaria specialist in Geneva. In addition to time lost from work and school, the disease discourages outside investment because companies hesitate to send representatives to malarial regions.

Although the market is vast, "people who need these drugs can't afford to pay," said Richard B. Sykes, chairman of Glaxo Wellcome, which plans to join the World Health Organization and the World Bank in a program called the Medicines for Malaria Venture. The nonprofit project, with a $30 million yearly budget, plans to develop and register a new antimalaria drug every five years.

The sum budgeted is only a third of the estimated average $500 million cost of discovering and marketing a new drug, but industry and public officials fear that without a new approach, no new antimalaria drugs will come to market.

The joint venture "has been created because the increased costs of developing and registering pharmaceutical products, coupled with the prospects of inadequate commercial returns, have resulted in the withdrawal of the majority of research-based pharmaceutical companies," said the W.H.O. director general, Gro Harlem Brundtland.

Robert Ridley, acting head of the program, said the idea to set up an independent group grew out of discussions by industry officials on how to keep drug companies interested in an unprofitable business area. In the joint venture, the companies will work with academic researchers.

Then, Mr. Ridley said, the industry would have to help make sure that any newly discovered drugs were made widely available. "You're not going to get a $1 million blockbuster drug, but you can make it so it's not a huge money loser," he said.

So far, 120 research projects have submitted requests for financing and three have been selected to receive $4 million through next year. Glaxo Wellcome will work with Bristol University, SmithKline Beecham with the University of California and Roche of Switzerland with the University of Nebraska.

Glaxo inherited Malarone when it took over Wellcome. Too expensive to put into commercial production, the company determined to offer it free to Kenya. But it was not as simple as that. David Pilling reports.

A child-size mound draped in a dirty blanket lies motionless on a broken metal bed. Flies circle around one end of the heap. A tiny foot protrudes from the other. The body appears to have been abandoned. Nobody, not a nurse nor a relative nor a friend, is in attendance.

The setting is a grim, mustard-coloured hospital ward in Siaya, a steamy, malaria-ridden district of Kenya on the shores of Lake Victoria. The pathetic mound is another statistic, one more victim of the mosquito-borne disease that is ravaging East Africa.

Yet suddenly, miraculously, the blanket twitches into life. A little boy, perhaps nine months old, twists round from his prostrate position and stares up with wide-eyed interest. Later we learn that the baby -- no one seems to know his name -- has responded to quinine, an anti-malarial of last resort.

The situation is getting worse. In much of East Africa, chloroquine, the cheap and widely available drug that has kept malaria at bay for decades, has become almost useless as disease-bearing parasites have learnt the art of resistance.

The drug was Malarone, a clever combination of an old compound called proguanil and a new anti-viral known as atovaquone. Glaxo had inherited the miraculous drug when it took over Wellcome, a British company with a distinguished tradition of research into tropical diseases.

There was a problem. Glaxo was more commercially driven than Wellcome, which had its roots in the charitable sector. Malarone was an extremely expensive drug to produce; its estimated retail cost was GBP 24 for a course of treatment. For desperately poor countries such as Kenya, it might as well have cost GBP 24,000.

But Malarone was not just a gleam in a scientist's eye. It was only months away from regulatory approval and had a fiercely loyal follow- ing inside the company. Glaxo felt morally obliged to do something with it.

"Here was Glaxo with this fantastic drug," recalls Bulloch, one of the driving forces behind the donation. "Perhaps we were a bit naive, but we felt that people would be falling over each other to make use of it."

Three years later, things have not worked out like that. Instead of the 3 m Malarone doses Glaxo could theoretically have distributed, the grand total is somewhat smaller -- about 100.  Most of those have been dispensed at Siaya where, after years of arguing, a pilot project finally got under way in April.

"I would never have believed it could be so difficult to give something away," says Bulloch. So why has it been so difficult? Why is the drug gathering dust in Glaxo's Nairobi warehouse while malaria rips a swathe through Kenya?

"I had never heard the word 'donation' before," says John Ouma, a lookalike of US boxing impresario Don King and head of the Department of Vector Borne Diseases in Kenya's Ministry of Health. "The word 'donation' was not in my vocabulary . . . You had to wonder what the hell they were talking about."

The suspicion in Kenya was that Glaxo was mounting a dastardly marketing ploy by weaning the country off existing drugs -- which cost pennies -- in favour of GBP 24-a-go Malarone. When it was hooked, so the theory went, Glaxo would pull the plug on the donation and start charging.

Such suspicions reflect a deep distrust in much of the developing world of pharmaceutical companies, regarded by many as serving only the interests of western patients and their share-holders. Glaxo, a company that had grown fabulously wealthy by selling drugs for peptic ulcers, herpes and migraine, seemed to fit the stereotype.

"People do ask why here," says Annette Alcock, a Nairobi-based aid worker. "They don't want something new foisted on them. They think it's imperialism all over again. There are still people here who see condoms as a western plot to stop Africans reproducing."

Even when Glaxo -- which operates the donation through the Atlanta- based Task Force for Child Survival and Development overcame initial suspicion, progress was hampered by a further doubt: was 1 m doses sufficient? After all, this was a global donation, not just aimed at Kenya.

But, argues Bob Snow, a malaria epidemiologist and adviser to Kenya's health ministry, such concerns are legitimate. New drugs, however effective, cannot be given out like sweets. They must be woven into the fabric of a country's existing drugs policy, which has often been painstakingly stitched together over years. Adding a new drug can throw the whole thing off killer.

Preventing abuse means keeping close tabs over how it is used. In poor countries, patients resist taking a full course of medicine, preferring to save precious tablets for future bouts of illness or to share with family members.

These include a urine test to determine whether a patient has actually been treated with first-line therapy (the temptation is to lie in order to qualify for free drugs) and microscopy to verify the type of infection. Children below 11 kg and pregnant women are, for the moment, excluded because sufficient research on these categories of patient has not been carried out.

To prevent Malarone leaking on to the black market, tablets are kept under lock and key. And to ensure full dosing, they must be swallowed in front of the physician on each day of the three-day course.

For Oyediran, strict guidelines are vital. "One hopes and prays hard that we'll have Malarone with us as an effective drug for a very long time," he says. "But those plasmodia are wretched, horrible things.

That's fine in theory, says Snow. But in practice, if Malarone is really to make a difference, it must be administered at village, not district, level. In the countryside, microscopes and trained clinicians are a faraway dream. Thus, even if the drug is free, with such a strict and costly protocol, it is unaffordable.

That would shorten Malarone's effective life. It would also undermine any plans Glaxo has to make a little money by selling it as a prophylaxis to western travellers. But it might, says Snow, bridge the gap until a more affordable drug, or combination of drugs, comes along.

"It's been great of Glaxo to start out with a donation, but in the long run you can't operate like that. If you could bring the price right down, we would have a lifesaver on our hands. Otherwise, it re- mains attractive, but it will probably stay on the shelf."

Far from it, say the optimists. From the agony of its birth could come a model of how to forge a public-private partnership. The Siaya pilot programme is up and running and, having thrashed out their differences, the various actors are building trust and a fragile consensus about how best to move forward. At a meeting in London last month, it was decided to press ahead with more pilot projects and to extend the use of Malarone as aggressively as possible to children and pregnant mothers. There is, says Glaxo, an absolute determination to make it work.

Back in Siaya -- where few are aware of Malarone, let alone the hooha it has unleashed -- anxious mothers are lining up in the hospital's open courtyard. Many of the children clutching their skirts have malaria.

Infectious diseases kill 17 million people every year, most of them in the developing world. Many of these diseases are treatable but the necessary drugs are either too costly or no longer produced. In addi- tion research for tropical diseases has nearly stopped.

The market is failing to provide life-saving affordable medicines for people in developing countries. "We are forced to watch our patients die because they cannot afford the treatments that could save their lives" said Dr Bernard Pecoul of MSF. "While we appreciate that pat- ents can be an important motor of research and development funding, there must be a balance to ensure that people have access to medi- cines."

The search for cures of diseases that affect people in poor countries has ground to a standstill. Of 1,233 new drugs brought to market be- tween 1975 and 1997 only 13 were for tropical diseases. While the highly profitable pharmaceutical industry concentrates on making treatments for impotence and obesity, doctors treating patients with diseases such as tuberculosis, malaria and sleeping sickness, are forced to use archaic treatments developed 30-50 years ago.

"Access to medicines is a matter of life and death. The European Un- ion (EU) must take action now to ensure that health is a priority in trade agreements and that new treatments are developed for neglected diseases" said Dr Pecoul.

Mpamba said there was also strong need to eliminate mortality and reduce morbidity caused by malaria especially in under-fives, pregnant women, the malnourished and chronically ill. He said the malaria-causing mosquito has in the recent past become increasingly resistant to insecticides. "Furthermore, the malaria parasite itself has developed resistance against chloroquine which is the commonest and most affordable anti-malarial drug in the country," Mpamba said.

He said the government is committed to eradication of malaria which was said to be second to HIV/AIDS in terms of mortality rate. World Health Organisation (WHO) resident representative Dr Eddie Magamu said it was necessary that all stakeholders join forces in the fight to eradicate malaria. "Partnership is needed to control malaria so as to bring down mortality rates as a result of malaria," he said.

The World Health Organization will announce today in Tanzania that it will spearhead a program to reduce death from malaria by increasing 30- fold the use of insecticide-impregnated mosquito nets in Africa.

The five-year program will seek to boost both supply and demand for bed nets by subsidizing local manufacture and increasing people's understanding of their usefulness. Although some very poor households will probably get nets for free, the strategy is to use market forces, rather than charity, to promote their spread.

"It's a huge piece of the child mortality pie globally. This program is likely to have an enormous impact on that," said Nils Daulaire, head of the Global Health Council, a Washington consortium of international health organizations.

The British government will commit $ 70 million to the program, a spokesman for the Global Health Council said. The U.S. Agency for International Development (AID) recently committed $ 15 million to pay for market research and bed net promotion--services that presumably will encourage local manufacturers.

Nigeria in West Africa and Kenya, Tanzania, Uganda and Zimbabwe in East frica are the most promising immediate targets, said John W. LeSar, head of the international health programs for the Academy for Educational Development, a nonprofit organization in Washington that will do the work for AID.

In some endemic areas, children are bitten by several malaria- transmitting mosquitoes each night, LeSar said. Nets not only decrease deaths from malaria, they reduce the nonfatal effects of the disease (notably chronic anemia) that make children susceptible to other infections.

Cost is a barrier in some places. In a Gambian study, only 14 percent of nets were re-treated when an insecticide give-away program was stopped. In one study, frequent washing of nets soiled by children shortened the repellent action significantly.

In addition, insecticide-resistant mosquitoes have been found. Use of nets, however, is less likely to promote resistance than the spraying of chemicals whose main purpose is to kill, rather than repel, mosquitoes.

When former Norwegian prime minister Gro Harlem Brundtland was elected director-general of the World Health Organization, she announced she would train her sights on malaria, a scourge of Africa. She is making good on her word.

A year and a half ago, Brundtland named David Nabarro to head the WHO's malaria effort. Nabarro had been an expert on infectious diseases with Britain's Department for International Development. On Wednesday, the WHO announced an enormous drive to provide nearly 60 million African families with insecticide-treated bed nets over the next five years. Bed nets have been used for at least a century as protection against the anopheline mosquito, whose bite causes malaria, but nets tear easily and mosquitoes can enter through the smallest holes.

Daulaire, head of the Global Health Council, the world's largest membership alliance dedicated to improving global health. "Mosquitoes are voracious feeders, strongly attracted by the smell of blood, and they will go through any tear or tiny hole." What is so significant about this new effort is that the bed nets have been treated with a nontoxic insecticide made from the chrysanthemum plant. The insecticide, which has been approved by the WHO, creates a chemical barrier that covers up small holes or tears.

A study in Gambia in West Africa found child deaths from all causes were reduced by a quarter because of the bed nets. "These kids were dying from pneumonia and other diseases because they were weakened by earlier bouts of malaria,"

An estimated 700,000 African children died from malaria last year. Fewer than 2 million African households have treated bed nets, and the number using them properly by getting them retreated or replacing them when needed is even lower.

But their lifesaving potential got an even bigger boost from a recent review of bed net studies that found that children sleeping under treated bed nets were 50 percent less likely to get malaria than control groups.

Program, the public and private sector of malaria-ridden countries, along with development agencies, chemical makers and scientific institutions. It is a global public-private partnership. The goal is to cut in half the world's malaria burden by 2010.

Treated bed nets, until recently, cost $ 4 and were out of reach for many families. A $ 70 million contribution to the campaign pledged by Britain's Department for International Development, will change that. One of the first major donations, this contribution will allow considerable economies of scale that could bring the price of a bed net down to $ 2.

The Academy for Educational Development, a Washington-based nonprofit dedicated to helping solve critical problems in such areas as health, has a $ 15 million contract with AID to educate the public about bed nets and develop a commercial market for them. "We think we can lower child mortality by 30 percent once the market is developed," says John W. LeSar, who oversees AED's international health programs.

"We are interested in whether the right people use nets -- poor families, exposed families -- whether they use them correctly and safely. The commercial people are interested in sales. We're public health people, so we are interested in how they are used" and whether their use becomes established behavior, LeSar says. The initial educational and commercial campaigns will be reinforced seasonally with reminders to people to get their bed nets ready.

"You don't get the disease. If we can jump start these commercial markets with government funds, then governments will have leveraged their funds considerably and can back out once the market is established."

Bed nets are only part of the solution to malaria, which goes through a number of stages, Daulaire says. Most people don't die from it, but they get very sick and vulnerable to other diseases, so early detection and treatment are important. "The holy grail of malaria control is a vaccine that works well against all of the different stages of the malaria parasite. A lot of work is going on with that . . . but we aren't there yet," Daulaire says. Work also is being done on environmental control of the anopheline mosquito, and unlike the massive spraying of DDT and other pesticides that occurred earlier, the thinking now is to concentrate on breeding grounds by draining standing water and introducing predator species to attack the mosquitoes.

Daulaire, who was the government's leading expert on international public health at AID, says the malaria campaign ranks with the Universal Childhood Immunization campaign launched by UNICEF in the 1980s under the leadership of the late James Grant. That campaign's goal was to immunize 80 percent of the world's children, up from 20 percent in the early '80s. It succeeded and has been one of the greatest public health victories of the century. If "Roll Back Malaria" succeeds as well, Gro Brundtland will have more than earned the enormous confidence the world's nations have placed in her.

DDT. But the negotiations, set to resume in Geneva next month, are drawing opposition from an unlikely quarter: public health professionals, who say DDT is necessary to stop the spread of malaria, a disease that kills as many as 2.7 million people each year, mostly children in undeveloped countries.

"A child dies of malaria every 12 seconds," said Dyann F. Wirth, a malaria expert at the Harvard School of Public Health and president of the American Society of Tropical Medicine and Hygiene. "That could go up dramatically if we lose this important control tool."

Some type of public health exception is likely, said Jim Willis, director of chemicals for the United Nations Environmental Program, which is sponsoring the talks. But the specifics are engendering intense acrimony between the public health experts and environmentalists, and have created some friction in the Federal Government, as it tries to formulate its policy for the negotiations.

DDT's poisonous effects, showing, for example, how it killed the robins that ate the earthworms that dined on the leaves of Dutch elm trees that had been sprayed with the insecticide. The public outcry was tremendous; the book led to the establishment of the Environmental Protection Agency in 1970 and the United States ban on DDT in 1972.

Responsibility, a doctors' group concerned with environmental health. They argue that even small amounts of DDT sprayed inside homes are harmful to the environment and cite studies suggesting that the pesticide turns up in the breast milk of nursing mothers and has other "subtle effects on human health."

On the other side are two scientists' groups, the tropical medicine society, and the Malaria Foundation International, a nonprofit organization dedicated to promoting research. Several months ago, at the behest, curiously enough, of a Vancouver environmental lawyer and cell biologist, Amir Attaran, the foundation posted a letter about the negotiations on its Web site, arguing that "setting a firm deadline to ban DDT places an unethical burden on the world's poorest countries."

Because mosquitoes develop resistance to pesticides, Dr. Kilama says that getting rid of DDT would be a mistake. "The mosquitoes are very complex and one should not rely on one measure alone, particularly one type of insecticide," he said in a telephone interview last week. "It's like when you fight, you have a pocketful of arrows and now you have only one arrow left."

Liroff, urges "more creative thinking about moving away from DDT." He points to an experiment in India, where gambusia -- a larvae-eating fish -- were deposited in bodies of water where mosquitoes breed. But Dr. Kilama, of Tanzania, said such steps are not practical in a country where a hippopotamus footprint after a heavy rain can create an instant breeding ground.

The 371 doctors, health economists and scientists, who include three Nobel laureates, warn of the consequences if the United Nations Environment Programme outlaws DDT along with a range of other pesticides known as persistent organic pollutants in a treaty to be negotiated next week.

The malaria experts accept DDT does environmental damage but accuse WWF of overstating the dangers to humans. While pesticide residues are found in breast milk, only one study - not two as WWF states on its website - has claimed DDT may be carcinogenic. The other six found no evidence DDT was implicated in breast cancer.

"If western countries like the US or UK want the environmental benefit of a DDT ban, let them pay for it. Africa, Asia and South America have neither the technology nor money to research and implement alternatives to DDT. The rich countries do. For them to advocate a DDT ban while holding tight the purse -strings for those alternatives is obscene."

In their letter, the doctors and scientists say that, although they agree DDT must one day be phased out, 'we also believe that human life must not be endangered in reaching that goal. In our view, setting a deadline for the elimination of DDT - whether that deadline is in 2007 or some other date - unacceptably endangers health in countries with malaria'.

Tropical Medicine, said: 'DDT is the cheapest insecticide and what I feel will happen is - as has happened several times already - if they can't use DDT they won't feel they can afford to replace it, so they will simply cut down on the total area that gets vector (mosquito) control."

Malaria is carried by mosquitoes. The most cost-effective method of controlling malaria is to control mosquitoes by spraying the walls on which they rest with DDT, a chemical which is toxic to these insects but not to humans.

The use of DDT has ensured that SAs malarial areas are now one-fifth the size they were before the Second World War. The disease, however, has been on the rise in SA and throughout the region. This is partly because of a reduction in DDT use, as well as higher rainfall in recent years and increased migration of people between SA and other highly malarial countries such as Mozambique.

Donald Roberts of the Uniformed University of Health Sciences in the US has studied the relationship between malaria and DDT use and found a strong negative relationship: the more DDT is used, the lower are malaria rates.

Many of the studies against DDT were, however, scientifically flawed and have subsequently been refuted. DDT, for example, is not a human carcinogen. Bird species actually rose during the period that DDT was used in the US.

In any event, no one is proposing that DDT be widely sprayed over agricultural fields and wetlands, as it was in the past, but that it is allowed to be sprayed in limited quantities inside dwellings. The amount of DDT that a US cotton farmer would have used on a 100-acre crop in 1968 is enough to protect every high-risk house in Guyana for a year or more.

Zimbabwe has come under pressure from, among others, tobacco farmers to cut back on DDT use. This is because exports might be affected if developed countries find any trace of DDT on tobacco. The fact that tobacco contains numerous carcinogens and that DDT has been proven not to be a carcinogen seems to have been conveniently forgotten.

The Malaria Foundation International, which is made up of more than 350 physicians, including the medical laureates mentioned above and malariologists, published an open letter (www.malaria.org/ddt.htm) to the Unep delegates urging them not to ban DDT until an affordable alternative is available.

The World Wide Fund for Nature says that the banning of DDT will concentrate minds in order to find a costeffective alternative by 2007. This seems like an unbelievably flippant attitude to the lives of the millions that are at risk from malaria.

The World Health Organisation previously supported the use of DDT in vector control. However, its new high-profile malaria initiative, Roll Back Malaria, does not even mention house spraying and prefers to promote the development of new drugs and a vaccine.

Efforts to develop a vaccine and new drugs are woefully underfunded. In addition, because profits in fighting malaria are limited, private sector research is minimal when compared with research into fighting other diseases.

One can only hope that the recent report that two 11-year-old Boy Scouts in Long Island, New York, contracted malaria at a scouting camp will bring home to the north the cost that malaria imposes on the south.

HOW many deaths does it take to justify assaulting the environment with pesticides? Not many, if they're in New York City. As soon as three people died from encephalitis, public officials and environmentalists generally agreed that any risks from malathion were negligible compared to the threat from mosquitoes.

Beyond the city limits, though, the answer seems to be more complicated. While helicopters have been spraying pesticide all over town, negotiators at the United Nations have been debating a proposed global ban on the use of DDT. The ban is opposed by doctors and researchers who warn that millions of people could die from malaria in countries that can't afford alternatives like malathion.

Ms. Carson contrasted the evil DDT with farmers' traditional insecticides made from "naturally occurring minerals" -- and then, without a trace of irony, went on to list two potent poisons, lead and arsenic, among the ingredients of the good old-fashioned compounds. She mistakenly claimed that DDT causes cancer, which wasn't proved then -- and still hasn't been.

DDT might have contributed to the decline of populations of some birds, like eagles and falcons, although some scientists have long attributed the declines to other factors. When DDT was banned in the United States in 1972, the Administrator of the Environmental Protection Agency overruled a subordinate who, after hearing months of testimony, concluded that DDT, used properly, did "not have a deleterious effect on freshwater fish, estuarine organisms, wild birds or other wildlife."

Except, of course, for mosquitoes. In 1970, the National Academy of Sciences estimated that DDT had prevented 500 million human deaths worldwide from malaria. Since then, as a result of the pressure from environmental groups and international agencies, the use of DDT has been reduced overseas.

Environmentalists maintain that malaria can be controlled by other means, even in poor countries, but the disease rate has soared in many places since DDT spraying stopped. Defenders of DDT have tried to dramatize the situation with letters, petitions and an Internet Web page (www.junkscience.com/ ddtfaq.htm) featuring "Rachel Carson's Legacy of Death," presented as a malaria clock that adds a new fatality every 10.5 seconds.

"The great thing about DDT, for poor countries, is that it's dirt cheap and lasts a long time," Dr. Ames said. "The United States doesn't need it, because we have better alternatives. Malathion is clearly preferable for us because it degrades so quickly in the environment and in the body. But not everyone can afford it."

Dr. Ames, incidentally, had some reassurance for the New York residents who are convinced that even malathion is harming them. "When they were spraying malathion to stop the medfly from invading California," he recalled, "hundreds of people in Palo Alto reported suffering symptoms from the chemical. But they reported these symptoms before the town had even been sprayed."

The London school, which is renowned in its field, has been working with the Tanzanian government on the issue ever since it was announced that Bill Gates' Microsoft Foundation had given it a $40 million donation to try and roll back the disease, which kills about three million people a year, most of whom are in Africa.

Professor Elcanor Riley from the London school told The EastAfrican that work would also be conducted with the Kilimanjaro Christian Medical Centre at Moshi and that over the next few years Tanzania could become a major international centre for field trials for potential new vaccines.

Ironically, the grant came as a result of a routine letter sent to the Gates Foundation last year asking for several million pounds for malaria research and was one of the thousands of such requests it receives.

The need for a vaccine in Africa is crucial as it is estimated the continent spends around Pounds1.2 billion ($1.9 billion) a year. With prophylactics proving increasingly ineffective, a new vaccine against malaria is becoming more and more vital.

Whereas the Tanzania centre will, however, concentrate on vaccine development, Kemri's focus is on environmental and therapeutic control of the disease, by encouraging the use of impregnated bed nets.

The report also identified Kenya, Tanzania, Nigeria and the Gambia as the four leading countries on the continent in malaria research between 1995 and 1997, with each country's researchers publishing more than 50 papers on malaria in internationally reputed medical journals.

The report, however, said that malaria research in Africa was hampered by lack of resources, with "88 per cent of research grants to African laboratories between 1993 and 1998 coming from organisations outside Africa."

Uganda Thursday launched a malaria prevention programme which hinges on the provision of insecticide-treated nets to avert over 100,000 deaths caused by the Anopheles mosquito-spread disease in the country annually.

"The overall objective of the Uganda national malaria control programme is to prevent mortality and reduce morbidity and to minimise the social and economic costs and losses due to malaria," Dr. Dennis Lwamafa, head of the programme, said.

"Smartnet is a revolutionary malaria prevention net that does not need re-treatment for up to 22 washings and costs far less than what a typical family spends on malaria treatment each year," Deus Mubangizi, the CMS marketing manager, said.

According to the inter-country workshop on community-based malaria interventions, the tropical disease claims the lives of 26,000 Kenyan children every year. The disease accounts for between 30-50 percent of the overall infant mortality in the country.

Moreover, malaria accounts for 30 to 50 percent of the country's overall infant mortality, it said. The report quoted James Sekento of the Malaria Control Programme as saying that pregnant women risked suffering severe anaemia and giving birth to underweight babies because of malaria.

Malaria is killing several people due to the absence of glucose and medication, according to a report published by Ifoyta, a party owned weekly. The paper reported an undisclosed but a large number of people including children who cannot take oral medicine are dying.

Administrator of Gambella Hospital Ato Hukoch Agid, who admitted the depletion of medication in the hospital disclosed that there was no budget allocated for a restocking. He explained the hospital has no money to purchase the required medicines but has made the Regional Health Bureau aware of the problem.

Ato Osman Agud, who is head of the region's health bureau, in turn acknowledged the notice given by the hospital. But, he explained his office has asked EPHARM, a government owned pharmaceutical, to give them a proforma invoice.

He explained that since they are prohibited to buy the medicine from elsewhere, they have to wait for the response from EPHARM, which they will relay to the Regional Finance Bureau in order to get the necessary funds for the purchase. The Regional Finance Bureau will not release the funds unless it gets a copy of the Proforma Invoice from EPHARM.

He called for the sensitization of the political leadership and functionaries, particularly at the regional and district levels, to start movements aimed at achieving prevention and control of the disease.

The Minister noted that the devastating effect of Malaria on pregnant women and children and its immeasurable potential of frustrating the efforts in the nation, make the focus on Malaria and the environment highly commendable.

The Deputy Director of Environmental Protection Agency, Mr. John A. Pwamang, disclosed that research is currently under way to develop and test a Malaria vaccine, adding "it is likely to be many years before a cheap and effective vaccine is widely available."

He noted that the mosquito control programme may have adverse effects on the environment and suggested that a risk assessment be conducted to determine control measures that are effective, efficient and produce minimal adverse effects on the environment and public health.

"We have been monitoring the situation and so far, the cases reported cannot be described as an epidemic. But, with the onset of the long rains, we expect the situation to get more serious," Ochola was quoted by the Daily Nation newspaper as saying.

"Some 8.5 million Kenyans are at risk from the malaria epidemic," they told journalists at the Health Ministry in Nairobi soon after receiving equipment, vaccines and insecticides worth about 95,000 US dollars from the WHO to be used in malaria control.

The ministers called for intervention measures such as vector control and use of insecticide treated mosquito nets to combat the disease, adding that the ministry was in the forefront implementing various malaria control measures.

Ongeri called for concerted efforts to fight the scourge, saying that recent revelations of the disease showed that even high altitude areas, formerly considered as malaria-free, were now experiencing the epidemic, resulting in many deaths.

"There is little immunity and all age groups are affected," Ongeri said, adding that in future, the government may be forced to invoke the Public Health Act to contain epidemics which were preventable.

While AIDS may have become the most devastating killer across much of Africa in recent years, here in the Kisii Highlands a mysterious malaria epidemic has for weeks been carrying off more people than any other disease, although the region, lying 1,800 metres above sea level, was previously regarded as largely malaria-safe as a result of its altitude.

The mosquitoes bearing the malaria parasite should die quickly in the cool nights of the highland plateau, but they have migrated from the considerably warmer shores of Lake Victoria into the mountains and are surviving.

The outbreak has also caused alarm in Nairobi, which lies at the same altitude and has thus far been free of the marial mosquito. When the first deaths occurred in Kisii in May, Dr Wycliffe Mogoa did not believe he was faced with an epidemic, but since then the director of the completely overstretched Kisii Provincial Hospital has seen more people die than in the rest of his previous career.

Plasmodium falciparum is responsible in 99 per cent of all cases, a parasite that causes the most dangerous form of the disease, malaria tropicana, which can cause death within 12 hours if not treated.

East Africa for the United States armed forces, believes climatic changes are primarily responsible. Under normal circumstances it ought to be extremely dry around Kisii, but El Nino has changed that. Even the plateau nights are now much warmer than before, and it has been pouring almost every day for weeks, although this is the dry season.

Pools of stagnant water are everywhere, providing ideal breeding conditions for the mosquitoes. Nevertheless, during the El Nino year of 1998 there was also more rain and more standing water, but considerably fewer malaria cases than this year.

"Nobody here can afford to take malarial prophylaxis all the time," one says, and Kisii Hospital is also suffering the effects of a lack of funds, with medicine soon to become as scarce as the beds themselves.

Nairobi - The World Health Organisation says that the recent outbreak of malaria across western Kenya, which has killed more than 300 people in one district alone, is symptomatic of the move of the mosquito into parts of Africa where it was rarely known before.

Kampala - Fever or malaria? The average Ugandan will struggle to tell the difference between the two. This is because malaria, which manifests itself in the form of a fever, is so prevalent in this country that one out of every four sick Ugandans would be suffering from this mosquito-borne disease.

Uganda still struggles with prevention and treatment. At the macro level, measures like malaria control, spraying in urban areas has either stopped, or is inadequate.  Simple, inexpensive measures like clearing bushes and draining pools, that could be implemented by civic authorities, are not being practised.

Fighting malaria is therefore well within our control if only we looked at it critically.  Studies have shown that the cost of treating malaria is much higher than buying a net.  Experience has shown that spraying can be successful.  The WHO malaria eradication project in the 1950s reduced vector concentrations in Kabale and Rukungiri to almost zero, within a year.

They may also breed along the edges of streams. As the rain season approaches, the danger of contracting the disease increases considerably and you need to take precautions against this lethal illness .

Filling in with mud or stones or draining places where water collects can kill the mosquito larvae. Regular clean-ups of neighborhoods also help reduce mosquito breeding. Pregnant women and children are especially prone to malaria because of their wenker immunity.

If possible, use insecticide Treated Bednests (ITNs) such as Powernets from the society for Family Health. ITNs can ensure your family's protection against the disease by repelling and killing mosquitoes.

You can also keep mosquitoes away by using fumigants such as mosquito coils or other local repellants such as mango leaves . In addition, pregnant women can be effectively protected against malaria by taking anti-malaria tablets through pregnant.

As earlier pointed out, exposing your family to malaria can have very serious consequencies. Many lives have been needlessly lost because simple precautions were not taken to protect people from the disease.

Christine Zulu, almost lost her life to the killer disease in March Principally because she had done little to protect herself from malaria. She says the disease sneaked up on her while she was on night at the University Teaching Hospital.

And yet, it was not until 10.00 hours, seven hours after the first symptom, that Christine took her first medicine, the prescribed 4 tablets of chloroquine to start with. But even though she completed the full course, she had apparently left it very late.

Infact almost too late. When her younger sister, Susan visited her the following day, Christine couldn't walk, nor could she recognise anyone or in hat surroundings she was. "Her eyes kept rolling in their sockets and I thought she would die right there and then," remembers the younger sister.

Hospital and for 48 hours, she remained on the brink of death. But on the third day, she began her slow painful recovery. In the meantime, she had lost both her speech and hearing and had developed severe anaemia. "It took me more than a month to fully recover .

Ndola City Council spokesman Mumbuna Kufekisa said yesterday because of the encouraging results, the sponsors Bwana Mkubwa Mine had pledged to pump more money into the project. Bwana Mkubwa has spent more than K100 million on the project for materials and other costs while the council has been providing labour and transport.

The company has pledged to release a further K60 million for the second phase of the drive. Half of the dambos which the council had identified across the city as notorious breeding grounds for mosquitoes had been sprayed with insecticide.

The council had embarked on the project after studies showed that malaria was responsible for most of the deaths recorded in the city. So far, all the dambos in high cost residential areas including Itawa, Kansenshi, Northrise and Kanini had been sprayed. Meanwhile, the Ndola City Council has discovered an anomaly where more than 30 apartments at the Itawa complex are not on the computer roll.

Mr. Kufekisa said yesterday the affected tenants had been given a period in which to settle their outstanding arrears. He also disclosed that the council had identified a number of people at the Itawa council flats who were running shebeens and hair salons illegally.

He said council houses were still the cheapest in comparison to other organisations. Council tenants were only required to pay K50,000 for a three bed-roomed house and K40,000 for a two bedroomed house in Masala complex.

A research by the Ministry of Health done between 1997 and 1999 has established that chloroquine has lost ability to cure malaria by almost 52 percent in various areas in Tanzania also referred as malaria prone regions.

Explaining on the situation of the disease recently, the Deputy Minister for health, Ms Tatu Ntimizi affirmed that the drug has lost its ability and millions of Tanzanians were in danger of dying of malaria.

Without disclosing the figure, Ms. Ntimizi said that more patients die of malaria in the country, noting that children and infants were more vulnerable to the disease. "Millions of Tanzanians are now in grave danger of dying of malaria more than ever. The treatment is becoming complicated day after day," she said urging the people to adopt preventive measures.The ministry has recommended the use of other drugs like fansidar, amodiaquine and comaquine. She said quinine should be used as a last resort.

Reports from other places in the country where the study was also carried out indicated a failure rate of between 40 to 50 percent. In addition, 12.5 percent of the children failed to respond to early treatment. A drug failure rate of more than 25 percent is considered unacceptable internationally.

In its report, WHO has recommended sulfadoxine-pyrimethamine as an alternative drug for treatment of malaria in Tanzania. Kenya is one of the countries which have already replaced chloroquine for the treatment of falciparum malaria.

Health, Ms. Tatu Ntimizi told the National Assembly that her ministry has already instructed the Medical Stores Department (MSD) not to import, noting that what is available in shops is only a leftover of what was imported earlier. She said the MSD has already made alternative medicines for malaria treatment, to arrive in the country within 6 months [must be imported medicine]. "The MSD had already awarded a tender for the importation of medicines which will replace chloroquine."

In its report, WHO recommends sulfadoxine-pyrimethamine [fansidar] as an alternative drug for treatment of malaria in Tanzania. Kenya is one of the countries, which have already replaced chloroquine for the treatment of falciparum malaria. Another country which stopped the use of chloroquine as the first line medication for the disease, owing to resistant strains being prevalent in many areas, is Malawi.

ProMED-mail makes every effort to verify the reports that are posted, but the accuracy and completeness of the information, and of any statements or opinions based thereon, are not guaranteed. The reader assumes all risks in using information posted or archived by ProMED-mail. ISID and its associated service providers shall not be held responsible for errors or omissions or held liable for any damages incurred as a result of use or reliance upon posted or archived material.

Maputo (Mozambique) - At least 60% of all Mozambicans seeking medical treatment suffer from malaria and an estimated 40% of the country's hospital beds are occupied by malaria victims, said the country's health minister, Francisco  Songane, on Wednesday night.

Describing the statistics as the worst in southern Africa and possibly the world, Songane said malaria was beginning to have a serious affect on Mozambique's economy. "The problem is that victims have to remain in hospital for at least three days even after treatment, clogging up the health system and staying away from          work," he said.

Farmers simply could not afford to take ill, as their lands stood fallow if the planting season was missed. The Mozambican government and World Bank have meanwhile forecast a significant slowdown in economic growth as a result of February's devastating floods, the United Nations information service, IRIN, reports.

Preliminary estimates of flood damage and related costs currently stands at US$1 billion, with more than two- thirds of the country's population still living below the poverty line partly as a result of the previous decade of civil war.

The widespread flooding, which destroyed homes and farms and washed away infrastructure has, IRIN said, served to deepen poverty. The government's Interim Poverty Reduction Strategy Paper, presented to the International Monetary Fund in February, has been outdated by the floods.

The time taken from pledges being made to actual food arriving in Mozambique could take between one and four months, while the withdrawal of foreign military assistance has resulted in a reduction of WFP aid flights.

Fewer that 30 aircraft are in operation, which WFP funding can only sustain until the end of this month. Road transportation is not yet a viable option as "the road network is in no condition to deliver food to isolated areas."

Zimbabwe's ministry of health and child welfare said on Monday it distributing chemicals to all provinces and districts in preparation for spraying during the malaria season which starts during the rainy season. public relations officer Bright Mpofu said that supplies would be in all areas by the beginning of next month. "The spraying exercise remains one of the strongest tools in malaria control," he said. "Districts are being urged to use part of their diseases control vote to supplement supplies from the ministry," he said. He said that although the ministry engaged spraying teams to three months contract, the community was being urged to participate to make the malaria control program successful. He said health workers were being trained on managing malaria.

Stocks for malaria drugs were adequate for the whole rainy season in all provinces, he said. The ministry was calling on the public to take special precautions when going to malaria areas, drain and fill neglected pools where mosquitoes could breed and to seek immediate treatment if one felt sick. A total of 20 districts along the borders of the country recorded high malaria incidents between January and June this year. the malaria control unit of the World Health Organization (WHO) said Zimbabwe, with more than 275 deaths recorded in march this year, was ranked the highest in southern Africa followed by South Africa which had 19 deaths.  WHO said about 14,000 people were dying of the disease in southern Africa every year, with half of them being children below the age of 14.

Nelspruit - The good rains of the past weeks may be good news for farmers but they are bad news for people living in rural Mpumalanga where malaria is reaching epidemic proportions, African Eye News Service (South Africa) reports.

Johannesburg - Scientists and medical researchers are predicting that, after a long hot winter, South Africa may be facing the worst outbreak of malaria since 1932. Making the possibility of an epidemic more probable is the fact that the malaria parasite is now resistant to many of the drugs used to treat it.

National Malaria Research Programme: "We are not yet facing a classic epidemic scenario where we have a widespread outbreak of malaria in areas which have never had it before. But the situation is very serious. It could well develop into an epidemic which would be absolutely crippling."

The breakdown of malaria control measures in neighbouring countries due to underfunding also contributes massively to the situation. Mozambique has not implemented malaria control measures for years because of the civil war that raged in that country. As a result it is now facing its worst outbreak in years and the disease is spreading.

Ironically, the very phenomenon that is leading to Southern Africa's increased malaria cases may actually save the subcontinent. Global warming is taking malaria to the rich. The World Health Organisation has reported that Europe has experienced a tenfold increase in malaria over the past two years. Last year 200,000 cases of malaria were reported in Europe.

Webmaster's Note:Please read this article for a perspective on the situation two months later.Note the point made about funding.  HIV is such a problem in Africa that resources for other health problems are extremely scarceThe countries in Europe that have been reporting malaria cases are Turkey, Armenia, Azerbaijan, Belarus, and Russia [southern, obviously].  Italy, Greece, and Macedonia have not reported autochthonous [locally-transmitted] malaria cases since the 1960s.  Many of the cases in Europe are connected to cessation or disruption of control efforts in the republics of the former USSR.

The disease killed about two million people in sub-Saharan Africa last year -- over 80 percent of the global total -- making it the leading concern of most of the health ministers from 46 countries due to attend the meeting.

The rapid spread of the infection in Africa -- which has only 10 percent of the world's resources -- is due to the tradition of unprotected sex, a high incidence of sexually-transmitted diseases and poor access to care and information, according to WHO.

"all malaria cases diagnosed in the last six years in the UAE were found in expatriates or those who visited countries plagued with the disease," reported gulf today daily on sunday. there are 12 mobile teams to monitor malaria across the country, and every year, a malaria test is conducted in 50,000 random blood samples, Dr. Mahmoud Fikri, assistant under-secretary for preventive medicine at the ministry of health, told the paper. all the malaria cases diagnosed have been treated locally, he added. he said the ministry is coordinating with the World Health Organization to test a new method to control malaria by using a biological fish to kill the larva that causes malaria instead of using chemical insecticides. natural breeding grounds of the Anopheles mosquitoes, which transmit the disease, are limited in the uae and have been further reduced during this summer. some 83,005 potential breeding grounds in the uae were identified and checked in 1994, of which only 1,493 showed the presence of the Anopheles mosquitoes. a delegation from the ministry will attend the regional consultation meeting on the "Roll Back Malaria" program, to be held in Cairo, Egypt, from September 14 to 16. fikri said the meeting is aimed at exposing the countries in the eastern Mediterranean region to the strategic plan for implementation of the program.

Even today, Dhabauli village under Bidupur block of the   district has been a witness to the devastations caused by this disease. There is not a single family in the village, of which one or two members have not died of kala-azar.

It is to be noted that bleaching powder is supposed to have already been sprayed in the town areas for wiping the kala-azar. But a number of people replied in the negative when asked whether bleaching powder was sprayed or not.

India are failing to respond to conventional first-line drugs  and three inexpensive typhoid drugs, highly effective in curing the life-threatening disease in the capital a decade ago as they have become largely ineffective, according to World Health Organisation (WHO).

Till 1972, chloramphenicol was the choicest drug for typhoid in the Indian subcontinent. But by 1992, two-thirds of thypoid patients were resistant to it that gave way to treatment with expensive quinolones, that are themselves losing effectiveness, the report said.

Resistance to drugs has become a global problem covering a variety of diseases including pneumonia, malaria, hepatitis, diarrhoeal diseases, tuberculosis (TB), AIDS, gonorrhea and even hospital-acquired infections.

Though vaccination is the ultimate weapon against infectious diseases, no vaccines are currently available against five of the six major infectious killers. "Today the situation in developing nations remains as grim as that of previous generations in industrialised nations," it said.

AIDS, which claimed about 2.6 million lives last year, is a particularly insidious disease as those infected become reservoirs for TB, kala azar, pneumonia and other infections some of which have themselves developed resistance.

About 98 per cent of gonorrhea strains in South-East Asia have become resistant to penicillin. Newer expensive drugs like ciprofloxacin are also showing a rising failure rate in treating gonorrhea, resistant strains of which along with other sexually transmitted diseases (STDs) have become a driving force in HIV epidemic, the WHO report said.

Nearly one-third of patients taking lamivudine -- a drug developed only a few years back to treat hepatitis-B -- are showing resistance to therapy after the first year of treatment. Lamivudine, though eliminates about four-fifths of the virus, rebounds more vigorously when treatment stops.

Malaria, a major killer in Asia and Africa, is reappearing in areas earlier deemed disease-free. Resistance to  chloroquine, the treatment of choice earlier, is widespread in four-fifths of the 92 countries including India, where the disease continues to be a major killer.

Unfortunately, many new drugs for malaria are expensive and have serious side effects. Resistance to mefloquine, another malaria drug, emerged soon after its introduction in south-east asia. Thailand has completely lost the means of using three popular anti-malarials, the report said.

TB, another ancient killer, is staging a major comeback with increased resistance to anti-TB drugs. Recent reports of global trends in multi drug-resistant (MDR) TB are particularly chilling keeping in view that TB is transmitted by tiny particles suspended in the air.

Resistant strains of Leishmaniasis flourish in areas with high  poverty, low surveillance and inconsistent treatment due to limited medical access, availability of spurious drugs and political discord.

Widespread confusion worldwide over the difference between viral and bacterial respiratory infections, which often show the same clinical symptoms, has led to 70 per cent of chest infections becoming resistant to one of the first-line drugs.

With the onset of resistance, newer treatments for respiratory infections are proving too costly for the poor.  Laboratory tests for the diagnosis of these diseases are expensive too, the report said.

Ten years ago, a shigella dysentery epidemic could be easily controlled with cotrimoxazole, a drug cheaply available in generic form. Nearly all shigella bacteria strains are not responding to the drug any more. Resistant to ciprofloxacin, the only viable medication left, is just round the corner.

Economic and social patterns have a crucial role to play in  this trend. The economic consequences of anti-microbial resistance can be staggering, the report warns. The cost of treating a patient with multidrug-resistant (MDR) TB is a hundred times more than that needed for treating a non-resistant case.

Overuse of anti-microbials by wealthy countries in food production, treating sick animals and promoting livestock and poultry growth is also contributing to increased drug resistance. About half of the antibiotic production worldwide is currently used for these purposes.

Dispelling a common misconception that pharma companies are frequently making new drugs to replace the ineffective ones, it said while newer versions of older drugs are being developed, there is a dearth of new class of anti-microbials.

The important point is that kala azar is preventable by use of vector control.  "An ounce of prevention is worth a pound of cure." is very applicable in the case of kala azar, which is a deadly disease, treatable only with highly toxic drugs, that is preventable by regularly conducted vector control.  DDT works for this purpose.  Typhoid is also eminently preventable by simple sanitation measures.

First detected in southern Europe, the deadly combination is now appearing in kala-azar endemic areas in the country.   A large number of such cases have already been seen in Bihar, one of the worst-affected areas.

This is causing serious concern as rapid urbanisation and widespread economic migration are seen to be leading to an increase in the incidence of kala-azar. Kala-azar cases are now reported from Bihar, Gujarat, Uttar Pradesh, Madhya Pradesh, Himachal Pradesh and also Jammu and Kashmir.

The reverse would also be true: HIV patients would acquire kala-azar easily. In fact, in endemic areas, kala-azar infections are known to get re-activated with HIV.  "We expected the rise in these co-infections," says Ramalingaswami.  "But we were surprised when we did not see it for quite sometime. Of late the trend is being observed, not just in India, but in other parts of the world   as well."

The Patna Medical College Hospital's head of the medicine department Gopal Prasad Sinha admitted that on an average 15 malaria patients including FM cases had been reporting to the hospital everyday for the last few weeks from different parts of the state including Patna and south Bihar.

When contacted, the director-in-chief of the state health services, V S Singh, admitted that there was a shortage of anti-malaria drugs and effective insecticides to control the disease. He said 18 districts of the state were reeling under malaria.

Singh informed that he had directed the civil surgeons of all the malaria- affected districts that in the areas where the disease had broken out in a virulent form, four quinine tablets be administered to even those not suffering from it as a preventive measure. With regard to the shortage of anti-malaria drugs and effective insecticides, Singh said the Centre had promised to supply both in good quantity to the state.

With regard to DDT spraying, Singh said mosquitoes causing malaria had become DDT resistant. He instead pleaded for the spraying of malathion. When asked about the malaria death figures, Singh said so far only 71 deaths had been confirmed while 56 others were yet to be confirmed.

The CAG report said one round of DDT spraying instead of the requisite two resulted in wasteful expenditure of Rs 1.66 crore. Susceptibility tests were not carried out as the then director had not obtain impregnated papers from the government of India since 1991. The state government did not send the names of three towns with high malaria incidence for coverage under the Urban Malaria Scheme as asked by the Centre. The state government also failed to place indent for the required quantity of DDT during 1992-98 while the use of machinery and equipment received from the Centre was delayed up to four years, the report added.

This article strongly suggests serious operational failures in the Indian Malaria Control Programme.  These failures appear to be throughout the programme, from case surveillance to drug treatment to vector control.

Failure to provide radical treatment to malaria patients ensures the future spread of malaria in the district because these persons have the parasites [gametocyte stage] available for anopheline mosquitoes to pick up with a blood meal.  This point is EXTREMELY IMPORTANT.  Malaria cannot be controlled effectively without reducing contact between mosquitoes and parasitemic persons.  This involves not only vector control but also drug treatment of patients.  In fact, proper malaria control strategy involves drug treatment of not only people with malaria symptoms, but of all persons who harbor the malaria parasites.  This requires a strategy called Active Case Detection.

The vector species is not mentioned in this article, yet knowing the vector is crucial to success of a malaria control programme.  Anopheles stephensi is often amenable to source reduction, as it breeds in urban areas.  Anopheles culicifacies is a species of rural areas.

A nationwide survey of insecticide resistance in the two major vectors of India, An. stephensi and An. culicifacies, to DDT, malathion, permethrin, and cypermethrin [or other pyrethroid currently in use] would be extremely helpful in guiding that country's Malaria Control Programme.  It would be especially helpful to programme coordination if the resources of the World Wide Web could be used in transferring this information across India, which is a large country.  This is an example of the nationwide coordination that is necessary for effective malaria control and has recently been enabled by the world wide web.  It is very unfortunate that these resources have not been utilized to their potential so far.

Take the case of East Singhbhum district, a malaria-prone zone where there has been "seven clinically confirmed" malaria deaths till November this year. Here, the EMCP apparently did not go beyond a "jeep bought under the programme and an accountant who is drawing Rs 1,000 every month". The Union government's directorate for anti-malaria programme suspended aid as the districts authorities had failed to submit utilisation certificate for fund allocated during the second quarter of the current financial year, sources connected with the Bihar legislative assembly committee probing into the outbreak of malaria disclosed.

Ranchi and Dumka have regular malaria officers. Fund allocated for malaria control has never been utilised properly in the last five years. Invariably, the money has been sanctioned a couple of days before the end of the financial year. About 60 per cent of the posts are vacant and staff have not received salary for months. Surveillance at the public health centres has completely failed,'' he added.

Webmaster's Note: Please see this article about DEATHS caused by kala azar, also in Bihar, also with shortage of DDT.  This article details operational failures similar to those here.  Unfortunately the article lacks information about what species are the vectors and what is their insecticide resistance status.

Hospitals in Dadri, for instance, remain packed with fever patients. And beds have been placed even in the corridors. Local hospitals have referred many patients to hospitals in Ghaziabad and elsewhere.

Dr Piyush Agarwal of Dadri's Bhagwati nursing home, said encephalitis in the area is being caused by cerebral malaria and also mismanaged typhoid. ``The symptoms can include high fever, difficulty in breathing, hypotension (fall in blood pressure) and erratic behaviour on account of the brain involvement. The onset can be sudden, or it can come on two or three days after the fever begins''.

Dr Dhirendra Singh said his Navin hospital was coming across 30 to 40 malaria cases a day, apart from many of typhoid. Several cases with symptoms of encephalitis have also arrived. "We have had 60 malaria patients from neighbouring Khandera village alone. Over 75 per cent of the village has had malaria," he said.

Larvae was found breeding in water accumulated in narrow garbage-laden lanes squeezed in between the houses. The CMC is, however, not to blame. After all, it is the residents who have the habit of throwing garbage on the streets, say officials.

Larvae was also found in unauthorised water tanks, buckets and large drums in several houses. But, the residents were let off with just a warning. However, water connection would be severed if larvae was found again on their premises, a senior officer said.

Officials admit the anti-malaria campaign lacks uniformity. The chief medical and health officer, Dr Sujit Ghosh, said corporation workers are too thinly spread to check houses at regular intervals. Equipment, too, is not enough.

Overhead and underground tanks are checked only after a malaria death is reported from a house. Corporation workers get busy with their fogging machines after one of the residents visit the local lab to get his blood tested.

In Kalighat, brick tanks in highrises under construction is a breeding ground for larvae. Dr Ghosh said a notice had been sent to city builders in February last year, requesting them to keep an eye on the tanks.

These fresh arrivals have disproved the claims of the district administrtion. Dr R N Sahay in an interview with this correspondent, said that from the 31,000 patients suffering from malaria, 25,000 blood slides have been collected by technicians at various points. About 11,529 slides were examined, of which 1618 cases were found to be positive out of which only 1529 patients have been treated. The patients who succumbed included a doctor who was in charge of a camp in kerdari block.

When his attention was drawn towards the reports submitted by various political parties and NGOs at a meeting addressed by Mr Shyam Rajak, the Bihar minister of state for energy who is also the minister incharge of Hazaribagh district that the claims of the district administration was wrong and more than 90,000 patients were suffering from malaria and more than 300 patients have so far died, Dr R N Sahay alleged tthat the claims were wrong, adding AIDS and Hepatitis B deaths in the district have also been included in the list of malaria deaths for fear of creating panic. Interestingly, this admission of the district administration not being able to control AIDS and Hepatitis B cases have been an eye opener.

But the civil surgeon admitted that the malaria epidemic broke out in the district in an epidemic form mainly due to gross negligence on the part of district malaria officer who inspite of availabilitty of anti-malaria drugs and DDT sufficient at her disposal, did not take tangible steps to distribute the same in the malaria infested areas of the district.

The civil surgeon said that the district administration swung into action only when they received reports of large-scale deaths in Giddi colliery of CCL in Churchu block and in Chouparan. He said that in Hazaribagh disrict in all 21 camps are functioning for treating the malaria patients and providing them on-the-spot treatment.

Chouparan, Ramgarh, Barkatha, Barkagaon and Keredari blocks of the district. A high-level medical team headed by an senior doctor from Delhi visited the affected areas and confirmed that in Hazaribagh disrict most of cases found were suffering from either cerebral malaria or malignant malaria.

While the incidence was higher, the malaria officials failed to provide radical treatment to 48,000 positive cases during 1992- 97. It is also worth noting that while the average rate of blood examination was very low, tests of blood samples were also delayed.

What is worse is that less than ten out of 100 fever treatment and drug distribution centres functioned. The malaria eradication [sic-Webmaster] efforts also suffered because laboratory facility was not adequate: one for 20,000 in tribal areas and one for 30,000 in non-tribal areas. And, in five high risk districts of South Bihar, 51 per cent vacancies of lab technicians were not filled. Added to this, the failure in distributing machinery and other items, like 96 out of 97 microscopes were not issued till August 1998.

Even under urban malaria scheme the state government's role was critical as collection of blood smears was only 1 to 1.5 per cent. Consequently, incidence of malaria cases increased during 1992-97. Also, the state government failed to send names of three towns for coverage by the government of India. Finally, the government of India's scheme for malaria, introduced in 1995, was not started in Bihar.

Did the flaws, mentioned above, in dealing with malaria menace led to the recent deaths in Hazaribagh and other areas of the state. Though Hazaribagh health officials, charged with negligence, say only 35 died of malaria, some voluntary organisations had made a list of 65 dead in 28 villages around the Giddi colliery area alone, till November 2. Some more deaths came to notice, taking the figure to more than 100.

PATNA: The failure of the state government to sanction any malaria control scheme during 1997-99 proved to be a major cause for the sudden outbreak of the disease in 18 southern and central districts of the state.

Vinod Chandra Pandey held recently with the state government officials including the chief secretary, the health commissioner and the acting director-in-chief of the state health services. Pandey strongly disapproved of the way the government tackled the malaria menace, particularly its surveillance aspect. He expressed his concern over the high casualty rate in Godda and Hazaribagh districts of south Bihar, according to highly placed sources in the state health department.

Initially, the authorities concerned with the malaria control programme had floated a theory that the disease had broken out due to prolonged rainy season. But this theory had no takers even among the top health department officials who felt that had this been the reason for its outbreak, then north Bihar districts like Darbhanga, Madhubani, Samastipur, Vaishali, Sitamarhi and Saharsa would have been devastated by the disease. These districts are faced with the perennial problem of waterlogging in the absence of flood control measures.

Following directives from the governor, the health department has sent Chief Malaria Officer D P Mandal to the malaria-affected districts to take stock of the situation and suggest measures to control the disease.

Intensive spraying of DDT could not be undertaken in these districts as well as those affected by kala-azar due to the state government's failure to sanction any malaria control scheme. Although DDT and medicine for treatment of both malaria and kala-azar are supplied by the Centre, the state health department did not place any order for supply of DDT during 1997-99 as it did not have the funds to pay for the freight charge and the labour cost it would have had to incur on its spraying, according to a senior health department official.

According to Maheshwari, the state government sanctioned such malaria control schemes this year as focal spraying of DDT in the affected districts. He, however, admitted that the focal spraying had been undertaken only after the outbreak of the disease. He claimed that the government had supplied DDT and medicine to all the affected districts but added that the spraying work should have been completed latest by May-June.

The director-in-chief of the state health services, V S Singh, said inadequate and erratic spraying of DDT during the last few years had led to the outbreak of malaria. "Malaria is likely to subside after December. After completion of focal spraying in the malaria-affected districts, the government would turn its attention to the kala-azar-affected districts.

Meanwhile, the state government told the Union health ministry that the last batch of SAG, the first-line drug for treatment of kala-azar, supplied to Bihar had been found to be substandard following tests carried out at a top laboratory.

Singh claimed that at least 12 kala-azar patients had died following administration of the substandard SAG. "The state government sent the drug for test following reports of death due to consumption of the said batch of SAG by the patients. The Centre has been informed about the finding of the chemical test of the drug. The state government has demanded supply of SAG of standard quality," he added.

An estimated 24 million people in Bangladesh are affected by malaria and defences against the mosquito-borne disease need to be strengthened, a World Health Organisation (WHO) report said here Thursday.

BANGKOK: Hundreds of Myanmar villagers have died of malaria and other diseases after being relocated by the government from their poppy farms in the Golden Triangle to mosquito-infested areas, sources said.

The relocation of the Wa community from the mountains near China to the border area near Thailand is part of the Myanmar government's effort to slow down opium production in one of the biggest narcotics producing zones in the world.

But sources at the Thai border with Myanmar put the death toll at between 800 and 2,000 people. "It's absolutely beyond doubt that large numbers of people are very, very sick and many have died because they really have no medical care available," said one respected observer of affairs along the Thai-Myanmar frontier. He spoke on condition of anonymity.

Heavy rains have worsened the situation with reports of other diseases such as dysentery, typhoid and anthrax spread by infected beef also claiming lives. A Thai army intelligence officer in Bangkok, speaking on condition of anonymity, estimated over 1,000 people around Mong Yawn, a Wa town, had died and that army border units have been on alert to prevent residents from the effected area coming to Thailand.

But the change of environment is proving disastrous, as they lack immunity to disease in lower elevations where drug-resistant strains of mosquitoes spread deadly cerebral malaria. The relocation was done with the approval of the United Wa State Army, described by the US State Department as the world's largest drug-trafficking organisation.

Yangon in 1989. They retain their weapons under the agreement and exercise control over large areas of Myanmar's rugged border with Thailand and China, where they produce heroin, derived from opium, and increasingly, methamphetamines.

Mae Hong Son are also on guard amid fears that diseases, especially typhoid, could be brought by migrants and refugees from Myanmar, said Songvuthi Huthamai, the provincial health office director. Toon Laikhun, a Myanmar exile, said he has heard about the epidemic from travellers from Myanmar.

A staff member at a health polyclinic in Sukaraja, some 70 kilometres (43.4 miles) east of Mataram, the main town on Lombok, said 10 people have died of malaria while 97 others have been found infected since the disease was first detected there in early July, the Media Indonesia daily said.

The rain, which has fallen every day this week, is accelerating the spread of illness in the refugee population, almost 40 per cent of which is estimated to be under the age of 15. Diarrhoea and respiratory infections such as pneumonia are on the rise, and the threat of malaria - carried by a mosquito population that thrives on damp conditions - is also growing.

"We have been working overtime to address the health needs of these children and their families," said UNICEF Executive Director Carol Bellamy. "Yet with these rains, conditions are certainly getting tougher. This is precisely the time we need the international community to redouble its commitment to the Timor relief effort."

Earlier today, the United Nations family of agencies appealed for nearly $200 million over the next nine months to meet emergency humanitarian needs in West Timor and provide for relief and reconstruction in East Timor. UNICEF programs that specifically address the health, education and psychosocial needs of children - including a comprehensive immunization campaign and back-to-school effort - make up $14 million of the total appeal.

"We are at a crucial juncture in the relief effort," Ms. Bellamy said. "We have managed to stay one step ahead of a major outbreak of disease, but it is clear that, with the arrival of the monsoon season, the health of tens of thousands of children remains at high risk."

In West Timor, some 240,000 refugees have been huddled in dozens of makeshift camps since being hounded out of East Timor by militia groups in early September. About three-quarters of these refugees are massed in the Belu region of West Timor, near the East-West border. Many have been living out in the open or under rickety lean-tos fashioned from dried palm fronds.

The rainy season - which was not expected until the end of November - struck early, making life miserable for those without proper shelter. UNICEF is responding with a rapid delivery of plastic sheeting, and UNICEF-supplied tents are being set-up as health centres and for dry storage of food and other relief items. The agency is also supporting the rapid installation of latrines and other sanitation facilities.

To prevent the spread of disease, UNICEF has organized mobile health teams in conjunction with partner agencies and local volunteer groups. In the West the teams are moving from camp to camp, vaccinating children against measles and treating malaria, diarrhoea and other illnesses. In the East a vaccination campaign in the large cities was launched last week. Reception centres at the East-West border are also providing health checks and vaccinations for children.

"By the end of November - in the heart of the rainy season - we can still expect to be aiding more than 100,000 refugees in West Timor. And for most of those who are already in East Timor, conditions will remain harsh for some time to come.

Nicaraguan medical authorities registered 17,552 cases of malaria in the first half of the year, up 20 percent from the same period of last year, an official of the health ministry said friday. director of the ministry's epidemic program Juan Bermudez blamed the rise on the rainy season, which is favorable for the breeding of mosquitoes --principal carriers of malaria. the ministry has launched an anti-malaria campaign, sending medical groups and mosquito nets to remote rural areas, he said. during the same period, cases of dengue fever in Nicaragua reduced dramatically to 3,478, from 5,480 in the first half of 1998, Bermudez noted.

The Ecuadorian government declared a health emergency in 15 provinces threatened by epidemic outbreaks of such diseases as dengue fever and malaria. Jorge Zambrano, a Health Ministry specialist in epidemics, said Monday that the government's declaration would allow authorities to ease the process of acquiring medicine to treat the sick. This year alone, 15,000 cases of malaria have been reported, Zambrano said in a press conference.

Heavy rains throughout the country have provided fertile ground for mosquitoes - the primary disease carriers - to reproduce and spread illnesses. As a result, the number of cases reported could rise, he added.

An outbreak of malaria and dengue fever has killed at least 14 people and has infected more than 14 000 others in Ecuador, health officials said Wednesday. The Health Ministry called for a medical state of emergency in 17 of Ecuador's 23 provinces, along the Pacific coast and in interior jungle regions bordering Peru and Colombia.

So far 14,192 cases of malaria have been confirmed, and six people have died. Health officials also detected 220 cases [eight deaths] of dengue, known to many as break-bone fever because of the excruciating muscle and joint pains it causes, said Jorge Zambrano, Director of the National Health Center director.

The last outbreak in Ecuador occurred in 1997 and 1998 during the El Nino weather phenomenon, which ravaged this small Andean nation of 12 million people with heavy flooding -- creating a perfect environment for mosquitoes.

Filho accused Para state health authorities of merely distributing malaria medication and not taking any preventative measures against the illness. The mosquitoes which spread the disease must be combated, the mayor said.

Malaria kills more people than any other communicable disease except for tuberculosis. While the disease is curable with early diagnosis and treatment, many of those affected in remote parts of the world don't have access to health services. One such region lies in the Amazon rain forest.

ASSAYAG: In the labs, the samples are analyzed. Scientists have discovered that the material used in the battle against malaria has lost its preventive efficacy. Malaria mosquitoes have mutated [Webmaster's Note: - the mosquitoes were selected for behavioral or physiological insecticide resistance by natural selection.  The resistance trait is probably not a mutation but existed as a rare gene in the original, susceptible population] and changed their behavior.  Now, scientists are trying to find another solution.

But there have been several incidents in recent months which make it clear that the threat is still present. There was an outbreak of West Nile virus in New York. Meningitis, which is very contagious, is causing concern on college campuses. And there has been a recent outbreak of tuberculosis, in Russian prisons. Several million people die from infectious diseases every year. And increasingly we hear from experts in the field of public health that the medical community is not taking this seriously enough.

Mr. DICKSON DESPOMMIER (Columbia University): There are very few medical schools in the country that actually give even the basic learning elements with regards to how to understand a disease outbreak, how to investigate whether it's infectious or noninfectious. These are issues which are placed on the back burners of most medical curriculums.

JENNINGS: Moreover, in the last 20 years, more than 20 previously unknown infectious diseases have been discovered. While tuberculosis and malaria have been around for ages, some strains of them have emerged which are resistant to existing drugs.

JENNINGS: Every day, 3,000 people in the world die of malaria, more than a million a year. One and a half million die from tuberculosis. The realities of the modern world are partly to blame. The world is getting smaller, tighter, more interconnected. People and products are on the move, as never before. Air travel means a disease can be halfway around the world, in a matter of hours.

JENNINGS: Anyone who's traveled to the Indian subcontinent or Africa knows that one of the things to be careful about is malaria. As we mentioned, about a million people a year who get it die. Malaria is transmitted from person to person by a mosquito. And, until fairly recently, it was not considered a serious threat here. That is changing. Here's ABC's Deborah Amos.

AMOS: Another ingredient for these malaria outbreaks is the dramatic increase in the number of people moving quickly around the globe bringing the malaria infection back to the United States. Then all it takes is a mosquito.

AMOS: Still, all these ingredients do not yet add up to a major malaria outbreak. Mosquito control remains the best defense. What scientists worry about, even more, are viruses which can also thrive in extreme weather conditions, and outbreaks that can come as a complete surprise.

EUROPE faces "a serious risk of an uncontrollable resurgence of malaria", warns the WHO in a new report. Drainage, drugs and insecticides eradicated malaria from the whole of Europe by the 1960s. Now civil disorder and irrigation threaten to bring it back unless controls are stepped up, the report says.

More European travellers are bringing malaria back from countries where it is endemic, and the big fear is that local mosquitoes could acquire the parasite from such travellers and re-establish a local chain of transmission. Three recent cases in Luxembourg and two in New York have fuelled concern over air travel as a means of reintroduction. The cases in Luxembourg all occurred within a few kilometres of the country's international airport, and were probably caused by mosquitoes stowing away on aircraft arriving from the tropics (New Scientist, 11 September, p 14).

Moscow. The two had never been outside the region. Similar cases occurred for the first time since the 1960s in Russia last year, and surveys have revealed infected local mosquitoes as far north as Moscow.

In Turkey, malaria was almost eliminated by 1989. But a major irrigation project in the southeast of the country caused cases to jump nearly tenfold between 1990 and 1994. A massive effort to control that epidemic is almost solely responsible for a fall in the total number of cases in Europe since 1996, but the control is tenuous. Turkey's tourist boom means that malaria could start to pose a risk for western Europe.

The WHO thinks that good medical care, vigilant surveillance and chilly winters will prevent malaria from re-establishing itself in northern Europe, despite the existence of mosquito species able to carry it.

But the species that live in southern Europe are better at maintaining the parasite. There were outbreaks of malaria that were spread by local mosquitoes in Corsica in 1970, and in Bulgaria in 1995, while in 1997 an Italian caught the disease from a local mosquito.

Three of the cases were in Luxembourg, all within a few kilometres of the country's international airport. They were probably caused by mosquitoes that had stowed away on aircraft flying in from the tropics. Sporadic cases have occurred near European airports before, but incidents are becoming more common as air travel and global warming increase.

Robert Hemmer of Luxembourg's National Service for Infectious Diseases notes that the last cases of airport malaria in the country, in 1997, occurred during hot weather similar to that in Europe this summer. Luxembourg is now considering spraying more aircraft with insecticide on arrival.

The other two cases, in New York state in the US, highlight the concern that local mosquitoes can acquire the parasite from humans and continue the chain of infection. Two boy scouts who attended a summer camp near wetland in Long Island developed malaria in late August. Mosquitoes carrying the malaria parasite were found near the camp. They were probably infected after biting someone who had carried the disease from the tropics. The whole area was sprayed and all 1500 members of the camp were traced and warned of the risk.

Europe it reached as far north as Britain. All the latest cases have responded to treatment, but the Malaria Foundation International, a research network based in London, estimates that 300 children in the tropics die of the disease every hour.

Webmaster's Note:This article notes potential for transport of malaria from endemic areas to currently non-endemic areas.  Please note that Luxembourg [as well as other countries in western Europe] and the United States have not demonstrated continuous malaria transmission at this time.  There have been instances of sporadic locally transmitted cases in these countries during the 1980s and 1990s but transmission has not carried over through the winter.

Microsoft mogul Bill Gates recently pledged to spend $750 million over the next five years to buy vaccines for millions of children in poor countries. In a single breath, he ignited the hopes of despairing parents in underdeveloped nations who can only watch helplessly as their sons and daughters die of diseases that barely touch children lucky enough to be born in rich countries.

Consider this from the Economist: "Of children who die before their fifth birthday, 98 percent are in the developing world. Of the millions who die prematurely of tuberculosis, malaria, measles, tetanus, and whooping cough, all but a few thousand live in the poor world."

Gates' generosity is aimed at creating a market for vaccines to entice the behemoth pharmaceutical companies to deliver products to those who desperately need them. If the drug makers could be convinced that a market does - or will - exist, then perhaps they might be willing to develop remedies for diseases common to poor nations instead of focusing their research almost exclusively on rich-world afflictions. The World Health Organization says that $56 billion is spent each year on health research, with less than 10 percent going to diseases that afflict 90 percent of the world's population.

It seems there is no other motive for a drug company. Don't bother mentioning the words "social conscience" to a pharmaceutical bigwig. He'll look at you with a glare that's the visual equivalent of a lethal injection.

Heart, when I bumped into an old acquaintance. He had, by diligence and degrees, climbed the ladder at a well-known pharmaceutical giant. I couldn't imagine how he had fallen on such hard times. As I ladled breakfast gruel into his tin bowl, I could see he needed to talk. So I sat down with him.

"Heck, it makes good business sense," I pointed out. "I reminded him that countries plagued by bad health can't develop economically. After all, companies need healthy workers to turn healthy profits. If we can improve life for these people, we can build our own market, create our own demand. As people get healthier and more prosperous, they will have the money and desire for more and better drugs of all kinds - and here we are to supply them. Imagine, everyone wins!"

Malaria. It's enough to give you the shivers. For the non-immune traveller, which includes virtually all UK citizens, regardless of birthplace, the risk of catching malaria in a two-week period without prophylaxis in east and west Africa is about 0.5% and 3.5% respectively.

Therefore, if possible, retire at dusk to a mosquito-screened or air-conditioned room. No room is entirely mosquito-proof and most travellers to the tropics have had the experience of tossing and turning while being tortured by whining squadrons of these irritating creatures.

The most efficient delivery system is to heat an impregnated mat on a small electric hotplate. Although this sounds fiddly, if not downright hazhardous, in practice both the mats and the hotplates are widely available, easily portable and of such low wattage as not to be a fire hazhard. The alternative, smouldering coils, are far more likely to irritate your lungs and tend to run out before the night is out. If your lodgings are partially open to the outdoors (as many are in hot climates), you will need a mosquito net to sleep under. The relatively recent innovation of treating the net with permethrin has improved the protective effect enormously.

If you must be outside after dark (to spot nocturnal wildlife perhaps), long trousers, long sleeves and good ankle protection are the order of dress. But mosquitoes can bite through thin material so insect repellent is essential and those containing diethyl toluamide (Deet) are the most effective. Concerns about Deet toxicity are now largely discounted, with most reports citing accidental ingestion, so families might opt for a roll-on preparation. Remember, mosquitoes prefer to hunt near ground level so pay particular attention to the ankles - old hands swear by tubular bandage anklets treated with Deet.

You should also comply with an appropriate anti-malarial chemo-prophylactic regime - which means taking the drugs at the right intervals, commencing prior to travel and continuing after your return, as per the instructions.

Most studies show that 20%-40% of travellers fail to comply with their regimes, mostly for trivial reasons. Which regime is recommended depends on the individual's particular circumstances. The variables to be considered include the prevalence of malaria at your destination, the strain(s) of malaria and the pattern of malarial resistance to particular chemical agents, and the side-effect profile of the agents. These factors are in turn dependent on your own medical history and what you plan to do when you get there. The beach bum and the bird-watcher may sit next to each other on the plane but their requirements are likely to be completely different. There is no substitute for a personalised travel-clinic consultation.

Where the risk is very low, as in Bali or Egypt, chemo-prophylaxis is not currently recommended. Where there is a low risk and resistance is still poorly developed (parts of Central America) a single agent - either chloroquine or proguanil - is sufficient. Most people would opt for the once-weekly chloroquine rather than the daily proguanil.

Asia and Oceania), the choice generally lies between chloroquine plus proguanil or mefloquine alone. When the risk rises to very high and resistance is widespread, as in much of sub-Saharan Africa, mefloquine is increasingly seen as the first choice. Much of the current debate (which exercises medical scientists as well as travellers) revolves around the choice between these two regimes.

The key information when balancing risks and benefits are, first, the efficacy of the drug(s), and second, their side-effect profile. There is a broad consensus that at present mefloquine is significantly more effective, with a 90% protective effect, compared with chloroquine plus proguanil, which was rated as being 70% effective in west Africa and only 50% effective in east Africa in the late 1980s.

Where does this leave the traveller who wishes to be well informed? It seems clear to me that people who expose themselves to malaria without taking the available precautions are risking their lives needlessly.

Local medical assistance should be sought at an early stage in the event of strange reactions in friends and family on mefloquine. If the drug has to be stopped, exercise particular attention to bite prevention while converting to an alternative regime. In the presence of additional personal risk factors for neuropsychiatric disease (including epilepsy, mental illness and recreational substance abuse) mefloquine is probably best avoided and an alternative regime sought.

No regime is 100% effective and therefore prompt diagnosis is essential: any unexplained fever developing seven days or more after arrival in a malarious area needs to be investigated. And finally, if venturing off the beaten track, I pack quinine for self-treatment. You know the old adage that if you've got it you won't need it.

Now, with the onset of the seasonal rains that spawn malaria-carrying mosquitoes and mark the beginning of the high-risk season, the numbers will only go up, authorities say. Experts attribute the sharp jump to the warmer-than-usual winter, a growing influx of immigrants from neighboring Mozambique, where malaria is rampant, and the spread of drug-resistant strains.

This month the South African Department of Health issued a malaria advisory urging anyone planning to visit the northeastern part of the country, including Kruger National Park, to take precautions and be on the lookout for symptoms of infection. Kruger, the country's biggest game reserve, took the unusual step of issuing a similar advisory several weeks ago.

Dr. Stephen Toovey of the British Airways Travel Clinic in Johannesburg, an expert in tropical diseases, said that public awareness plays an important role in pushing the tourism industries to encourage visitors to take precautions.

In Kenya, one of Africa's most popular tourist destinations, public health authorities have issued renewed warnings about malaria. The disease, which was already a significant problem in Kenya, has been spreading into previously malaria-free highlands and showing an increasing resistance to chloroquine, once the malaria prophylactic of choice.

Clinic and the South African National Parks (www.parks-sa.co.za) recommend anti malarial drugs for anyone visiting reserves like Kruger or Chobe National Park in Botswana. Mefloquine, better known by its trade name Lariam, is the most widely recommended because it is taken just once a week, beginning a week before the visit and continuing for four weeks after the visit. The primary alternative, doxycycline, must be taken every day, beginning a couple of days before the visit and continuing four weeks after leaving the malarial area. A new Glaxo Wellcome drug, Malarone, available in some 30 countries as a treatment for malaria and in Denmark as a preventive as well, has not yet been approved in the United States by the Food and Drug Administration. None of the drugs is completely effective, and each has potential side effects.

The health department considers the risk of contracting malaria almost nonexistent in South Africa's biggest cities, Johannesburg, Cape Town and Durban, as well as in the wine country outside Cape Town.

Even though the victim had been infected with malaria a year before, he didn't take preventive medications. In addition, he apparently didn't learn a lesson from his 25- year-old son, who visited him for two weeks in Kenya and came down with malaria.

The ministry noted that travel agencies are now offering special last-minute flights to Third World countries. These deals can be dangerous, because there isn't enough time in a few days to take preventive treatment.

Another Haifa resident recently sued the Mombasa Paradise travel agency, because it sold him tickets three days before the flight to Africa without informing him of the need to get medications and vaccines. As a result, he came down with a severe case of malaria, was hospitalized in intensive care, and developed respiratory and renal (kidney) insufficiency. He now needs dialysis and a respirator.

Webmaster's Note:Although two weeks is sufficient time before a trip to begin taking malaria prophylaxis, a longer period of planning is needed for a first overseas trip.  The reason is that vaccination series, i.e. hepatitis A/B; yellow fever etc. take up to six months.

Anaemia - decrease in number of red blood cells and/or quantity of hemoglobin. Malaria causes anemia through rupture of red blood cells during merozoite release. The anaemia caused may be extreme. Pallor may be visible in the patient.

Animal trap - A cage, generally made of cloth, that is baited with an animal such as a cow, goat, etc. Collections of mosquitoes are made on the walls of this trap to assess and compare populations biting domestic animals with populations in dwellings.

Cerebral malaria - this grave complication of malaria happens at times with P. falciparum infection and involves malaria infection of the very small capillaries that flow through the tissues of the brain. This complication has a fatality rate of 15% or more, even when treated and is extremely serious.

Examples of endophilic anopheline species include Anopheles darlingi and An. funestus. Endophilism makes the blocking of malaria transmission through application of residual insecticides to walls easier to accomplish.

Erythrocytic schizogony - the process of asexual reproduction of malaria parasites within red blood cells Exerythrocytic schizogony - the process of asexual reproduction of malaria parasites outside of red blood cells, usually in the liver. This process is asymptomatic.

Exit trap - A trap constructed to capture mosquitoes that are exiting a house or structure. Exit traps are often used in studies that compare the tendency of mosquitoes to rest indoors after feeding versus to fly outside after feeding.

Gametocyte - the sexual reproductive stage of the malaria parasite. Gametocytes [macro- and micro-gametocytes] circulate in the blood stream, are picked up by the Anopheles mosquito, undergo sexual reproduction in the midgut of the mosquito, and attaches to the mosquito's midgut, where they form an oocyst that eventually produces sporozoites.

Gametocyte rate - percentage of persons in an area who carry gametocytes. Expressed as a percentage. The less the gametocyte rate of an area, the fewer infective humans are available for mosquitoes, and the less likely that transmission is to occur. (MacDonald 1956).

Hypnozoite - a stage of malaria parasites found in liver cells. After sporozoites invade liver cells, some develop into latent forms called hypnozoites. They become active months or years later, producing a recurrent malaria attack. Only P. vivax and P. ovale species that infect humans develop latent stage hypnozoites. Primaquine is the only available drug active against hypnozoites.

Hypoglycaemia - hypoglycemia -blood glucose less than the lower value of normal (70-110 mg/dl [3.9-6.1 mmol/L in SI reference units]). Glucose levels of 40 and below constitute severe hypoglycemia, a life-threatening emergency. Hypoglycemia is common in malaria, as malaria parasitized red blood cells utilize glucose 75 times faster than uninfected cells. In addition, treatment with quinine and quinidine stimulate insulin secretion, reducing blood glucose.

Infant parasite rate - The percentage of infants below one year old who show parasites in their blood films. If the infant parasite rate is zero for three consecutive years in a locality, this is regarded as absence of local transmission, provided that the survey is done every year and enough slides have been examined.

There are two reasons for this. The first is that the reproductive cycle of malaria in the mosquito takes 10-11 days, and the second is that if the mosquito lives a long time, it will be able to take several blood meals, and will have a higher chance of biting a human who has malaria parasites.

Malaise - subjective feeling of being sick, ill, or not healthy. The feeling is generalized, varying from mild to severe in intensity. It may be the lone clinical manifestation of malaria, or may accompany other signs and symptoms, such as fever, headache, or nausea.

Protozoan - A member of the Kingdom Protista. Protozoa are single-celled organisms [eukaryotes]. The single cell performs all necessary functions of metabolism and reproduction. Some protozoa are free-living, while others, including malaria parasites, depend on other organisms for their nutrients and life cycle. Malaria parasites are members of the Phylum Apicomplexa.

Radical Cure - treatment intended to achieve cure of P. vivax or P. malariae malaria. These two species have exoerythrocytic [outside of red blood cells i.e. in the liver] stages. Requires primaquine treatment, which destroys latent exoerythrocytic stage parasites (hypnozoites). Typical case patient: a returned traveller from Central America who has had a relapse of malaria.

Refractory malaria - malaria that is not responsive to residual treatment. The cause of the lack of response to residual treatment is usually defined to be factors other than physiological insecticide resistance. Examples of causes of refractory malaria are vector exophily and zoophily with failure to enter houses. An example of refractory malaria occurred in the Jordan Valley during the early 1950s. Anopheles sergenti and Anopheles superpictus were evading residual treatment of dwellings by resting in caves and natural fissures in earth (Farid 1954).

Reproduction rate - Reproduction rates > 1.0 indicate an expansion of infections in a population while those < 1.0 indicate a decline in infections in the population. The goal of malaria control is to decrease the reproduction rate. This can be accomplished by altering mosquito numbers, longevity of female anophelines, biting habits, and recovery rate of gametocytemic person. Reduction of mosquito numbers through larval control is less effective by itself than causing mosquito mortality through adult control. The reason is that not only does adult control cause a reduction in mosquito numbers, but it also causes reduction in longevity of female anophelines [larval control doesn't do that]. The fewer gonotrophic cycles that a female mosquito has, the less likely that it is to transmit sporozoites (MacDonald 1956, p. 620).

Residual treatment - treatment of houses, animal sheds, and other buildings where people or animals spend nighttime hours with insecticide that has residual efficacy. The goal of residual treatment is to block transmission by stopping human-vector contact.

A common finding in malaria patients that sometimes can be detected by physical examination. May occur in otherwise asymptomatic patients and is of use in conducting malaria surveys of a community, although it should not be the only factor considered when counting cases.

Sporozoites infect liver cells, disappearing from bloodstream within 30 minutes. The mechanism for this amazingly rapid disappearance from the bloodstream to the liver is still unknown. Sporozoites are delicate and spindle-shaped stages that are released into the haemocoel of the mosquito when the oocyst ruptures. Some eventually find their way to the salivary glands of the mosquito.

This involves the use of drugs, prompt diagnosis, insecticide sprays and insecticide-treated bednets, improved community-based systems, proper case management, improved health information systems, and proper environmental management geared towards vector control, plus a continuous search for an effective vaccine. This article highlights these components of a multilateral approach to malaria control, and is particularly aimed at drawing the attention of healthcare providers and indeed the policy-makers in Africa where the disease has had a devastating effect"

Attempts at curtailing the devastating effect of malaria in Africa have been punctuated with many obstacles. The major obstacles are the rapid development and spread of vector resistance to residual insecticides and parasite resistance to clinically useful drugs.

Other obstacles include lack of adequate and effective alternative antimalarial drugs that are acceptable, safe, affordable and easily available. Poorly managed health services in most African countries have also limited the effort to combat the disease. The people of sub-Saharan Africa need a strong political will and adequate financial backing, to ease the severe effect of the disease on the continent.

Rapid and prompt diagnosis of malaria infection, followed by adequate drug treatment is a major tool in malaria control. The classical method for diagnosis is the examination of a blood smear under the light microscope. This technique is sensitive and specific, but labour intensive, and requires a good microscope and skilled personnel.

Inspite of widespread problem of antimalarial drug resistance, use of drug remains the most effective option for malaria treatment. Chloroquine, historically the first-line drug for the treatment of malaria, is readily available and usually affordable in most African countries.

However, lately, the malaria parasite, Plasmodium falciparum, has developed ways of avoiding the effect of this drug. Thus, people infected with these drug resistant parasites remain sick even after taking the adequate dose of chloroquine that would have "cured" them. Current efforts to improve malaria treatment are directed towards developing new antimalarials, new drug combinations and making better use of currently available drugs. A suitable replacement must not only be effective but also affordable and with relatively less or no side effects. The biggest effort in this direction is currently in the development of artemisinin and its derivatives. Artemisinin is clinically effective against both chloroquine sensitive and resistant parasites and is being used against severe and uncomplicated forms of malaria. However, this drug is characterised with recrudescence, that parasites in the liver, which are normally not affected by the drug, could reappear shortly after those in the bloodstream have been cleared. Efforts are being made to combine this drug with other antimalarials to enhance its antiparasite activity, and also reduce the chances of developing resistance. Other suitable drug combinations are being looked into. WHO is collaborating with industry to develop a novel combination of two old drugs, chlorproguanil and dapsone. A triple dose of this combination, given at 24 hours interval, was found promising in trials conducted in Africa. The drugs short elimination half-life is an advantage, as it reduces the chances for development of resistance. Another promising drug combination is Malarone, comprising atovaquone and proguanil.

Successful trials with second-line therapies involving the combination of an antimalarial drug and antibiotics have been reported. A 93% prophylactic efficacy was obtained in a Kenyan population with a combination of mefloquine and doxycycline. A combination of quinine and tetracycline was effective, but showed side effects. Attempts to reverse chloroquine resistance have also been successful. Reversal drugs like chlorpheniramine which have a two-fold effect of being antimalarial as well as antihistamine would be useful for individuals who get allergic chloroquine-associated "itching" reactions. Pyronaridine, another promising alternative to chloroquine, has been found to be 100% effective among children, with uncomplicated form of malaria, in an area of high chloroquine resistance in Cameroon. Mefloquine, another useful drug in the treatment of both chloroquine sensitive and resistant infections has a major draw back. It has a tendency of precipitating mental confusion, even in non-predisposed individuals. Although the drug is said to be safe after the first trimester (three months of pregnancy), its toxic effect on the developing child is not fully understood. Further studies are underway to ensure that the drug is relatively safe.

At the end of the day, antimalarial drug policy, formulations or alterations should be based on sound scientific findings. A carefully planned and well-executed drug surveillance will provide useful information and guidelines, especially on the time-point at which a switch from a failing first-line drug to a second-line drug should be made.

Malarone drug donation programme was established. This will ensure that good and effective drug combinations reach the people at subsidised rates. However, because of the limited health budget in Africa, the possibility of acquiring cheap and sub-standard drugs is anticipated. To curtail this problem, antimalarial drug policy should carefully monitor drug importation.

The problem with easy availability of drugs is that it allows for improper use such as erratic and inadequate dosages. This subsequently results in unnecessary drug pressure, which may lead to the selection of resistant parasites. Thus, to avoid such situation, there may be a need to train potential drug shopkeepers on how to give advice to their customers on correct dosages and if possible to monitor the drug intake by patients. This approach of using Direct Observed Therapy (DOT) has been implemented successfully by the Global Tuberculosis Control Programme in the management and control of drug resistant tuberculosis. Alternatively, potential drugs should be classified and withdrawn from the shelf, so that instead of being sold across the counter, are distributed by community health centres in correct doses to the patients. Measures to ensure transparency and avoid corruption should also be instituted.

Azadiracata indica) for their anti-malarial activities. The development of new and effective drugs is a challenge. To achieve this, the interaction between the public sector and the pharmaceutical industry must be strengthened with improved mutual collaboration and adequate funding.

Chris Curtis showed that both methods reduced the prevalence of anaemia and the number of malaria-infective mosquitoes biting each night by 90%. ITN was however found more cost-effective, and households preferred the treated bednets to house spraying. ITN reduces child mortality and the incidence of mild and severe malaria. The significant positive impact on malaria control, the acceptance and cost-effectiveness of ITN should be good indicators for decision-makers to consider re-directing policies on this very important control tool. Currently, the use of treated bednets is not as widespread as it ought to be. Implementation of ITN programmes should be encouraged and supported as widely as possible in Africa. Emphasis should be placed on the effective development and marketing of simple and affordable treatment kits for self-use in homes. This would be more user-friendly, avoiding the cumbersome community-based treatment, and encourage more people to use ITN. Until an effective vaccine becomes available, malaria control will rely predominantly on ITNs to reduce human-mosquito contact.

Proper management of the sick child is a cost-effective health intervention strategy, which according to WHO, has been estimated to have a large positive impact on the global burden of disease in the developing world. An initiative known as the integrated management of childhood illness (IMCI) was launched by WHO and UNICEF, to address case management of the clinically ill child in developing countries, with emphasis on malaria and pneumonia. The initiative hopes to train and support health workers, conduct in-patient training and drug supply management courses, monitoring and reinforcement of skills after training, and develop a guide to improve household management of childhood diseases. These are aimed at improving the standard of case management in developing countries. The knowledge and expertise of the rural clinical health workers in patient history taking, physical examination, diagnosis, treatment, and patient education have direct relevance on the quality of care received by the sick child at the community level. Good clinical decisions can only be taken by properly trained and well-informed clinical health workers.

For instance, a study in the Gambia and Tanzania showed that the best clinical intervention for children with severe malaria anaemia and signs of respiratory distress must be blood transfusion, to save their lives. Strict observation of good clinical practice, re-training and updating the knowledge of clinical health workers in case management, provision of essential drugs, supplies and equipment in rural health centres should therefore be addressed.

Malaria control would also benefit from improved community-based systems. The family is the first hospital for any child with high fever in Africa. Improved home management of malaria will therefore have a positive impact on treatment and control. Proper pre-packaged drugs with trained shopkeepers may bring about drug dosage compliance, and improve malaria treatment in the communities. Adequate health education on how to reduce human-vector contact, proper use and treatment of bednets with insecticides, correcting myths that surround many diseases at the community level, would be a boost to malaria control in Africa.

Most African countries are involved in one developmental project or the other. Some of these projects include World Bank-assisted water schemes, construction of dams and bridges, oil drilling and mining activities, urban planning and development, logging activities, road and railway constructions, building of new airports, etc. These projects have been known to inadvertedly lead to increase in mosquito breeding sites, thereby increasing human-mosquito contact, and indeed transmission. It is suggested that such projects should include health personnel for proper evaluation of the health risks associated with the projects in their immediate communities.

Good drainage systems will reduce mosquito-breeding sites and improve the sanitary condition of urban centres. Proper environmental management will not only lead to sustainable economic resources, but also reduces the creation of new breeding sites for disease vectors. This would be an added responsibility to the various national vector control programmes in Africa.

This would obviously eliminate the "fire-brigade" approach to management of epidemic outbreaks in Africa. A MALSAT study in Namibia, Kenya and Zimbabwe has demonstrated that early warning of epidemics is crucial in the fight against malaria. The current MARA project of mapping malaria risk in Africa is an excellent example of information-based approach to disease control. Decision-makers in Africa need such reliable information well in advance, spelt out in a simple language, devoid of technical jargons or unprocessed satellite data. The present orientation of HIS needs to be restructured for effective information management at the three levels of healthcare delivery, tertiary, secondary and primary.

This would enable the end users of health information, namely, clinicians, nurses, midwives, traditional birth attendants and other health workers, to translate them into improved quality care delivered to the patient.

The development of an effective vaccine for use in Africa and other malaria endemic areas, remains the ultimate quest for malaria control and perhaps, eradication. About eight potential vaccines for malaria are currently in different stages of development. The recent establishment of the African Malaria Vaccine Testing Network (AMVTN) is very timely. Its overall objective is to provide a forum for interaction by scientists and policy makers involved in the planning, coordination, and execution of malaria vaccine trials in Africa. Considering the duration of the different phases of vaccine trial, it may take another 20 years before a malaria vaccine is in the market. Until then, the integration of the various methods outlined above, would remain the only practical option for malaria control in Africa.

To answer questions of efficacy, affordability, acceptability and sustainability of control programmes within a particular community, an economic consideration in the evaluation and implementation of disease control interventions is of utmost importance. These are important points that influence the decision of policy-makers towards the choice of which control measure to adapt. Taking ITN as an example, Anne Mills noted that there are three key policy questions that need to be addressed. These include, how much does it cost? Is it affordable? Finally, is it an efficient use of scarce resources? The willingness of the people to pay for ITN varies in different communities, with different socio-economic characteristics. This willingness however, does not translate to actual purchase of treated bednets in these communities. The people are faced with serious economic reality, between buying a bednet or food for the family. It is evident therefore that subsidised distribution of bednets through community health centres and free distribution of insecticides should be an integral part of any successful national ITN programme. On drug therapy, the overall cost depends on both the cost of treatment and of getting the patient to seek treatment. At present, this cost is very high, patients therefore resort to self-medication, self-diagnosis, and across the counter services from drug shopkeepers in their communities.

MFI and DAM are committed to creating international awareness on the burden of malaria. They support, educate and assist in malaria-related activities, stimulate discussions, secure funds, and encourage the most effective use of available resources for malaria research and control. Proper implementation of disease control programmes will depend largely on the availability of well-trained personnel. Emphasis should therefore be placed on training health professionals, technicians and malariologists including vector biologists, molecular biologists, epidemiologists, health economists and sociologists, among others. African governments, NGOs and international funding agencies are encouraged to participate in providing the needed critical mass of well-trained Africans for proper implementation of disease control programmes in the continent.

It is known that Africa is home to various vector-borne diseases other than malaria. These include river blindness, sleeping sickness and leishmaniasis, among others. Certainly, a cost-effective integrated approach will be beneficial also, to the control of these other vector-borne diseases. With the current global concern, it is imperative for scientists, clinicians, policy-makers, health managers and health-care providers in Africa, to act in concert with other players, and reduce the burden of malaria on the continent, using an integrated approach. The active participation of all stakeholders is indispensable, and should be focused towards achieving a 50% reduction of malarial deaths in the next ten years, reduction in poverty and an appreciable human resource development, as earmarked by RBM.

Welcome to Pesticides and Spraying Techniques.  You may enter any of the discussions above by clicking on the appropriate link.  Or, to start a new discussion of your own, click on the "Create New Conversation" button.

Welcome to Mechanical Mosquito Control Options.  You may enter any of the discussions above by clicking on the appropriate link.  Or, to start a new discussion of your own, click on the "Create New Conversation" button.

As your organization is active in regions of the world affected by malaria, I thought I would write to you, in my capacity as president of the Malaria Foundation International, to let you know of an important development in the battle against the disease. Leaders of the G8 countries have endorsed plans by the World Health Organization (WHO), World Bank and other international agencies to launch a bold multi-agency, long-term programme in malaria control.

The promise of high level political support, and the ambitiousness of the planned new programme, are the culmination of growing international recognition of the gravity and deterioration of the malaria situation, in particular in Africa. We are perhaps standing at what is an historic watershed in efforts to combat the disease, and any support from your organization would be most welcome.

Yet malaria control efforts suffer from a lack of co-ordinated investment and implementation. Similarly, global expenditure on the research needed to develop new tools is estimated at a fraction of that spent on asthma, not to mention AIDS. Spending on cancer research in the United Kingdom alone is double that spent on malaria research worldwide.

Moreover, just as the explosion of parasite resistance to drugs makes it more pressing than ever to find new drugs and vaccines, the pharmaceutical industry worldwide has been reducing its support, but it is hoped that this trend will reverse.

Our goal is to promote the better use of existing tools and the development of new ones, and to help ease the health, economic and social problems caused by malaria. At present we support programmes in international communications and networking, education and training.

If you would like more information on the Malaria Foundation International itself, it is probably simplest to just consult our Web site (www.malaria.org), which gives details for example of the composition of our international governing and scientific boards. You will find further details of the Roll Back Malaria (ABM) initiative on the attached briefing sheet and can follow ABM developments at the Malaria Foundation International web site. We encourage you to disseminate this information widely amongst your colleagues and would be happy to provide you with related articles for your internal publications.

The planning meeting for the NIAID Malaria Research and Reference Repository began with a welcome by the two chairpersons, Drs. Mary Galinski and John Adams.  The welcome was followed by a brief reminder of the meeting's purpose, which was to gather ideas from investigators involved in various aspects of malaria research concerning how the new malaria repository should function.  NIAID will consider the recommendations of this group in further development of plans for the repository.

Branch, NIAID, thanked the participants for coming to the meeting and restated its purpose - to focus on input from investigators directly involved in malaria research to determine what needs should be addressed by the new repository.  Dr. James opened the general discussion by reviewing the history of the Multilateral Initiative on Malaria, and presenting an overview of current NIAID activities in malaria research including the establishment of a malaria research and reference reagent repository.

NIAID has attempted to respond to these stated needs of the malaria research community by establishment of a malaria reagent repository for the use of qualified scientists worldwide.  The Institute has created an interim facility for one year (FY 1998), during which time the mechanism will be put in place to make a seven year contract award for a full repository.

Dr. James outlined the additional aspects of the full repository, which will expand on the capacity of the interim repository. The full repository will include access to Plasmodium parasites, vector reagents, human sera and human tissues.  As a part of this contract, a scientific advisory committee (SAC) will be established to provide ongoing advice on issues such as prioritization of reagent acquisition, regular review of progress, etc.   Capacity to provide reagent quality analysis and control (QA/QC) will also be provided, to relieve donors of the bulk of this burden.  In addition, the repository will serve to provide public information and will support workshops and training activities.

The purpose of this planning meeting was to find out more specifically what is needed by malaria researchers so that the repository can supply materials accordingly. She stated that the intent of the repository is to provide malaria reagents to the entire research community, not just NIAID-supported investigators.

Research Risks (OPRR) to provide guidance on protection for human subjects in research.  Institutional Review Boards (IRB's) have been established to review federally funded human subject research to be certain that the investigator is complying with federal regulations involving protection of human subjects.  Localities/institutions may also have established IRB's, but where the research is funded by the US government these IRB's must also conform to US federal regulations, regardless of the state or foreign country of origin.  Informed consent or waiver of informed consent is the approach required by IRB's.

Such an arrangement assures the anonymity of the tissue donor.  Both the tissue collector and the repository operator must be reviewed by an IRB and comply with IRB recommendations.  Informed consent must be obtained for each sample sent to the repository, unless the IRB finds that the research involves only minimal risk to the donor.

Genetic studies are becoming increasingly popular, and with them come complicated  issues regarding use of human genetic material.  Genetic privacy laws have been passed to protect individuals from insurance, health and employment discrimination based on genetic predisposition to certain conditions.

There are currently 16 bills pending legislation in the US Congress, and another 100+ bills in at least 34 states in the last year have dealt with this important issue.  In general, unless conditions for limitation or waiver are met, informed consent must be obtained for genetic studies involving humans.  It has been agreed that the benefits to society must outweigh risks to the donor.  The critical nature of patient privacy is pointed out by the formation of the National Bioethics Advisory Commission by President Clinton in 1996.  A Genetics Subcommittee report expected in January/February, 1998, will publish guidelines for the use of stored existing and prospective human genetic materials.  Any potential contractor should be prepared to keep abreast of developments in this area.

It represents a unique resource to the scientific community through which small amounts of  reagents are supplied free of charge to requestors.  The repository also dispenses information and technology transfer through publication of a newsletter, which contains updates of protocols and announcements of research initiatives to its recipients.  New reagent classifications have resulted from commercial developments by the repository, and workshops have been conducted, e.g., Heteroduplex Mobility Assay and Shipping of Infectious Materials.  The repository has been cited in over 1300 scientific publications.

Sometimes a donor delegates only one time use per requestor, after which the requestor must contact the donor for permission to use the reagent again; certain institutions (e.g. biotech companies) consider all requests as having commercial potential, assuming there is no such thing as research without commercial prospects.

Recipients are responsible for payment of shipping charges.  Dr. Sharma noted that 70% of reagents are requested by NIH-funded investigators.  He also pointed out that shipping reagents to overseas sites is often a problem because of difficulties in obtaining approvals for shipping from the countries to which reagents are to be sent.  This may present a problem for the malaria repository, since many research sites are located outside the US.

Dr. Haldar raised the subject of how complaints to the repository were dealt with.  Dr. Sharma indicated that these cases were rare, but pointed out one specific example of a reagent recall in which all recipients were sent a letter of apology by the contractor.  He also stated that it sometimes turns out that the complaining requestor hasn't followed the protocol recommended by the donor or contractor as carefully as he/she should have.

Dr. Krishna asked whether most donations to the DAIDS repository are solicited or unsolicited.  Dr. Sharma replied that donations are largely unsolicited, due to the great extent of advertisement of the repository at major meetings and by the reagent reporting system.  New products are constantly being announced.

Dr. Taylor asked if there are any particular requirements that must be met in order to donate reagents to the repository.  The answer was that once a new reagent has appeared in a publication, donors are encouraged to send samples to the repository.  When a reagent is sent by a donor to the repository, a reagent form (stating how it was produced and a protocol for its use or a brief description of how the reagent may be used) accompanies the shipment.

Dr. Leke asked what can be done to ease shipping problems to African countries, where time required for shipping and high costs can create prohibitive concerns for both donors and recipients of repository reagents.  Dr. Sharma explained that the January, 1995 "tightening" of infectious agent shipping regulations by the US Department of Transportation and Air Transportation has loosened somewhat in succeeding years.  The use of liquid nitrogen shipments has improved the safe transport of infectious materials from areas as far away as Siberia, Estonia and Malawi, in the case of AIDS reagents.  Shipping problems which still remain to be solved include shipping for arrival on weekends or holidays and the policy that no infectious materials are allowed in the airspace over India.   Dr. Sharma pointed out that the NIH Office of Safety works closely with DAIDS to ensure shipping safety.

Other queries had to do with storage of the repository materials once they are received.  In the case of the DAIDS repository, all storage facilities are located in the U.S., but satellite laboratories could potentially be opened in other countries for temporary storage, especially when a country wishes to send only part of its supply of a reagent to the central repository.

Discussants agreed that such satellites would be particularly useful in the case of malaria, since most disease occurs in Africa and shipping materials to/from Africa is often complicated.  Satellite repositories could also be used for reagents belonging to investigators who are unable to continue to support a project, but do not want to dispose of reagents collected under that project because of their potential utility to others.

As an addendum to these discussions, Dr. Collins of CDC pointed out that a special permit is needed for blood samples from endangered species (e.g. certain species of monkeys), which will be something to remember when the full repository is up and running.

Chloroquine  is still treating most malaria cases in Tanzania, and therefore  change of  policy in combating malaria should be reviewed.Note that Tanzania is discouraging the use of Chloroquine as a first line treatment for malaria, encouraging Fansidar which is not effective in severe cases.Chloroquine is equally  important as  other  antimalaria drugs.

Speaking to the Board on 18 May, Dr Brundtland outlined her plans for WHO. In future, the WHO Secretariat's work would be grouped into four areas: building healthy communities and populations; combating ill health; external relations and cooperation with other UN agencies, the private sector, nongovernmental organizations, donors and other stakeholders; and building sustainable health systems in Member States.

The Director-General Elect, who takes office on 21 July 1998, called on the EB to work with her in changing WHO. "What I would wish to see is a working relationship between the Secretariat and the knowledge base represented by the Board. I would welcome the opportunity for real policy discussions around this table."

Dr Brundtland proposed that the Board join her in more informal settings - such as a retreat in October 1998 - to focus on policy discussions concerning the main directions which the WHO should be pursuing under her stewardship. She has already suggested "Roll Back Malaria" &"Tobacco Action", "Health Sector Development" and "Health and Development" as policy initiatives and she invited the Board to help her formulate other health priorities.

"WHO's reform must be understood and pursued as a continuous process, the purpose of which is to keep the Organization vigilant and responsive to the evolving needs and circumstances of its Member States in a rapidly changing social, political and economic situation."

J-F Girard of France to explore the complex issues related to WHO's Revised Drug Strategy after the World Health Assembly was not able to agree on a proposed resolution during deliberations last week.

Office for the Americas but which is a separate legal entity, is requested to consider this issue as well. This would bring the conditions of employment of the Regional Directors in line with the conditions applying to the WHO Director-General.

Following the election of twelve new Member States as members of the Executive Board during the World Health Assembly last week, the Board's composition and the countries' representatives are listed in Annex 1.

European leaders will announce funding increases in excess of a hundred million dollars.  The Clinton Administration has yet to agree to any increase at all.  "If the Administration wishes to advance its environmental agenda with the POPs treaty, it must make this commitment now," said Dr. Musil. "With climate change exacerbating the spread of malaria, we cannot afford to wait."

Dr. Kamini Mendis, of the University of Colombo in Sri Lanka, and colleagues there and in France report in the April issue of Infection and Immunity their success with this leading malaria vaccine candidate in a primate trial.

Four weeks after immunization, the scientists inoculated the animals with P. cynomolgi parasites isolated from a donor monkey. All six control monkeys became infected, with patency lasting at least 44 days. By contrast, all of the immunized monkeys showed high antibody titers against the antigens and only one of nine was not protected against challenge.

The remaining animals showed "...either no parasitemia at all or transient parasitemias which were patent for only 1 or 2 days," according to Dr. Mendis and others. Moreover, monkeys immunized with the 19-kDa fragment showed sustained protection against a second challenge 6 months later.

They point out that if the protection conferred by MSP1 vaccines is dependent upon the high antibody titers elicited, the next "...challenge ahead for preparation of an analogous human P. vivax vaccine will be to replace the potent Freund's adjuvant." Preliminary data suggest that comparable antibody titers can be obtained "...by using alum, which is the only adjuvant currently acceptable for human use."

Dr. Mendis and colleagues noted that the sustained protection observed in p19 vaccinees to a second challenge could have been due to the first immunization or, more likely, "...boosted by a minimal exposure to parasites during the first challenge." In other words, protection against homologous Plasmodium strains "...might be induced by a single complete blood stage infection." Such a finding "...implies that vaccine-induced immunity could be boosted by natural infection, a feature which could be of considerable importance for the deployment of an MSP1 p19-based vaccine in malaria-endemic areas," the scientists propose.

"These results are now being confirmed in a trial with larger numbers of animals," the researchers say. Dr. Mendis and associates stress that "...the real relevance of the results reported here will by determined only by clinical trials with the P. vivax MSP1 recombinant analogs."

Like flying syringes, mosquitoes excel at pricking your skin and drawing blood. But some species also inadvertently spread diseases, like malaria. Now researchers have taken an important step toward genetically altering mosquitoes so that they are incapable of transmitting disease. A report in the current issue of the Proceedings of the National Academy of Sciences describes a new method to insert genes into a mosquito that get passed on to its offspring.

One obstacle to genetically engineering mosquitoes has been the lack of a clear "marker"--a distinctive genetic trait that can reveal whether a gene was successfully inserted. Biologist Frank Collins of the University of Notre Dame in Indiana realized that the answer was as close as the lab next door, which for 30 years had been maintaining a colony of mutant mosquitoes with white eyes instead of the usual reddish brown.

Irvine, thought they might use the mutant bug to test a fancy trick: Take a bit of DNA, called a transposon, that likes to wiggle into genomes, and use it to insert a fruit fly gene for darker eye color into a mosquito's DNA.

They aimed for the part of the embryo that produces sperm or eggs in the adult. One generation later, they had their proof that the approach works: Of 120 surviving adults, three had offspring with eye colors that were reddish brown instead of white, Collins says.

The work is just the first step on the long road to engineering disease-resistant mosquitoes, says Becky Wattan, a biologist at the University of Arizona. The next step is to home in on the mutation that knocks out disease transmission and rig it to spread through a population.

"From a medical perspective, the major interest is to see if we can identify genes that will interfere with the ability of (the) mosquito to support development of parasites like malaria parasites, or mosquito-borne viruses like dengue and yellow fever," explained Dr.

Bites from disease-carrying mosquitoes spread illnesses such as malaria and dengue fever, which kill millions of people every year. So far, scientists have not yet discovered an effective vaccine for either malaria or dengue fever.

But in an interview with Reuters, Collins explained that genetic manipulation of the Aedes aegypti mosquito (the species which transmits malaria) might render the insect incapable of transmitting malaria parasites.

Transposons are able to detach themselves from one genetic location and insert themselves into another. At the same time, this move necessitates the creation of a copy of the transposon to fill the gap left behind. This means that potentially thousands of copies of this gene can be created in a single individual. "If an individual that is saturated with transposons mates with an individual that does not have transposons, the offspring will all have half the saturation," Collins explained. He says this means that "transposons can effectively propagate in a way that drives them through a population, so that ultimately every member of the population is saturated with transposons."

Scientists say that if the technique works with characteristics such as eye color, it should work for genes which hinder the mosquito from harboring the malaria parasite. "The long range goal will be to drive such antiparasite genes into the natural population of mosquitoes,"

He says any research into a genetic means of thwarting disease transmission does not mean science should abandon its search for a vaccine or cure for mosquito-borne illnesses. Collins believes transposon techniques would not be "an exclusive (disease) control strategy but rather a new method to be used in conjunction with anything else that may be effective or partially effective."

Public health officials blame the resurgence of malaria worldwide on the increasing resistance of mosquitoes to insecticides, and on growing resistance of the malaria parasite to many drugs used to treat the disease.

Dr. Jorg Schneider of the University of Oxford and his team used DNA encoding pre-erythrocytic antigens of P. berghei in a series of immunization experiments in mice. The researchers, in Oxford and London, UK, found that "...priming with plasmid DNA followed by a single boost with a recombinant modified vaccinia virus Ankara...expressing the same antigen..." confers complete protection against the malaria parasite, Plasmodium berghei, in two strains of mice.

All of the mice immunized with this protocol were protected against infection at the first challenge, and the majority of them were also protected at a second challenge, 28 to 35 days later. All of the mice demonstrated "...very high levels of splenic peptide-specific interferon-gamma-secreting CD8+ T cells."

When the vaccination protocol was administered in the reverse order--priming with the modified vaccinia virus Ankara and boosting with plasmid DNA encoding pre-erythrocytic antigen--protection against P. berghei was not achieved.

The mechanism underlying the efficacy of one immunization sequence but not the other "in unclear," Dr. Schneider and colleagues say, but they speculate on a possible mechanism. "The [modified vaccinia virus Ankara] vector appears more immunogenic than DNA for CD8+ T cell induction; however, because of the large number of viral genes that are co-expressed, the immune response to the malaria antigen or epitope may not be immunodominant, but priming with just the malaria antigen using plasmid DNA may produce sufficient primed CD8+ T cells to the malaria epitope to allow the recombinant [modified vaccinia virus Ankara]-induced response to focus on this rather than viral epitopes."

The protective effect of the P. berghei pre-erythrocytic antigen supports the idea that its P. falciparum homologue may represent a malaria vaccine candidate, the investigators report in the April issue of Nature Medicine. In fact, they have shown in follow-up experiments that the same protocol described above can be used to elicit high expression of CD8+ T cells to a P. falciparum epitope in chimpanzees.

The modified vaccinia virus Ankara "...appears to be an exceptionally safe live virus vector," and has the potential to be incorporated into ongoing human vaccine trials using plasmid DNA. Dr. Schneider and others also point out that the vaccinia virus alone may be effective in boosting a CD8+ T cell response in persons living in areas endemic to P. falciparum, who experience "...natural priming from infective mosquito bites."

A unique, mobile chunk of genetic material called a "transposon" can be used as a vehicle to plug new fragments of genes into a mosquito's DNA, so they become part of an insect's genetic blueprint, UCI transformation biologist Anthony A. James, postgraduate researchers Craig Coates and Nijole Jasinskiene and colleagues report in the March 31, 1998 issue of Proceedings of the National Academy of Sciences.

This is the first time anyone has found a way to routinely introduce stable, inheritable foreign DNA into mosquitoes, James said. He and his colleagues hope the method will lead to the introduction of an altered genetic code into certain mosquito populations-combating diseases such as malaria and dengue fever.

"It would be a sort of gene therapy for mosquitoes," James said. Each year, 300 million to 500 million people worldwide become ill with malaria and several million die. Between 200 and 300 children are estimated to die from malaria each hour.

Public health officials say the disease is now resurging worldwide because mosquitoes are growing resistant to insecticides and the malaria parasite is gaining resistance to many drugs used to prevent the disease. This resurgence is prevalent in nations where many people are too poor to afford the more effective drugs.

James began working on this area of research in 1986, focusing on genes from mosquitoes' salivary glands, where specific interactions occur between a parasite and the mosquito. By the early 1990s, he had identified areas of genes that, if altered, might be used to help block transmission of disease. But how to get a synthetic, parasite-resistance gene fragment into a mosquito so it could be passed on to further generations?

James and colleagues fruitlessly worked on ideas. For seven years, promising leads turned into dead-ends. Then James came up with the idea of using a transposon as a vehicle to introduce gene fragments into a mosquito's DNA.

A transposon is a genetic taxi cab: a short chunk of DNA that has the ability to jump out of a DNA chain and move itself-and any other genetic material it happens to be carrying-into another part of a DNA chain.

On a break during an entomology conference in Italy, James asked colleague Frank H. Collins of the University of Notre Dame about his latest research projects. Collins told him about a strain of mosquitoes that passed along a trait to offspring that turned their eyes white, instead of the normal dark reddish-brown. Immediately, James got an idea: Why not use the eye color trait as a marker in his research?

A team of scientists including James, Jasinskiene and Coates, as well as representatives of Notre Dame and the Centers for Disease Control and Prevention, set to work with dozens of tiny embryos of white-eyed mosquitoes. They injected them with a transposon called "Hermes," which carried a new bit of DNA that controlled eye color. Hermes originally came out of the genetic code of a housefly.

A second team of UCI researchers injected another group of white-eyed mosquito embryos with a different transposon called "mariner," which also had the eye color gene fragment plugged into it. Mariner originally came out of the genetic code of a fruit fly.

Both teams saw that offspring of the white-eyed mutant mosquitoes ended up with reddish-brown eyes, indicating the new eye color genetic fragment was successfully passed along to offspring. The bit of DNA was passed along for at least 10 generations, proving that both Hermes and mariner acted as effective DNA delivery systems.

This technology takes a first step toward generating strains of mosquitoes that cannot transmit various diseases. Scientists must next develop synthetic, disease-resistance genetic bits they can plug into transposons and then introduce into mosquitoes. They also will study how the altered genome would behave in mosquito populations.

Their report, published in the current issue of the journal Nature, focuses on the life cycle of the Plasmodium family of protozoa that cause malaria. The mature organisms live inside blood cells, and are passed from human to human via the bite of the Anopheles mosquito.

However, the normal pH level of the mosquito gut -- 7.4 -- initially inhibits this type of growth. But scientists say the introduction of an (until now) "mystery" chemical seems to trigger a subsequent rise in pH, allowing the malarial life cycle to continue.

The London researchers now say they have identified this chemical as xanthurenic acid. Xanthurenic acid alone appears to adjust the mosquito's pH environment to Plasmodium-friendly levels: the investigators say experiments proved that the introduction of other, similar acids "failed to induce gametogenesis."

In their accompanying commentary in the same issue of Nature, malaria experts Richard Carter and Lisa Ranford-Cartwright of the University of Edinburgh in Scotland say xanthurenic acid may be "the 'ignition key' to transmission of malaria through mosquitoes."

They believe that mosquito-borne transmission might be interrupted by the introduction of a species of genetically-altered insects that lack the capacity to produce xanthurenic acid. Tests assessing the viability of Plasmodium in the bodies of these new types of mosquitoes could be a crucial next step in antimalarial research, they concluded.

WASHINGTON--The U.S. Agency for International Development announced Thursday a new initiative aimed at controlling the global emergence of lethal infectious diseases, saying it will develop programs in targeted countries to fight the escalating health threats posed by bacterial resistance, tuberculosis and malaria.

Congress, recognizing the potential danger from infectious diseases overseas, awarded the agency an additional $50 million for fiscal 1998 specifically for control of infectious diseases--the first time in four years that, "instead of cutting our budget, Congress has added to it," Daulaire said.

In response, the agency is pursuing a 10-year effort that it hopes will reduce by at least 10% the deaths caused by infectious diseases, excluding those caused by acquired immune deficiency syndrome, by 2007.

The $50 million is in addition to the agency's public health budget of $850 million, which is spent on maternal and child health, family planning and the control of AIDS and the human immunodeficiency virus that causes it.

USAID has estimated that more than 17 million people worldwide will die from infectious diseases in 1998. This health problem has gotten worse in recent years due to numerous factors, including rapid population growth, overcrowding, poor sanitation, poverty, loss of trained health personnel and decreasing resources available to public health services in the poorest of countries, according to USAID.

The money will fund a range of programs from buying drug-treated bed nets in Africa that protect against malaria-spreading mosquitoes to teaching Latin American pharmacists to stop dispensing antibiotics willy-nilly.

The funds -- a surprise allocation from Congress late last fall -- also will help establish a world system to detect emerging infections and outbreaks earlier, so doctors can respond before too many people die.

If the strategy works, within 10 years it could cut by at least 10 percent the 17 million people who die annually of infectious diseases, Dr. Nils Daulaire of the U.S. Agency for International Development said Thursday.

"We for years have looked for nickels and dimes to be doing more" against infections, Daulaire said. "It's a very valuable down payment on both the health of people around the world and on the protection of Americans themselves."

AID will outline its spending plan Monday at a meeting of international infectious disease experts sponsored by the Centers for Disease Control and Prevention. The CDC, whose scientists are called to diagnose and fight outbreaks worldwide, also is working with global anti-infection programs.

Many pneumonia, meningitis and dysentery germs now resist standard antibiotics; malaria no longer responds to the inexpensive therapy -- chloroquine -- half the time in some African countries; and the TB that kills 3 million people a year is rapidly becoming resistant to many drugs.

Developing countries fuel the problem by selling antibiotics in corner stalls to patients who often never see a doctor and don't know they should take the pills until the disease is entirely gone. AID money will educate pharmacists, health workers and patients in an attempt to change that.

Even regular bed nets cannot prevent mosquitos from spreading the disease every night, but an AID study found impregnating bed nets with pesticide could lower infection rates by 25 percent. The new money will buy treated nets and teach local health workers to recognize symptoms of malaria at its earliest stages, when it's most curable.

Getting the $50 million from Congress last fall was a surprise for AID, a frequent target of politicians opposed to spending U.S. resources abroad and one that some critics even attempted to shut down.

The funds came after Sen. Patrick Leahy, D-Vt., successfully argued that global infections threaten Americans' health, so the nation must fight back. He has pledged to help find continuing money for the foreign program next year as well.

Surveillance could be improved by giving communities incentives. If local health workers reported an outbreak of polio, for example, vaccination teams could head there to show there was an immediate benefit from reporting.

Discussion followed Dr. Kazura's presentation for the Vaccines and Immunology Focus Group.  Dr. Galinski lead with a question concerning storage of archival material - is it appropriate to keep archival human sera from past studies in case someone should want to reexamine it; how is it classified?  Dr. Ved Brat, interim repository contractor, explained that human serum can be classified either as a human product or or reagent, depending upon whether or not identifiers are available.  Identifiers for human material tracing it back to a particular individual would necessitate its classification as a human product.  A sample with no link to an individual would be classifiable as a reagent.  A set of samples linked to a particular ethnic group, parentage (general) or sex would also be classified as reagents (but this narrows the classification somewhat).

Dr. Sharma indicated that sharing with contributors information on what is being done with reagents that are donated to the repository keeps a spirit of openness and assures contributors that their contributions are valuable.

Dr. Dame asked whether there were a separate budget recommended for support of each area (e.g., parasite strains, clones, monoclonals, etc.);  Carl Henn, of NIAID Contracts Management Branch (CMB), replied that the scientific advisory committee will be established when the full repository contract is awarded to help to select funding priorities.  This planning meeting was convened to start the process, since the committee will not be in effect during the year of the interim repository.

Dr. Leke asked the group what would be the repository's expectation of people in endemic regions.  Dr. Adams addressed the question by stating that probably investigators in endemic countries would be expected to donate parasite isolates, human tissues (blood, serum, etc.) from population studies, and other reagents which may be new markers for pathogenesis, drug resistance, etc.  In turn, these investigators could expect, through the repository, to gain accessibility to typing reagents, reference sera, monoclonal antibodies, genomic DNA and primers for diagnostic PCR, as well as training in the use of various assays.  In other words, the benefits would be reciprocal.  Dr. Leke added that P. ovale and P. malariae are occurring more frequently in Africa and that standardized monoclonal antibodies against these two species should be added to the repository along with those against P. falciparum and vivax.

Regarding maintenance of insect colonies, Dr. Collins reiterated that the vector group felt  insectories are a priority which should not be delayed until the third year of the contract and wondered whether this could be accommodated.  Mr. Henn of CMB replied that a pre-award amendment to the contract can be made to establish an insectory component before the third year.  NIAID program staff stated that they would look into the possibility of obtaining additional funding for earlier startup of vector production by the full repository.

Dr. Galinski suggested that the Malaria Foundation's web site and specifically its Malaria Research Network and WorldWide Malaria Directory could be utilized to inform investigators about the repository and encourage them to contribute reagents and participate in the development of a functional repository.  She offered her assistance in engaging the global scientific community in this process through utilization of these electronic resources, which can be found at: http://www.malaria.org.

Dr.  Leke suggested that, in addition to making reagents available, it would be useful for the repository to sponsor workshops and training in the use of these reagents in the endemic countries.  She added that training in DNA extraction and cryopreservation would be especially helpful.  Dr. Gottlieb reminded the group that discussing training activities will be part of the scientific advisory committee's duties when the full repository is established.  In addition, Dr. James stated that some of the endemic country training is included in the RFP for Clinical Research and Trial Preparation Sites in Endemic Areas (RFP-NIH-NIAID-DMID-98-19) and will be covered by that contract.  In addition, some of the recently awarded Fogarty International Center training supplements contain malaria training initiatives.  Thus, the repository will not be totally responsible for this aspect.

The meeting was adjourned with the reminder that this represents a beginning which will be expanded upon as the repository plans develop, and increasing numbers of investigators add both their ideas and reagents.

Here you can find our Home Page for Those Using Text-Based Browsers. By forgoing the use of graphics, Java, Javascript, frames and similar technology, you can access these pages using an older PC running an older version of a browser and with slower connections.

The range of databases on offer comprises amongst other things subject bibliographies, full text databases, dictionaries. Here you will find databases freely accessible as well as those, which are liable to costs being therefore available on computers of the Goettingen university data network only.

This reference tool identifies superlative sources of information about a subject of inquiry, viewed through the lens of expert opinion. The subject specialists who select the citations mostly professors and librarians.  "Six superlative sources" and a longer list of other high-quality references are given for each topic covered. are provided.

YourDictionary.com well organized, comprehensive, and authoritative portal for language, and language-related products and services, including direct links to hundreds of online  general and technical mono- and bi-lingual dictionaries, thesauri, etc.

LiteratureClassics"LiteratureClassics.com, part of the Classics Network of websites, is the internet's leading provider of information on texts generally considered to be worthy of scholarship. The site features essays, electronic texts, links and resources for hundreds of literature authors, in a dynamic, interactive environment."

The OTA works closely with members of the Arts and Humanities academic community to collect, catalogue, and preserve high-quality electronic texts for research and teaching. The OTA currently distributes more than 2500 resources in over 25 different languages, and is actively working to extend its catalogue of holdings.

Here you will find the classic books from the start of this century and previous centuries, from authors like Shakespeare, Poe, Dante, as well as well-loved favorites like the Sherlock Holmes  stories by Sir Arthur Conan Doyle, the Tarzan and Mars books of Edgar Rice Burroughs, Alice's adventures in Wonderland as told by Lewis Carroll, and thousands of others.

CIA factbook The U.S. Central Intelligence Agency lists basic statistics (e.g., population, literacy, life expectancy of women at birth, languages, coastline, resources, number of Internet users, miles of pipelines, electrical consumption) for the countries of the world.

CIA reference maps The U.S. Central Intelligence Agency provides outline geo-political maps for the regions and countries of the world. Most of the maps are of a scale that includes the larger cities of a country or region.

German Culture: Tatyana Gordeeva's  clearly presented gateway to Germany. This is a comprehensive survey of Germany and German culture, government, language, language-learning, literature etc., arranged by topics and subtopics.  It includes a  review of Germany which treats its dominant social, political, economic, and military aspects in a concise and objective manner.

Blinkx has "smart folders" that allow you to index, link and organize  audio, video, P2P, Web sites, e-mail and local documents together  in a convenient way.  It also allows peer-to-peer networking.  It must be installed to be used.

The Internet Guide .co.uk is dedicated to helping beginners to the Internet understand it better. The Internet Guide covers a wide variety of topics, such as html, email, tcp/ip, search engines, security, viruses, browsers, newsgroups, chat programs, file sharing, FTP, Telnet and more.

"A9.com remembers your information so you don’t have to. You can keep your own notes about any web page and search them; it is a new way to store and organize your bookmarks; it even recommends new sites and favorite old sites specifically for you to visit."  It also gives site information on URLs it lists.

ForschungsPortal.netUsing ForschungsPortal.net you will learn in what federally sponsored research facilities in Germany which themes are handled and what information is available via the portal for which themes.

This is a search engine that focuses on scientfic Internet sites, filtering out many of the irrelevant sites. "Scirus is the most comprehensive science-specific search engine on the Internet. Driven by the latest search engine technology, Scirus searches over 167 million science-specific Web pages"

For those times when you want to find more than just web pages and web sites, some of the "specialty search engines" herein will prove useful. Also called topical search engines, "vertical" search engines or "vortals," they'll help you search through specific types of listings in different areas.

To optimize its use, narrow your search by clicking through to your desired category and then searching.  This way irrelevant materials are filtered out.  Many of these categories and subcategories are  custom-managed by people rather than automatically.

All answers are delivered by e-mail.  We will normally answer your questions within five work-days.  As a special service in processing your questions, we are integrated with the worldwide information service alliance "QuestionPoint."

For your search you can use the booleans and (this returns a set of only those cases where all words occur), or (this returns a set where all hits with any one of the listed words occur) or not (excludes any word or phrase following the word "not" from the returned set).

Without these booleans a search with and will be performed. You can also use asterisks as wildcards to search for matches to the beginnings of words only - you can't put asterisks at the front or the middle of words.

During their office hours as well as by appointment our subject specialists are at your disposal to answer subject-related questions; you can find names, rooms, telephone numbers and specialities in the following lists.

At the information desk one can get any information desired concerning catalogues and bibliographic references whether on the spot or in writing (postal mail, fax, e-mail) for users from beyond Goettingen. This is also where inter-library information is given and where the inter-library loan order slips can be found and are to be handed in.

We are eager to be of assistance in the use of our electronic and card catalogues and regularly offer introductory mini-courses in the use of the local, national and international databases.  For more details on these German-language presentations, see  Schulungsangebote).

On-line orders are legally binding. Bills are enclosed with the consignment, payment being due in Euro without subtractions within fourteen days. Personal data on the customer (name, address and information necessary for billing) will be stored for a longer period of time since it is to be expected that orders will be made on a regular basis.

Normally, holdings of the Goettingen State and University Library and photographic and scanned copies obtained by normal check-out or inter-library loan normally may not be lent to be used as the basis for reprints. The use (i.e., reproduction of pictures) requires explicit permission and, generally, the payment of a fee.

You can do searches of the online catalogue by subject using the Goettinger Online-Klassifikation (GOK), a universal classification system which attempts to organize the complete spectrum of scholarship into a single hierarchical system.  The most important accessions since about 1993 are included within this system.

Choose the subject your are interested in from the following list. You will then get a subclassification of this subject area.  Further selecting eventually brings you to a list of materials in the library's online catalogue in this specialized area.  The materials listed can be checked out or used in the library.

Written information services provides bibliographic information of every kind and is also available for other questions about library's holdings.  In particular, here is where to address questions about works appearing before 1800 and that are thus not normally available for being checked out.

We will gladly help you in your preparation for a visit to the Goettingen SUB.  Specific information about this can be found in our info 25. In addition, for questions about orders for copying and scanning, we are at your service and will help you find the most reasonable manner of reproduction.  Of course, we will give you a cost estimate.  Our Repro-Center's current prices can be found on our Orders for Copying, Photographing and Scanning Documents.

For questions on (German) genealogy, you can also consult the Genealogisch-Heraldische Gesellschaft Goettingen e.V. (Goettingen genealogical and heraldic society).  This site is in German but does have a link to an English-language German genealogical server.

Soon you will see on your right the courtyard called "Lichtenberghof," with a sculpture of this famous Goettingen scholar seated therein.  Go in here and use the building entrance which is straight ahead of you.

You will see a pedestrian crossing with stoplight.  Cross the divided street (Berliner Strasse) and continue straight ahead on the Goethe - Allee heading downtown.  Continue along the right-hand side of this street.  Directly at the Leinekanal, at the corner of the Goethe - Allee / Prinzenstrasse and Papendiek, turn right onto Papendiek.

After a few meters, you will see the courtyard named "Lichtenberghof" on the left (east) side of the street, after the historical library building proper.  Use the entrance straight ahead of you at the end of the courtyard, passing the sculpture of the seated  famous Goettingen scholar on your left.

Exit at the Goettingen-Nord Autobahn exit, taking the feeder road (Highway 388) to and east across Hannoversche Strasse where the road becomes "An der Lutter." After two pedestrian stop lights, turn right onto the ramp and thence onto Robert-Koch-Strasse , going south in the direction of the Klinikum. At the second stop light, turn left to arrive at the Klinikum's parking lot (fee-based). Enter the Klinikum through the main entrance. The Medical Library is straight ahead about halfway through the building on the right-hand side.

Take it north in the direction of the university hospital (Klinikum). Drive past the Klinikum, following the signs to the "Universitaet-Nordbereich" beyond the Klinikum and after the overpass, turn right onto the Goldschmidtstrasse, and follow it to where it ends at Tammannnstrasse.

Before exiting the station going east, in the direction of the city center (Ausgang Richtung Zentrum), use the  display panel above the entrance to find out how long before the next bus comes and which platform it use.  Outside,  veer right (south) to the bus stops.

Follow the street (Goldschmidtstrasse) east to where it ends at Tammannnstrasse.  The building on the left side is the physics building.  The divisional library for physics is located directly across from the main entrance.

Goldschmidtstrasse bus stop.  Follow the street (Goldschmidtstrasse) east to where it ends at Tammannnstrasse.  The building on the left side is the physics building.  The divisional library for physics is located directly across from the main entrance.

Another emphasis is on conservation and restoration of photographic material. Currently the database includes more than 11,000 entries with call numbers for holdings in three co-operating libraries. Most of them record monographs and articles from more than fifty international journals that are part of Goettingen's special collection area "information, book and library science".

The Book-and-Paper database provides you with an easy to use and wide-ranging search tool. The general index allows to search for authors, title keywords, corporate body, ISBN, conference location etc., the subject heading index in German language offers subject access.

Data are automatically inserted into the order form. (For this function, JavaScript must be activated on your browser.) Otherwise, please put the name of the items you wish to purchase in the lower field by using the "cut and paste" function.

Problems and questions Output on screen from the database is currently being amended. In case certain disfunctions persist or if you have any question concerning BuP, we look forward to receiving your message.

To receive free email updates, please enter your e-mail address into the field below and confirm your choice with a click on the button. You will be directed to a welcome screen and will receive a message via e-mail. Please reply to this e-mail as outlined therein to finish the subscription process.

Goettingen State and University Library actually has subscriptions to about 860 journals of the field of history. About 150 freely accessible electronic Internet Journals are available via the History Guide.

The journal titles are searchable in the online catalogue of Goettingen State and University Library. There is a direct link to the journals contents (since 1993) via the Online-Contents-database (OLC) of the GBV. Of special interest for historians are the OLC-SSG history and contemporary history databases which are allowing free access to the contents of history journals. Copies of journal articles can be ordered online using SUB's document delivery service GAUSS as well as the GBV direct service. The copies can be delivered in digital form directly to the e-mail of the customer.

A database of 300,000 records, by far the most complete online bibliographical resource on British and Irish history, including relations with the empire and Commonwealth; an essential resource for those drawing up bibliographies in British and Irish history for any purpose from writing undergraduate essays to preparation of course syllabi and advanced research; includes books, articles in journals, articles in collective volumes, and review articles.

The IMB now comprises 300,000 articles, all of which are fully classified by date, subject and location, and provide full bibliographical records. Now online, the IMB offers an unparalleled tool for medievalists to identify the contents of current work published throughout Europe, the Americas and the Asia-Pacific region.

A comprehensive bibliography for German history. The web site offers general information about the bibliography as well as online access to the records of the last volume of the print edition. Online access to the whole database comprising until now the volumes 1991 to 1997 will be given in the future. In the meantime a CD-ROM edition can be purchased.

The Die Virtuelle Deutscha Landesbibliographie is a meta catalogue allowing parallel access to several bibliographic databases of regional german history. It is organized in cooperation of the AG Regionalbibliographie and the university library of Karlsruhe.

The Internet offers an increasing number of relevant electronic resources for historians, including e-journals, digital source collections, bibliographic databases, and electronic discussion lists (e.g. the H-NET lists).

If your search in OPAC goes beyond the case where you know a specific title and you want to look for material within a subject area or theme, you should consult our introduction in Topical Searches in OPAC for History.

The Acta Sanctorum Database contains the entire Acta Sanctorum , including all prefatory material, original texts, critical apparatus and indices. Bibliotheca Hagiographica Latina reference numbers, essential references for scholars, are also included. "

"The MLA International Bibliography is a classified listing and subject index of scholarly books and articles on modern languages, literatures, folklore, and linguistics which has been compiled by the Modern Language Association of America since 1926. The electronic version includes the Bibliography's entire print run, and currently contains just under 2 million records. In addition, the MLA Directory of Periodicals gives full information on over 7,100 journals and book series. "

"Periodicals Index Online is the new name for Periodicals Contents Index - a database of millions of article citations published in the arts, humanities and social sciences, across more than 300 years."

Each work kept has been the subject of a historical and philological examination and is accompanied by a didactical 'memento' which supplies chronological, bibliographic, critical and statistical information. All relevant Clavis Patrum Latinorum entries have been fully integrated. "

This server could not verify that you are authorized to access the document requested.  Either you supplied the wrong credentials (e.g., bad password), or your browser doesn't understand how to supply the credentials required.

The accessibility of library catalogues has much improved with the coming of Internet and the WWW. It remains however a laborious undertaking to consult several library catalogues in search of an item. Searches have to be repeated, using the proprietary web-interface of each catalogue.

As said before, the standard allows for simultaneous consultation of catalogues, a facility that previously could only be obtained by physically joining the catalogue records into one union catalogue. Most Belgian academic and research libraries now are providing their data concerning monographs to the CCB (Collectieve Catalogus van Belgi / Catalogue Collectif de Belgique) and their data concerning periodicals to Antilope. The Antilope catalogue is maintained by the library of the Antwerp University through continuous updating based on the changes reported by the participating libraries. The CCB on the contrary, is recreated almost every year by merging the complete catalogues of the participating libraries. Both databases are published on a CD-ROM called 'Union Catalogues of Belgian Research Libraries" which allows them to be consulted through one interface. In both cases it takes a lot of effort to produce the databases.

The implementation of Z39.50 is not so simple as the above paragraphs would lead to believe. If one would like one's library system to interact with another one, agreements are needed. One can reach an agreement with each library separately on a bilateral basis. This may prove to be a course that advances very slowly and might deter new libraries from implementing the protocol because there will be no guidelines.

The WG-Lib proposal for a concerted action aims at setting these guidelines by reaching a common agreement among Belgian libraries about how the Z39.50 protocol could be implemented for the benefit of all. One of the benefits could well be a virtual union catalogue, not only for consultation but also for cataloguing and resource sharing.

One of the primary tasks of WG-Lib is to initiate projects that extent the number of services that libraries can provide over the BELNET network. WG-Lib identified the implementation of Z39.50 as having great potentiality for such services.

A further step will be the possibility to consult several catalogues simultaneously. Therefor a common Z39.50 profile has to be agreed upon and/or one or more gateways to the participating catalogues may need to be created. Participating catalogues may include catalogues converted to the Z39.50 compatible ERL-platform.

Though mentioned as a last step, it is evident that linking with other information navigation and delivery services, will be paid continuous attention to and that links will be established whenever relevant and possible.

Several hundreds of links, sorted by topics (history, literature, mathematics, biology, business, law,...) and by resource types (databases, banks of images, electronic periodicals, open archives,...). The medium is mentioned in any case.

Electronic publications are deposited by the publisher and are stored in a temporary database. Accepted publications are transferred to the permanent database, where they managed by the library staff.

This service provides photographs, numeric recordings on cd-rom, digital copies, microfilms and slides of documents preserved at the Royal Library, insofar as this is not contrary to the regulations regarding preservation, protection or copyright.

The project makes provision for the introduction of digital photo libraries within the different partners to replace conventional multimedia slides. This will involve a richer and more flexible perception of the works of art. A critical mass of around 1,500 digital photographs supplied by KIK-IRPA and a further 300 supplied by the KIK-IRPA/KBR consortium is essential in order to test the system's technology as well as its educational value. However, this number will allow tests to be conducted on only one complete course subject.

With the support of the technical provider, who will be selected following the establishment of a focused set of specifications, the partners will test the mutualisation of picture digitisation within the framework of databanks that are distinctive, yet accessible from a single gateway. Above and beyond this, the partners will study the technical, educational and legal implications of multimedia use in the teaching of art history.

They will define a set of recommendations involving processes for the exchange of artistic heritage imagery, from generation through to dissemination and including database descriptions. They will also define standard metadata, adopt a technique for watermarking disseminated images and propose measures relative to the long-term conservation of integrated data and the enhancement of image delivery procedures.

KBR databanks. Lastly, the partners will determine the structure necessary in order to continue efforts on a grander scale once the project has been completed by widening the partnership to include other learning centres (university or other).

New information and communication technologies will also enable the introduction of this imagery and scientific information in order to meet the long-expressed desire of politicians to see better interpenetration between the work provided by the universities and Belgium's federal scientific establishments, whose ranks include KBR and KIK-IRPA.

Substantively, an operational module will be proposed at the end of phase one of the project for the production, classification and dissemination of images to professors at the university partners. The validity of this module and its educational implications will have been tested and evaluated on a course subject.

At the end of this initial phase, a critical report will be presented on the legal implications of this new teaching method along with recommendations for the experiment's development during phase two.

Phase two itself will be devoted to system testing and initial system applications. In addition to the images digitised by KBR and KIK-IRPA during phase one, illustrations from a different course will be digitised at each of the partner university institutions and made available to professors in the network. There are also plans to make the pilot system available to other interested institutions. At the same time, the system's multimedia bases will be presented to the students.

The ProVirlib project complements the VirLib II project. Its main purpose is to disseminate the Virlib II system in order to accelerate the electronic delivery of documents within the Belgian interlibrary lending system.

During the first phase of the project, the VirLib II system will be installed in six university libraries. Both the professional and end users will make an evaluation of the system, analyzing its technical aspects, its functionalities and its user-friendliness. The evaluation criteria will be clearly defined.

The purpose is to reach the end users as well as the information providers. The actions will focus more on awareness raising than on training, because the technology used in VirLib will make the use of the system self-evident and ease of use has been taken into account during the design of the system.

Professional associations will be set at work for most activities (organising seminars, distributing brochures, setting up infodesk at the meetings of the society...). Staff members of the professional associations will assist in organising the activities. Accordingly some professional associations of librarians and documentalists have been proposed as partners. Since they recrute their members from the wide variety of libraries, they are very well placed to identify and to reach the interested public. The project will also contact professional associations of users of information (e.g. the scientific association of Flemish general practitioners.

Demonstrations should preferably show the complete process starting from searching a document through the WWW-access to catalogues up to reading or printing the requested document on the workstation of the enduser.

Locating the title of a periodical and ordering and receiving an article can be demonstrated to end users. Demonstrations will preferably make use of materials belonging to the institution where they take place.

Administrative contacts withe the Office for Scientifique, Technical and Cultural Affairs (OSTC) (i.a. sending reports, asking for advance payments by the partners, surveys of expenses by each partner).

In case of a tie, the coordinator's vote shall be decisive. The coordinator invites the partners to the meetings and sends them, at least one week before the day of the meeting, the agenda as well as the required enclosures. The coordinator draws up the reports of the meetings.

The reports contain the names of the authors (institutions, possibly individuals). The coordinator numbers the reports in accordance with a preestablished shedule. The reports have to be validated by the management committee, unanimously or by means of a majority vs. minority vote.

The general objective of the UniCat project is to establish a gateway allowing users to simultaneously search and retrieve bibliographic records from Belgian library catalogues. As such UniCat can be considered as a virtual union catalogue of Belgian libraries. This gateway will be based on standards and protocols such as Z39.50 and OAI (Open Archives Initiative). In the project a uniform and multilingual web front-end to this gateway will be developed.

ELAG, the European Library Automation Group, brings together once a year people involved in library automation in the leading European libraries and information centres. The organization counts 450 members in 27 countries all over Europe. Last years over 100 colleagues attended the seminars.

The meetings aim at in depth discussions of particular library automation topics and at the promotion of informal exchange of ideas and experience. The topics covered are technical and meant for participants with computing background.

A number of papers are given about the main theme of the meeting, for example: "The virtual library", "Document publishing and delivery", "Object oriented approach", etc.. New automation projects in the participating institutes and countries are presented and discussed. The applications operational at the organization hosting the seminar get particular attention.

Yearly progress reports, relating on new developments, are made, before the meeting takes place, by each member-organization,are put on the Web-site of the local organiser.During the seminars time is provided for discussing these.

Also the workshops produce much enthusiasm among the participants. Here certain topics are thoroughly debated in small groups. Each time several workshops are organized on diverging subjects, as for example : "Authority data", "Navigation tools", "Quality control on the web", "Intelligent agents" and "The changing role of the librarian".

The driving force behind the seminar is the motivation of each individual participant to bring in the best of his experience and to learn from his member colleagues. One of the main benefits of the meetings are the informal contacts between the participating members.

It should give the BeZIG and WG-LIB an overview of the present state of affairs concerning the automated library management systems in use, the cataloguing practice and the Z39.50 implementation in Belgian libraries.

By probing the opinions, expectations and potential engagements of libraries regarding a co-operative action to implement the Z39.50 protocol in Belgium, the enquiry should enable BeZIG and WG-LIB to define priorities, set out a realistic course and inform and advise the existing library consultative bodies about it.

By addressing a large number of libraries and documentation centres in Belgium it will bring the existence and mission of WG-LIB to the fore and create some awareness with respect to future developments in the Belgian library landscape.

A concerted action for the implementation of Z39.50 should eventually lead to a wider availability of catalogue data. Since many Belgian libraries already aim at this wider availability by contributing their data to the union catalogues Antilope and CCB, all of these libraries have therefor been selected to receive the enquiry.

As a consequence of the above selection criteria, (BelNET institution and/or dataprovider for Antilope and CCB), public libraries have not been considered for the enquiry. This does not mean that these and other libraries will not be able to profit from the results of the concerted action. If a library, not mentioned in the list, is willing to answer the enquiry, it can obtain here the questionnaire in PDF-format.

Part 2 deals with technical issues related to the library management system (section 1), the cataloguing practice (section 2) and the Z39.50 implementation (section 3). Please follow the guidelines to fill in those parts that are relevant to your library.

In this particular summer blockbuster (Ariadne, to which I'm sure many readers frequently refer in the same paragraph as Star Wars), I'll attempt to remove some of the mystique surrounding this much-maligned standard, and illustrate some of what it can be used for".

The Z39.50 Cross Domain (XD) Attribute Set allows a client to perform simple non-domain-specific searches of a database. It is not intended for sophisticated domain-specific searches or for searches where semantic precision is required. Such searches should use domain-specific attribute sets. Cross Domain searches are semantically fuzzy.

Library of American Studies is a collection of approximately 30.000 titles in the social sciences and humanities of the United States: literary criticism, history, biography, politics, foreign relations, the arts, film, music, religion, law, gender studies, popular culture, ... and of course a large reference collection. The books are shelved by subject, in open stacks which is unique in the Royal Library and which facilitates the use substantially.

Henri Delanghe obtained his 'Licentiate' in History from the Katholieke Universiteit Leuven, a masters of International Affairs from the School of International and Public Affairs at Columbia University, and a Ph.D. in Eonomic History from the Katholieke Universiteit Leuven. He has held positions at the United Nations' Development Program, the Katholieke Universiteit Leuven and the Institute for the Promotion of Innovation Through Science and Technology in Flanders. His research is on competition, foreign direct investment and innovation in the 20th century.

Research areas and teaching interests include modernism and postmodernism, colonialism and postcolonialism, popular genres, and the relationship between literature and economics. Numerous publications on literatures in European languages.

Leuven. He teaches, among other studies, American Cultural Studies and Current U.S. issues at the Lessius Hogeschool. His main publications are in the field of English Literature, translation and interpreting studies.

Kristiaan Versluys received his Ph.D. in Comparative Literature from Harvard University in 1979 and currently teaches American literature in Ghent. His specialties, about which he has published widely, include Jewish-American literature and the literature of the American city.

Resource Center aims to serve those who, in connection with their work, need information about the United States Government's foreign and domestic policies; political and legislative developments; defense and security matters; and social issues. Within these subject areas, the Information Resource Center's experienced staff can help enquirers to develop detailed and extensive information, or assist in identifying appropriate information sources to contact in the U.S.

Researchers, government offices, members of Parliament and their staffs, journalists, and university faculty are all regular users. The office hours of the Information Resource Center are: 9 a.m to 5 p.m., Monday-Friday, excluding American and Belgian public holidays.

The answer to many enquiries received by the Information Resource Center can be found on the website of the U.S. Embassy at http://brussels.usembassy.gov/faq.html The Information Resource Center maintains a public website specialized in U.S. foreign policy issues: www.uspolicy.be.

This website is updated on a daily basis and contains major statements by U.S. public officials, the latest documents and reports as well as contributions by think tanks, ngos and other non-governmental institutions.

Fax 02/512-7046 e-mail libertjm@state.gov The Program Office promotes understanding of U.S. society and culture, and discussion between Belgians and Americans on issues of mutual interest. It organizes conferences, seminars and lectures on a wide range of issues, mostly in collaboration with Belgian academic, cultural and professional institutions. It undertakes travel programs and supports academic conferences about subject matter involving the United States at Belgian universities, university-level institutions and professional organizations. Requests for speakers can be addressed to the director of the American Center.

The Program Office runs a videoconferencing facility at the American Center. It allows the Center to organize live discussions between Belgian invitees and U.S. Government officials or non-government experts in the United States.

American Center also entertains requests for financial support of conferences, art exhibitions and festivals (among other types of initiatives). Support can only be awarded to Belgian initiatives featuring Americans or (an) aspect(s) of American culture. Requests can be addressed in writing to the Director of the American Center. As part of the grant program, the American Center awards yearly book grants to a number of Belgian university centers specializing in American Studies.

BLASA's mission is to further the pursuit of American studies in Belgium and Luxembourg. It does this by organizing lectures, study days, cultural events and regular residential academic conferences, open to BLASA members as well as to the general public.

Links to our web site are welcomed. Unless a copyright is indicated, information on the Center for American Studies (CAS) web site is in the public domain and may be copied and distributed without permission. Citation of the Center for American Studies as source of the information is appreciated.

Links to Other Sites Our Website has many links to other embassies and private organizations. When you link to another site, you are no longer on our site and are subject to the privacy policy of the new site. We are not responsible for the content of these other sites.

You may choose to provide us with personal information, as in e-mail with a comment or question. We use the information to improve our service to you or to respond to your request. Sometimes we forward your e-mail to others who may be better able to help you. Except for authorized law enforcement investigations, we do not share our e-mail with any other outside organizations.

The Center for American Studies has access to ProQuest's Academic Research Library. ARL is a collection of nearly 3.000 recent online periodicals in all academic disciplines -- half of them in full text or real image format; half of them abstracted.

The Royal Library is working on establishing a depository for electronic publications. This depository will include all belgian publications and publications from international organisations, for which the Royal Library is depository library. The catalogues of publications will be available via the Internet, but the publications will only be consulted inside the Royal Library.

The Royal Library cannot be held liable for the illegitimate use of photographic reproductions it has delivered. These photos are delivered by means of a handwritten statement or notes (reminder) of the applicant and are destined for his private use only. They can under no circumstances be reproduced without the consent of the author or his rightful claimants.

Nobody shall be allowed to resell or reproduce a photo delivered by the Royal Library without having obtained its consent. Anyone requesting a photographic print shall be obliged to comply with the applicable legal stipulations, particularly the legislation regarding copyright.

Any reproduction of a document belonging to the Royal Library is subject to copyright, regardless of the means or aids that are used (books, photomechanical, cinematographic, televised or printed reproduction, magnetic or electronic recording, digitisation, CD, CD-ROM, diskettes, audio-visual programmes etc.).

Any reproduction of a document shall have to be accompanied by the mention "Copyright Royal Library of Belgium" as well as by the exact references: author, title, place and date of publishing, book number and page or folio.

The Royal Library only delivers reproductions of documents it possesses. No photographic prints shall be made of books or documents if the Royal Library thinks their condition makes them unfit for reproduction. No negatives or negative films shall be delivered.

The VirLib project is a cooperative project between the Royal Library Albert I, the libraries of the University of Antwerp and the Universit Libre de Bruxelles and IRIS, a company specialised in digital image processing.

The purpose of the VirLib project is to develop an electronic document delivery system to be used by ILL departments in Belgian university libraries. It can be considered as an extension to the Impala system. This system is based on the concept of distributed Virlib servers used for the transmission and receipt of PDF documents through FTP or TIFF files through email.

At one side the technical networking innovations originate in a high cadence, while the old bibliographic sorrows find no relief. The emerging cooperative activities make the library profession experience that better service to the end-user can only be obtained if more standardised ways of working are applied.

Lively discussions emerged after most papers, if not spontaneous then provoked. An issue that occupied several members is, that for certain INTERNET questions there is a tendency to reinvent the wheel.

As usually part of the meeting was dedicated to the "Round table discussion". For some of the members this session offered the unique opportunity to get the information, on the systems of their interest, directly from the source i.e. from the key developers or from the key users. The ongoing success of this session is due to this open way of exchange of information and experience.

Thus another interesting ELAG meeting ended. The conclusions of this year are very similar to those of the previous years. The contents was enriching. The hosts did a maximum to please their guests. The usual attendants were happy to meet again. The newcomers were satisfied with the animated concept of the meeting. The social events, an important part of the meeting, proved to be inspiring. Berlin was exciting, sparkling of dynamism and on top of all that the weather was exceptionally nice.

A heavy program again, but the ELAG members seem to prefer well furnished meetings.This brings me to the pleasant task of expressing our thanks to all the persons who were involved in the organisation of this Library Systems Seminar. In the first place there is Heinz Habermann, who took the initiative of a meeting in Berlin. Prof. Beyersdorff from the Deutches Bibliotheks-institut and Dr.Baron from The Staatsbibliothek zu Berlin and there staff excellently planned and realized everything into all the details. It was a pleasure to be so well surrounded and to dispose of such royal and comfortable meeting places. Special thanks go to the sponsors of the social events. The evening in old Berlin offered the opportunity to incorporate in an easy way the newcomers and to better appreciate the local food and habits.

Science, Research and Culture was a good starter for more informal scientific, technical and other kind of discussions. The active participation of the numerous German colleagues has been particularly appreciated. ELAG hopes that some of them will become regular members.

War 1 named Prussian State Library, since 1914 placed in a representative neobaroque building in the capital's mainboulevard Unter den Linden, and in the first half of this century the greatest and most important general research library of Germany with about 3 million volumes and 70 000 manuscripts.

One part of the stock - books, especially rare ones, manuscripts, autographs, and bequests -was transferred to Silesia and Pomerania - after the Potsdam Conference of 1945 forming the western part of Polonia. These are either missing or they turned up in Russia and Polonia and that is, where they are until today, the most important holdings being in the Jagiellonian Library in Krakow. Its a very difficult chapter in our relations with Russian and Polonian libraries, you know, and for some years there have been very delicate negotiations on the political and the expert levels and up to the present no success whatsoever can be seen in the question of restitution.

A new building according to the plans of the well-known architect Hans Scharoun was erected in West-Berlin, near the Potsdamer Platz and the Berlin Wall, next to the old center of the city. And then - quasi overnight - the Berlin Wall came down and Germany was reunified. In the Unification Treaty it was laid down that the State Museums former Prussian State Museums -' and the German State Library should be integrated into the Prussian Cultural Heritage Foundation, their holdings being unified with the holdings of the State Library in West-Berlin.

The historical event had taken place, the hearts of the staff in the western and eastern parts of the library were full of joy and enthusiasm and eager for action. A conception for a library in two buildings was made, our board of trustees agreed with the plan and we began the task of unification of the two libraries with about 4 million volumes each and all functions of great research libraries, a gigantic task unprecedented in the history of libraries and this is a work in progress now and will be for a long time to come. In the old building of the former Prussian State Library Unter den Linden - named House 1 - there will be built up a historic research library of about 3 million volumes published before 1956, together with the unified departments of manuscripts, music and maps and the department of children's and youth's literature. The final realization is depending on the reconstruction of the building and the re-erection of the central reading room which was destroyed in World War II.

In the Scharoun Building - namend House 2 - there will be built up a general research library with the modern literature and with all facilities for information services in all fields of the humanities and social sciences,' together with the departments of middle-eastern and eastern Europe, the Oriental areas and East Asia, the departments of Newspapers and of Official Publications and the international exchange.

The State Library at Berlin is today again the biggest research library in Germany with about 9 million volumes, 900 000 maps, half a million music prints, more than 100 000 manuscripts, about 900 bequests and so on: I will not bore you with more figures. These holdings are our capital and we do our best to modernize our service but in the framework of our unification and financial problems, especially with the reconstruction of our House 1 Unter den Linden, the modernization of the library for example in the field of electronic services and network is deplorably slow: Of course we are cataloguing the monographs in the Berlin-Brandenburg Union Cataloguing System, we are cataloguing our periodicals in the National Periodicals-Database which we are producing together with the Deutsches Bibliotheksinstitut, we are making strong efforts in retrospective conversion of our pre 1985 holdings in connection with Saztec, we are running an automated lending system and a little CD-ROM-network but all these applications are isolated systems: We don't have an integrated library administration and information system and we still don't have an OPAC.

But the plans for an integrated library administration and information system are ready, the financing seems to be relatively certain, the first steps for the LAN are done and we are hoping to decide on our future system at the end of this year.

Year 1995 has to be considered as a year when automation extended from descriptive and subject cataloging department where has been mainly used since 1993 (and ten years before in an off-line form) to acquisition department at the beginning of processing and to stock management department at the end of it.

Foreign books were partly processed as a first type of document. Czech books had to wait for building of a structured network in the library and for creation of program converting data from national record structure into the Unimarc. At the end of 1995 all new acquired books have their records in the database of the integrated library automation system Aleph.

Aleph helped us to make the flow of documents through the library more rational leaving multiplicates go directly from acquisition to the stock. We have now more possibilities for tracing documents through the library.

OPAC of the National Library now contains more then 120 thousands of records. Most of them were entered for being published in the Czech national bibliography of books and therefore without holdings information important for circulation. For more then one year many people from service and other departments worked on searching shelf marks and inventory numbers in card catalogs and entering them into the database.

We expect all will be finished in the first half of 1996. We see it as a condition for introducing the Circulation modul in the fall 1996. Only on money depends whether the number of records will fast grow through adding records that result from great project of retrospective conversion of the main card catalog using scaning, OCR and taging for Unimarc structure.

National authority files are under preparation. As a base for personal names card file is used which has been scanned and each record finaly structured according to Unimarc/Authorities. Additional sources are databases contained data about regional personalities created in large regional libraries of the Czech Republic.

Because of some problems with Aleph and limited human resources there are some databases still built under CDS/ISIS. The most important of them is database maintained as a germ of the Union Catalog of CASLIN (Czech and Slovak Library Information Network), which is regulary converted into Aleph, where it is accessible for Czech, Slovak and other libraries and their users via Internet. Records from the database containing articles from Czech journals and newspapers are presented on WWW server.

The goal of this project is preservation of and access to rare manuscripts through their digitization. Our library has already co-produced 2 CD-ROMs containing old Czech manuscripts, an intensive digitization programme is starting in May, 1996.

The LINNEA network, which originally was created for the academic libraries has now grown up to a national information network. The majority of the users and dataproducers come by now outside the academic sector. This is mainly due to the new databases MANDA and ARTO (see below) but also due to an intentional change of policy: the decreasing public funding makes it necessary also for the national library to cover as much of the funding as possible with charges from the users. Below is a short list of the products and projects TKAY deals with. More information is available on our Web-server //linnea.helsinki.fi/tkay/enindex.html or directly from me (antti.soini@helsinki.fi).

Bibliotheca Baltica is a conference on libraries of the Baltic See countries. There is an initiative to create a Web-server collecting data from libraries of the member states. The National library is active in this and will probably also be the host of the home page.

The UseMarcon project as a whole aims to develop a Generic MARC Convertor that can solve the current conversion problems of MARC formats. The ultimate goal of the project is to develop a toolbox capable of converting bibliographic records from any MARC format into any other MARC format, through a central format : UNIMARC. Use of the toolbox will require no programming experience.

Founded as an instution incorporated under public law in 1978 and financed by the federal states and by the federal government its duties are: providing supraregional services for libraries, carrying out research and development in the field of librarianship Distributed at four locations, the "house No.1 of DBI has moved to an interimistic location at the river Spree site, here from 1999 on a ministry of federal government will reside.

Active participation of GBV in efforts for the interconnection of open library systems / networks (namely increased efforts and responsibility in DBV OSI II: after the interconnection of retrieval functions based on Z39.50 the project will technically integrate document ordering and delivery functions in 1996; GBV will beresponsible for the integration of Pica-based environments in this context).

As a guideline for cataloguing, the data base contains 4 million titles from the German National Bibliography and the British National Bibliography. To these, a further 2.5 million English titles from the Library of Congress will be added shortly.

At present the Music data base holds about 200.000 records relating to manuscripts and printed music from the 15th to the 19th centuries. These documents are held in more than 500 libraries and in public, private and ecclesiastical historical collections.It can be considered the main source of information for the national retrospective bibliography of printed music.

The specialized data bases include information about bio-medical and health science but eventually include information relating to grey literature and abstracts in all branches of learning. The databases have the possibility of handling a wide range of specialised subjects.

The National Sound Archive database holds records of about 7.000 items from the National Sound Archives, the S.Cecilia Academy in Rome and the Trotta Sound Archive in Perugia. The items catalogued are in the field of music, folk tradition, oral history and theatre. It can be regarded as the core of what could be in the future, with the cooperation of other record libraries, the National Union Catalogue of Sound Documents.

Lombardy, but we are downsizing it on a UNIX mainframe with Adabas/Natural. We wait for it in the next winter, togheter with a new OPAC, based on WWW concepts. The problem now is to change the old hardwares in our libraries and it will happen sooner but not before the end of Springtime 1997. We have a home page through CILEA at this address: www.cilea.it Many libraries have now the access to Internet and we are trying to set up a new virtual regional catalog connecting other libraries, even adopting different softwares like Musa of Brescia.

The system for cartographic materials (CCK) was successfully migrated from a NCR/Unix platform to DEC-Alpha/Unix platform and is now steadily available with much improved response times for the users. The migration of the financial system will be done via an upgrade for the software combined with new hardware. Completion of this activity 1996. All KB software licenses have been checked and updated in such a way that all KB-users can use the necessary software products for their work within the KB, and in addition a wider variety of products at home.

After profound preparations and an formal EC tender procedure, work has started for the implementation of a new network-infrastructure within the KB. AT&T and SINET have been selected as vendors and these two companies will replace the existing coax/lOMb Ethernet with a new Cal 5 UTP cable network for data and speech, with 10OMb capacity. The new network will solve the existing bandwidth problems. It will be ready by mid 1996. At that moment all the necessary infrastructure for other major projects is available (e.g. for AIW). Part of the 1995 activities for the new network was the development of a security-policy that will be implemented as part of the network in 1996. The security procedures are based upon organisational (procedural) and technological (fire wall) components.

With the continuing growth of the number of users the need to reduce the workload of the network manager is felt stronger and stronger. Therefore a network management system has been selected. It will be installed as part of the new network in early 1996.

Preparatory work of the selection and purchase of an automated system for the personnel Department has been completed. Final decisions will be made in 1996. The KB management information system MOSAIK has been completed. It is developed by KB because no existing products are suitable for a library environment. The MOSAIK system will be further expanded in 1996.

General Affairs a Facility Management System was selected and implemented. A lot of time and effort was devoted to the creation of a teleworking-facility with ISDN. After its first installation many technical problems occurred and only after extended problem-solving sessions with the vendor, it was possible to make the system more stable.

The first half of 1995 was devoted to investigation and preparation. Visits were paid to Deutsche Bibliothek and Bibliotheque National and together with the library research section of the KB work was done within several COBRA task groups, one of which was devoted to long term availability of electronic documents.

In June 1995 a blue print for the Dutch Depository of electronic Publications was presented at the ELAG conference in Trondheim (to be published in 'Program' soon). The second half of 1995 was devoted to the building of a prototype version of DNEP. Several working groups were created, one technical, one for networked documents, one for cataloguing format extensions and an overall steering/project group.

The most important developments in this area concerned spin-off products of Infoservices. Alexicon, the networked information service of the KB, has migrated to the WWW-environment and authoring facilities for publishing on Alexicon have been developed to assist information suppliers.

Basisclassificatie Web) is a system for the retrieval of Intemet Resources relevant to academic research. The resources are selected by subject specialists of the KB and classified according to a classification scheme, in use by all academic libraries in the Netherlands. It is planned to extend the NBW into a distributed system in which interested @ cm participants and contribute in a joint effort to disclose information on the Internet.

New efforts in this field are also the development of national and European access points for networked resources. NL-menu, the dutch home page maintained by the KB Editorial Staff of SURFnet InfoServices, aims to provide users (in the Netherlands and outside) a well-organised and structured view of the public networked information services in the Netherlands, based on registration.

After the successful completion of the building of a prototype the construction of an operational AIW started in 1995. AIW will offer the user access to a diversity of electronic resources and also gives possibilities to edit the retrieved information in a publishing environment. The system will be developed in a Netscape environment and version 1.0 will be available in April 1996. Contact: marco.deniet@konbib.nl for further information.

UseMARCON aims at the development of a generic MARC convertor that can solve the current conversion problems of MARC formats. A toolbox will be developed that is able to convert bibliographic records from any MARC format into any other MARC format, through a central format. No programming experience is required to use this toolbox. After a tender procedure Jouve has been chosen to develop the software and the first test results are quite satisfying. The final results of the project will be delivered in mid-1996.

CoBRA-METRIC will investigate the feasibility of a common format and tool for the exploitation of national bibliographic data. After an inventory of the different formats used by the partners in this project (national libraries of the Netherlands, Belgium, Germany and Sweden) a common format has been formulated. After this CAP-Volmac has been assigned to develop the necessary software. In mid-1996 the product will be ready and will be made available for other national libraries.

Pica is a non-profit library co-operative organisation founded in 1969 and providing central cataloguing, interlibrary loan and end user information services, as well as local library systems to its members and other participants.

National Library of Aruba. The contract calls for Dynix to supply all of the Dynix modules, as well as all hardware required by the Library. The library will begin by building a Cultural database using the Dynix Community Resources module.

Windows with a transparant lint between the local library system (GLIS, GeacPlus, Advance) and the national bibliographic utility in the Netherlands Pica. The GeoCat system is succesfully installed in two universities and others will follow soon.

The third edition of TechRom was released with over 1.000.000 bibliographic records from the major technical institutions in Delft and Eindhoven andthe Centre for Mathematics in Amsterdam. This CD-ROM is distributed to technical universities and other institutions all over Europe.

Stichting Bibliofoon Nederland (Dutch Bibliophone Foundation) maintaining a question-and-answer service in science and technology for the public at large. At nation-wide 06-telephone number gives access to an audiotext system (at present however limited to certain telephone districts).

Recent activities of the KB are the realization of an Advanced Information Workstation (AIW), thus creating an electronic environment for users, in which facilities for quality access and processing electronic information are integrated. As part of this activity also the local-network had upgraded.

European countries. The project aim is to integrate several library systems through the z39.50 protocol. The program is partly funded by the EU library programme. The project started in January 1995 and has a total duration of 30 months.

A few words about The Norwegian Library Bureau (AL Biblioteksentralen) since we have never been present at ELAG meetings before.The company is owned by the municipalities of Norway, and our main objective is to provide bibliographical services, books and other media and equipment to public libraries.

We run a data base, BIBBI, of books of relevance for public and school libraries. The software BIBBI is developed and owned by us. lt is a small data base, slightly more than 85 000 records and with an annual growth of 5-6 000. Entries are added very shortly after the books are published. Data is recorded at bibliographical level with subject headings and classification.Furthermore, we have a bigger data base that we use for our service of retrospective catalogue conversion, where the data from BIBBI is included as the essential part. We are the biggest, but not the only, supplier of bibliographical data to Norwegian public and school libraries. The distribution of data is very smooth: subscribers that use one particular system get the weekly file of new MARC records by electronic mail and have the data automatically installed in their system. Other subscribers can download the files of new data from our WWW-server, or they get diskettes at intervals that they choose. MARC records can also be downloaded online from the data base.

WWW-server has been operative since October 1995. We emphasize providing Norwegian libraries with the most relevant links to Internet resources including simple interfaces to the most relevant search engines, and our Web-pages are also quite extensively used.We have implemented a simple search functionality for our Web-pages based on WWWWAIS. The data base BIBBI can be searched via a WWW-interface. Two different display fortmats are provided, a full format for paying visitors and a smaller one for free. We publish a number of publications within the library field, and some smaller ones among these are to be found in our Web-pages.

Department of Journalism, Library and Information Science at Oslo College. The section is a professional centre for consultancy services in the fields of librarianship, archive and information technology.In August we moved to new offices on the main campus of Oslo College.

January 1995. A project followed up the results from "Do the library find the answer?" The aim of this was to find out why the library did not find the answer. Was it the type of personell manning the information desk, the education or the attitude of the persons in question that had to be changed.

Many institutions seem to need both specific archive keys and archive routines.BRODD defines many archive keys per year for different types of customers. We have also defined archive routines and chosen and adjusted archive systems for many customers.

The aim of most of the projects in this group have been reorganising library services.We have carried out 11 projects of this type. The customers varying from county authorities, city authorities to small special libraries. BRODD participated in the EWOS PT031 where we evaluated the use of mOSI for the library sector.

BRODD has had several projects outside the IT sector such as writing a handbook in mediating literature (fiction) in school libraries, market surveys for different services, changes in the book trade due to IT etc.

September 1995 the National Library staff members concentrate on the adoption of the USMARC bibliographic, authority control, holdings and other formats, in order to be ready for data input in this format into the new system. At the moment the format integration is being discussed and implemented.

IIn addition to the information given in the BAN's Progress Report 1995 I have to inform ELAG members on the following.On the whole the situation in regard to the library automation did not change for the best. On the contrary in some cases it even deteriorated, in some cases to mark time means to lag behind and to move back.

The first stage of the project of computerization of Botanical Institute Library which is a part of BAN ended resulting in installation of a local network with file-server and 5 workstation (PC 486s) in the library. All the equipment and some other machines and materials were bought for the money that this library earned by publishing and exibition activity in Japan based on the books from the library stock. Now the implementation of automated cataloguing system is in progress. The system employs CDS/ISIS software package and UNIMARC format, which is chosen as the basis for all local databases and main electronic catalogue of BAN.

The new software tools for production of printed outputs of the Slovak national bibliography were prepared and we managed the transition to the new format UNIMARC and ISBD rules regarding the printing of the bibliographies. This software processes the output from the ALEPH system and prepares data for the final step of processing on DTP. We also plan to produce the CD-ROM with Slovak national bibliography in the course of this year. The first sample was already prepared.

Though delayed, the second phase of installation of a new structured cabling system for our LAN enabling flexible management and development of the network for the future is being completed. It is based on DEC elements and it includes an optical backbone ring. The total costs of this innovation project providing 450 connections are about 130.000 ECU. This covers essentially the needs the SNL.

Slovak National Library also prepared and maintains its WWW server. It contains information about Matica slovenska and its components, including Slovak National Library, Slovak National Literary Museum and Archives etc., various actual information and electronic version of the journal Kniznice a informacie (Libraries and Information) as well as local information and electronic versions of local newspapers. WWW server is available at the URL: http://www.matica.sk/. We are still developing this WWW homepage as a comprehensive information server focused on the needs of our users, Slovak librarians, and on the national culture generally, providing also relevant links to other resources of the INTERNET abroad.

Ministry of culture to work out first the project of computerization of libraries controlled by the Ministry and later also the program of computerization of all Slovak libraries which should be submitted to the government. If this program is accepted by the government as a part of a state information system, it would provide financial means for libraries to do it.

COBISS which means that by the end of 1995 144 libraries were included, both active and passive participants, in the online shared cataloguing system, all of them having the possibility to use local COBISS applications. Most of the new members are public libraries that are financed by the Ministry of Culture according to the project "Programme of the automation and inclusion of public libraries in the COBISS system in 1995/96." In addition to the above, there are 64 associated members in the system with both the possibility to download the records in local applications of other vendors and to use other COBISS services.

For the majority of the new members which used other local software systems, we made retrospective conversions. The utilisation of the COBISS/OPAC system has grown considerably as well, e.g. the increase in the number of log-ons to various databases/catalogues is about 27%,in the number of searches about 66% , and in the number of displays about 61%.

They can also send new records to be introduced in the data-base REBECA. A central team, at the Ministry of Culture, is in charge of the bibliographical control of records sent by the libraries, and takes special care to the removal of duplicate records by using ad hoc developed programs.

Although the cataloguing rules, the subject indexing system and the record format used by all the State Public Libraries are the same, a common set of basic agreements and guidelines on those topics has been established between them.

The results of the project are very positive not only for the State Public Libraries connected to the Ministry of Culture, but also for the rest of them, as they receive regularly the updates of the database REBECA on streamers, so they can download and integrate bibliographic records in their catalogs.

The SGCB has initiated, in December 1995, the publication of "Correo Bibliotecario", a monthly newsletter on library topics. "Correo Bibliotecario" is the means of dissemination of information about the Internet through State Public Libraries and other Spanish public libraries.

During the last years, GUL has invested in four 3M SelfCheck systems to provide means for the readers to check out (and desensitize the security strips) their own books in four of the different libraries. The experiences of these devices vary at different libraries, but for the libraries with a large amount of their collection in open shelves and shortage of staff, more than 30 % of their lending is done with SelfChecks.

CWIS (Campus Wide Information System) project. Step one in this project is to make all important CD-ROM bases available to the researchers at their departments. Further steps include publication of other sources in electronic form, e.g. research information, dissertations, but also investigation of the possibilities to electronically publish material from the library's special collections, e.g. the women's collection (a national collection), the manuscripts and the Sound and Video collections.Since Netscape has become the de facto standard program at the university, the efforts to implement WWW interfaces to all services should be strengthened.

The library also has plans to allocate some resources to follow the development of VTLS and other library systems. Within a three year period GUL plans to conduct a non-biased evaluation of VTLS and other library systems. The buzzword for all suppliers seems to be "client-server", "Z39.50" and "data warehousing". One of the suppliers with advanced plans in using these techniques is VTLS Inc., with its new VIRTUA system.

To make a copy of the LIBRIS database(s) available for free searching via the Internet with standard Web-browsers and "forms" as the user interface. Develop an integrated information service which can handle databases and digital documents as well as references to printed material and links to external (networked) resources.

To start a gradual migration from the mainframe to a UNIX-based environment and develop transparent gateways and bridges between the "old" and "new" platforms. The final goal is to run the whole system, including cataloguing and interlibrary loan (ILL) under UNIX.

During the autumn of 1995 the LIBRIS Dept. made an inventory of search engines for step 1 of the project and contacted a lot of vendors to get details of the architecture and functions of the systems. A project plan and an application for funding was sent to a newly created foundation which will support IT development in Sweden. In January 1996 a Request for Proposal was sent to vendors which were considered to fulfill the requirements. The RFP pertained to search engine, Web server, Z39.50-server and a gateway from HTTP to Z39.50. At the moment we are evaluating the proposals and according to the project plan we intend to have a test installation running in the middle of June at the latest. The regular service is scheduled for September/October 1996. Then we will proceed to include more databases and start the second phase of the project.

The LIBRIS ILL system has proven a great success and it now handles ca. 400.000 requests a year. It is used by all kinds of libraries and it is planned to include the holdings of the major public libraries (county libraries) in the LIBRIS database. This will be the first step to expand LIBRIS into a truly national bibliographic database. The statistics module of the system is being refined at the moment. This will make it possible to monitor the ILL activities of the member libraries very closely and it will also form the basis for financial compensation and redistribution among the member libraries.

The National Archive has created a union catalogue for the holdings of the Swedish archives. The LIBRIS Dept and the National Archive has initiated a coordination project which will make it possible to exchange information about the holdings of of archivals, manuscripts, photographs, pictures, maps et al. and retrieve it in a unified way. The intention is to also to encourage the museums to take part in the coordination activities. The first step has been to exchange authority files between LIBRIS and the National Archive and the intention is to gradually merge it into a consolidated file. The exchange format will be expanded to other types of information and the cataloguing rules of the different institutions will be harmonised. The ultimate goal is to make it possible for end-users to get access to the information in a unified way.

LIBRIS databases for end-users was introduced. It has been improved and refined in two steps. It is now possible to sort hit lists and delimit searches by all kinds of material types. A new windows-based communication program, called WinLink, has also been promoted to make it easier for professional users to take advantage of the Windows functions when searching and cataloguing in LIBRIS.

CERN has a central and five satellite libraries. They are open 24 hours a day and seven days a week. The real specialization of the CERN Library is the grey literature in high energy physics and related topics. The Library has a limited collection of monographs (30 000 titles), 750 open subscriptions and near 20 000 preprints. Currently the submission, description and world-wide distribution of the preprints are completely paperless. This service is our most interesting feature.

We plan to build, around the ALEPH GUI OPAC, a series of services including: ILI, request forms, subject preselected searches and a link to the full text preprints, currently managed on a separate machine with its own search engine. At that moment the integrated library automated system will appear as a unique service to the readers joining the traditional OPAC to the full-text preprint server.

There are currently available four electronic journals, 17 more are close to becoming available. A short series of talks has been organized to discuss the impact on readers and library services of this kind of publications.CERN is also preparing, together with Elsevier, the electronic version of Physics Letters B.

The Central Library of the Swiss Federal Institute of Technology in Lausanne has outsourced to us its cataloguing tasks on the ETHICS system from 1st April 1995 onwards. The volume of their acquisitions is quite irregular within the academic year and this move allows all concerned to adapt human resources allocation to the actual amount of work required. The library still maintains a head of cataloguing, to carry out quality control and to coordinate with the REBETH network, and still indexes its documents. Similarly, a small law library belonging to a private foundation and open to lawyers and law students, in Lausanne, has outsourced to us the whole management of the library. Currently, half our activity consists in providing cataloguing and indexing to other libraries as they require.

A feasibility study on merging the retroconverted database and the main cataloguing database took place from August to November. The study identified areas in which the retroconverted data needs to be improved before merging the bases, and defined a strategy for carrying out both manual and automated corrections during the first part of 1996.

A new mission statement for UKOLN was drawn up this year. It states the objectives of UKOLN as follows: UKOLN is a national centre for support in network information management in the library and information communities. It provides awareness, research and information services and has the following goals: to promote awareness of emergent issues at technical, service and policy levels to provide a focal point for research, development, and performance measurement to influence policy makers and service providers in the interests of the communities it serves to demonstrate high-quality information services.

The staff at UKOLN are involved in achieving these objectives by their work in research, promotion and the provision of information services. In addition UKOLN is represented on a number of committees influential in policy making.

Over the last year the activities in which UKOLN has been involved have increased, and the staffing has grown in number to reflect this. At present there are eleven staff at UKOLN and recently three new posts have been advertised.

In 1995 a new research officer post was created to support research into the use of networking in public libraries. Sarah Ormes started work in this post last September. At the end of November 1995, the British Library, on behalf of the Department of National Heritage, commissioned UKOLN to carry out a survey of UK public library access to the Internet. The survey revealed that public libraries have very limited connectivity and are only able to make limited use of the facilities available on the Internet. The report (http://ukoln.bath.ac.uk/publib/licsum.html) is available on UKOLN's web pages and a printed version can also be obtained from UKOLN.UKOLN is an active participant in Project EARL, an initiative to develop a collaborative framework for providing networked information services in the public library context. An audit of information resources carried out as part of Project EARL was analysed and written up by Sarah Ormes.

ARIADNE is a parallel print and Web magazine covering Internet issues for librarians and information specialists. It describes and evaluates sources and services available on the Internet and also reports on progress and developments within the Electronic Libraries Programme. The University Library of the University of Abertay Dundee is a partner on this project. The second issue is now available.

A series of lectures is underway, entitled the Follett Lectures, with the aim of raising awareness of international developments and issues relating to the electronic library, and stimulating further discussion. Beginning in May 1994 with a paper given by Clifford Lynch of the University of California, the series has included speakers from as far afield as Australia and the United States.

Providing innovative ways to access and integrate local and remote resources for library users. OCLC not only continues to add databases to EPIC and FirstSearch, but also creates its own - NetFirst. This new file is an authoritative directory of Internet resources, with hot links to references. WebZ was introduced to maximise the potential of the Web by providing seamless access through a single WWW - based interface, not only to Web sites but other Z39.50 systems.

In some areas we may duplicate work taking place elsewhere. This will only be the case were results are not available to us when we need them. If, when such results are available and they are better than what we have developed ourselves, we will swithch to the "other" results. This will for instance be the case for MARC conversion.

All development within the project will aim at POSIX compliance. Special care will be given to produce high-quality, cost-effective and well-documented software with a wide applicability.Experiences gained in the project will lead to recommendations to define the requirements for international services and legal and financial arrangements between central organisations. Also, the project will point out requirements for further development of the standards and associated communication profiles implemented.

In the first scenario the end user has the possibility to store retrieved records directly in the local database. It may therefore be a tool for library staff as well as for the general end user.This possibility may also be available for the local system user in the third scenario.

Some servers will support SORT, some will support Item Order, some Update etc. There may not be a single server supporting all services. Even when two servers support the same service, it may not be supported the same way. This is also the case for the basic services.

Systems may change, over time, both the services they support and the content of them. The changes may come about due to user requirements or due to general development and standardisation. For the time being, however, we will have a network of servers offering different sets of services and different sets of possibilities within the services.

The software modules are developed in two versions: version 1 is a limited version supporting the basic services except EXPLAIN. version 2, or final version, has a general Protocol Machine and API which supports all servces and local origins and targets which support a subset of the services. The subsets are decided by each system owner.

ONE is now in the third phase and we are testing the first version of the software modules. So far this testing has been a mixture of interconnection testing and a limited Trial Service. Since most of the partners have implemented targets but not integrated clients, we have had to use ready-made clients (commercials and others). Nearly all the clients we have tried are Z39.50 version 2 clients. This means that it is not possible for all partners to test e.g. Scan in phase 3.

We have had difficulties in setting up clients for the ONE servers. Most clients are by default set up for US servers and the instructions for how to change this are not always good. Furthermore, in some clients it is not possible to send user-ID and password correctly. The client insists on separating them with a slash, while the server may expect a space. Also the logging facilities have turned out not to be sufficient in order to see what goes wrong. These and other similar problems have delayed the actual user testing in phase 3.

At the moment we are updating the specifications for the final version of the software based on the experiences so far. We are analysing the posibilities in EXPLAIN and are defining level of information and format of the EXPLAIN information within EXPLAIN fields and subfields.

Phase 4 will be a development phase as well as a interconnection testing phase. All software modules, final version, is planned to be ready implemented in phase 4. Phase 5 is the Trial Service phase where all users connected to the different partners' systems may use the ONE servers. Most of the servers will be available without charge, but many will require user-ID and password. Each partner will decide how and to whom of its end user it will offer the services.

Back then, David Buckle, the director of OCLC Europe, visited DBI for the first time. Both institutions discussed a multitude of projects and tried out some of them functionally. But despite the intensive efforts the different activities did not lead to a specific project. The reasons for this are validated in library politics.

The data we receive from OCLC in MARC-format contains the bibliographical data of the single articles like title, author(s), journal title, publisher, publishing place and ISSN as well as the source of the article, that means the information about volume, pages and publication year.

In the Serials database the bibliographical data of journals, periodicals, newspapers and conference proceedings can be found, together with the holdings locations of German libraries. The bibliographical data includes for example the journal title, sub- and other-titles, publisher, publication place and date and ISSN. The holdings information shows, which volumes of the journal the single library owns. The library can be identified by the supplier acronym.

The entry in the new DBI-FIRST-database combines the data of the three differing databases. Besides the information about the article taken from the OCLC-data, the number of document of the journal can be found as well as the holdings information of the German supplier libraries which both is information taken from the Serials Database. This information and the information of the article-source is checked by an algorithm to make clear, if the German supplier library owns this special volume in which the article can be found. The algorithm is the result of a study carried out at DBI.

The document-order system enables users to order the desired literature and articles directly out of the database-application and to shorten the time of getting original texts.If an article is found in DBI-FIRST it can be ordered directly at the shown supplier-libraries holding the requested volume of the journal.

Winters Tale" had it easy. If an item was in print, it was true. We at the libraries have long known that this is not so, and that an important part of disseminating information is also an evaluation of this information. Things were bad enough when print whas the sole medium, now with everyone writing and being their own publisher on the Internet, more specifically on the WWW, our job as evaluators are much worse than before - and much more important. Our job is not only collecting information but also to know something about what we are collecting, be it books or WWW sites. With this in mind it is an awesome challenge to give a 45 minute talk on Quality of Information on the Internet.

This is not a simple question. Maybe the best answer is: When the user gets what he or she needs. If the users requests examples of really useless and insignificant information - or perhaps even racist or perverse information, than for that user that is quality information even if in another context the same is example ot the thrash that should be banned and burned. The user might even be a politician looking for information in a campaign against the sordid information you can find. To that user hatred litterature is "quality" information. Actually, the criteria for quality of information on the Internet are not too different from those for ordinary litterature.

Publishers, here represented by the owners of the information servers, have just as important role here as in the world of print, pherhaps even more important. The only guarantee we users have for the accuracy of the information is the name and reputation of those who make it available. In the word of print the nature of the journal where a paper is published is an indication how serious the paper is. The publisher has an important role in evaluating the information he publishes. The editor and referees are often scorned and ridiculed, but they serve an important function. On the net several organizations have annnounced they will assume that role and vouch for the information on their servers.

This is often difficult. Often documents have no name attached to it, only some webmaster. A WWW page often gives the name of not the author or editor, but the "maintainer". WWW pages often contain hardly any information about the origin of the page. This might be becuse it is assumed the users comes from another home page with all the relevant information. But this might not be the case. The jump could be from some WWW search engine which has found the page and indexed it separately.

This is a very tricky area. For most of the information that is free on the net, no one helps us with evaluating this. Worse, kranks and outgroups of all sorts has taken to the net and set up beautiful information pages advocating their special plan of how the World can be saved in five days. I will not deny them the right to do that, but the problem is: How do this information compare to the "mainstream" of current thought (to use a better word for common sense). As an example, is quite easy for me to give some evaluation of Catholic and other Christian sources, as here I have some solid base of other information sources to compare with. I am in much deeper waters in evaluating sources of information about Islam. In evaluating Internet material, and in particular in the newsgroups discussions, one should always keep in mind that in any movement the extremists are the most active. And on the Internet, nobody knows you are a dog.

What is a document anyway? The image we get presented on the screen is not one single datafile, they are a collection of text and pictures wich are not united to a unified presentation untill they come together on the computer screen. To get the whole "document", numerous files has to bee downloaded. And the document can consist of several separate text sources combined by hyperlinks. In working on this paper I found an example - an article by Miriam Farber named "The Quality of Information on Internet." The bread article and the bibliographic information was on two different URL locations. Bibliographic information and abstract wa on http://www.earn.net/nsc94/abstracts/abst06.html, the whole article on http://www.earn.net/nsc94/papers/paper06.txt. The Altavista search engined retreived both as two seperate hits. Is this one or two documents?

In evaluating these, here are some important points: How good are the search facilities? What kind of search logic do they offer, can one use Boolean logic? Is it possible to search on phrases or proximity of terms? Is truncation possible, and can we also avoid it? Are there stop words, and do we want stopwords? One searcher's stopword can be another searcher's vital term. Some search terms requires phrase searching - consider my name for instance, Even Flood. If you are looking for information about me, you are not interested in reading about precautions in the event of flooding (I hope). Also it is not nice if the search engine has "even" as a stop word. How comprehensive are they? How many pages have the got?

But big is not nessecarily beautiful, more hits might mean more noise. In the case of diabetes, it most certainly does. So the next critical point is: How do they choose to display the results, or in other words, what are the algorithms the engine uses to determine which hits are the most relevant? When you get thousands of hits, it is important that you get to see something interesting among the first ones you see on the screen. The size of the engine's database is not everything, just a important is the quality of the papers indexed and displayed.

The AltaVista search on diabetes gave very many peripheral documents among the first ones displayed. In general - if you searching for something specific with unique search terms or many search terms, use one of the larger engines like AltaVista. But if the subject is a broad one, use one of the smaller engines that are likely to retrieve fewer, but more central documents. Or, often just as good, use one of the systematic indexes.

There is an excellent review of the two most popular search engines, Lycos and AltaVista by Tracey Stanley in the leatest "issue" of the electronic journal Ariadne. In New Scientist for 6 April 1996 there is a review of the economy and future of the search engines.

Again the important questions are: Who picks the entries and evaluates them? And how is the indexing? These are the same issues as in ordinary librarianship, and I will not bore you by going into them here.

Library-Oriented Lists and Electronic Serials, http://info.lib.uh.edu/liblists/home.htm which indexes lists and electronic publications of interest to librarians; and Directory of Scholarly Electronic Conferences - http://www.mid.net/KOVACS/ which indexes "all" lists. Or very many anyway. Of special interest are the lists Web4lib, web4lib@library.berkeley.edu and the list dedicated to quality information on the web, info-quality-l@coombs.anu.edu.au, which is brand new. The former list has a web information page at http://sunsite.berkeley.edu/Web4Lib/ where you can read all about it and also search the archives. The latter is part of a project dedicated to quality of information on the Internet, a part of the WWW virtual library project (more below). Another list, which I have not tried, is the postlist for the Infofilter discussion group, INTEVAL. It is in the Infofilter project which also reviews sites. Evaluations of sites from this project is at http://www.kcpl.lib.mo.us/infofilter.htm.

This is were everything is happening right now. It is happening fast and all at once, commercial services are coming with information, both free and paybased services. They are services that are new online, like CNN News and Encylopaedia Britannica's online service Britannica Online. And they are old services in new clothing, like OCLC Firstsearch and Knight-Ridder's ScienceBase which is a WWW based interface to several of Dialog's databases. Several publishers like Elsevier, Blackwell, Springer and Academic press are coming with traditional scholarly publications online which parallell the printed publications, giving libraries some very hard choices. Quality assessment of these services does not so much involve the content of the information. We have a better guarantee here that it is solid, as someone is actually putting their good name and reputation, not to mention their salaries, pension and children's education, behind the fact that people has to come back and keep using their services. We can depend on that they are what they claim they are.

Our quality control must instead concentrate on the following: How good is WWW as a search interface? This must be queried, both for the old established services and for the new ones. Is some cases, like the Britannica Online (BO) WWW is a very efficient tool. WWW combined with a remarkable seach engine makes the BO an excellent information service, in all meanings of the word excellent.

Somewhat, but it takes longer time. Queries that could take on or two command statements in the old search languages now takes longer, and we have to go to several screens. In general - flexibility has been sacrificed on the altar of user friendliness.

But hypertext has made possible a new search possibility. New with the WWW publications is the posibility of enhancing the databases with hypertext links between references and documents and from citation lists in one document links directly to full text of the document cited. This is a very interesting development, and here we can expect much more will happen.

Again, yes. but. The information are there as before, but it might not be as accessible. Limited searching on controlled terms and use of classification and thesaurus are issues that must concern experienced searchers.

Frankly, in several cases the Internet lines and servers are not yet (april 1996) good enough for commercial systems. The lines are slow and often the servers are overloaded. One bibliographic database service we have tried is sometimes so slow one has good time for a cup of coffe between each reference downloaded, this is of course unacceptable.

This is very touchy issue because user's interests and publisher's interests are conflicting. User wantcopies he can study at leizure and share with colleagues, the publishers want their money for use of their material. Things that were easy with traditional online services, like downloading of many references, are now made deliberitely hard in the new services. OCLC Firstsearch is an example. Also remember that a WWW document is not one file, but many files -pictures and text in different places. I already mentioned the problem of defining what constitutes a document. I will leave that one for the catalogers. WWW has made it easy to find documents and display documents, very difficult to store them.

Security and economy in using the commercial services are also of much concern, but are somewhat outside the scope of this paper. Comparison to other surces of the same information is something we have to evaluate. We can often access the same information in four ways: WWW, printed version, CD-ROM and traditional online databases with command driven systems.

I will be brief on this one, otherwise it would require several separate conferences. Just to mention a few important problems: The WWW is a new medium, only a few years old. How can we be sure the information will be there in years to come? Librarians think in periods of hundred of years. Information is our heritage to the future, librarians job has always been to preserve it and hand it over to the next generations. In the electronic world, standards changes every year or so. WWW and HTML is constantly evolving, and at the present it is branching out in different dirrections - browsers I got four months ago is now longer usable on many sites. And remember - five years ago no-one has heard about the WWW except a few programmers at Cern. Two years ago the hottest item was gopher, WWW was just an innteresting new arrival, but that was all. Where are we five years from now? Probably drowning our sorrows in hot coffe (Java). Will today's documents still be there and will we be able to access them?

Other interesting projects are the Infofile project alreaddy mentioned and the The Clearinghouse for Subject-Oriented Internet Resource Guides - http://www.mich.ulib.edu/chhome.html . Both places we find reviews of Internet sites written by (I hope) professionals who review the sites of their expertise.

Documents are made availible for which no copyright is due and for which the provider does not want to be paid. Any user can access these documents but it may still be required to collect statistical information for further analysis.

Documents are made availiable for which copyright is due and where a copyright licensing arrangement has been effected. In this case a limitation in access has to be realized so that only those users will get access to the documents which are covered by the license. Statistics have to be collected.

Steering Committee consisting of the directors of Pica and of the participating libraries. Project work is being organized and coordinated in the Project Management Group and - as far as common activities are concerned - carried out in the Working Group Services and in the Technical Working Group. The project manager responsible for progress and reporting to the General Steering Committee is provided by Pica, the person in charge of this function is F. van Bohemen. Apart from this the project includes a number of distinct sub-projects (some of them planned, one already operative).

One of the initial assumptions for WebDOC was, that with the inclusion of commercial partners the element of competition would have to be considered and that some commercial publishers would not be ready to cooperate in a fully transparent working frame that would imply sharing statistical and other data with colleague publishers. For such reasons, the cooperation with commercial publishers and service providers is organized in a number of sub-projects. In each of these subprojects, one publisher / service provider, a number of libraries active in the respective field and Pica are involved. The first of these sub-projects, which is already operative, is based on a master agreement with Wolters Kluwer Academic Publishers. Talks are on their way to prepare similar subprojects in cooperation with other academic publishers (such as Academic Press, Elsevier Science and Springer). In the framework of a general technical cooperation Pica and the Research Libraries Group (USA) collaborate in the development of an integrated information discovery and delivery service for end-users.

Bibliographical data together with the links to the electonic documents themselves will be exchanged between the two systems. Apart from that, RLG is an active partner in WebDOC since October 1995 and will establish a subset of its members as active participants in the pilot phase of WebDOC. WebDOC has been launched in February 1995 and should be mostly completed by the end of 1997. The first two phases of Technical Preparation and of Service Preparation are by now completed, experimental service will start in May 1996 and continue until the end of 1997. The main tasks currently are the loading of the local document servers and the parallel creation of the WebCAT database. The project thus still runs as scheduled even if some amendments of the time-table had to be made mainly due to the fact, that service integration proved to be far more demanding both in terms of time and effort than did technical development. From a technical point of view the basic features required for the WebDOC service by now are availiable and ready for use. A demonstration environment is accessible via http://www.pica.nl.

After conclusion of the project the partners will have to decide upon a possible regular service based on the results of WebDOC and ta king into account the experiences made during the pilot phase. Some of the major issues to be discussed at that stage are by now getting shape and I will briefly pick out four of these. This is not done in order to anticipate an internal discussion but because some of these aspects in my eyes are of interest to a broader public beyond the range of participants actively involved in the project.

Economic aspects: one question frequently avoided by libraries (at least in Germany) is whether services for localisation and access to electronic documents such as WebDOC can be maintained in a commercially oriented context and still be attractive to library end-users. Furthermore we are likely to see more and more competing services in this field and this competition will have at least an important global aspect in which European players will face US-American ones. It will thus be necessary to assess some of the project results in the light of economic considerations - the tight cooperation with RLG may be especially useful at this stage.

I could go into lenghty speculations about the future of the Web itself at this point: the governing technical metaphor of an essentially static textual relationship of information units may soon be challenged fundamentally by dynamical operations based on techniques for distributed applications - Java maybe is only the first of more challenging candidates to come. Such a process is likely to have some consequences in the WebDOC environment, too, but these are only faintly visible today ...

Personally, I do not believe that library services (or books altoge ther) will be obsolete in the near future as some people are ready to suggest nowadays. Still, there is a real danger in some fields of libraries getting pushed in a defensive position by services that - technically - can do without the mediating role of librarians. In this situation libraries have to define the fields of action where library-mediated access to information ressources will present an added value in the future. The Web - as any information cosmos - has a strong and specific tendency towards entropy. Libraries have done their best to counteract this tendency in the past and are in a good position to continue. Participation in activities like WebDOC surely is one of the most effective ways to prevent libraries from becoming mere museums. WebDOC is a good example for the way libraries might contribute substantially and specifically to the quality of electronic services.

The IETF has grown into a large open international community of network designers, operators, vendors, and researchers concerned with the evolution of the Internet protocol architecture and the smooth operation of the Internet. Technical activity on any specific topic in the IETF is addressed within working groups. All working groups are currently organised into nine areas (for example the applications area, the network management area, the user services area). Each area is led by one or more area directors, who have primary responsibility for that one area of IETF activity. These technical directors compose the Internet Engineering Steering Group (IESG).

Work in progress: mailing-listsIn order to follow work in progress, one needs to follow the discussions on the mailing lists. Each working group has ist own mailing list. Mailing lists are usually archived and made publicly available through Hypermail.

Working documents of the IETF are called Internet-drafts. These drafts have no status and have a maximum time to live of 6 months. The IETF secretariat announces and disseminates the drafts and keeps an index of them, but it does not archive them.

Let's take a closer look at the URI-working group. This working group started from the more informal BOFs atIETF meetings: get together sessions called "birds of a feather". The issue addressed was the need to develop a framework for the operation of resource discovery systems on the Internet. How should one search for, identify and locate information items?

The URI working group has been discussing the topic of Uniform Resource Names (URNs) for over three years. As of today there is no consensus on how a URN service can be implemented such that it satisfies everyone's needs. The URI working group of the IETF was only documented as a working group in the Applications area, at the IETF meeting in Stockholm in July 1995 - at that same meeting the IESG decided that the working group "completed" it original goals and that current work was too broad of scope for a single working group to ever attain consensus.

New working groups have been formed to deal with the specific items of remaining work: they are the URN- and the URC-working groups. These working groups are still working out their charter. So what are the results of the URI working group?

When embedded within a base document, a URL in its absolute form may contain a great deal of information which is already known from the context of that base document's retrieval, including the scheme, network location, and parts of the url-path. In situations where the base URL is well-defined and known to the parser (human or machine), it is useful to be able to embed URL references which inherit that context rather than re-specifying it in every instance.

The handle system has the following components: naming authorities, handle generators, the global handle server, local handle servers, caching handle servers, client software libraries, proxy servers, and administrative tools. For reasons of performance and availability, the global, local, and caching servers are implemented as distributed systems comprising many server computers. All components, except the local handle server, have been implemented and are available for general use by the research community. This year (1996) the Library of Congress is working with CNRI on a prototype repository for storing and managing digital items. The items will be given handles using the CNRI scheme for URNs.

This URN scheme supports dynamic relocation and replication of resources. Existing DNS technology is used to resolve a path into sets of equivalent URLs, and then one URL is resolved into the named resource.

This document focuses on the syntax and function of URNs, the nature of registered and unregistered naming authorities, and the relationships of URNs to an open-ended variety of resolution services that might link these objects.

This first Metadata Workshop convened 52 selected researchers and professionals from librarianship, computer science, text encoding, and related areas, to advance the state of the art in the development of resource description (or metadata) records for networked electronic information objects. An effort was made to define a core of resource description elements. These core elements have been defined to apply for document like objects (DLOs) and for the purposes of resource discovery on the Internet.

At the second Metadata Workshop held in Warwick, UK, in April this year (1996) some deployment strategies were discussed. It was generally felt that the Dublin Core is especially well suited for authors and publishers to supply metadata and that encoded in HTML-tags it would provide the means for self-description on the Web. This would in turn facilitate machine indexing of Web-documents by the established search engines on the net. A syntax and guidelines are being developed to make it possible for authors to actually use the core elements in HTML-documents.For more sophisticated usage of metadata, for special collections for example, the core elements should be extensible to suit local conditions. At the workshop the 'Warwick Framework' was defined to provide a carrier architecture for description packages - each package being separatly encryptable, individually extractable, and providing general (Dublin Core package) and specific information on the resource: subject information, terms and conditions for access, archival information, etc.

ROADS is an eLib funded project to implement software for resource organisation and discovery in subject-based services. It is one of the many projects in the UK Electronic Libraries Programme which is working over the next few years to improve availability and access to electronic resources for the higher education sector. I am working as a Research Officer for the project, specialising in metadata, and I am based at UKOLN at the University of Bath. In this presentation I intend to give a brief review of the ROADS project concentrating on the choice of metadata format and our experience in using that format.

Other UK services using similar metadata option to ROADS are the NetEc service providing access to working papers in economics, and the IPCA International Parallel Computing Archive covering documents and software related to high performance computing.

A number of options exist for metadata each with their own strengths. Different metadata formats have been developed to meet the special requirements of different constituencies e.g. USMARC, TEI (Text Encoding Initiative) independent headers, URCs (Uniform Resource Characteristics)and IAFA/whois++ templates. There are other metadata formats which are also in use in specific contexts e.g. the US GILS and the Harvest SOIF formats. Each of these metadata formats differ markedly in their syntax, rules for formulation of content and compatibility with existing protocols. They also differ in their level of deployment for description of internet resources. Work has been progressing on identifying and deploying a core set of data elements, the Dublin Core. The recent OCLC/UKOLN Warwick Metadata Workshop has made proposals for using the Dublin Core for 'self-description' of resources by information providers and as a basis for semantic interoperability.

The choice of standards for ROADS was based on the criteria of simplicity and availability to allow for speedy start-up of the subject services. To this end we chose to use a simple attribute:value record structure for the metadata, based on the IAFA template definition.

This format is outlined in the 1995 Internet Draft 'Publishing information on the internet with anonymous FTP' which, although it has expired as an internet draft, is available from the Internet Engineering Task Force archives <URL:http://info.webcrawler.com/mak/projects/iafa/iafa.txt>. The format has been adapted for use with the whois++ protocol by Bunyip, and a revised definition is available from Bunyip <URL: http://services.bunyip.com:7001/products/digger/help/templates.html> . This format was chosen as it is mid-way between the complex formality of MARC national formats and the more arbitrary structure of a proprietary record. An advantage of the IAFA templates is that they were designed for our intended purpose i.e. as a description type for internet resources. They do not contain redundant features only necessary for the description of hard copy resources. The eLib subject services have found this format suitable for use by contributors from varied backgrounds with minimal training.Since the start of the project the IAFA template structure has been amended to allow for compatibility with the whois++ directory service software, the most relevant change is the linking of related attribute values by the ordering of attributes rather than the use of version numbers.

The whois++ directory service protocol was chosen for the search and retrieval of records. This is a lightweight protocol to implement, designed for compatibility with the IAFA/ whois++ template. It also offers possibilities for use of ROADS in other contexts (e.g. research registers, project directories).

A later version of ROADS will pilot implementation of the common indexing protocol (CIP) to allow for a distributed system of shared indexing. This would enable 'summaries' (or centroids) of the full subject service indexes to be collected on servers forming a whois++ mesh. Searches not satisfied by the individual subject services could optionally be referred onwards on the mesh.

Our initial experience of deployment of the IAFA/whois++ template has allowed us to collect statistical information on the frequency of use of both template types and attributes. We hope this will provide useful feedback for the development of the whois++ template structure.Within the IAFA draft a number of template types were defined. The different template types contain attributes particularly relevant for the description of the differing sorts of internet resource.Following is a summary of template types relevant to ROADS.

Use of the templates by the subject services reflects the level of granularity and aggregation at which they are indexing. The subject services have tended to identify high quality resource providers at an organizational level and the majority of descriptions are of servers rather than the detailed content. The record creators are using the service template type to distinguish these document collections from individual documents, for which the document template type would be used.Other related services such as IPCA, NetEc and ALIWEB have a majority of document template types as they tend to index at a lower level of granularity, describing individual papers and reports. IPCA and ALIWEB also show a greater spread of template types e.g. software, organization clusters, user clusters, siteinfo and datasets.

In order to deal with the proliferation of titles on web pages an additional attribute has been created for alternative titles.  addition of administrative attributes In practice there has been a need for more administrative data to be held in records e.g. record created date, date for record review, record creator.

As use of the whois++ becomes more widespread it is important to continue the work defining and documenting the template structure. At present our commercial associate partner, Bunyip, are making a significant contribution in this area.

As part of the move towards standardisation of the template, it is necessary to agree a control procedure for extensions to the attribute set. In order to promote interoperability unnecessary proliferation of attributes should be discouraged.

Investigation and implementation of the use of summary indexes or centroids is included in the project plan, and ROADS v2 due for release in early 1997 will include the results of this work. Summary indexes (or centroids) held by index servers will enable referral of searches through a whois++ mesh.

The emphasis of the project lies on the establishment of an electronic chain starting with online searching in a mulitude of databases and proceeding to online ordering and electronic document delivery. And these services should be integrated into the local user interface.

The systems involved in the project (Union Catalogue Systems, National Service Centres and Information Retrieval Systems) have got a standardized Z39.50- interface that enables the users of each system to access each of the other systems, actually through their familiar user interface. They can use a intersection of the search possibilities of the own and of the remote systems; i.e., the access to a remote system goes off transparently for the user.The project scope did not include the development of a new user interface on a standalone Z39.50-client. Such a client was considered difficult to specify and expensive to develop. Today there exist various Z39.50-clients for different platforms that can be used for an independant access to the systems that already have the Z39.50 interface. The project in the essence equipped the systems involved with a Z39.50 interface both for target and origin function that today and in future will belong to the standard functionality of a library or information retrieval system.

First we have to have in mind the involved systems and the general approach of the project. We have two classes of systems among the partners: the information retrieval centres and the bibliographic database systems.

Bibliographic database systems normally have less powerful search engines. But on the other hand their data are deeply structured and indexed according to complex cataloguing rules and thus can be retrieved very precisely.

Please note: The general approach of the project is to use the command syntax and the features of the local search engine interface for searching the remote databases. Thus the user can apply his client expertise to the remote databases instead of using another user interface. This approach goes back to the original intention of the Search and Retrieve protocol standardisation efforts in the eighties to interconnect bibliographic database systems. There was little or no idea of client-server concepts and there was no idea of the Internet. Today a high percentage of the needs of non-professional users may be covered by Z39.50-clients or by WEB-pages mapped to Z39.50-clients. The most common search fields are supported, often combined with boolean operators. Some Z39.50-clients also support the request and display of MARC-format records. Today, if you already have a Z39.50 interface for your database a custom Z39.50 client may even serve as research client for both remote and your database for public access in your library.

In this case the target is correct but not smart rejecting a query because the title index is a word index and no phrase index. The query has to be analysed and cannot be mapped simply to the title index.

When your Client is poor If you got a client that does not support a functionality you need to make benefit of server functionality you will probably replace it by another. If the client is the one you use with your local system and you do not want to replace it you may have to enhance it by adding functionality.

Example: Your own server does not support thesaurus functionality, you cannot make use of a structured hierarchy of terms. But another system might well support thesaurus functionality and your users might want to use it (and they probably have been using it on the CDROM or another customized client for that server).

By the time you might get aware of restrictions of your server compared with others in the eyes of remote users. Also servers may be enhanced by new functionalities. But this is likely the less probable solution of all discussed. Server enhancements are complex and expensive and will merely depend on market pressure. In the scope of DBV-OSI II project server enhancements were definetly not intended.

Z39.50 standard is still evolving. The very productive Z39.50 Implementors Group (ZIG) is an open forum and meets quarterly. The ZIG encourages every interested party to join them and to contribute to the discussions and the work on the standard.The new powerful record syntax Generic Record Syntax (GRS) enables to adress single record elements and to negotiate the format of that element for best display and layout purposes.

Z39.50 is the protocol of choice for information retrieval. The protocol provides a standard interface to the heterogeneous world of database systems. But the protocol cannot achieve miracles. If a server is poorer than yours in functionality no standard in the world can help to make this server better.The Z39.50 protocol cannot even out differences beteween servers either when these differences are found on the level of basic understanding of certain features.

The EXPLAIN service will be valuable to find out detailed information to configure the client and to support users with on-line help. The more up-to-date, reliable, detailed the EXPLAIN information will be the better for the clients and for the servers. Because the quality of servers will be measured by the quality of their EXPLAIN database.

In spite of these traditions and political goals, politicians have been discussing the problem of charging for library services not only in the past few years. An analysis of the development in the past twenty years shows that there were more or less two reasons for discussing the changes. Very often people in politics and administration have called for charging fees for library services in times of severe economic or budget problems. These fees would have the purpose of improving the income of the respective community. Sometimes other reasons were stated, for example in order to build up a barrier against over-extensive use or to create better cost-awareness.

The discussion about costs and fees in German libraries has gone through three phases. The first phase began in the midst of the eighties when an economic crisis created budge tary problems in a large number of German communities and large cities. Due to the lack of library acts, communities are not forced to create efficient library services. In consequence, many of them reduced the budgets of their libraries, closed branch libraries and stopped building new libraries.

The discussion in the second phase focused on university libraries, regional library centres and the German Libraries Institute. This happened during a process of building the two national or supra-regional databases (one for journals and the other one for monographs). These union catalogues consist of data put in by all the co-operating libraries and can be used for cataloguing and interlibrary loan. Nearly all of these libraries fall under the responsibility of the 16 Federal States of Germany. Some of them had the idea of being paid for their input by the financing bodies of the supra-regional databases. These databases, as a consequence, would have been forced to charge for the use even by the contributors. The cause for ideas like this was, once again, the introduction of new technology and the need for high investments.

Libraries are operating in co-operation within a very sophisticated supra-regional information network. There is the danger that even by changing only a part of the present structure, results may be achieved which nobody had expected and which nobody wants in that form.

Charging for input and output of co-operatively built-up databases means shifting money from one pocket of the civil service into another one without any effect on the pub lic income in general. Accounting administration costs a lot of money. This sum might even be higher than the additional income (if there is any).

How can it be achieved that the comfortable and fast service aimed at, is not used too much because of its comfort and promptness, so that the available resources no longer suffice for all the tasks to be carried out?

The issue of fees and the amounts to be paid is therefore a central question of the whole SUBITO initiative. After the decision on payment of fees and the amount to be paid, it must be decided who is to be the debtor of the fees and whether subsidies of the fees are to be introduced, if it is intended to enable certain user groups to avail themselves of SUBITO services appropriately in spite of financial difficulties.

The first group pays a fee calculated according to the costs which may not necessarily cover the total costs. When calculating the fees, the offer of competitive institutions must also be taken into account and there should in no case be a prohibitive effect.

Indexing of the contents in the regional and supra-regional reference lists can be misleading. Therefore, it can happen that essays seem suitable according to their title, but it later turns out that they deal with quite a different subject than that required.

In both cases, charging a nominal fee would only lead to a quantitative reduction of interlending orders without improvement in meeting the needs of the users. Unnecessary interlending orders could only be avoided with speedier handling, greater insurance of delivery as well as better indexing of the records.Those fields in which , besides the described cases, unnecessary i.e. misuse of interlending can happen are so small that the effect of fees as a nominal charge can be neglected.

It does not matter whether the market price, a political price or a nominal charge is to be the guideline for calculating the fees: in every case precise information about the costs of the present ordering system as well as about the costs of the SUBITO services are essential.

Inspite of the time delay and the work load involved for the libraries to be questioned and the evaluating panel we decided to carry out an empiric costing survey. Ms Samlenski will continue now on this.

DBI was pleased to take on this study. For many libraries, interlibrary-loan processes present a task which is work and cost intensive. In spite of this, there was no unifying vision or even nationally recognized research results regarding the amount of costs accrued in processing an interlibrary loan order.

Within this comprehensive study, it was also important to us (DBI), in addition to sheer cost analysis, to work out the essential factors causing ILL-costs to rise and how they could be reduced. More and more, in light of large budget cuts libraries in Germany find themselves having to manage a range of services which has either remained the same or has become even larger with fewer staff and shrinking funds. Therefore, knowledge of the factors influencing costs is indispensible in order to be able to implement all resources in the most rational manner and to introduce rationalisation measures where needed.

In selecting the libraries for study, it was important to obtain a representative cross-section of numerous scientific libraries relevant for interlibrary-loan with their varying technical and organisational solutions for processing ILL orders. Therefore, the twelve scientific libraries from both the old and the new German federal states were selected according to their type, organization (a central library with subordinate branches or a central library and independent branch libraries) subject-specialization (natural or human sciences collections) loan load, technical equipment etc (see Fig. 1.).

The evaluation of the data provided for calculation was conducted in the 12 participating 12 libraries with considerable effort and great attention to detail. In each case, all staff members wrote detailed accounts of time spent on specific loan activities over a period of 10 consecutive working days.

The libraries were provided with documentation screens drafted by DBI and explained in full detail before beginning the study. These documentation screens contain all work processes necessary for interlibrary-loan divided up into their simplest steps.

As the steps for processing an ILL order can vary from library to library, the documentation screen was given in modular form. In this way, each library was able to select the work steps applicable for them. At the same time, the modular structure made it possible not only to calculate the total costs but the costs of each individual or series of steps and to compare those of the individual libraries as well. Each library made exact records of the amount of time spent by staff, sorted according to the various salary groups, as well as of the material consumed and technical equipment necessary for each order.

The evaluation of the resulting data and the average cost of carrying out loan requests in each of the 12 libraries was conducted at DBI. In each case, the personnel costs were calculated and the non-personnel costs (paper, microfiche), costs for technical equipment (office equipment, hard- and software) and overhead costs (department heads, secretarial offices, staff administration) were then added.

Standard values were used where individual costs would have made the comparision overly complicated. This is the case for salaries and wages, for current costs of computers, copy-machines and other technical equipment as well as for overhead costs.

In this way the costs were calculated accrued in the delivery library for fulfilling a request for a monograph or a copy and for processing an order, which cannot be fulfilled. Using these results as a guideline, the costs accrued in the ordering library were then calculated.

In addition to these figures, the results of our study provide information about cost types, where they occur and who must bear them. Furthermore, they revealed the relation of total costs to personnel, non-personnel, investments and overhead costs.

Results show that the costs incurred in the individual libraries are not as variable as could have been assumed considering the differing working conditions and processes. But Prof. Beyersdorff will continue on this point.

ILL-order in one library. In those cases where the loan order is passed on through two or three libraries the costs of all libraries involved in processing this order must also be added (those of the delivering libraries and those of the ordering library) in order to arrive at the total costs (see Figs. 3 and 4 ).Costs for copies are regularly lower than those for the delivery of monographs. Here you need add itional time for bibliographic search and for loan procedures.

Costs for the active interlibrary loan are lower than those for the passive one. This is the case especially in those libraries with very low costs for the delivery procedures. The reason is that these libraries are responsible for certain fields of subjects, for example the entire field of applied sciences, economics or medicine. They try to locate the documents by all means available and, as a result, the costs for bibliographic searches are very high.

The more orders are processed, the lower the costs are per order. The reason for this phenomenon is the better relation of fixed costs to the number of orders. In addition, libraries with a large number of orders to be processed are forced to introduce good organisation and optimise work flow.

On-line catalogues are minimising the costs of bibliographic searches. Where there is a lack of these instruments you find very high personnel costs, because you need professional people with a relatively high income.

Computerised administration not only in the process of searching, but in the whole business (i.e. loan procedures, statistics, accounting) is necessary to reduce the costs of the whole process. Concentration of holdings relevant for interlibrary loan is important. Otherwise high costs for searching and transport will arise.

Electronic services are paid by both the libraries (or the financial bodies which are responsible for them) and by the user. The relation between the two has been calculated on the basis of an exact cost analysis.

In FP3, there are 51 shared cost projects; 3 Concerted Actions (ie platforms or groupings set up to address common interests or problems), 5 feasibility projects in the area of improving international record exchange, and numerous studies - the list is already becoming long. Added to this is now 15 new projects out of the first Call for FP4 plus 7 concerted actions/accompanying measures. There are a range of sources of further information. For projects, these include two volumes of synopses for FP3 and FP4 projects respectively. There is also a range of studies dealing with background technical topics. They are published by the Official Office of Publications as EUR reports, in the collection Libraries and the Information Society. The technologies covered include: chipcards; neural networks; performance measurement toolbox; and technical studies for systems librarians, dealing with SR over X.400, client-server, and DFR v Internet tools. Other recent work covers open distance learing, knowledge models for networked library services, deposit collections of electronic publications, and new models of national bibliographical services.

In all these areas, there are projects and results which are contributing to the development of better quality library services in a European context. This was a start-up programme, which had as its objective the need to start change and begin a process that would be fully exploited later. We wanted a wide spread of actions involving as many libraries, types of library, sizes of library, and other partners as possible. The results are accordingly somewhat fragmented - the programme worked not to a top-down master plan, but relied on a bottom up approach of grass roots initiatives. Only now are we beginning to be in a position to analyse the results, to assess which are the key building blocks and components for the future. This is also an applied research programme - one of the goals is to test and evaluate, to experiment as a basis for future operational service development. Given the spread of activities and projects, the following is a very subjective view of significant developments.Of the electronic services that have been developed electronic document delivery is the most common. The projects here have ranged from using advanced networking technologies (eg, the relay between different document delivery networks developed in the EDIL project) to those testing new methods of organisation and service as much as the new technologies, eg AIDA. The service models vary from those that are fully electronic to those where access to the information and placing the request is electronic but where delivery may be made by more traditional means, such as an interlibrary loan. Gradually, over the programme, there have been more document delivery projects which are integrating access to information in text, digital and image form. One thing they have in common: they are trans-European. Even if, in some cases, there was a focus on setting up national or regional links, an important aspect was also the development of connections between these and replicated services in partner countries.

The next service area that is important is that of electronic publishing and of investigating new methods of interaction between source suppliers (publishers) and libraries (and their users). Three projects - DECOMATE, COPINET and ELSA involve publishers. One project (ELSA) is taking many of the electronic journals projects further by mounting the full-text in SGML and investigating the user-interface and service issues. The others are testing particularly usage, copyright and charging issues.

Obviously in this area, these issues are critical if services are to evolve that are satisfactory to users and that are sustainable. Copyright is a potentially crippling barrier to the effective development of electronic services; however, the library community itself can only wield limited influence in legislative areas. What can be done - and is being done through projects and concertation - is to open dialogue with the publishers, to take a pragmatic approach towards developing and testing solutions in partnership.

However, they are particularly important in a European context. Projects do not have to be large to be significant: the project CHASE is developing conversion tools so that national bibliographic data can be exchanged using UNICODE. Another small project - HELEN- has developed software that transliterates from latin to Greek alphabets and vice versa. It has allowed one of the partners to integrate the software in its OPAC, which has both a Greek and a latin language alphabet, so that both can be remotely interrogated from latin alphabet terminals. The core software is, however, written in such a way that it could be used as a basis for other transliteration pairs.

It is perhaps useful at this point to recall the structure of the current libraries programme. If the first workprogramme under FP3 focused first on applying new technology cost-effectively to the resources and functions of traditional library services, the second workprogramme targets the networked library infrastructure in Europe, including both libraries and their natural partners in the information chain, as well as initiating 'outreach' actions to the networked information world. This continues the goals originally set for the libraries actions, which are essentially long-term and are based on mobilising change and on developing a sustainable infrastructure and viable roles for libraries in the information age. So far we have catalysed and now we need to consolidate to create the real European-wide platform for modern, electronic library services.

Keywords are integration and extension.The programme has 3 Action Lines, represented by a model of three concentric circles, with the library at the centre. The inner ring is the library in its local context, typically the library in relation to other campus services of the university for academic libraries, or the library in relation to other community/local government services. The second ring is the most important focusing on the world of libraries and on the relationship between libraries and their traditional suppliers of materials. The third and outer layer is the library in the context of the networked information world. The focus is on service and on networking. The rings are defined in a sense by the relationships between the library and other players rather than by the technologies, or even by the services. This means that it is not always easy to be unambiguous about where things fit in the programme. It also means that there are issues which are relevant throughout the programme - most prominently, user access and end-user interfaces; authentication of user and of materials and resources; integration of information and documents from different sources; usability. Certain technologies also appear throughout with WWW, Z39.50 being the most common.

ELAG meeting, there are a number of issues relevant to service quality to which the programme is hospitable. The first underpins Action Line C, where what is aimed at is the development by the library of value-added services to their users. Libraries can supply information about quality of resources, can mediate between their users and the networked information available, can develop services which both catalogue and prioritise resources, and can then re-package, re-integrate or customise the information and documents retrieved to make them either more usable by the person requesting the information or to make them usable by a larger number. There is scope for libraries to act in partnership with other organisations in the networked information world. Background to this Action Line is provided by one of the studies mentioned earlier, namely the knowledge models one which presents a model of how the library can provide access to the plethora of resources for their users and how to represent the resources and the choices available.

If Action Line C is looking at electronic services in their broadest sense, the other action lines are dealing with electronic libraries. In Action Line A, one of the issues is how to integrate into library collections electronic documents and materials - whether these are digitised by the library or bought in. There are major questions of how to manage these, both as a collection (as a store or archive) or as individual documents. This is likely to lead to new organisational models for libraries and to reengineering traditional library tasks and revisions of library workflow. Not to be forgotten is how to maintain the longer-term access and availability of electronic information. In Action Line B, we are trying to stimulate new models of distributed library services - work still needs to be done on technologies capable of supporting these, but more importantly also on the service and organisational models that will be needed between libraries if the services are to be consistent and coherently presented to the user. This Action Line is also tackling the question of authentication of publications and of data.

FP4 actions, here is a selective list of four which will to some extent be tackling issues pertinent to quality of information/data and of service. TOLIMAC is developing a new access and management interface, based on chipcard technology for the delivery of library, campus-based, inter-library and networked services to academic library users. BIBLINK is looking to develop an electronic CIP system - but an enhanced one, which will see publishers submitting an agreed subset of the publication and the national agency returning bibliographic and other necessary document description data for issuing with the publication. It is also going to look at whether/how authentication can be added to the service. The bibliographic information will also be added to the national bibliography which in itself will lend a degree of verification/authenticity to the document. Similar ideas have resulted from the deposit collections study, which sees bibliographic control and authentic identification (and location) of works (including recognition of authorship) as a key contribution to be made by national libraries. DELICAT will develop a prototype system for quality control of bibliographic records exchanged over networks. CAMILE is a concerted action, which will raise awareness of the quality management and perfomance measurement issues being addressed in the current projects.

These are only selected specific examples from the range of projects which in their various ways are all providing tools or test-beds of library services delivered electronically. They contribute, through example, to the necessary experience needed to develop and promote quality-based library services.

I propose to expand the subject to discuss all aspects of Internet search services: the harvesting, indexing, retrieval, user interface, the libraries' participation and cooperation regarding the development of search services and their possible support to enduser searching. The problem of cataloguing, describing the content of Internet records resp. Providing metainformation shouldn't be in the focus of this workshop.

Could mobile code, Java applets and similar developments be used for an improvement of the search services, for the capacity-saving presentation of results, for intensive afterprocessing on the local computer or for improved user support and education? Which other applications are worthwhile?

During this workshop I propose we identify quality criteria for indexing services on the Internet. Existing indexing services exhibit still so many flows and bad behaviour that we can learn from them in a very pragmatical fashion. By using these services we can list which features need improvement, which features are missing, and which are well developed.If we could formulate quality criteria (consistency, predictability, stability etc) which are most relevant for each of the features that we identify we could end up with a quality control guide for indexing services.

We then considered possible criteria for analysing search services. If criteria are established then search services could be evaluated against these criteria. Lack of readily available information about individual search services was immediately identified as a problem area. Fortunately we were able to benefit from work done by Traugott and Angela at Lund, and we examined an analytical form which has been used to gather information about a number of search services. Angela demonstrated the Opentext service showing how the categories outlined in the form can be used to evaluate this search service. For any search service areas of interest would come under the broad headings of: provision of general information, harvesting techniques, indexing policy, retrieval process, user interface and documentation.

By its very nature librarians record the information about publications using text. An alphabet is used to represent elements of the particular language.Textual form of storing and displaying bibliographical information prevails till date. The very first library systems used simple, yet powerful cataloguing system: a hand-written book. This method evolved into a classical manual card catalogue. Initially, served as a universal language of the well educated. Most of the early "library catalogues" are written in Latin. Today national languages are used for cataloguing. The advent of computer technology allowed much faster access to a catalogue stored in the electronic form. However computers were not good (and still are not) at handling text especially in languages different from English. The basic computer alphabet the ASCII (or ISO 646) represents only 127 symbols - mainly Latin. The simplest approach to coding of non English languages like, for instance, Cyrillic is romanisation. Romanisation uses alphabet from one language to represent the other. Librarians very often use romanisation to store bibliographical data. It is worth pointing out that romanisation, in the global sense, may introduce further complication.

Format for Authority Data allow the defintion of a set of different entries that can be searched for. In the majority of existing system the authority records are filled in mainly with data from one cultural/language region. Seldomly one can find authority data which includes multilingual entries. This limited scope of data is entirely due to a focusing of library efforts on a local (in a geographical sense) user.

The next stage of the software evolution was the introduction of localized software. By the term localization we understand the process of adapting software to a particular language. By the very definition localized software is intended to be used on a limited geographical area mainly one nation. The best examples of localized software are text editors. The main difficulty in software localization is on the one hand internal coding of the alphabet and on the other the visual representation of particular characters. Several mechanism have been designed to allow coding of languages other than English and yet allow backward compatibility with ASCII. ISO 2022 uses escape sequences to code characters, others like ISO 8859 use code page switching. The code page switching is used within Windows and most to-date WWW browsers. Coding systems like ALA IS06937/2 are often used to store bibliographical data. The main limitation of localized software is the inability to simultaneously processing of multilingual data within one document (either formatted or not). This is mainly due to the internal structure of the existing operating systems and computer hardware.

The Intemet brakes all national barriers. Neither pure ASCII nor localized software is suitable for the global village. Globalized software should allow the use of many languages within the same document. Electronic libraries can be accessed from any place in the World.Certain systems allow the user to initiate a global search. Even though, the user would prefer to use its mother tongue to process it. One can find many examples of bibliographical data where words from different languages are freely intermixed. Human reader quite easily recognizes the difference between say English and German words. Automated systems do not possess such a capability. The same word written in different languages may represent completely different entities e.g.

The same word stripped off diacritic and read by a Czech user would be interpreted as love.All leads to the conclusion that for the sake of saving the semantics, data (formatted and/or unformatted) should carry the additional information not only about fonts but also about languages. The similar problem is presented to the user who accesses the system through a voice channel (e.g. blind user). From the "dumb voice synthesizer" point of view a letter 'o' with acute accent which presently is coded in the same way in Spanish and Polish is spoken quite differently in both languages.

Unfortunately software houses cannot agree on one universal format of font data. Recently Adobe Systerns, Apple and Netscape Communications announced the introduction of a new font standard. ln the same time Microsoft will press for its own forrnat. Such a situation in a longer time will further complicate the already messy situation.

The Z3950 represents one attempt to globalize at least the format of information exchange between different systems. Many of well known automated library and information retrieval systems have their Z3950 interfaces under development. The situation is not that simple in former COMECON countries. As an example only in Poland there exist at least 10 different mappings of Polish diacritical letters onto extended ASCII set. There seems to be a great need for further unification.

The multilingual nature of the Internet requires the introduction of new mechanisms of handling the information in different languages. Software localization does not seem to be the right solution. The main feature of globalized software seems to be the ability of automatic or semi automatic adjustment to different languages.It is fair to state that the existing systems, standards and mechanisms already have some features of globalized approach. In particular there exist a universal alphabet: Unicode. There also exist a standard for data interchange protocol: Z3950 and many library systems have authority support. Most of the available client software feature total inability to successfully combine all this characteristics into a successful multilingual workstation. Unfortunately local user point of view still dominates among both software producers, librarians, and end users.

The protocol can handle the fact that an index does not exist, but when several fields are indexed in the same index. The result set may get a very low recall. Even when an index only contains data from one field the search result may not be what the user had anticipated. If for instance the search for "title = little prince" retrieves all records where the words "little" and "prince" occurs in the title field, the noice may be severe.How can the search result be improved when this is the case?

There are many different types of databases connected in a network. Some may be general, some covering a very special field. The result of retrieval by subject may be very different from different databases due to differencies in classification or indexing.How can the search result be improved when this is the case?

The z39.50 protocol has become a very extensive application protocol covering many services and many facilities in the Search service. If a search method can not be used in the network, the search result may not be good.Are there search methods or search criteria exising in operational systems that are not covered in the protocol? If so, which are they?

When the user is searching a system he/she does not know, many factors will influence the biased judgement of the quality of the search result, whether this is measured as high recall or high precision.

There will be many different implementations of the protocol. Implementors' Agreements will be defined in order to help interoperability. But will this be enough to ensure high recall and precision? The EXPLAIN service contains many possibilities for describing the remote systems/databases. When EXPLAIN is implemented it will hopefully increase the quality of search results.Which features of EXPLAIN are most important for this task?

Above is described some factors which may influence the precision and recall of a search result and which will cause the user to experience the search result as of high or low quality.Which other factors are important for the recall/precision/quality of the search result?

The group started by identifying the factors which influence precission and recall in a network. One concentrated on factors in addition to the ones that influence the search results in local systems. The group emphazised that the remote server should behave "as the local server" to the end user. Then the group discussed how to improve precission and recall in a network environment.

Even the libraries that use the same cataloguing rules have developed different practice which leeds to differencies in the catalogue records. This causes records not to be found in a search even if they are present in the database.

Connected to the use of cataloguing rules is the choice of headings and uniform titles. At least uniform titles are usually chosen in the native language which may reduce recall in a network environment.

It was discussed whether electronic publishing would make cataloguing rules superfluous or even obsolete. Or whether at least electronic publishing could bridge different cataloguing rules. By using the electronic form of a document in cataloguing we may capture the pure descriptive information, but not all the "added on" or value-added information. This type of information will still be problematic in network environments.

Each country has at least one biblographic format. Most countries have a national MARC format. Within IFLA one has agreed to exchange bibliographic data internationally in UNIMARC format. But few systems today, except the national libraries, are able to produce UNIMARC records. If the client and the server system are not able to use a common format, the records in the search result set can not be presented to the end user.

While many languages will be present in the bibliographic records in one and the same database where bibliographic data are concerned, the added on information may only be in one language. The name of organisations or corporations often vary from one language to another (e.g. NATO - OTAN). Furthermore concepts in one language can not always be mapped to concepts in another. Both precission and recall will be reduced due to these factors.

The logical data model, such as linking of records, differ very much from one system to another. The procedure of retrieval of parts of multivolume works will therefore vary from one system to another. In a network this may cause poor recall and even poor precision. The protocol as it stands today makes it possible to retrieve records on a lower level with the high-level record, because they can be transferred as one record. The inclusion of a high-level record in the low-level record causes problems.

In some systems articles are included in the index (The day he returned), in others they are not (day he returned). Some systems offer only words in title for searching while others offer both words in title and title in direct form.In systems only offering words in title the recall will be high, but precision will be low.

The profile of a collection influences both the cataloguing and the classification of the items. The meaning of one and the same term may be different in two different collections. If the end user does not know the profile of a collection/database the precission of the search may be very poor.

There are many different classification schemes, some general, some special for a field. Within one and the same database many different classification schemes may be present.c There are also many different control vocabularies, again some general, some defined for specific fields. And several different vocabularies will be present in one and the same database.

The use of the classification schemes, and controlled vocabularies, differ from one library to another. But it also differs from one librarian to another. It was mentioned in the workshop that one and the same experienced librarian classifying the same document twice, with a few weeks apart, decided on two different classification codes.

Nearly all systems use stopwords in their search modules. Some systems are sophisticated and has a language-dependent stop-word list, others has only a minimum of three characters per term. The use of stopwords in a network environment may reduce recall considerably.

The z39.50 covers many search possibilities as well as the possibility to use extended character sets. But in the present version the ability to follow links in for instance multivolume works or complex periodicals is missing. This is the case both for searching and presenting the search results. The attribute set STAS do, however, include types for thesaurus search.The protocol, or rather the attribute sets, defines the types of search criteria one may use. The present attribute sets do not cover all types of search criteria that are used in library systems. Furthermore, there are possible to missinterpret some of the attributes and thus cause low recall in the searching.

The end users belong to very different user groups and thus have different requirements to recall and precision. Even one and the same user may in one search prefer high recall, high precision not being important, and in another prefer high precision, high recall not being important.Knowledge base One way of improving search results is by building a knowledge base for all systems using the information in that to restructure search requests. This is a very expensive solution and not yet successfully implemented on a large scale.

One may make a mandatory list of search criteria that all systems must support. Author and title would be included, but which type of subject heading should be chosen? Which other types of data should be included?

By capturing descriptive data from the electronic form of the documents one would eliminate local versions of spelling, data entry etc. introduced by the cataloguer, but one would still have the different versions used by the publishers.

The end user must be informed of the practice of stopwords in the remote system. Can one search for "the" in the meaning "tea" or is it a stopword. May one search for UK or is it a lower limit of three letters per term.

There are many different scenarios for evaluating the relevance of those aspects. like * A national bibliography of printed material * Scientific university publishing * Commercial publishing * "Cataloguing the Internet"

I am sure that all of you will be able to add other topics, based on your experiences. In this climate of as yet far from ideal RECON methodology, it will be a challenge to discuss and analyze: (a) the card catalog, (b) the goals of each library, (c) importance of and adherence to international standards.

The exchange of experiences between the participants showed that the main issue was less technological than methodological, in other words that the success of a retrospective conversion was less linked to the chosen technique itself than to the care brought to the initial analysis.

As illustrated in figure 1, however, this subdivision only helps to classify the problems needing to be addressed: it does not produce isolated classes which can be studied entirely separately. They are on the contrary all linked to each other, meaning that any choice of decision belonging to one class is likely to influence choices in all the 3 other classes, by adding specific constraints.

These data should be quantitative (when relevant). In fact, this process is like taking several pictures of the collections and/or of their representation in the catalogues, each under a different angle for each criterium.

Each sector in one layer represents a part of the collections or of the catalogues, whose documents or catalogue cards share a common characteristic regarding the applied criterium. Each of these characteristics will possibly induce different constraints on the other key elements classes: results, how and costs.

Creating machine readable records may be done in many ways.The choice of a technique (or a set of techniques) is helped by the work done in assessing the key elements of the two first classes. The characteristics of the catalogues as the result of the What analysis and the expectations of the Results may lead to choose different techniques for the various subsets of the catalogues.

States looking above as intermediary may be an end to a partial retrospective conversion, for a cheaper result, instead of a step towards a more evolved state. Card images, for instance, may be accessed through specific browsing software in a virtual drawer, exactly as a traditional card catalogue would be, as far as access data are concerned (headings, but no word search, availability etc.). Plain text could also be a final step and still provide more access points than a card catalogue, thanks to full text searching.

It is well known that there are huge differences from country to country in the cost of living and in the added cost of work due to library qualification (i.e. the unqualified worker / qualified librarian ratio may range from 1.1 to something like 3).

These factors have of course a strong impact on the cost of the various elements of a retrospective conversion. This whole section had then to be restricted to some considerations independant of a local situation.

The four classes of key elements explained above were not presented in random order (librarians are used to sort): it is reasonable to know what one has got before deciding what one wants, and to choose the techniques and calculate the costs afterwards.However, this is not a one-way process: as shown in figure 1, all key element classes are linked to each other.

But eventually, when the whole multidimensional space approaches consistency (it never reaches full consistency: it would cost as much as cataloguing the whole library again!), the retrospective conversion may proceed in enough confidence that the most appropriate solutions have been brought up at the most affordable cost.

Networking opened these library catalogues - now online databases - to everyone. What are the problems and how we could improve the access to these databases? Are there standards or rules, that could be applied to tackle the problem of several languages, when a new database is created today?

Other topics such as multilingual access via the World Wide Web, problems of translation, questions of transliteration and character sets were considered briefly but not discussed in detail given the time constraints.The group assumed the following context for the discussion: multilingual access to a general library collection, and that users do want to carry out multilingual searches and access documents in several languages.

When searching, the user opts to search in one of the available languages (e.g. German or English) and retrieves all documents indexed using the concept concerned, thanks to the links between the different language expressions of the concept. When the user displays the resulting bibliographic records, tracings for the subject headings are in the language used for the search.

However, the greatest difficulty encountered in this approach is one of cost: the creation and maintenance of such a list, in the context of a general library collection, requires substantial outlay and staff. Such a task needs to be carried out in co-operation with other institutions. In addition, it is limited to documents which are subject indexed, and this does not necessarily cover a large part of the data in the catalogue. Finally, it may require extensive changes to systems and / or formats other than UNIMARC in order that they accommodate the multilingual structure.

Coding of such data may take place either directly in the bibliographic record e.g. in the National Library of Canada 9xx fields are used to hold the different translations of a concept, or in authority records e.g. in the Swiss National Library it is planned to store multilingual headings in multiple 1xx fields in the authority record. The latter case offers greater facilities for global changes and management of a list, but requires greater changes to formats and linkage within the system.

This type of multilingual searching requires a client which analyses search terms input by the user and provides translations which extend the search. An example of this approach, applied to titles only and as yet in specific subject areas, is offered by the CANAL/LS project which is developing a linguistic server: users will be able to enter requests in German, French, English or Spanish. Keywords are extracted to be translated into a language selected by the user and then re-sent to the catalogue.Theoretically, this approach could be applied to all fields in the bibliographic record. It could be carried out on the demand of the user in specific requests. In a client form, it might require fewer changes to bibliographic or authority formats or to systems themselves.

Its applicability to a general context needs to be explored. The traditional problems of synonyms, ambiguous titles and semantic context remain. It might be better suited to abstracts and full text than to the relatively poor bibliographic record. The choice, maintenance and storage of multiple dictionaries requires significant resources.

Library in each country, as for example in Canada, where the National Library undertakes the translation and maintenance of bilingual name authorities and ensures that French equivalences to LCSH / CSH are available in its cataloguing records. In some countries, it may be more appropriate for another institution to carry out this task, perhaps in the university environment. In the area of corporate and name access, mention was made of the IFLA ideals of an international authority database in which multiple forms of a name are linked by a single ID number. In the area of subjects however, the majority of the group felt that the goal of a generalised multilingual access was a utopian idea given different needs and specialisations between countries and also between libraries within a country.

In the field of science and technology, it was pointed out that the English language is predominant, and it was suggested by some that in this sector the idea of multilingual access to data is no longer relevant. However, the group was of the opinion that in a general and non-specialised context there remains a need for multilingual access to bibliographic data. Frequently, users may be able to read and understand a text in another language, but not be capable of finding the appropriate terms to search for such a document.There is still much talk about multilingual access but very little concrete action apart from some isolated efforts: on a European level, it would be useful to revive the goals of the MULIS project and to pursue the studies begun within the CANAL/LS project. Going beyond access to library catalogues, and looking at free-text or structured searching of World Wide Web sites, it is clear that the majority language is English. If we want other languages to be taken into consideration, it is time to act.

PALINET has seized the opportunity to work cooperatively with some of its member libraries and other organisations, to develop a monograph table of contents service that will benefit library users to have access to library online catalogs, as well (potentially) users of other services such as bibliographic information services.

The addition of table of contents data to the basic bibliographic record greatly improves the specificity of access and makes it possible to perform searches in large catalogs that result in much more precise, relevant output than is possible within an unaugmented catalog.

The exchange of ideas and experiences among the participants might lead to an immediate assessment of the most relevant aspects to be considered and to the proposal for future initiatives aimed at a deeper investigation of specific subjects.

Solutions that combine the two approaches are also possible and a number of intermediate situations can be implemented.Much can be said on the characteristics, advantages and disadvantages of the different alternatives. The breadth of products and technologies available on the market makes possible to find a solution to any kind of user requirements.

We agreed that it would be useful if the most important library systems in Europe might produce and make public in the future some statistics on the usage of their services and on the level of user acceptance.

While the Web approach has the advantage of being a cheap and relatively easy solution, intended also for not expert users, it lacks of flexibility because of the limitations of the language HTML and is strictly dependent on the application running on the server: in the client-server architecture of a Web solution the weight of server is much higher than the client.

In any case it would be useful to make frequent analyses of the transactions logging to have some information on users behaviour and on their capability to exploit the system features. Statistics on the number and the results of queries might help in designing and implementing new services and in thinking new styles of User Interfaces.

Both characteristics are technologically conditioned by the client/server architecture in the network environment.The digitisation of information and the possibility of digitised information processing enable the users to get the information they search for from the system of integrated information services directly into their working environment, where they can integrate it into their work.

Dynamic technological development and changing users' demands raise a set of completely new demands for libraries which have to fulfil them in best possible way considering the limitations of their environment (available means, staff, existing infrastructure, etc.).

When dealing with quality of electronic services in network environment it should not happen that causes and consequences are exchanged, i.e. electronic services in network environment are means to fulfil user needs and not the objective.To prevent such a situation which is according to IT (Information Technology) satisfaction level statistics in libraries not quite uncommon, the workgroup started with the deployment of quality through the problem solving paradigm where users needs are stated as a problem to be solved. In this way, quality can be expressed through the difference between stated needs and fulfilled needs. Smaller is the difference, the better quality is the solution.

People are experienced in solving everyday problems and problems at work, and it seems naturally to define quality in the context of solving problems. By establishing this link quality is easier to understand and easier to ensure.

Importance is given to problem recognition, problem understanding and the method of solving the problem. More views should be applied to understand the problem well. This is achievable through intensified communication among interested parties. Causes preventing quality were discussed.

Management of users needs and quality management of internal processes (services) which objective is to satisfy these needs can substantially improve quality. And it is important to respond in realistic time to change in users needs. It was emphasised that incompletely understood problems cannot guide to quality solutions.

" Ask any person what he or she thinks about a current national problem; energy, juvenile delinquency, drugs - almost any problem will do for this test. That person will know or at least will have an opinion about the solution to the problem.

Regarding IT problems, the group also discussed the question whether the better tools themselves can improve quality of electronic services or there is also a need for qualified personnel - systems integrators. New tools are developed almost daily - especially in Internet environment and it is questionable whether new tools alone can significantly improve quality of services. There is a potential danger to develop services that are technologically "top" but "bottom" regarding their usefulness. A qualified system integrator can help avoiding such a situation.

Quality lessons learned in manufacturing industries have been reviewed (devising appropriate specifications, ensure conformance to specifications, standardised procedures to minimise defects). There was some discussion whether quality models proved successful in manufacturing industries are directly applicable to information field. It was shown that the user-library relation is more complicated in network environment than the customer - supplier relation in manufacturing environment. At least communication and information infrastructure should be considered when developing electronic services in network environment. Dissatisfactory functioning infrastructure can prevent the user from using an electronic library service.

When solving complex problems in quality domain, the solving method gains importance. In a sense, we could even state that quality problems result from inappropriate methods of solving problems. So, if we improve the methods or use more appropriate ones, there should be less problems with quality. It seems that systems engineering can help with built-in quality in its methods. Currently there is not much evidence of its application in library environment.

There is a lot of evidence about problems in implementing quality standards. It seems that some problems are due to the generic nature of the standards what causes problems in their interpretation into concrete environment while other problems are caused by the fact that quality standards have been built based prevailingly on the experiences of manufacturing industries. Some even disagree that standardisation is an appropriate way in ensuring quality. Standardisation processes generally follow two objectives. Ensuring quality is one and the other one is providing an evidence for the user (customer) that the process (service) which is set according to the quality standard, indeed ensures quality. In reality, second objective sometimes prevails over the first objective what causes a lot of dissatisfaction by the users. However this problem is not caused by quality standards as such, it would exist even if there were no quality standards. Implementation of ISO 9000 in libraries was considered. Two reference books were briefly reviewed.

The situation caused by intensive development of information field - primarily Internet information services, was discussed. It seems that the library is becoming a de facto market player - not because it wants that position but because of the development in the information field. This creates a new (competitive) environment where libraries need to provide services via the net. This new environment is structured gradually; current situation was described as an information chaos. This caused that the group searched for attributes which could ensure the position of the library in the future.

Hagiographical studies have never taken such an important place as in recent times: innumerable publications and conferences have been highlighting for some years the eminent role of hagiographic sources in our knowledge of societies, cultures and civilizations of the Christian world.

John Bollandus (+ 1665). Methods may have progressed, as well as knowledge, even the aspect of the books has changed, but the spirit is always the same. It is the spirit of a team of specialists, entirely devoted to hagiographical research: only hagiography, but the whole of it (Latin, Greek, Oriental...).

This practical inventory, published in 1983, indicates whether a specific saint was the object of an article published in Analecta Bollandiana or of a book reviewed in the periodical.  Its aim and contents differ completely from those of the Indices since it includes only the articles and books dedicated to a specific saint; the secondary references to saints in articles, reviews and bibliography are not listed.

Such contents make the Analecta Bollandiana indispensable in any department of medieval, Byzantine, Slavonic or Christian oriental studies, as well as of Church history, comparative religions, ethnology and folklore.

With both the inheritance of the great tradition given by the Acta Sanctorum and the actual support of a highly qualified international scientific committee, Analecta Bollandiana has been for a century and will remain the ideal forum for everyone interested in Christian hagiography.

Bollandiana the collection Subsidia hagiographica comprises monographs, critical editions and supplementary reference works. These include the catalogues of hagiographical manuscripts of several important libraries as well as the famous Bibliothecae hagiographicae, which list all Greek, Latin, and Oriental hagiographic texts up to 1500 A.D.

Although venerated throughout the Christian West, St Roch has nevertheless remained a mysterious personage.  Beginning in the second half of the fifteenth century the cult of the holy pilgrim, protector against the plague, spread from Lombardy to Venice and from Venice German merchants took it to Nuremberg and southern Germany, from where it swiftly spread to the rest of Europe.  But who was in fact St Roch and what were the causes which led to his cult becoming so deeply rooted with such speed so that traces of it can be seen everywhere including representations of him in works of art?

Padua in February 2004.  Their exchange of views led to the abandonment of opinions previously considered certainties.  The joint examination of hagiographic, literary, iconographic and documentary sources as well as the discovery of new texts all gave rise to the problematical image of a new saint who appeared in the wake of a new illness - the plague.  It was the result of a process of hagiographic elaboration but not as such a product of pure imagination.  It was the invention of printing which led to the rapid progression of the cult by the laity of this lay saint, both at its origins and in its elaboration.

All Christian saints wish to meet Christ but go by many different paths, which is why there is such a great diversity in the accounts devoted to them.  From the literary point of view hagiographers have also chosen varying means and various styles ranging from the very simple to the most sophisticated, in simple or rhymed prose, metrical poetry and rhythmical verse.

The thirty studies collected here illustrate the various solutions adopted in accounts written in Latin and their aim is to reveal the richness of a literature intended to please as well as to edify.  The works edited, thirty in number, were for the most part unknown before they appeared in print in articles.  They come from communities in Belgium, England, France, Italy, Serbia and Tunisia.  One hitherto unpublished contribution is devoted to hagiography in Normandy in the eleventh century.

This catalogue contains an exhaustive description of the rich collection of Greek hagiography in the Biblioteca Ambrosiana (Milan).  Two hundred and seven hagiographic manuscripts and fragments dating from the ninth to the seventeenth century have been analyzed, with particular attention being paid to codicological aspects.  They contain over 1300 separate hagiographic texts referring to 375 saints.

Based principally on the canons of councils, the work of Gregory of Tours and about eighty Lives of saints, this study is devoted to the figure of the priest in the Merovingian Gaul, which is much less well known than that of the bishop.  The figure of the priest or rather the figures of the priests: the title indeed suggests the plurality of situations and cases.  Childhood and studies, conditions and rites of ordination, civil status, way of living, activities and authority, material resources and relations with the bishop: no aspect has been neglected.  A thorough study of terminology also provides new insights.  The work also contains a prosopography of priests of the 6th and 7th centuries with over 380 entries.

L'hagiographie remains the reference manual for anyone whishing to be initiated into the critical study of hagiography.  The structure of the book is threefold: starting with a typology of the sources (which are not only saints' lives, but also calendars, martyrologies, etc.), it continues with an exposition of the method, as it was developed by the Bollandist H. Delehaye, and it ends with a concise history of the genre "hagiography" from the Acts of the Martyrs to the present times - a real tour de force, without any equivalent elsewhere.  An important bibliographic supplement (100 pages) has been added, thus connecting Aigrain's manual with today' research.

Unique repertory of the saints venerated in mediaeval Iceland. Each entry specifies the churches where the saint was venerated as well as his feast-day; where relevant, it mentions literary works (sagas) devoted to him and her, and local iconographic depictions of him and her. The work also contains a list of all the churches and chapels whose existence is attested prior to 1400: the names of the saints associated with each place, which can easily be found on a large scale unfolding map, the date of consecration of the edifice and the sources in which it is mentioned are listed. A fundamental reference work for Icelandic church history.

Thessalonica in the second half of the Xth century. It abounds with colourful episodes in which various historical personages, such as St. Photius of Thessaly, St. Athanasius and St. Paul of Athos, are encountered.

Caesarea and the Syriac and Hieronymian martyrologies mention the martyr Athenogenos, chorepiscopus of the town of Pedachthoe (today Bedohtun), a victim of the Diocletian persecution. Hitherto there was only the short epic Passion BHG 197, published in 1987. With this work we now have the publication, together with a translation and commentary, of another version of the Passion BHG 197b, a text of an entirely different historical quality and in large measure ancient. Particularly worthy of mention are the three long interrogations of the bishop, of the lector (and martyr) Ariston, and of the cantor (and renegade) Severianos. Also noteworthy are the names of other martyrs (including Peter I of Sebasteia) and a number of picturesque details of rural Christian life. In addition, the epic Passion, accompanied this time by a translation, is republished here on the basis of some ten manuscripts.

After presenting Jacob de Voragine and his work (date of composition, sources, readers) the author catalogues 926 manuscripts of the Legenda aurea. This makes it possible to study the various groups of manuscripts regarding the transmission of the text and to follow their diffusion. A vital work in the history of hagiographic writing and the text the most widely read during the early Middle Ages.

The aim of this new collection, devoted to historiographic research, a field which is considered today to be particularly important, is to exploit the archives not only of the Bollandists and some of their correspondents but also of scholars who in modern and contemporary times have been interested in hagiography.

Charles Du Cange (1610-1688), who was interested in everything to do with the history of France and Picardy as well as the history of the Christian Orient and Byzantium, made ample use of the first few volumes of the Acta Sanctorum while preparing his Glossaries of late Latin and late Greek.  He too lent effective help to the hagiographers of Antwerp, especially by his examination of the Greek manuscripts of the Colbert Library at Paris.

As for the correspondence between Delehaye and Cuthbert H. Turner (1860-1930), an Anglican, exegete and historian of the early centuries of Christianity, it provides a touching example of the relations between two scholars of different confessions who carried out their research with the greatest of rigour but each with respect for the conscience of the other.

The Acts are published in chronological order, which is determined by the day of the liturgical celebration of the saint taken from a calendar and/or a martyrology. For each day it is necessary to establish the list of all the saints who are celebrated or who have a liturgical office anywhere in all of Christendom. This presupposes a systematic and painstaking study of the calendars, which may exist in Latin, Greek, Syriac, Arabic, Coptic, Ethiopic, Armenian, Georgian, Slavic, Celtic, or other languages.

After that one proceeds, for each saint, to build up a file containing the diverse elements which will be discussed in the commentary. One must trim away any repetitions, track down any obvious falsehoods, and distinguish fictitious persons born only of variant spellings of the names of authentic saints and those of whom we possess what might turn out to be merely fables.

Before the monographs for each day is found a list of Praetermissi et in alios dies rejecti. This is a catalogue of saints or venerable persons whose biographies in our judgment should be omitted or included on another day. The Syllogai are very brief notices. They are limited to noting the memory of those of whom we have preserved only the name.

Translationes, Gloria posthuma, inscriptions, etc.) relevant to the saints of the day. The commentaries examine the problems and difficulties which the biography of the saint in question can pose and employ the scholarly methods appropriate to the period of the document. These methods have been developed and refined by the Bollandists in their work.

Without a doubt it is useful to recall that in every age and in every place a saint is a person of note. The saint exercises an influence on society in civil and ecclesiastical affairs. This occurs during the life of the saint but also after the saint's death. The communities which the saint has created, institutions he or she has founded, rules drawn up, and the cult rendered to the saint, all perpetuate his or her glory through space and through time.

It is also the case that much of what we know as history from the beginnings of Christianity to the Middle Ages is known only thanks to hagiographical texts. Even in the modern period it is impossible to speak of history, archaeology, architecture, sculpture, painting, music, literature, folklore, or ethnology, without calling to mind the life and cult of some saint. Even in the study of law, are not some of the most ancient documents found in the Acts of the martyrs? Almost all the fairs of the Middle Ages, international, national, and regional, were attached to the memory of a saint. Every detail of domestic and public life is found in the Acts of the saints. And they show us as much about the lives of every-day folk as about prominent people.

This is why the Acta Sanctorum embrace general history (civil as well as ecclesiastical); the particular history of different countries, towns, and monasteries; the chronology, geography, and topography of a large part of the globe: and all of this from the beginning of the Christian era up to the 16th century.

Begun over 350 years ago, the Acta Sanctorum have from the start been at the forefront of critical method and of scholarship. Rare indeed are those historical works which can be compared to them, by reason either of breadth of documentation or precision of detail.

In order to disseminate, the software of the project will be packaged and documented.The aim is to give to the Belgian PIB service an easy installation process and a specific documentation explaining the main functionalities.

The aim of this workpackage is to keep the consortium aware of the recent evolutions of legal restrictions and of technical developments on the diffusion and the use of virtual documents and to adapt the VIRLIB-system to these evolutions.

VirLib II will "enable the interlibrary loan departments affiliated to the Impala network to deliver directly to the user's workpost, in electronic format, any article asked for by the end user" . VirLib II will also study the technical, commercial and legislative evolution of the diffusion of electronic documents. The technologies for the diffusion of information (security, format of electronic documents, watermarking, meta-data, etc.) are indeed in constant evolution".

The WP03 of VirLib II aims to make a study on the use of virtual documents. The first part of the WP03 will focus on the legal aspects of the use of the electronic document. The second part produced by the UIA will focus on the technical development on the use and the diffusion of virtual documents (authentication of the end user, integrity of the document).

The evaluation of the VirLib system took place after the completion of the two first workpackages : WP1 "Improvements and Packaging of VirLib Software" & WP 2 " Development of a PDF server". In the technical annex of the project, those two WP were prerequisites before the evaluation trials. The aim of the WP 4 is to " Test of the technical developments made under the WP1 & 2 in a real environment".

The purpose of this workpackage WP2 co-ordinated by UIA is the development of a PDF server for electronic delivery of ILL materials between libraries in Belgium using the Impala document ordering system.

Impala, Instant mailing procedure for automated lending activities, provides Belgian libraries with a system for sending and receiving interlibrary loan (ILL) requests. It is used for returnables (books) as well as for non-returnables (photocopies).

In fact, VirLib is integrated with Impala to the effect that after successful receipt of the file, a clickable URL is displayed in the Impala application. Moreover, all processes besides scanning happen in background, so users in Inter Library Loan (ILL) departments are not confronted with the technical details involved when converting documents from TIFF to PDF or when sending/receiving PDF files through email or FTP. When a problem occurs, a monitoring system alerts the ILL desk and allows the user to intervene.

The tests-users who evaluated the system are the actual librarians of the three ILL departments. Those persons have known the system for a long time and work daily with Impala. They were not confronted to an entire new system they had to understand. Being used to work with Impala, they had only to learn how to use the few new VirLib functionalities that were added to the system.

The supplying library receives the request and can use the "Scan button" to launch a scanning operation. This operation launches the VirLib acquisition software. The librarian has just to check the scanning process.

The librarian does not need to understand the whole process in details. All the operations are in background for the ILL librarians who are therefore not able to act directly on the system. They only can verify if the whole system works well (if the requested document is supplied), if the scanning process works well, and if the quality of the received document is good enough. The computer specialist checks if the system (the servers, the communication, and so on) is working well and solves technical problems when they occur.

We observed the users interacting with the new system in context, i.e. in this workplace. This WP 4 did not aim to focus on the Impala system in its entirety. As we said it before, the VirLib functionality is a little part of Impala. The evaluation focused only on the usability of the Virlib functionnality.

The reliability and the rapidity of the system are the two aspects that were evaluated. The evaluation of the system itself was made in the normal conditions of use. They were made in two steps : the first trials were realised internally, and the second set of trials were conducted in collaboration with the three ILL departments of the institutions involved in the project : UIA, ULB, KBR. This second aspect is the main point that was evaluated in the trials.

The evaluation began later than expected for several reasons previously detailed : the VirLib software had only been installed by the end of June. The evaluation was then taking place during holidays.

This installation was later accompanied by some explications about the modules of VirLib and about how the system works. The tests have been made in two steps : the internal tests and the inter-institutions tests. During the internal trials a comparison between VirLib and Ariel was also made.

An internal trial is a request which is made by an institution and supplied by the same institution. Such tests are possible because in VirLib a unique server is used for both operations : the reception of documents coming from other VirLib institutions and the sending of documents to those VirLib institutions . The same server can then be used for the two steps of an Impala demand and a library can be at the same time the requesting library and the supplying library.

The staff was invited to become acquainted with the new system, to evaluate it and to point out the main technical problems. Those first tests were foreseen to take more or less 10 days. A preliminary report was made to point out the problems to be solved and to suggest some possible improvements to the system.

The evaluation tests were made by a person of the ILL staff and controlled by a neutral observant. A computer scientist collaborated also to the evaluation : to give information about the technical problems occurring at the VirLib Workstation.

This approach enabled detailed analysis of the performance of users doing real work with the product being evaluated. Users undertook real work tasks while observers made notes and timings were taken. The observations were subsequently analysed in detail, and usability metrics for efficiency, effectiveness, productive period etc. were produced. It was a user-based evaluation. A debriefing with the person of the ILL staff has been made at the end of trials by the observant to fill in the grids.

This first phase was used for installing the software on the local PC and to make it in such a way that it works properly. The main problems occurred during the scanning process. This phase wanted to focus on the main aspects of the evaluation : reliability (maturity, fault tolerance, recoverability), usability (understandability, learnability, operability), maintainability (analysability, changeability, stability, testability) and portability (adaptability, installability, conformance, replaceability.).

This test also wanted to compare VirLib and Ariel. Due to the delay occurred during the first set of trials, those tests were reduced to the minimum. They have been made according to the remaining time. They also wanted to test the new Ariel integration inside VirLib.

This step was realised by the ILL department staff itself and was focused on the evaluation of the system. It aimed to calculate the timing of the several steps of the delivery of an article, to evaluate the quality of the documents and to precise the reliability of the system.

A request in Impala involves two libraries : a requesting library which sends the demand of an article through Impala and a supplying library which has the article and can send a copy of it. Therefore the requesting library and the supplying library were playing a part in the evaluation of a unique document request .

The requesting library is concerned by the request itself, the reception and the quality of the incoming files as well as the updating of the Impala interface. The supplying library is concerned by the reception of the request, the scanning process (via the Plug-in), the conversions of files and the sending of the files to the requesting library. To allow this double part of the evaluation of a unique request, two different grids were created : one for the requesting library and another one for the supplying library; in order to allow the matching between the different grids, the Impala number of the request was requested to be noted on top of the evaluation tables.

Four evaluation grids were provided to allow the persons in charge to evaluate the system following the same way as the other and to standardise the results. Two grids allowed to evaluate the tasks of the requesting library and two grids allowed to evaluate the tasks of the supplying library.

One grid is a work document allowing to take note of the encountered problems, of the timing, of comments for each step of a Impala request and finally the quality of the sent document. First of all those grids served to evaluate the reliability and the speed of the system.

The trials wanted to evaluate if the system works well and if not, they wanted to make a list of the encountered problems and to precise their frequency (Note : special attention was paid to the reliability of the system during the scanning process).

However, it was not necessary to have a precise timing of each step of the supplying of a request. Timings were consequently preferably based on date/hours mentioned in Impala and in the VirLib monitoring.

It had been decided not to evaluate the time needed to find the requested document on the shelves of the library and the time needed to photocopy the article either. The important time was the time needed to make the treatment of a request ; that means the time needed to scan and to send the scanned document to the requesting library.

The person in charge in the supplying library wrote down in the grids the date and the starting time and the end time of the scanning, and the monitoring time (when the file is sent to the server of the requesting library). In the requesting library, the tester only noted the time indicated in the monitoring.

The Impala number allowed to put together the two parts of a same request : the evaluation grids filled in by the requesting library as well as those provided by the supplying library. The information about the two libraries involved and the tester could also give some information : for instance about the frequency of problems occurring during the tests made by a specific library or between two specific libraries.

The information concerning the number of pages of the document sent was also very important. According to the previous tests already made, frequent problems occurred during the scanning process and when the number of pages was too large.

The grids highlight also some aspects of the system which were not directly linked with individual tests. The first grids allowed us, on the one hand, to make a synthesis of the encountered problems and their frequency and on the other hand, the average of all the tests would give us an indication of the time needed for each step of the process.

These two grids allowed to evaluate the functionality, the ergonomics of the system. For each step of the process, the person in charge could also suggest some improvements of the system. Those grids were filled in at the end of the evaluation period in one go. As we have said, the Impala system was not changed entirely, so the evaluation concerned only the new VirLib adds.

The aim of those tests was to test the local installation and to be sure that the inter-institutions tests could be realised in good conditions. The ILL departments could then see the technical problems and solve them when they occurred. Those tests were realised by only two institutions : ULB and KBR but not by the UIA that had used the system since October 1998 and that had already done the internal tests.

July, August and September 1999 following the availability of the persons involved in this work : on one hand, persons in charge of the evaluation in each institution and on the other hand, the librarians who work in the ILL departments.

At the end of the tests, the person of charge in the institution had to make a summary of all the trials. This synthesis summarised all the problems encountered, the frequency of their occurrences and the solutions chosen to solve them. It would give a first average of the time needed for each step and for the whole process of a delivery.

With the HP ScanJet 4c/T, the KBR team faced a lot of problems. The problems occurred when the KBR team tried to improve the quality of the scanned documents. In fact, the documents scanned in black and white were unreadable on screen as well as on paper. Firstly this poor quality of the image was attributed to the glazed paper that was used, but the scanning of a copy of the same article was also of bad quality.

Secondly, they tried to adapt the standard settings of the scanner software. Those adaptations posed problem. The scanning process was all the time interrupted during the scanning of the second page of the document. The ACQVIRLIB module sent a message saying : " This program has performed an invalid page fault in module Acqvirlib.exe, ...", and indicating that the program would be closed. In fact, the program was not closed but the whole system was blocked. The system worked only with the standard settings of the software but the quality of the scanned document was bad.

To improve the situation, a second set of tests was made with the HP ScanJet 6200, and it worked well and caused no problem. This scanner was not provided with an ADF, the librarian has to scan manually each page of the document and load the preference settings. Therefore the whole process is time-consuming. KBR elaborated this to IRIS and again IRIS doesn't encounter any problem but can not tell what is done wrong.

With the installation of the new scanner, the corresponding scanner software was not installed on the hard disk of the PC because the scanner was working with the old version. The VirLib system using the original scanner software, this situation caused a lot of problem. The system was blocked. About twenty tests were realised during July and August 1999 and treated internal requests (requests from ULB to ULB) as well as normal Impala requests (requests from another institution to ULB). Only 4 tests were successful.

First of all, we have to note that the Ariel software poses less problems than the VirLib software because Ariel uses its own image acquisition software while VirLib calls the standard TWAIN interface and is thus less device dependant than Ariel.

The few trials allowed us to conclude that when an HP scanner with no ADF is used, the ARIEL software is easier to use than VirLib. Moreover, with the HP TWAIN interface the manual intervention of the librarian is frequently needed (manual feeding of sheets, manual selection of the zone to be scanned) and each page was scanned two times for VirLib (pre-scanning and scanning).

The first trials were completed later than expected. The complexion of this step was behind the schedule. The encountered problems reduced the collected data. Few aspects of the system could be evaluated during this part of the evaluation. This step was principally of use to install the scanner and the software on the local PC. The evaluation of the whole system (including the worksations and the network) was reported to the second set of trials.

This difficult installation of the software led us to insist on the fact that we have to pay special attention on the selection of appropriate scanning equipment and on the installation of the system in the ILL departments of the Pro VirLib partners.

Inter - institutions trials a. introduction The three VirLib institutions (KBR, UIA, ULB) participated to this second phase of the evaluation of the VirLib system. They lasted two weeks (from the 18th October until the 29th October). New grids were made to take into account the critical remarks noted during the first set of tests. The three partners filled in the grids for each document supplied electronically to the two other institutions or received electronically from them.

The requests sent before the 18th October or received after the 29th October could not be taken into account for the evaluation. Some data of those tests were however used during this evaluation ; for instance, the data concerning the time needed to scan a document is an information that could be informative and interesting by itself even if we did not have all the data about the request.

This set of tests took place later than foreseen. The holidays and some technical problems (for instance KBR experienced problems with setting up an email account) delayed the start of the inter-institutions tests. They began late but they only could begin when the technical problems linked with the scanner installation were solved.

In agreement with the others partners, for the supplying library it was decided to test only the time needed to scan the document and to fill in the request; but the time span between collecting the document, making a photocopy, scanning the document, and the notification in Impala was not taken into account. Because the time needed to collect, copy & scan the document was not considered as a part of the VirLib system but as a problem of the ILL service of each institution.

At the ULB, there are also several libraries : the library of law, the library of Human Sciences and the libraries of Applied Sciences on the campus of Solbosch and the library of Medicine in the campus Erasme. Each campus has his own ILL department. Only the ILL department of the Solbosch participated to the evaluations.

The evaluation is based on the 25 requests that were supplied during the two chosen weeks but some of them could not be taken into account in this evaluation for several reasons that we will detail below.

"real world working environment". They allowed us to evaluate some aspects of the system. The organisation of a session of intensive trials was not judged useful by the other partners. The system was not evaluated in conditions of misuses, in extreme or bad conditions. Any unsuccessful request have been sent again to the requesting library using the files conserved in the "archives" folder nor the "outgoing" folder.

Note 1 : As all the requests were sent by UIA, the results can be viewed as on the one hand, the evaluation of the capacity of the ULB and the KBR to deliver a document to UIA and on the other hand, the quality of the service. In fact, each library was playing a specific role ; UIA was exclusively the requesting library and ULB and KBR were exclusively supplying libraries.

Note 2 : the time noted by the persons in charge in the grids can differ from a team to another. The time used is generally given by the internal clock of the PC or of the server or the watch of a member of the team that are usually not synchronised (the differences can be of several minutes). Those data have then to be viewed as indicative.

In general, the time needed to introduce and prepare the works is obviously divided into the number of pages. The average time needed to scan a page is then shorter for numerous pages than for few pages. This aspect is more considerable for a scanner more performing and faster like the Bell & Howell than for a HP ScanJet.

Few tests were realised at ULB scanning directly from the original book without having previously photocopying the articles. The results of those tests have clearly prove that the direct scanning of the book is more complicated, less ergonomic and more time-consuming than photocopying and scanning the copies.

The average time needed for this step was 11 minutes 25 seconds. This average seems normal according to the fact that each 15 minutes, the work station is watching if a new file containing a document is ready to be sent.

This aspect did not pose problems. There is only one article sent by the KBR that was declared "unreadable" because the copies were too dark (Impala N 852208). This problem was due to the darkness of the scanned copies (on the evaluation grids filled in by the KBR, there is a remark that mentions that the original copies were "very dark").

The two remaining articles were received incomplete by the requesting library. For the Impala request N 851681, the ILL department of UIA only received the first page of the document. For this request, the ULB ILL department informs that the problem comes from the format of the article that could not be sent via VirLib. The other article not received entirely was the Impala N 851171; no precise cause was pointed out except the fact that the requested article contains 36 pages and was the biggest one of all the requests of this evaluation.

Due to the fact that the first step was disturbed and delayed by the problems occurred during installation of the scanners at ULB and KBR, the Ariel tests were reduced to the minimum. The few data collected about Ariel are the result of the ULB first trial.

This tool is a management tool used preferably by a technically skilled person (that is a system manager or an ILL manager with some knowledge on the working of the VirLib server). It is the raison why the guidelines are included in the technical documentation.

The evaluation was made without extensive uses for two reasons. Firstly, the Impala interface gives enough information on the request including the electronic deliveries (consequently, the staff did not often use it and it has not been introduced in their procedures yet) and secondly, the few number of the electronic deliveries did not encourage the staff to use it. Nevertheless, the use of this tool will increase rapidly with the participation of new partners and the extensive use of VirLib.

The user interface of the monitoring can obviously be improved A real explanation of the system is only given in the technical documentation of the VirLib server and not in the Impala manual. That implies that the monitoring of the system is under-used and that the real function of this tool is not well understood by the librarians. To resolve this problem, a short presentation of this tool could be done in the Impala manual to allow the users to better understand the global system and its possibilities .

Several aspects of the monitoring tool to be improved were underscored. The displaying of information (its presentation) and of functionalities can be improve. For instance, a clear separation between the delete-functionality and the display-functionality could be a real improvement as well as the asking of a user confirmation when the delete-functionality is used (in this case, the addition of a message-box could be useful).

In the same idea, the displaying of information can be improved to allow a easier manipulation of the tool. The separation between the different Impala requests could be more obvious or, the deletion of some unnecessary fields (like fields of copyright) that makes the system less usable and that shows redundant information (data contained in the fields "mail" and "mailto" are identical) could make the system easier to use.

The ProVirLib tests will be useful to better evaluate the system because they will be preceded by a precise nomination of the actors. This tool will be managed by a single person (who will play the role of system manager) and will be evaluated only by him.

The delay caused by the technical problems concerning the installation of the VirLib software on the local PC has lead us to pay attention to this aspect for the future integration of new VirLib partners.

The VirLib evaluation is based on two sets of trials. The internal tests were delayed by some technical problems. On the other hand, the inter-institutions trials were few in number (18 complete trials).

This situation was caused by several reasons : The tests were conducted in the " real world working environment" in Impala. The ILL departments involved in this evaluation do not deal with the same scientific domains (field of UIA is biomedical while the field of ULB and KBR is Human sciences and Applied Sciences). All the requests were consequently sent by UIA which means that only the KBR and the ULB were evaluated.

The evaluation was focused on the reliability (capability of software to maintain a level of performance) and the efficiency (relationship between the level of performance of the software and the amount of resources used of the whole system) rather than its functionality or its usability.

The new VirLib functionality did not pose any problem because it is integrated in the well-known Impala system. Pro VirLib will give some additional information about the portability (the ability of software to be transferred from one environment to another) of the system.

The results are reasonably successful. When the scanner installation problems are solved, the system works well. Two of the three requests which failed were caused by a problem of format or of quality of the copies scanned and were not directly linked to the system. The reliability of the system is good. The sole unsuccessful request correspond to the biggest file (36 pages).

With a performing equipment, the VirLib system is easy to use and efficient. The time needed to scan and to send a demand is competitive with the time needed with Ariel. The new VirLib functionality is well understood and does not change the work of the librarian of the ILL department. The old way of delivery was more simple because it was done in fewer steps.

This addition of work increases automatically the cost of the delivery inside Impala and make this task more laborious. The efficiency of VirLib decreases quickly when no ADF is used. Efficiency at that moment becomes inferior and lower than the Ariel software (because Ariel has developed its own software). At the moment, the system is not frequently used but this new way of delivery will be quickly the most efficient.

In the second phase of the VIRLIB project the stress is on the development of a real delivery service of electronic documents added to Impala, i.e. the Belgian system of managing and transmitting interlibrary requests for loan. In other words, the system VIRLIB II will enable the interlibrary loan department of any scientific library affiliated to the Impala network to deliver directly to the users workpost, in electronic format, any article asked for by the user in question.

More precisely, VirLib II will consolidate and improve the Acquisition module of the electronic documents (when a paper document is digitalized, it is automatically converted into an electronic document which the user can read) and develop a PDF server in order to deliver the documents to the user.This system - VirLib II - shall be tested in a real environment so as to make it entirely available to the other Belgian scientific libraries within the framework of the ProVirLib project.

Simultaneously, VirLib II will keep a documentary eye on the technical, commercial and legislative evolution of the diffusion of electronic documents. The technologies for the diffusion of information (security, format of electronic documents, watermarking, meta-data etc.) are indeed in constant evolution. The same is true for the legislation and the contracts with providers of electronic information. In the end, electronic documents coming directly from the editors will be integrated in the Belgian electronic document delivery system of interlibrary loans.

All cataloguing of the national imprint of book material is now made in BIBSYS, the shared catalogue system of the Norwegian university- and college-libraries, reusing the preliminary records created by The National Library Branch in Rana (NBR) in connection with the legal deposit. The records are currently transferred to our local system for bibliographic production and online services.

The activities of digitizing selected picture material from our collections have been continued.Two projects are so far completed: The Fridtjof Nansen picture database (1992) and a database containing posters and photos from the period of German occupation of Norway during World War II (1994). A project for digitizing portraits related to the life of Henrik Ibsen is in progress. For the digitizing purposes both in-house scanning and Kodak Photo-CD services are used. The retrieval and presentation of integrated pictures and text based information is based on in-house developed software for Macintosh (MediaFinder).For the exhibition "Nordic Explorers" touring eight European countries 1996-1998 an abridged multilingual version of the Fridtjof Nansen database is prepared.

Traditionally, copyright owners were never able to prevent personal use of their works, that is to prevent someone from using a work for his or her own learning, enjoyment, or sharing with a colleague or friend - without any motive for profit.

Before the 90'ies, copyright practices used to be quite favourable for libraries. They allowed generous copying and other non-commercial use of documents. Since the 90'ies the laws have been changed to harmonize the EU legislation, to fight piracy and to adapt to the changes caused by the electronic environment. The scope of rights accruing to copyright owners would therefore seem much broader in the digital environment than it is in the analogue world.

Therefore librarians have paid attention to the development of this matter on a global level (WIPO), a European level (DG XV: Copyright Office) and a Belgian level (copyright legislation of 30.06.1994 and the implementing measures of the Belgian Ministry of Justice). The next Commission proposal for a Directive on copyright and related will have a big impact on libraries' work and their ability to carry out their service obligations.

Even if digital technology poses a threat to copyright protection and if there is a real need for copyright holders to increase copyright protection with added rights, it is essential that any new rights are balanced with suitable exceptions. Unfortunately, the tendency is to leave the future of access to information to self-regulatory licencing mechanisms. In an environment where information can be monopolised, citizens, libraries, archives and museums could be left in a nearly impossible negotiating position.

The second solution to solve problems of reproduction in the digital world, is licencing. The intention of the European Commission in the proposed Directive is to leave the future of access to information to licencing mechanisms. However, in contract law information producers, intermediaries and end users are free to create their own rules, without government intervention but freedom of contract may become contractual coercion.

The university libraries are noticing significant trends as publishers try to erect barriers to the storage and access of information, and present licence agreements for the electronic access to journal titles in which additional fees are requested, document delivery is hindered, and non-cancellation clauses are introduced. The library position in copyright law in the digital age is being threatened. The rights libraries have in the printed environment are being challenged by the publishers.

ECMS are technical solutions to add extra protection to back up digital copyright works. They are being perceived as the obvious answer to piracy. Depending on their sophistication, these will be able to track and control movement of works in digital form. They will also be used to prevent unauthorised access. The library community is concerned about the effects of technical controls used to underpin copyright protection.

Such controls, designed to prevent copyright abuse, could be used to increase the price of information access. Used in this way, it could mean an abuse of a monopoly besides being dangerous to have total control over any information.

Copyright is concerned with the rights of authors, composers, artists and other creators in their works. Copyright law grants them the right for a limited period of time, to authorise or prohibit certain uses of their works by others. Most of the materials available in libraries consist of works protected by copyright law. This means that certain kinds of use of those works in libraries must not be made without the authorisation from the authors.

Copyright protects 'literary and artistic works: this includes novels, short stories, scientific writings or manuals, and musical works, works of graphic and plastic arts, films, documentaries, but also computer programs and databases.

The rights provided by copyright belong to the natural person who has created the work and are twofold: economic rights and moral rights. The main aim of copyright is to provide a stimulus for creativity. This means that the law has to make sure that the author will have an economic return on his creation and that he can protect his creation from being violated in one way or the other.

The economic rights include the right to copy or otherwise reproduce the work and the right to communicate his work to the public . They also include the right to translate the work, to transform, to perform it in public or broadcast it.

Of course, each country has always maintained sovereign authority to decide where to make the traditional trade-off between giving authors a monopoly over their works and granting users access to original information, and thus, to decide how to implement the provisions of the Bern Convention.

For the right of reproduction, most EU copyright legislations contain exceptions for users to copy freely a part of a work or a complete work for private, research or/and educational purposes. With these provisions the governments have tried to balance the interests of the users of copyright material and the creators of this material.

Contrary to the moral right, "the economic rights shall be movable, assignable and transferable, in whole or in part, in accordance with the provisions of the Civil Code. In particular, they may be the subject of alienation or of an ordinary or exclusive licence".

He shall enjoy the right to respect for his work that shall permit him to oppose any alteration to that work. Notwithstanding any renunciation, he shall maintain the right to oppose any distortion, mutilation or other alteration to his work or any other prejudicial act to the same work that may damage his honor or reputation.

All these rights are exclusive rights, which means that the owner is the only one allowed to give authorisation for the use of his work. The owner can be the author or the publisher. The rights last for the author's life plus 70 years (before: 50 years) after his death. Economic rights can be transferred or licenced, however moral rights are considered to be inalienable.

"Neighboring Rights" which are also movable rights that may be assigned and transferred, in whole or in part, in accordance with the provisions of the Civil Code. They may, in particular, be the subject of alienation or of a simple or exclusive licence. Those rights mainly belong to Performers and Producers and consequently are not relevant in the VirLib context.

Copyright is provided for in national laws. Those laws give protection within the national territory. Since 1886 international protection was provided for with the adoption of the Bern Convention for the Protection of Literary and Artistic Works. More than 100 countries signed this Convention and are bound by it.

Since the establishment of the Bern Convention, it has been accepted in international law that authors have exclusive rights to authorize or prohibit the reproduction of their works in any manner and form. The Bern Convention, however, has also accepted some limitations and exceptions.

Diplomatic Conference many changes to these articles were proposed, especially to Article 7. Due to a constructive lobby of the international library community these Treaties are less harmful for the future of access of information than the draft proposals.

The following statement was included in the Preamble of the Treaty: "the Contracting Parties, recognizing the need to maintain a balance between the rights of authors and the larger public interest, particularly education, research and access to information, as reflected in the Bern Convention."

"The reproduction right, as set out in Article 9 of the Bern Convention, and the exceptions permitted thereunder, fully apply in the digital environment, in particular to the use of works in digital form.

The issue of debate between the library community and the publishing industry before the adoption of this Treaty was the viability of the exceptions under copyright for private, educational and research purposes in a digital environment. The new WIPO Copyright Treaty gives ground to extend the so called 'user rights' to digital material.

Article 7, most of the libraries efforts went into lobbying for a sufficient provision on the limitations and exceptions for users under (electronic) copyright. The new Article 10 of the WIPO Copyright Treaty contains the limitations and exceptions. It allows for the applicability of the old limitations and exceptions under copyright in the digital environment, taking into account the three step test of Article 9 (2) of the Bern Convention.

It is also understood that Article 10 (2) neither reduces nor extends the scope of applicability of the limitations and exceptions permitted by the Bern Convention; in the Agreed Statement, it is said "that the provisions of Article 10 should be understood to permit Contracting Parties to devise new exceptions and limitations that are appropriate in the digital network environment".

Convention. The European Commission has tried in the last seven years to harmonise the European copyright environment, especially in respect of the new media and information technology that have changed the international copyright landscape considerably.

The considerable economic interests at stake and the lobbying power of the copyright industries have had an influence on the development of national and international copyright law and on library activities.

The objective of those directives is to harmonize the law of the European partners. These Directives have given the industry more and more protection over access to electronic information. The significance of these Directives is that they have to be implemented into your national copyright law. It is, usually, no longer possible to change their content at a local level once the Directive has been adopted by the EU Council of Ministers.

The right of reproduction has always been considered the cornerstone of copyright. It is to be found in virtually all national laws and international conventions, and has been partially harmonized at Community level, notably for computer programs, databases and related rights.

The reproduction right is a prerogative giving the authors the exclusive right to authorise or prohibit direct or indirect, temporary or permanent reproduction of their works, by any means and in any form, in whole or in part.

That is a reproduction of a fragment or of the entirety of an article (...) or of a fragment of a work fixed on a graphic or analogue support or on another support. The works initially fixed on electronic support are concerned.

"fixed on a graphical or analogue support or on another support" can be reproduced without the authorisation of their author for private use or didactic purpose and when such reproduction does not conflict with a normal exploitation of the work.

Belgium has provided for an exception to the reproduction right for photo/print type reproductions ("reprography"), combined with a right to remuneration. The Royal Order does not take account of the evolution of the technology and it concerns only the works "fixed on a graphical or analogue support" and consequently not the works in original digital format. The Royal Order functioned well for the paper environment, but there is a problem to apply it to the digital environment. The interpretation (wide or restrictive) of the text has legal consequences. The law adds also that copying machines ("appareils permettant la reproduction") are concerned, that means also the digital device.

Analogue copy as well as numeric copies of all works (fixed or not on graphical or analogue support) are concerned by the Copyright law. At the moment, the modalities for perception of those "taxes" have not been fixed yet and a special Commission will be created in the Ministry of Justice to take account of this evolution.

Rental means making available for use, for a limited period of time and for direct or indirect economic or commercial advantage; "lending" means making available for use, for a limited period of time and not for direct or indirect economic or commercial advantage, when it is made through establishments which are accessible to the public.

It is important to distinguish Inter-library Loan of print documents from Inter-library Loan of electronic documents. First of all the term loan suggests that the material is sent back at one point in time. This is only the case for books in the print environment but not for material in the electronic environment. Terms that could cover the activity more accurately are "Inter-library Resource Sharing". Those concepts means that after a limited period of time the original -or the copy- is resent to the supplying library, which is not the case in Impala . This is the reason why we do not take account of this directive in this report.

Art. 23.-(1) An author may not prohibit the lending of literary works where lending is carried out with an educational and cultural intention by institutions that are approved or officially established for that purpose by the public authorities. Art. 62.-(1) Authors shall have a right to remuneration in the event of the lending of literary works Art. 63. After consultation with the institutions and the copyright administration societies, the King shall determine the amount of remuneration referred to in Article 62, Such remuneration shall be collected by the copyright administration societies.

A 'database' is a "collection of independent works, data or other materials arranged in a systematic or methodical way and individually accessible by electronic or other means". The publishers can thus argue that the set of articles in digital format constitutes a database.

A database could simultaneously receive both types of protection: copyright protection for the expression -the selection and arrangement of the data; and sui generis protection against the unfair extraction of a qualitatively substantial part of the data itself. The sui generis protection lasts 15 years, while the copyright protection lasts for the life of the author plus 70 years.

In respect of the expression of the database which is protectable by copyright, the "author" of a database shall have the exclusive right to carry out or to authorize: temporary or permanent reproduction by any means and in any form, in whole or in part and any communication, display or performance to the public.

Belgian law provides limitations on the rights set out where there is use for the sole purpose of illustration for teaching or scientific research, as long as the source is indicated and to the extent justified by the non-commercial purpose to be achieved.

In accordance with the Bern Convention for the protection of Literary and Artistic Works, this Article may not be interpreted in such a way as to allow its application to be used in a manner which unreasonably prejudices the rightholder's legitimate interests or conflicts with normal exploitation of the database".

In the Belgian law as well as in the legislation of the other European members, the actual laws on the copyright will change to fit the new European Directive and to integrate into the national laws what has been decided on the European level . Then the actual law can be considered as "temporary". It is the reason why we have focused our work on the European draft Copyright Directive.

When all the European Parliament and the European Council will adopt the Directive on harmonisation of certain aspects of copyright and related rights, the final decisions will have to be implemented into national copyright law. It is, usually, no longer possible to change the content of the Directive at a local level once the Directive has been adopted by the EU Council of Ministers. At the present state of the law, the Member States would keep some free options ; for instance, they have the option of applying exceptions to both the reproduction right and the communication to the public right in the case among others of use for the sole purpose of illustration for teaching and scientific research.

On 10 February 1999 the European Parliament voted in first reading under the co-decision procedure on the draft Directive. A large majority of MEPs (437 to 47, with 51 abstentions) adopted the text. The Amended proposal Directive for copyright Directive was presented by the European Commission on 21 May 1999.. It has in some aspects taken account of the concerns expressed by several associations (including EBLIDA) on the original text and on many of the proposed amendments by European Parliament. The amended wording concerning temporary copies and the improved wording on technical protection systems are especially welcomed as well as the special attention given to public establishments such as libraries or archives. But associations as Eblida judge that further improvements are urgently needed and will continue the debate of this draft Directive especially in the Council of Ministers.

The Directive would "adjust and complement the existing legal framework, with particular emphasis on new products and services containing intellectual property (both on-line and on physical carriers), so as to ensure a Single Market in copyright and related rights while "protecting and stimulating creativity and innovation within the European Union (EU)". In fact, the proposal wants to "represent a fair balance between the divergent and often conflicting rights and interests concerned. At the same time, adoption of the proposal will allow the EU to meet a significant part of its international obligations under the new WIPO Treaties and prepare the ratification of these Treaties by the Community".

It would in particular harmonise rules on the right of reproduction, the communication to the public right (including making protected material available on-demand over the Internet), the distribution right and the legal protection of anti-copying systems and information for managing rights".

The harmonised definition of the reproduction right would cover all relevant acts of direct or indirect reproduction, temporary or permanent, whether on-line or off-line, in material or immaterial form.

There would be an obligatory exception to the reproduction right for certain technical acts of reproduction dictated by technology but which have no separate economic significance of their own (such as certain 'cache' copies arising during transmission over the Internet).

The European Parliament requested a restriction for "documentation and conservation purposes". Both provisions thus do not cover essential user services such as copying of works which are longer available on the market, indexing, or copying for interlibrary loan.

Member States could, for example, maintain their current systems for compensating rightholders for private copying or photocopying. The Directive would not, therefore, introduce any obligation on Member States to introduce such private copying or photocopying levies or harmonise their level.

The market in "on-demand" services is one of the main areas of growth, with further technological developments to come. "On-demand" services are characterised by the fact that material stored in a digital format (such as texts, films, phonograms, software, or databases) is made available to the public or its individual members in such a way that they may access it and request its transmission individually with respect to time and place.

As the exploitation of works and other protected material in the context of "on-demand" services will, to a large extent, depend on EU-wide markets and a clear and coherent level of protection of these activities across Member States, the proposal would harmonise the rights applicable to "on-demand" transmissions.

In addition to the specific exceptions concerning the reproduction right, Member States would also have the option of applying exceptions to both the reproduction right and the communication to the public right in the case among others of use for the sole purpose of illustration for teaching and scientific research.

This means that not only exceptions for the digital environment will be very restrictive to take account of new technologies and to further EU harmonisation but also that existing national exceptions of the analogue environment will be reduced to the listed few. In the WIPO Copyright Treaty 1996, Member States are given permission "to carry forward and appropriately extend into the digital environment limitations and exceptions in their national laws which have been considered acceptable under the Bern Convention" and the agreed statement to article 1.4 of the WIPO treaty states that "existing limitations or exceptions apply in case of electronic information and the new exceptions should be provided for if needed. The EU Directive which is also aiming at implementing the WIPO Copyright Treaty is more restrictive than international treaties.

The proposed Directive would leave all exceptions that are listed (except for one) purely as options to the Member States, they might or might not be implemented into national legislation. Exceptions would be entirely unharmonised and without guarantee that they will be translated into national law to ensure that exclusive rights are still balanced by some exceptions in the public interest.

Moreover, when applying the exceptions, Member States would have to limit them to specific cases and to respect the economic interests of rightholders. The WIPO Treaty imposes this "three-step-test (an economic prejudice test) to validate any exception to the copyright. The national tribunals will probably appreciate those terms in a various and different way but the European Court of Justice will give an univocal interpretation that will allow any distortion of concurrence between Members States.

All exceptions to copyright (except disability and library exceptions) are linked to fair compensation to rightholders. The precise form of such compensation (which may, but does not have to take the form of levies on copy shops, sales of blank tapes and equipment, as exist in most Member States) would be up to the Member States to decide in accordance with their legal traditions and practices.

EBLIDA affirms that the article 5.3 must be revised allowing the members to have exceptions for the use and the copy of documents for purposes of education, formation, research and private uses according to the fair uses.

Another problem is the exact definition of the mention "to the extent justified by the non-commercial purpose to be achieved" in article 5.3. It is difficult to qualify Research because there are links between academic and scientific research with commerce and industry and it would be difficult to separate what is commercial and what is not. Moreover, there is no proof that copying insubstantial amounts for commercial research prejudiced the legitimate interests of the rightholders or conflicted with a normal exploitation of their works.

The distribution right provides authors with the exclusive right to control any form of distribution to the public by sale or otherwise of the original of their works or tangible copies of their works (e.g. on paper, CD, CD-ROM, tape, as opposed to on-line form). The distribution right does not apply to services in general or on-line.

The proposal would confirm that the distribution right shall be exhausted within the EU with the first sale or other transfer of ownership within the EU of the original of their works or tangible copies of them by the rightholder or with his consent (the principle of "Community exhaustion"). Under this principle, once an author has agreed that tangible copies of his work may be sold in one Member State, these copies can be sold throughout the EU. Currently, some Member States consider the right to be exhausted even if the ownership sold or transferred concerns territories outside the EU ("international exhaustion").

This system, which was agreed upon by consumer electronics manufacturers and copyright owners, prevents the making of digital copies of a digital copy. In other words, SCMS systems allow one copy to be made of a work, but prevent copies being made of that copy Other technical measures effectively prevent the making of any copies of digital works.

States to provide adequate legal protection against any activities, including the manufacture or distribution of devices or the performance of services, which would enable or facilitate the circumvention without authority of effective technological measures (such as application of access codes or decryption) designed to protect any copyright or related rights.

Similarly, Member States would have to provide adequate legal protection against any person who, without authority, removes or alters electronic rights management information or distributes, imports, broadcasts, communicates with the public or makes available copies to the public works or other subject matter from which the electronic rights management information has been removed or altered without authority.

The amended proposal for a Directive has taken on board the immensely important distinction between the circumvention of technical protection systems for lawful purposes and the circumvention to infringe copyright. Only this distinction ensures that technical blocks cannot stop legally permitted copying. The amended recital 30 recognises that circumvention should be prevented if done without authority but that the necessary authority could be either given by the rightholder or conferred by law. The new recital ensures thus that rightholders cannot unilaterally impose technical protection systems. Currently, the corresponding article 6 does not reflect this important principle.

Libraries have now entered a very different regime governing the way in which electronic information is distributed: the regime of the contract or the licence, which has now become the prevailing mode of publishers for authorizing the delivery of electronic information.

The licence, or the contract, is a different thing from copyright. Licencing means giving rights to use property without transferring ownership. Under the terms of a licence, the library, or the university, owns nothing at all, but it does have certain rights to use information in certain ways. In fact, in the networked environment, there is rarely a tangible artifact that one can own, particularly if the information is mounted on a remote site, for example a publisher's site. There is no object to own.

A licence is additionally an agreement negotiated between two parties: a willing owner (a willing publisher) and a willing customer, just as with one's apartment contract. The licence is thus very much a marketplace arrangement.

A licence is, furthermore, an agreement that describes absolutely every part of one's deal with an information producer: who can use the information, when they can use it, how they can use it, how much they can do with it. The licence describes the technology conditions that exist. The licence describes the price, the term of the contract and the kinds of promises that both parties make to each other about the deal.

A licence is, most of all, a legal agreement. It binds the two parties that sign it. It is signed by responsible parties who have the authority to sign for the publisher and customer. Thus, librarians these days have not only to understand how copyright works in relation to printed and traditional material, but they are starting also to need to understand how contract law works. A copyright owner (in many cases the publisher) sends a licence agreement that is actually an invitation to negotiate the terms and conditions under which the product(s) can be used. Most of the licences are written by lawyers and the technical language used puts many librarians off reading it.

Because these publishers believe that copyright law cannot control the re-distribution of information in electronic formats, and because librarians want to utilize electronic information in their institutions, the producer community has moved to using contracts instead of copyright law.

In theory, there is no reason why fair dealing and the library copying exceptions cannot be applied to information in digital format. The printed book or journal environment provided limited physical access over which control was exercised in accordance with long established protocols The problem is that digital technology has made it easier to make copies of protected works. Digital formats are readily accessible at any desktop at any time. They can easily be stored, reproduced, re-utilized and disseminated from anywhere to anyone in the world without loss of authenticity or quality. It allows for conservation and preservation of the library stock. Protected material is thus much more vulnerable. Publishers are thinking that potentially, unauthorized copies can be substituted for purchase and that the revolution in computer and telecommunications technologies requires a new consensus on the management of information in order to maintain the efficient flow of information from author to reader.

Furthermore, at the moment, there is no consensus yet at the US national level or at the European level about how copyright applies to electronic information. The publishers believe that current copyright law cannot control the re-distribution of information in electronic formats, and because librarians want to utilize electronic information in their institutions, the producer community has moved to using contracts instead of copyright law, so that the market will advance.

A director at the Publishers Association declares : "Copyright licencing has developed throughout the world as the main solution to problems caused by photocopying and electronic copying. (...) the system of copyright licencing will be the base on which we build a new electronic architecture".

Technical controls are another way to protect electronic document. Electronic Copyright Management Systems (ECMS) such as encryption, tagging, digital fingerprinting, data identifiers, watermarking etc. are being perceived as the obvious answer to piracy. Depending on their sophistication, these will be able to track and control movement of works in digital form.

In the past, the ILL regulations guaranteed the necessary level of information for researchers and students. Even if the library was no longer able to subscribe to a journal for financial reasons it was accepted that it could provide a user on demand with a copy from a published work which was supplied from another library via inter-library loan.

The trend in publishing is for "on demand delivery" of articles to individual users. Libraries have conducted this service for several years and have delivered articles to individual users by mail, fax and electronically. Currently, many information suppliers are specifically targeting end-users and offering them direct document access, retrieval and delivery.

ILL provided by libraries. At the ECUP meeting, the publishers have affirmed that "The electronic delivery of information significantly changes the commercial relationship between publishers and user groups. Electronic uses of copyright material will be facilitated by individual contracts between publishers and user groups, including librarians. Such contracting will allow for Electronic Document Delivery (EDD) directly from publishers to users and this excludes Inter-Library EDD carried out in the name of ILL. One way forward might be the development of a model contract between publishers and user groups". For them, ILL should be treated in the same way as Electronic Document Delivery and should not be a free activity.

Although there exists no empirical evidence that fair use causes material or undue harm to providers, many information providers nonetheless are seeking to discontinue the well-established principle of fair use, and they are using the new electronic environment as the reason and means to do so. They consider that they are in an economic competition with libraries.

EBSCO and Harrasowitz) have cooperated to create a suite of generic standard licences for electronic journals. The licences are intended to help publishers, subscription agents and libraries to create agreements that express what they have jointly negotiated. They do not prescribe the outcome of negotiations, but are designed to account for the varying needs of different types of customers, and the requirements and policies of different publishers. They are international in application and are the result of consultation with librarians, publishers as well as the subscription agents. The licences are voluntary-based and open to anyone wishing to adopt them, as they are in the public domain. They are available on the website: http://www.licencingmodels.com.

Concerns over the effectiveness of the copyright system in a digital environment have inspired rightholders to look for alternative protection regimes or strategies. Beside contract law, ECMS is also a potential substitute for the copyright regime. Technological measures will be applied mostly in combination with contract. The measure constitutes both the starting point and the final touch to the contractual relationship between information provider and consumer. The combination of both instruments poses a direct threat to the copyright system.

In any event, any prohibition on acts of circumvention should be limited to circumvention for purposes of infringement. This will ensure that the contours of any anti-circumvention prohibition will be conformed to those of copyright law. Under this approach, anyone who circumvented a technical measure for purposes of making and distributing unauthorised copies of a work would breach not only copyright law, but also the contiguous prohibition on circumvention for purposes of infringement. On the other hand, someone who disabled a technical measure to facilitate the making of a copy permitted by law -- for example for purposes of engaging in acts permitted by a scientific research exception -- would fall outside the prohibition. In short, by prohibiting the disabling of a technical measure for purposes of facilitating an act restricted by copyright, but not prohibiting circumvention for purposes of facilitating a permissible act, legislators would respect the boundaries of copyright.

The European amended proposal has taken on board the immensely important distinction between the circumvention of technical protection system for lawful purposes and the circumvention to infringe copyright. Only this distinction ensures that technical blocks cannot stop legally permitted copying. The amended Recital 30 recognises that circumvention should be prevented if done without authority but that the necessary permission could be either given by the rightholder or conferred by law.

In the digital environment, access to the electronic periodicals is bought via a licence which is regulated by contract law. The introduction of contract law to regulate the use of digital resources has focused on the question of the status of copyright exceptions.

In contract law information producers, intermediaries and end users are free to create their own rules, without government intervention. However, freedom of contract may become contractual coercion, especially when dominant undertakings abuse their market power to impose contractual rules.

Copyright exceptions were introduced in first place to balance the monopoly of the rightholders to safeguard access to information in the public interest without having to ask every single time for permission, and to be able to copy a reasonable amount of a work that would not be in conflict with the normal exploitation of that work. It is therefore essential that copyright exceptions are kept in the digital world as they ensure that licences can be agreed between a rightholder with almost exclusive rights and a user being able to rely on at least a few fair practice exceptions that are guaranteed by law.

In fact, at the moment, the large-scale application of contracts is disturbing the delicate balance between intellectual property and information freedom, because the rightholder's intention is now to replace all legal copyright exceptions with negotiated licence agreements.

Assuming that contracts concluded over the Internet are valid in principle, the question arises whether the terms of these user licences can override the statutory limitations of copyright. Does an information producer have the right to contractually subject a user to restrictions that go further than copyright law prescribes?

The overridability of copyright limitations is a bigger problem in the digital environment than in the analogue world, where everyone relied on copyright law to set the limits of permitted action. The question of the overridability of Copyright Limitations by Contractual Agreements is currently the object of much attention in the United States, where this question has already led to extensive legal discussions, case law and even legislative initiatives. In Europe, the discussions have only recently begun. This difference between US and Europe may be due to the fact that copyright rules are not subject to constitutional pre-emption in any of the Member States, and no provision similar to paragraph 301 of the U.S. Copyright Act has been enacted as a consequence.

European legislature has already expressly enacted copyright limitations of a mandatory nature. In rare cases, the legislator has avoided possible conflicts between contract law and copyright law by expressly providing that copyright rules have precedence over any contractual provision to the contrary. This is the case of the directives on computer programs and databases, which both contain provisions stating that contractual provisions, which prevent users from accomplishing specific acts allowed therein, are null and void.

But besides the rights given to users under the Computer Programs Directive and the Database Directive, the question of overridability of user freedoms has been the object of little attention from legislators and authors in Europe. Moreover, whereas both of these directives specify which exemptions may not be set aside by contractual agreement, the Proposal for a Directive on the harmonisation of certain aspects of copyright and related rights in the Information Society keeps silent on this issue.

Memorandum, the Commission puts much importance on contractual relationships, as a means for information producers, intermediaries and end users to determine directly the conditions of use of protected material generally through the negotiation of licences between rights owners and users. Under any one of the legal systems in force in the Member States, freedom of contract is the rule, and contractual restraints the exception.

However, in the same text she specifies that "in contrast, we submit that restrictions implemented in favour of schools, libraries, archives and museums should not be immune to contractual overrides. Because, in the digital environment, the involvement of public libraries in the sphere of electronic document delivery is increasingly considered as coming in direct competition with the services of publishers or other commercial information providers, thereby affecting the normal exploitation of works and the legitimate interests of rightholders".

In the current amended proposal of the European directive on copyright, all the exceptions outlined are subject to the so-called three step test meaning exceptions allowed only for "certain specific cases and shall not be interpreted in such a way as to allow their application to be used in a manner which unreasonably prejudices the rightholders? legitimate interests or conflicts with normal exploitation of their works or other subject matter.". Publishers have started to set up electronic document delivery services themselves. It is thus possible that they use this directcompetition with the "normal exploitation" of the work as an argument to limit the exceptions allowed to libraries in the directive.

Group recognises that the term "normal exploitation of a work" must be interpreted, when "in an electronic environment, a library service does not compete with a similar service or product obtainable from the publisher", that means for instance that " if a library wants to digitise material which is already obtainable in electronic form from the publishers, or when the library delivers to a remote user an article which the user could have obtained from the publisher, it is in conflict with the normal exploitation of a work. However, it adds that "being in conflict with the normal exploitation of a work should not imply that libraries cannot provide the service. It simply means that the library has to pay royalties to the copyright owners for the material sent to the users".

Because there is only little information currently available on the true economic impact of the activities of public libraries on the electronic exploitation of protected works, it is difficult to determine the proper form and scope of any possible limitation intended to benefit public libraries with respect to the digital environment. Ultimately, such a limitation, if needed at all, would have to take into account the interests of the rights owners, as well as the information and cultural policies at the root of the public library system.

In the meantime however, many believe that the existing limitations should not apply in the case of electronic document delivery, which would therefore be subject to the rights owner's authorisation. This is in fact the position adopted by the European Commission in relation to the current draft of the Proposal for a Directive.

The aim of the Directive is and the exception for library are obvious, but the service supplied by the Inter-Library Loan department can also argue another exception allowing reproduction for purpose of illustration for teaching and scientific research. However, the purposes in this exception could be too restrictiveand the "three-step-test" condition of the Bern Convention is also applied on this exception. Moreover Recital 29 that points out that "global solution must be sought within the framework of contractual relation" is also valid for this exception.

Lucie Guibault points out that "Before deciding whether to enforce such a contract against a particular user, it is quite conceivable that a court would first examine whether this contractual agreement runs contrary to established copyright policy and whether its enforcement would be in the public interest. In practice, the court may be further influenced by the fact that the obligations derive from a fully negotiated agreement or from a standard form contract. A court may also confer different weight to the several copyright limitations, as a result of an analysis of their grounds for adoption and a review of the public policy at stake".

As we have said every electronic document delivery service conducted by libraries can be considered as in direct competition with the "normal exploitation" of the work as laid down in Art. 9 (2) of the Bern Convention. However, some persons consider that being in conflict with the normal exploitation of a work should not imply that libraries cannot provide the service, but that it simply means that the library has to pay royalties to the copyright owners for the material sent to the users.

The European amended proposal Directive imposes now that "the rightholders receive fair compensation" to compensate for their prejudice in the case of reproduction on paper, private copying and illustration for teaching and scientific research. The precise form of such compensation would be up to the Member States to decide in accordance with their legal traditions and practices.

If the rightholders receive fair compensation, they will not call up the "three steps" anymore to unauthorised the ILL with their electronic journals. But this situation has some limits : the new system could be seen as a kind of pay-per-view system because compensation will be asked for each consultation or each communication.

Moreover, the lack of any provision for fair practice exceptions in the EU Copyright Directive for commercial purposes will mean that, in industry and commerce as well as in many research projects carried out in universities, all copying and uses of copyright works will have to be paid for. In the longer term these costs could have a considerable inflationary effect.

With the new Directive the library user could be forced to pay-per-view for digital information that he or she would get now free of charge in the library. Libraries will pay via a licence for the right to make digital information available for their normal users, like they are paying now for books and journals which they also buy to make them available for their users.

At the moment, there is no provision in the new European Directive that would ensure that contract law cannot override copyright law. The Directive needs thus mandatory exceptions and a new article similar to Article 15 of the Database Directive that ensures that any contractual provisions contrary to these exceptions shall be null and void. Mandatory exceptions could then not be ignored in contract or licence agreements. In the European countries it allows access to information held in copyright works without having to always ask for permission and to allow fair copying for private, educational and research purposes that cannot be wiped off by contracts. Currently, the proposal directive is defending another politic : it says that " the exceptions referred to in Article 5(2) and (3) must not, however, prevent the definition of contractual relations designed to ensure fair compensation for the rightholders".

For the avoidance of doubt nothing in this Licence shall in any way exclude, modify or affect any statutory rights which may from time to time be granted to libraries and their users under the applicable national Copyright law.

Finally, if no solution can be found, libraries have to pay attention to the law chosen for the interpretation of the licence and the court chosen for submitting a claim against the Publisher or the Library. The Rome Convention of 1980 governs the legal question concerning contractual obligations. First, it grants the parties freedom of choice regarding the law applicable to their relations, and in the absence of choice, it stipulates that "the contract shall be governed by the law of the country with which it is most closely connected."

"It shall be presumed that the contract is most closely connected with the country where the party who is to effect the performance which is characteristic of the contract has, at the time of conclusion of the contract, his habitual residence." The law thus chosen will apply without prejudice to the principles of the Treaty, in particular the principles of free movement of goods and services.

The choice of the law is a fundamental clause of the contracts. In most licences it is the law that is most suitable for the Publisher. From a perspective of cost, it is advisable that libraries amend this clause to the law and the court that is most convenient for them. It can be difficult to end up using US law for the interpretation of the licence and having to go to a US court to advocate the case.

In this part of WP3 we look at the developments in the legislation concerning encryption. First we will have a look at the international laws and directives; then at the regional developments in the European Union.

We are concerned by the legislative aspects of encryption because we want to know whether we are violating the law and because we want to have a background if we decide one day to use encryption technologies.

At this time the VirLib system does not use cryptographic methods to authenticate the users nor to protect the integrity of the document. For the authentification of the users VirLib uses IP-filtering in combination with a login and password.

The integrity of the document is not really protected but the document contains a copyright notice that appears only when the document is transmitted through VirLib-Impala. The privacy of the end users is preserved by the use of "dynamic" URLs, each newly delivered document has a URL based on two random numbers. In addition none of the documents is accessible for more than two months. The technical aspects concerning the authentification of users and document integrity are treated in the last part of this workpackage.

Multilateral Export Controls) was an international organisation for the mutual control of the export of strategic products and technical data from country members to proscribed destinations. It maintained the International Industrial List and the International Munition List.

This organisation allowed export of mass-market cryptographic software, including public-domain software, since 1991. The main goal of the COCOM regulations was to prevent cryptography from being exported to dangerous countries, export to non-dangerous countries was usually allowed, although states often required a licence to be granted.

The so-called Wassenaar Arrangement is an arrangement on Export Controls for Conventional Arms and Dual-Use Goods and Technologies. Dual-use goods are goods that can be used for both civil and military purposes. Certain cryptographic products, along with other technology are stated as such.

Australia, New Zealand, Russia and the US did not apply this Note and control the export of mass-market and public-domain crypto software. There is a personal-use exception allowing the export of products when they are accompanying their user for the user's personal use (e.g. on a laptop). Also it seems that export via the Internet is not covered by the Note.

The Wassenaar Arrangement has been revised in December 1998. As a result the General Software Note is submitted to some restrictions but there are some relaxations to e.g. export of products that use encryption to protect intellectual property.

States agree to control dual-use goods "with the objective of preventing unauthorised transfers of those items". In addition they agree to exchange information "in order to consider, where necessary, the scope for coordinating national control policies to combat these risks".

Cryptography Policy of March 1997 is often mentioned as a basis for legislation concerning encryption, on regional as well as on national level. The Recommendation is a non-binding agreement that identifies the basic issues that countries should consider in establishing cryptography policies at the national and international level.

The guidelines are based on some considerations concerning the rapid development of the global information and communication network and it's important impact on the worldwide economic development. The users of information technology must have trust in those infrastructures, networks and systems; and in the confidentiality, integrity, and availability of data on them; and in the ability to prove the origin and receipt of data. Because of the vulnerability of the data to threats to its security it is important to ensure the security of data through legal, procedural and technical means. The guidelines recognise that cryptography can be an effective tool for the establishing of a secure network by providing authentication and non-repudiation mechanisms for the data on it. In addition cryptography has a variety of applications related to protection of privacy, intellectual property, electronic commerce, etc. They include the need for law enforcement and public safety, but also the need for compatible encryption policies as part of interoperable networks.

The fundamental rights of individuals to privacy, including secrecy of communications and protection of personal data, should be respected in national cryptography policies and in the implementation and use of cryptographic methods.

Governments should co-operate to co-ordinate cryptography policies. As part of this effort, governments should remove, or avoid creating in the name of cryptography policy, unjustified obstacles to trade.

These principles should be seen as "interdependent and should be implemented as a whole so as to balance the various interests at stake. No principle should be implemented in isolation from the rest."

Some see the OECD principles as a victory for privacy over US key recovery, but the principles are vague enough to allow a broad interpretation, and states can choose a privacy-oriented or a law-enforcement-driven policy as the principles do not endorse nor prohibit key recovery.

"Contracting Parties shall provide adequate legal protection and effective legal remedies against the circumvention of effective technological measures that are used by authors in connection with the exercise of their rights under this Treaty or the Bern Convention and that restrict acts, in respect of their works, which are not authorized by the authors concerned or permitted by law."

Technology, the Council of Europe stated that "measures should be considered to minimise the negative effects of the use of cryptography on the investigation of criminal offenses, without affecting its legitimate use more than is strictly necessary". Nevertheless there is no mention of which measures nor how the balance could be found in the "conflict of interests between the needs of the users and law enforcement".

The recommendation also states that "specific obligations should be imposed on operators of public and private networks that offer telecommunications services to the public to avail themselves of all necessary technical measures that enable the interception of telecommunications by the investigating authorities" and "specific obligations should be imposed on service providers who offer telecommunication services to the public, either trough public or private networks, to provide information to identify the user, when so ordered by the competent investigating authority".

The main change for cryptography in this proposal is that for the export of cryptographic products within the EU the licences should be replaced by simple notifications and that controls should include the export through intangible means.

A draft proposal on a Europe-wide network of Trusted Third Party Services states that the provision of certification services should be done by private Trusted Third Party Services. This draft proposal drew attention to a public key infrastructure, but also dealt with the legal access problem through key recovery.

The EU Council Resolution on the lawful interception of telecommunications (96/C329/01) contains a requirement for network operators and service providers using cryptography to provide intercepted communications to law enforcement agencies "en clair".

"In order to make good use of the commercial opportunities offered by electronic communication via open networks, a secure and trustworthy and trustworthy environment is therefore necessary. Cryptographic technologies are nowadays widely recognised as the essential tool for security and trust in electronic communication.

The Communication describes the tasks of certification authorities (certificates and key management), the need for mutual recognition of certificates issued by foreign certificate authorities and the legal problems. The most important one results from the different national rules and regulations, in particular the absence of common requirements for certification authorities, of technical and operational requirements to be met by certain categories of digital signature products, of liability rules and legal recognition of digital signatures.

In January 1996 Belgium noticed that it had a law that may prohibit the use of non-escrowed encryption. In December 1997 this law was amended to expressly allow the use of encryption. The provision of indicated encryption services is in the hands of the Belgian Institute of Post and Telecommunications.

June 1998 "Modification du droit de la preuve". This modification states that a document with a digital signature is an original when it is proved that the integrity of the content of the document has been preserved.

In March 1999 the Belgian Government adopted an "avant-projet de loi" concerning the certification authorities with regard to the digital signature. The proposed technology to be submitted to a regulation is the technique based on asymmetric cryptography combined with the utilisation of a certificate delivered by a recognized certification authority.

A press release of 27 August 1999 of the Ministry of Economic Affairs specified the new export controls, which stated that export controls for mass-market cryptography are limited to the absolute necessary. Mass-market crypto export within the EU has already been liberalized by the EU. Except for export to a few countries or for sensitive (military) applications, companies can now decide themselves whether a product falls within the category of mass-market crypto for which a general licence suffices. There is no general requirement to declare, but exporters must be able, when requested, to hand over the specifics of exports. When in doubt, the Federal Export Agency (BAFA) will help (see address list).

The government does not intend to restrict the free availability of cryptography. It considers the use of safe cryptography as a necessary condition for protection of data privacy, for the development of e-commerce and for the protection of business secrets. It will actively support the spread of secure encryption in Germany. This includes especially the promotion of the security awareness of users, companies and the administration.

The government will try to increase users' confidence in the security of encryption. It will therefore take measures to establish a framework of trust for secure encryption, especially by improving the verifiability of cryptographic products on their security functions and by recommending the use of verified products.

The government will not let the spread of strong cryptography erode the interception powers of the law enforcement authorities and the security service. The competent ministries will therefore closely follow up the developments and issue a report after two years.

The government greatly values the international cooperation in crypto policy. It will advocate market-driven, open standards and interoperable systems and promote a stronger multilateral and bilateral cooperation .

If encrypted information is found in a computer during a house search, the police can order anyone who can reasonably be supposed to know the means of encryption to decrypt the information (article 125k section 2 DCCP). The command cannot be given to a suspect (article 125m DCCP).

In March 1994, a Dutch predraft law on cryptography leaked out, the drift of which was a prohibition of having, using, or trading strong cryptography. The government wanted to restrict cryptography in order to maintain the capability of tapping all possible communication channels. Only those with a "legitimate concern" could apply for a user licence or a trade authorization. One condition for granting a licence was giving information to an administration agency; the text did not state whether this information concerned only the algorithm or also all the keys used.

At a December 1996 public debate on cryptography, representatives from the Ministries of Economic Affairs, Transport (responsible for telecommunications) and the Interior clearly were in favour of the use of a key-escrow scheme, in line with (their interpretation of) the OECD discussions. Such a scheme would initially be voluntary and left to market self-regulation. However, the Ministry of the Interior official (responsible for national security) stated that, although he did not think primarily of legislation, in the long run, use of non-escrowed encryption could give rise to (criminal) suspicion by law-enforcement, thus effectively mandating escrowed encryption.

Thus, if the police encounters encryption in a wiretap, they could command the conversing parties to assist in decrypting. In the draft new Law on Intelligence and Security Services, a similar power would also be granted to the national security agencies. Initially, the draft Computer Crime Act II (version of January 1998) also proposed to extend the power of the police to demand decryption to be given to suspects, in case of serious evidence against the suspect and if this is urgently necessary for finding the truth. After protests from the legal community against this infringement of the privilege against self-incrimination, this provision was deleted from the draft.

For legal access, a "partnership approach" of government and industry should develop a "set of instruments acceptable to all parties" that ensures government access to encrypted data. "If industry does not participate sufficiently actively in developing said set of instruments, the government will emphatically consider to fulfil the need for legal access with further legislation."

EU Member States. Crypto export by intangible means (i.e., over the Internet) is not covered by the regulation and is therefore free, if one does not export to embargoed countries and conforms to the Official Secrets Act (copyright, patents, and contracts). The Department of Trade and Industry (DTI) advises to apply for a licence anyway, and to consult a lawyer. In July 1998, DTI released a White Paper on Strategic Export Controls, which at 3.2 proposes to extend the controls on exporting crypto software to intangible transfers. Under such a policy, also exports by fax and email should fall under the export controls. The text of the current regulation can be downloaded at DTI's Control List page.

Nigel Hickson of DTI stated that export controls for approved products should be lifted. The policy Paper on regulatory intent concerning use of encryption on public networks of June 1996 announces that export controls will remain in place, but that the government would try to simplify export controls for encryption products used by licenced TTP's. This announcement was repeated in the Consultation Paper of 19 March 1997 on Licencing of Trusted Third Parties for the Provision of Encryption Services. In the April 1998 policy announcement, DTI commits itself to working internationally on the "updating and streamlining" of export controls, and this is repeated in the March 1999 consultation document.

Select Committee, in its report of 18 May 1999 on this consultation document, recommended "that the Government consider the case for a review of the rationale for the continuation of export controls on cryptographic products, in the light of their widespread availability, and the procedures by which such controls are implemented."

Article 10 of the draft bill contains a power to require disclosure of a crypto key. For encrypted material lawfully obtained, a written notice can be given to a person who appears to be in the possession of the key, to provide the encrypted information in intelligible form (that is, in the condition in which it was before any encryption or similar process was applied to it), or, if the notice explicitly orders so, to disclose the key. A notice cannot require disclosure of keys intended only for authentication that have not in fact been used for other (i.e., confidentiality) purposes. The notice needs to be authorized by the appropriate authority (depending on the powers under which the encrypted material was obtained), such as the Secretary of State, a judge, or a senior police officer.

Failing to comply with such a notice is an offence punishable with up to two years' imprisonment. It is a defence to show that you do not have the key, if you give sufficient information to enable possession of the key; likewise, it is a defence to show that it is not reasonably practicable to disclose the key, if you show that you provided it as soons as this was reasonably practicable.

If the notice to provide a key requires secrecy of the giving of the notice, of its contents and of the things done in pursuance of it, tipping off someone about this is punishable with up to five years' imprisonment (with several defences, such as informing a legal adviser). Various safeguards are proposed to limit the use of the keys obtained through a notice. A Code of practice will be issued about the exercise of this power, and a Commissioner will be appointed to oversee the use of this power.

Although key escrow is not contained in the draft bill, concerns were raised that a key-escrow requirement might feature in secondary legislation, as a condition for approval as a Registered Cryptography Service Provider.

Because of the many critical reactions to the crypto proposals, the decryption power provisions were lifted from the Electronic Communications Bill in November 1999, in order to be reinserted in the Regulation of investigatory Powers Bill.

The new proposal adds proportionality and goal requirements (required to comply with the European Convention on Human Rights), stating that the decryption command must be necessary for national security, crime prevention or detection, or for the UK's economic well-being, or must be likely to be of value for the exercise of a statutory power.

The penalisation of not complying with the decryption order is extended with the requirement that a person is guilty only if he has or has had possession of the decryption key. (As I read it, this means that the burden of proof lies with the Prosecutor to show that the addressee (at one time) possessed the key, while (presumably after this has been argued) the burden of proof to show inability to decrypt lies with the addressee.) The tipping-off offence is limited by adding that the police can only require secrecy if the police obtained the encrypted material at stake through a means that it is reasonable for law-enforcement to keep secret.

The exponential growth in the production of knowledge, the decreasing resources and the rising costs of books and journals have made it more and more impossible for the individual library to purchase all the information relevant to its users.The effect has been that libraries have become more and more dependant on interlending and document supply and many regional, national and international cooperative schemes have been put into place.

Inter-library Loan (ILL) of printed material has long been an accepted activity in the print world. In an electronic environment, the term ILL and the activity itself are hotly contentious issues. The electronic periodics are bought via a licence that often do not allow ILL. For several years, librarians and publishers have been trying to reach a common position. One of the obstacles in reaching agreement is the lack of clear definitions that cover the wishes of librarians over how they propose to share their resources.

First of all the term loan suggests that the material is sent back at one point in time. This is only the case for books in the print environment but not for material in the electronic environment. Terms that could cover the activity more accurately are Inter-library Resource Sharing and Inter-library Use. As long as this is limited to sharing the information between libraries(that is the case in VirLib) and not with third parties, these terms could be used alongside on demand Electronic Document Delivery to end-users (third parties).

Inter-library Loan in an electronic environment has not been a subject of extensive research. There is more research material available in the area of Electronic Document Delivery. At the moment, it is difficult to precisely define the copyright status of electronic document delivery in many European countries.

It concerns only the delivery methods which directly use documents in their electronic version to make ILL. The paper journals are not concerned by the licence's restrictions. The allowed uses for the paper document are only concerned by the Belgian and European copyright laws.

The licence terms are often not precise enough about the authorised uses that can be made from the electronic journals. The ILL is usually not authorized by the publisher or it is allowed under a lot of restrictive conditions.

In the licences agreement, there are often some clauses describing authorized users of licenced information. An "Authorized User" is "a person designated in a Licencing Agreement as having permission to access or otherwise use the digital information that is the subject matter of the agreement" . Licences set out who may access licenced information, when users may access it, and what they can do with the information after they have it. Agreements often include provisions expressly forbidding access to certain persons or entities or limiting the circumstances under which permitted users may access licenced materials.

Articles may be forwarded to other members of the institution but no dissemination to individuals who are not members of the institution should take place. The electronic version may not be used for inter-library loan.

When ILL are allowed, the licences often give restrictions like:  The request must come from and be sent to a library (not directly to an individual) and the requesting library must be a non-profit library (e.g. educational or governmental). (...) They cannot sent ILL copies from the files to libraries in for-profit institution."

The electronic form may be used as a source for Inter Library Loan whereby articles can be printed and these print copies be delivered via postal mail or fax to fulfil ILL requests from an academic, research or other non-commercial library. Requests received from commercial, for-profit companies or directly from individuals may not be honoured.

Electronic editions of journals of those publishers can now be used to satisfy interlibrary loan requests, but only printing out requested articles and sending them out in the printed form. Libraries will thus have the same functionality as before (or even better, since there will be no need to find volumes on shelves and make photocopies).

Sciences or Swets & Zeitlinger allow obviously that the hard copy is used for ILL (in the limitation imposed on interlibrary loans of paper copies), moreover they do not specify any precise methods of delivery.

Most of the time, publishers who allow to use the electronic files to make ILL, add a number of requirements that limit the ILL or that are too complicated to be met. For instance, Elsevier is asking the lending library to report twice a year (in July and January for the preceding six months) on to whom (what library) articles have been sent, by journal title, publication year and number of copies. These reports are asked among others to monitor quantity limitations. If the number of copies provided in one calendar year for any one journal title to any one library exceeds five articles, the lending library (that is, our licencee) may be asked to pay a fee on all additional copies at the standard document delivery copyright royalty rate. Elsevier Science will bill for those charges after it receives the reports. Libraries, of course, have the option to supply only up to five copies and turn down ILL requests over five.

If the current tendencies are confirmed, only the publishers will be allowed to use directly the electronic version of journals and the libraries will be only allowed to use and to send a paper copy of them for ILL because publishers consider the reuse of their electronic document by the libraries as a direct competition with their interests.

We can already see this in the licence conditions for hybrid journals that appear both in print and electronic formats. Publishers of such journals almost universally allow only the print version to be used for interlibrary loans. Although no publisher has explained clearly the rationale for this restriction, it is easy to figure out its role. Obtaining a copy of the paper article is slow, cumbersome, and expensive, and this serves to deter wide use of interlibrary loans as substitutes for owning the journal. If interlibrary loans of electronic versions were allowed, though, the borrower would be in almost the same position as a subscriber. Even if only paper copies of electronic versions of an article were allowed, the ease of making the copy from the digital form and mailing it out would make interlibrary loans much faster and less expensive, and that might undermine the market for subscriptions.

This situation is also dangerous for the libraries because they can propose a direct end-user access to this information, at prices that go far beyond the current Inter Library Loan prices. Furthermore, as we have said, the current Directive links the exception for the purpose of illustration for teaching or scientific research with the principle of fair compensation for rightholders This could endanger the free flow of information, scientific communication, and public education.

Many publishers, meanwhile, reject fair-use arguments as a basis for encouraging unauthorized reproductions of electronic works, and they have been pressing for new technological and legislative protections.

At the moment, there are too much differences between the publishers. Even if some model licences are now appearing, the licences currently proposed by the publishers have not been homogenised yet. The library can not manage all this diversity of licence terms. Therefore, a daily ILL politic using the electronic files cannot be considered currently.

They are interdependent and they need to co-operate to face the problem of the increasing price of the serial publications and the reduction of their resources. The current Inter Libraries Loan is based on the principle of reciprocity between the affiliated Belgian libraries. The Belgian ILL system has to respect the autonomy of each institution.

A survey was done in 1996 to know what kind of service is expected from Belgian ILL by the user. This survey has shown that there is a strong demand for an electronic document supplying. Users want a faster transmission process. They want to receive the electronic document via e-mail and also want to be allowed to print them. The users want to reduce the time needed to receive an ordered document. The proliferation of computer technologies has significantly influenced user expectations on document delivery services.

VirLib adds a new functionality to the Belgian interlibraries loan service Impala. The VirLib approach to electronic document delivery focuses in fact on the electronic delivery of documents that previously existed in print format. The term electronic stands for the use of telematics applications for the submission, follow-up and delivery of ILL requests.

In the technical annexe, the promoters of the project have given a definition of the project as follows: "the first phase of the project has developed an electronic and modular pilot system of ordering and delivering documents. The second phase of VirLib wants to develop a real delivery service of electronic document added to Impala, i.e. the Belgian system of managing and transmitting interlibrary requests for loan.

In other words, the system VirLib will enable the interlibrary loan department of any scientific libraries affiliated to the Impala network to deliver directly to the user's workpost, in electronic format, any article asked for by the user in question."

We have then to consider all the possible ways that can be used to deliver a document through the Impala system and the VirLib System. First we will try to identify the different ways of delivering a document. Secondly, we will study each of those ways from the point of view of the copyright problem. We will take account of the actual Belgian law on the copyright and of the future European directive but we also will take account of the "authorized uses" specified in the licences.

There is a great difference between the paper journals and the e-journals. The original support of the periodic implies what users can do with it. Paper journal and print information are governed by copyright law but electronic information is accompanied by contracts, rather than governed by copyright law : the librarian buys access to the electronic copy for a specific period of time and usage. This is the reason why the ways of delivery using the same original support are gathered together.

It is the traditional ILL process to deliver a document. The ILL service makes some photocopies of the requested article and sends it by traditional mail. The user receives a paper copy of the article.

This second method is the same as the method used by Ariel. With Ariel software, the ILL department scans documents directly and transmits the electronic file to other Ariel workstations anywhere in the world, using either FTP or e-mail; and prints them out on a Windows-compatible printer. Then the document can be sent to someone who has access to MIME e-mail, enough electronic mailbox capacity, and access to a TIFF viewer.

This method directly delivers the electronic version of the document to the user. The ILL department of the request library receives the file and stores it on its server. It sends the user an e-mail with the clickable address of the file on his server. This method is justified by the user's need to receive the document as quickly as possible.

The first objective of VirLib II is to simplify and to accelerate the delivery of document. VirLib aims at reducing the time span between ordering by and actual delivery to the user. In this context, the most easy and efficient method should be to reuse the articles in digital format. In the technical annexe it is said : "In the end, electronic documents coming directly from editors will be integrated in the Belgian electronic document delivery system of interlibrary loans".

In the digital environment licences have been introduced to regulate the use of digital resources. The librarian buys access to the electronic copy for a specific period of time and usage. There is still a wide variation of practices in the licencing of e-journals The terms of the licences are different for each publisher.

Those ways are only possible for the journals of a few publishers who allow libraries to use the electronic version of their documents to make ILL and who do not specify precisely the transmission methods that are allowed .

Those methods are authorised by publishers like EDP Sciences or Swets & Zeitlinger. For instance Swets licence allows "Institutions may use hard copies derived directly or indirectly from the electronic edition of the publication for the purpose of inter-library loan with the same limitations that apply to paper copies for that purpose made from the print edition of the journals".

However, the direct competition between services developed by publishers (electronic delivering) and services like VirLib that provide articles in PDF format is obvious. And it is not clear if "limitation imposed on interlibrary loans of paper copies" allows that electronic copies are directly sent to end users.

In this chapter, we will study the legal problem of the use of electronic documents. In Impala, electronic document delivery is limited to the scanning of documents on request. If the article is coming from a paper journal, only the Belgian copyright and the European Directive have to be consulted. On the other hand, if the inter-libraries loan is made with an electronic document directly from the publisher (even if a print copy is used) libraries have to respect the national and international copyright law and the signed licences.

We will study in this chapter what was, what is and what will be allowed to do in Virlib. We will summarise the first report and finally we will see for the actual Belgian law and the European future directive .

This report is divided into three parts. The first part deals with questions concerning the establishment of the VirLib system and its databases. The second deals with problems raised by the running of the virtual library and with the legal protection of the VirLib system.

The VirLib system will contain catalogues of available documents and could also contain databases with text and images. The inclusion of works in catalogues, by means of bibliographic references or subject indexes, is free from the copyright point of view.

Storage of complete works (texts, sounds and images) in a database, such as planned in the pilot database, constitutes reproduction in the meaning of copyright law and requires the authorisation of the proprietor.

For transmission of documents to the user VirLib will apply three methods, mailing of a photocopy, fax, and electronic transmission. The report examines the copyright implications each of these methods has. A photocopy of a work is a reproduction and supposes in principle prior permission by the author. A library that makes a copy should however enjoy the exception made for reproductions for private or didactic purposes by the copyright law of 30 June 1994, as long as the copy is made for research purposes, as teaching aid, or for use in study tasks. This exception on the exclusive right on reproduction permits copy of the work without prior permission by the author, in return for payment.

According to the major current of legal doctrine transmission by electronic means constitutes a public communication of a work (visualisation on a computer screen) followed by an act of reproduction (copying the document on a printer or a disk). The printing should enjoy the exception on the right on reproduction, for didactic purposes if the printing is done by the library, for private or didactic purposes if the printing is done by the end user. It is doubtful whether the exception for reproduction for private or didactic purposes applies to storage on a disk however, and it remains unclear whether electronic copies are covered by this exception.

As to the use end users make of documents, they must respect any copyright on the documents that may exist. If there is no copyright on the document, the user can use it freely but must respect the right sui generis of the manufacturer of the database.

The databases made for VirLib can be protected by copyright, according to the EU directive on databases. This protection presupposes that the database is an intellectual creation as regards the choice or the arrangement of its contents. The holder of this right is the individual who has created the database. If this is an employee, the right may be transferred to the employer by an express clause in the employment contract.

The software made for VirLib can be protected by copyright, if it is original, in the sense that it is an intellectual creation, according to the law of 30 June 1994 on the protection of computer software. The holder of this right is the individual who has created the software, but the law on computer software provides a presumption of transfer of rights to the employer.

Concerning exceptions to copyright in the EU directive, any transposition of the exception made for use as teaching aid or in scientific research needs legislative action, because the exception made for reproduction with a didactic purpose is not sufficient. Moreover, member states have the option to maintain traditional exceptions on copyright, but this does not permit, at least in the case of Belgium, to add any specific exception intended for databases.

With regard to the exceptions on the sui generis right, these have very limited practical scope because only the legitimate user of a database can avail himself of these exceptions. This is particularly true for the exception made for copies as teaching aid or for scientific research, because only the copy of the contents database is exempt from the sui generis right, not the distribution or the public performance. The transposition of the exceptions to the sui generis right in Belgian law would have to be the subject of completely new provisions.

For using VirLib II, we have to consider the reproduction right because it are copies of documents that were sent and the communication right because as soon as the work is communicated in an immaterial way, without using a material support, we can consider that there is "communication" whatever technique is used.

Directive on legal protection of databases introduces in place of the previous exceptions of reproduction for "didactic" purpose, a new exception of reproduction based on the reunion of three conditions : the reproduction can be of a fragment or of the entirety of an article or of a fragment of a work fixed on a graphic or analogue support or on another support. It has to be used for the sole purpose of illustration for teaching or scientific research (or private use) and it does not perform acts which conflict with normal exploitation of the work. This exception on the exclusive right on reproduction permits copy of the work without prior permission by the author, in return for payment. This new provision is important because publishers can now argue that electronic delivery is in direct competition with their services. We have to pay close attention to this aspect.

The problem of VirLib is that there is not any exception of communication right for purpose of illustration for teaching or scientific research in the Belgian law. The accord of the author is required for a "public" communication. Every immaterial communication of the work outside the "family circle" is considered as a public communication. Consequently, we can consider that an e-mail sent to a user, and even to a librarian of the ILL service, can be seen as a public communication and thus requires the authorisation of the author.

The first report is still valid when it says that " According to the major current of legal doctrine transmission by electronic means constitutes a public communication of a work (visualisation on a computer screen) followed by an act of reproduction (copying the document on a printer or a disk). The printing should enjoy the exception on the right on reproduction, for didactic purposes if the printing is done by the library, for private or didactic purposes if the printing is done by the end user".

For VirLib II, we can at the moment argue of the exception of reproduction right for purpose of illustration for teaching or scientific research. But the absence of exception for communication (visualisation on a computer screen) is still the main problem of the electronic delivery.

As we have seen, the exceptions provided in the Belgian law can be overridden by licences. In short, the reproduction of electronic files and the digital reproduction of paper are allowed by the new Belgian law. However the sending of electronic files is not legal (no exception for the communication). Libraries have to pay fair compensation to rightholders (this has not been fixed yet).

The Belgian law was not yet adapted to the information society. To know the further developments of the Belgian law, the future European Directive will be studied. As we have said, the current Belgian law on copyright will be transformed and adapted to the Directive. In the Article 11: Final provisions, the text says : "Member States shall bring into force the laws, regulations and administrative provisions necessary to comply with this Directive by 30 June 2000". But the earliest that changes will be introduced into Belgian laws is likely to be 2002 as the Directive is not likely to be adopted until 2000.

First of all the European Directive is still a proposal that means that it is subject to changes. The proposed Directive leaves all exceptions that are listed in Article 5.2. and Article 5.3. as pure options to the Member States. Therefore they would not only be entirely unharmonised but also without any guarantee that they will be implemented in the further Belgian copyright law. Even if those exceptions are still present in the final text of the European directive, Belgian libraries have to be vigilant and to force the Belgian government to keep them in the Belgian copyright law.

At the moment there are no words that guarantee that Contracts should not override an exception. The explanatory memorandum of the amended Directive states that recital 28 should encourage the development of contractual arrangements for activities not covered by the exception introduced for the benefit of establishments such as libraries and other cultural institutions. This provision is given in the database Directive (Article 15), and corresponds therefore with the acquis communautaire. The licences contract can currently override an exception.The intention by the European Commission in this proposed Directive is to leave the future of access to information to licencing mechanisms. Amendment 24 specifies that the exceptions are limited to certain specific cases and that global solutions must be sought within the framework of the contractual relations between the parties concerned.

As we have said, publishers who have started to set up electronic document delivery services themselves claim that every electronic document delivery service conducted by libraries is in direct competition with the "normal exploitation" of the work as laid down in Art. 9 (2) of the Bern Convention. If we consider that library services compete with a similar service or product obtainable from the publisher when the library delivers to a remote user an article which the user could have obtained from the publisher (this is not the case for paper journals).

The amended proposal directive includes the introduction or continuation of remuneration schemes to compensate for the prejudice to rightholders. In the case of reproduction on paper, private copying and illustration for teaching and scientific research (recital 26; Article 5(2)(a), (b), (ba) new and 5(3)(a)). Because they will receive compensation, the rightholders will not call up the "three steps" to unauthorise the ILL with their electronic journals.

Belgian libraries have to be careful when those compensation will be fixed because this will increase the global cost of each delivery. At the moment, the Belgian standard cost of an ILL is 200 BEF for the loan of a volume or a photocopy of up to 30 pages. This price of an article supplied with the VirLib system could become rather higher than the current price. The new service will be a kind of pay-per-view service and it can be more expensive than some commercial Document Delivering services.

However, strict copyright rules, especially in Europe, and anxiety on the side of the publishers do not allow Impala to directly deliver from the electronic files of the publishers but nevertheless it has been demonstrated that Impala can keep track of copyright fees to be paid directly to the publisher or to a copyright collecting agency.

Right of Reproduction (copying) and Right of Communication to the public which relates to digital transmission and use will be concerned. The Right of communication to the public is the right to authorise or prohibit any communication to the public of originals and copies of their works, by wire or wireless means.

In Article 5.2. (c) of the original draft Directive, Member States were permitted to exempt certain acts of reproduction from the reproduction right for the benefit of establishments which are accessible to the public, such as public libraries. The provision did not define those acts which may be exempted by Member States but requested that they would have to identify certain special cases which are in line with the three step test.

The proposed Directive provides a special licence for both rights : the Right of Reproduction and the Right of Communication if this is used for the sole purpose of illustration for teaching or scientific research. This is a difference between the Proposal Directive and the current Belgian law that does not provide such an exception for the right of communication..

That means that VirLib libraries could enable users to view electronic material on the screen of their computer (but simple private viewing of digital information in a library would need the authorisation of the rightholder). This exception for the communication could be an obvious improvement for the Belgian ILL service if it is maintained in the final European Directive and if it is included in the Belgian law. The fact that this exception for communication right is not provided in the Belgian law is the current most important problem to solve in VirLib II.

The Proposal Directive declares that " existing national schemes on reprography, where they do exist, do not create major barriers to the Internal Market; whereas Member States should be allowed to provide for an exception in respect of reprography."

An exception exists consequently for "reproductions on paper or any similar medium effected by the use of any kind of photographic technique or by some other process having similar effects, provided that the rightholders receive fair compensation". Moreover, the compensation provided by the directive for reproduction using the reprography technique is already fixed by REPROBEL.

The current proposal directive also authorises "Temporary acts of reproduction which are an integral and essential part of a technological process, including those which facilitate effective functioning of transmission systems, whose sole purpose is to enable use to be made of a work or other subject matter, and which have no independent economic significance, shall be exempted from the right set out in Article 2".

This exception can be used by VirLib II because the digital document is stored in a local server and its access is secured by a coded URL and overall because a death stamp will automatically delete the document from the library server. If the document is printed by the librarian to be given to the user, any electronic copy of the document will be conserved.

For this exception, there is no restriction about the uses and the users like "to the extent justified by the non-commercial purpose to be achieved" as it is provided for the exception for "the sole purpose of illustration for teaching or scientific research". A fair compensation for the rightholders is required but for the paper copy, there is yet a Royal Order and compensations are fixed. If the electronic file is directly sent to the end-user, a compensation (that has not been fixed yet) will be paid to the rightholder.

All the ways of delivery could enjoy the limitations to the rights of reproduction and communication when use is for the sole purpose of illustration for teaching or scientific research, as long as the source is indicated and to the extent justified by the non-commercial purpose to be achieved, on condition that the rightholders receive fair compensation.

The exceptions do not precise any specific means or form of the reproduction and any specific kind of communication. They have thus covered all kinds of reproduction (electronic or not) and all kinds of communication to the public of originals and copies ("by wire or wireless means, including the making available to the public of their works in such a way that members of the public may access them from a place and at a time individually chosen by them"). Any original support of document, any technical process made on it, any way of delivery are concerned by the Directive.

The VirLib acquisition software produces a DAT file which includes metadata (with copyright information). Those metadata are written on the front page of the delivered document received by the user. The VirLib system can thus enjoy this exception. But, for this case, the use (user) is restricted and the compensation is not yet fixed.

The directive does not mention any specific support of delivery. This could mean that a digital copy can directly be sent to the user. But the user must respect any copyright on the documents that may exist. The copyright information in the metadata require users to use those documents "for personal use only" .

We looked at some other European projects and their way of handling the copyright problem. More information on the projects can be found on the following websites. Nevertheless their legal information was limited.

Because the legislation concerning copyright varies from country to country BLDSC charges a publication-specific copyright fee as appropriate. Customers who do not normally pay a copyright fee for articles may, under certain circumstances, choose to use our Copyright Fee Paid option.

UK Copyright Licencing Agency. Copyright fees are set by publishers and vary with the publication and the date it was published. All copyright fees are passed to the UK Copyright Licencing Agency for worldwide distribution to publishers and other rightholders.

Making photocopies of copyright-protected materials is only allowed for small parts of printed materials (a chapter from a book, single contributions to newspapers, journals or collections). It is the user who is responsible for observing the copyright laws related to the delivered materials. This means that it is not allowed to copy the documents or to pass them on to a third party.

According to this arrangement, publishers have the legal viewpoint that deliveries of paper copies of copyrighted documents are not covered by the rules of exception of  53 UrhG. However, no additional costs for copying are to be charged by the publishers during the trial phase of SUBITO 1, i.e. up to 31 December 1999.

CANDLE sent a questionnaire to a number of electronic publishers. The responses showed that publishers are attracted to very secure systems to prevent misuse, although they recognize that "small scale misuse would not be a commercial threat". Similarly, publishers also had mixed feelings about the idea of using a caching proxy. Most publishers had already made off site access licences.

Elsewhere, it is mentioned that "pay-per-view material is not treated differently from the other electronic copyright material except that before the access to the electronic document the end user shall be made aware that he or she needs to pay for that".

To ensure copyright compliance, the encryption procedure used by TOLIMAC enables libraries to guarantee that the electronic documents received from the provider are available only to the end users who ordered them and who complied with the copyright regulations of the country, as applied by the library.

The TOLIMAC libraries have an agreement with the electronic information providers that allows payment based on actual use of their services. The system also makes it possible to charge copyright fees according to users' categories.

Consortia are Associations of groups of users that are now frequently encountered. They are formed in order to share resources and to bring their combined purchasing power to negotiate advantageous terms for the supply of journals, and other research literature or data.

A consortium represents the associated organisations as a unique client. For both sides, negotiation of the terms of a licence is much easier and quicker with one representative alone than with multiple agents negotiating separately. There should be much less duplication of effort for even such products that could be afforded individually, e.g. in developing a single contract, in negotiating all customization of products together, and in joint implementation, publicity, problem solving, and training.

Better prices and conditions can be obtained in a negotiation for a larger number of users. A bigger funding capacity allows the licencing of products which could not be afforded by individual organisations. Asking for specific conditions is easier for larger user groups. As budgets become tight, libraries look toward consortia as a way of reducing costs by subscribing as a group to commonly used databases, relying on the economics of scale to bring prices down.

Consortia are also more likely to be able, utilizing the expanded resources among the membership, to add value to the products that they purchase, e.g. by adding local holdings to citations. Finally, the vendors themselves are moving towards consortial licencing as a preference.

Furthermore, consortial licencing often serves the "greater good", in that larger partners carry some of the cost for the smaller ones (e.g. in the case of Academic Press electronic journals). The technological capacity of the group frequently jumps to that of the most advanced partner.

The publisher offered libraries the opportunity to increase holdings by banding together with other libraries. The publisher allowed each member to access an electronic version of every title subscribed to by another institution.

ANOTHER IMPORTANT PREREQUISITE for the new delivery models was the growth of the Web. As libraries began to migrate from mainframe to client-server systems, it became possible to expand holdings without proportionate increases of staff. "The libraries could access material but did not have to maintain it". Web-based systems also made remote access possible, which in turn became a sore point with publishers. Such systems can control access to resources by enabling a range of Internet Protocol (IP) addresses specific to a campus.

A consequence is that local users (the primary users) are disadvantaged on the altar of free interlibrary cooperation. If, however, cost recovery for ILL was the norm then there would be no problem with the publishers claiming payment for documents delivered to libraries outside the consortium.

Large groups (consortia, states, or nations) negotiate prices for entire sets of journals with publishers and the result of these contracts is to abandon the concept that libraries will subscribe to good journals, and replace it with the concept that they will subscribe to whatever a publisher happens to publish, good or bad. This may ensure the survival of the publishers, but insulate them from considerations of quality and efficiency, with the predictable result being the decline in overall value of the scientific literature.

OhioLINK is the almost legendary alliance of many types of libraries cooperating statewide to purchase licences to electronic products centrally. It is a consortium of Ohio academic libraries in both the public and private sector ranging from major research institutions to community colleges. This is the first major attempt in the US to create a virtual, statewide library system. More than just linking the holdings of participating libraries within the context of a 48-hour delivery system for books and journal articles, OhioLINK provides the platform as well for statewide delivery of commercial and other databases, Internet access, and experimentation with the development and testing of new information tools, and joint licencing.

OhioLINK, which since 1992 used major infusions of state capital to wire campuses. All the schools got money from the same source, so no individual library was penalized even as the entire system received more resources. Today, with an annual capital budget of $3.2 million and a two-year operating budget of $14.6 million, the consortium is a significant line item on the state budget. The authority to say yes for 79 public and private institutions at once has given the consortium enormous bargaining power. If the schools had signed up individually for the enhanced library version of Britannica Online, it would have cost the state $250,000 a year.

A new way of negotiating with publishers has in the last two years become quite common in North America, i.e., negotiating not with single libraries but with consortia or groups of libraries. At the moment in the US, there are probably 50 or so consortia that negotiate for electronic information with publishers. They are often but not always state consortia.

In Europe, several countries have begun to create a national consortium to defend their libraries and their aim is to get the best possible price and terms. Those consortia give every member of the national education and research community access to the required electronic information. Such a national solution is planned at the highest level of education and research administration and would avoid wasting time and resources inherent to the development of incompatible local systems.

One of the better examples of joined efforts for the management of electronic resources comes from England, with the CHEST service (Combined Higher Education Software Team) whose mission is: "to obtain quality software, datasets, training materials and other IT products for the UK Higher Education and Research Community at low prices and attractive terms" and with the BIDS service (Bath Information and Data Services, http://www.bids.ac.uk) founded in 1991 and providing networked information for end-users in the higher education and research communities at a national level. These two UK services are supervised by the Joined Information Systems Committee (JISC) (http://www.jisc.ac.uk/) whose mission is "to stimulate and enable the cost effective exploitation of information systems and to provide a high quality national network infrastructure for the UK higher education and research councils communities". In the domain of electronic journals, a UK Higher Education Pilot National Site Licence is now in operation with four publishers.

Finland, a consortium of 16 universities, 7 polytechnics and 1 research institute has signed an agreement with Academic Press on 14 July 1997 and negotiations with the Institute for Scientific Information which produces well known reference databases are now in progress. Finland's libraries consortium recently licenced the entire Academic Press collection (175 titles, from Hormones and Behavior to Molecular Phylogenetics and Evolution).

According to these agreements the subscribers are ensured an archival copy of/selective access to the relevant journals, covering the years they actually paid for, and publicly financed libraries which have not signed the agreements can freely be provided with copies of articles (digital or on paper).

Consortial negotiations can be quite efficient. They are efficient because instead of every academic library in the state of, for example Ohio, conducting separate discussions with publishers, the 45 academic libraries in Ohio colleges and universities have one officer who negotiates for all academic libraries in the state. Consortial negotiations can put libraries in a much stronger position with the producer, because instead of one library buying one item from a publisher -- and many libraries doing that many times over -- they can bargain as one. There are two good effects: libraries can reduce prices to some extent, maybe by 10 or 20% , and libraries can secure more advantageous terms of use.

The work field of the VOWB concerns: university libraries, higher education libraries, corporate libraries and documentation centres, government libraries and documentation centres and libraries in institutions and associations and (central) public libraries .

In December 1996 the VOWB started the project called ELEKTRON with the financial support of the Flemish government The aim of the project was the development of a Flemish network for electronic delivery of scientific documents to the desk of the end user. In the first instance the Elektron project involved the scientific periodicals. In the long run the setting up of the system should also enable the participating institutions to make available their own scientific documents.

This was only possible on two conditions: on the one hand all interested libraries had to cooperate in the purchase of electronic information with all organizational, financial and juridical consequences and on the other hand the libraries had to cooperate to create a technological environment wherein the user has access to several data bases from only one point.

The project took off in December 1996 and was tested by the libraries of the universities of Antwerp, Ghent and Louvain. By the end of 1998 the VOWB organised a larger target group: universities, non-university higher education institutions, research libraries in the public sector, public libraries and research libraries in the private sector got involved.

The system of the electronically delivery of full text documents was conducted in three different phases. The testing phase aimed to connect the libraries who have access to the systems of Libris, Vubis-Antwerp and the system of Ghent. During the second phase the access was enlarged to all the Flemish research and public libraries, including the libraries of the non-university higher education institutions. In the long run it is also the intention to make the system accessible to the private sector.

The first realisation was the availability on Internet of the renewed union catalogues CCB - books - and Antilope - periodicals -, and of a limited selection of bibliographic databases (on line contents database, reference databases and the databases containing full text electronic documents). These databases can help the user to find the document if it is electronically available, and if not, guide the user via the union catalogue to the library which can deliver the document in printed form. The order is done electronically, the delivery if possible, too.

On 15 February 1999 a definite plan on the general availability of secundary electronic information was approved by the VOWB. The institutions themselves have to arrange the linking with the primary information.

One cannot speak of a real consortium yet, since the VOWB does the negotiations with the publishing companies but still leaves the final signing and final responsibility of the execution of the licence agreement with the participating institution. In the actual situation the VOWB acts more as a sort of umbrella consortium of smaller consortia which are temporarily organised everytime a group of institutions is interested in a certain (serie of) database(s). The consortium offers only facilities (like examining the licencing principles with the different publishers) but does not take any decision concerning the collection of the participating libraries. Within the consortium libraries can use the expertise of the VOWB and arrange cooperation with other members of the consortium.

For the execution of the ELEKTRON project a real, separate organisation outside or inside the VOWB will be needed. Diffferent organizational and management structures are possible. One can choose for a strong structure with a large staff or for a loose structure where one counts on the assistance of the participating institutions.

One of the essential objectives of the project was the development of a uniform system for the identification of the user and the settlement of a system of accounting from institution to institution, and from institution to user.

Belgian law For VirLib II, we can at the moment argue of the exception of reproduction right for purpose of illustration for teaching or scientific research. But the absence of exception for communication (visualisation on a computer screen) is still the main problem of the electronic delivery.

The Belgian law has not been adapted yet to the information society. To know the further developments of the Belgian law, the future European Directive will be studied. As we have said, the current copyright Belgian law will be transformed and adapted to the Directive. In the Article 11: Final provisions, the text says : "Member States shall bring into force the laws, regulations and administrative provisions necessary to comply with this Directive by 30 June 2000". But the earliest that changes will be introduced into Belgian laws is likely to be 2002 as the Directive is not likely to be adopted until 2000.

We have considered that all the exceptions provided by the directive will be automatically introduced in the future Belgian law. Those exceptions are optional, which means that Members have the choice to implement them in their national law or not. The implementation of those exceptions is not guaranteed at all. Belgian libraries will have to lobby with the Belgian government to make sure that the exceptions will be authorised in Belgium.

The reproduction right has always played a key role in copyright protection. Its role will increase even more in the new information society environment. Once protected material is converted into electronic form and transmitted digitally, it is much more vulnerable to exploitation by copying than in the past. Many publishers reject fair-use arguments as a basis for encouraging unauthorized reproductions of electronic works, and they have been pressing for new technological and legislative protections.

The amended Directive wants to encourage the development of contractual arrangements for activities not covered by the exception introduced for the benefit of establishments such as libraries and other cultural institutions.

The Commission puts much importance on contractual relationships, as a means for information producers, intermediaries and end users to determine directly the conditions of use of protected material generally through the negotiation of licences between rights owners and users. Under any one of the legal systems in force in the Member States, freedom of contract is the rule, and contractual restraints the exception.

The Recital 29a specifies : that the exceptions are limited to "certain specific cases and that global solutions must be sought within the framework of the contractual relations between the parties concerned".

In the licence conditions for hybrid journals (both in print and electronic formats), publishers almost universally allow only the print version to be used for interlibrary loans. Recently some large publishers have announced changes in their policies. Electronic editions of journals of those publishers can now be used to satisfy interlibrary loan requests, but only printing out requested articles and sending them out in the printed form.

Few publishers like EDP Sciences or Swets & Zeitlinger allow obviously that the hard copy is used for ILL (in the limitation imposed on interlibrary loans of paper copies) and moreover they do not specify any precise methods of delivery. Electronic articles from those publishers can be used for VirLib.

In this context, considering all those restrictions, libraries can use exceptions to both the reproduction right and the communication to the public right in the case among others of use for the sole purpose of illustration for teaching and scientific research as long as fair compensation is provided to rightholders. Using this copyright exception users can have access to information without having to ask every single time for permission, and can also copy a reasonable amount of a work that would not be in conflict with the normal exploitation of that work.

The new Directive is an improvement for the current Belgian law because it allows exception for communication. This implies that electronic files can be sent through network (via e-mails) between the Belgian ILL departments.

The interests of publishers and librarians need to be re-balanced in order to seize the benefits of digital information flow. Legislation provides a framework of copyright, privacy, competition and consumer law that protects against misuse while facilitating the flow of information from author to reader. If laws need to be amended, such changes should be made on the basis of the mutual agreement of all members of the community.

Neither publishers nor librarians should shy away from the issues that divide them, especially the scope of fair use and the exchange of copyright information between libraries. A more detailed analysis of the impact of copyright exemptions is needed.

A monitoring of all the current licences and a precise list of the authorised uses allowed by each publisher would be difficult and time-consuming to make and to maintain. The restrictions and the permissions are varying from one to the other and the text of the licence agreements is changing all the time.

Since the printed edition of journals can be used for ILL transactions, the Belgian libraries have to continue to subscribe to this version to be certain that they can do ILL. This is the current politic followed by the Belgian libraries which continue to subscribe to the paper version and allow access to electronic version of those journals when the publishers of those digital editions offer them at no extra cost to subscribers to the print versions .

"To the extent that an institutional password verification server controls export of individual and demographic information, passwords could work surprisingly well in a SSL-protected context. A primary benefit is that users are familiar with the model. There are important missing pieces here, particularly the protocol to permit resource operators to verify userid/paswords pairs with institutions that issued them. Probably the greatest weakness of this approach is the dependency on each resource operator to protect userids/passwords pairs, and the danger of systemic compromise due to a security failure on the part of a single resource operator".

Electronic uses of copyright material will be facilitated by individual contracts between publishers and user groups, including librarians. Such contracting will allow for Electronic Document Delivery (EDD) directly form publishers to users and this excludes Inter-Library EDD carried out in the name of ILL. One way forward might be the development of a model contract between publishers and user groups."

"The reasons for this option not being taken up are somewhat unclear, however it seems that one important reason is that most universities? document delivery demand stems mostly from ILL requests, which they are bound to fulfil at little or no cost to the receiving university on the basis of reciprocity. Although the costs of fulfilling these requests by hand are much higher than the royalties to be paid in the TULIP option, these royalties are "out of pocket" as opposed to the personnel cost involved with copying the original articles. Elsevier Science does not permit the electronic files to be used for ILL; "

This is essential for all service providers who wish to provide large scale commercial services. It should be noted that at present large scale document delivery services do not deal directly with the public due to this problem (for example BLDSC only deals with libraries who operate on behalf of members of the public).

"Kluwer Online may not be utilized for any commercial or non commercial fee for service use, or sale. The electronic form may be used as a source for Inter Library Loan whereby articles can be printed and these print copies be delivered via postal mail or fax to fulfil ILL requests from an academic, research or other non-commercial library. Requests received form commercial, for-profit companies or directly form individuals may not be honored.

In addition, you have the right to use, with appropriate credit, figures, tables and brief excerpts forma an article in an Electronic Journal in your own scientific, scholarly and educational works or similar work product.

B. Except as provided in Paragraph (A) above, you may not copy, distribute, transmit or otherwise reproduce material from an Electronic Journal or Wiley InterScience or systematically store such material in any form or media in a retrieval system; or download and/or store an entire issue of an Electronic Journal; or store content from Wiley InterScience in electronic format in electronic reading rooms or print out multiple copies for inclusion in coursepacks; or transmit any material from Wiley InterScience and the Electronic Journals, directly or indirectly, for use in any paid service such as document delivery or list serve, or for use by any information brokerage or for systematic distribution of material, whether or not to another User and whether for commercial of non-profit use or for a fee or free of charge. The Licensee, may print out and send single paper copies of articles from an Electronic Journal for interlibrary loan. "

Institutions may use hard copies derived directly or indirectly form the electronic edition of the publications for the purpose of inter-library loans with the same limitations that apply to paper copies for that purpose made from the print edition of the journals. Specifically, copies must be made in compliance with Section 108 of the Copyright Act of the USA and Technological Uses of Copyright Works (CONTU Guidelines), the text of which is available as part of the USA Copyright Office Circular 21. The electronic transmission of copies of articles for inter-library loan purposes is not allowed. "

The research unit of INRIA, at Sophia Antipolis, keen to be widely open to its local and regional partners, has created a "Partners club". It is a scientific and technical club that allows its members to be informed on the state of the art and research prospectives in the area of information and communication science and technology, scientific computing and control of complex systems.

This club is widely open, both thematically and geographically. Industries from all activity sectors, public organizations and all socioeconomic actors in the region and having an interest in the area of information and communication science and technology are welcome.

The main activities of Intech'Sophia is to organize seminars on specific themes, being of interest for a majority of its members, each seminar including three to four talks. The speakers will come from INRIA, or from other public research organisations as well as from industry. These seminars are organized every quarter and are open to the employees of the club members without fees.

E-learning is a very broad term encompassing many different usages of computers in a learning situation. Not only affecting distance learning, computers are now a classic medium for education at any level. Still there is much to be done to fully understand and take advantage of the introduction of this new communication channel in the learning situation.

In parallel the development of the World Wide Web gives us access to an overwhelming mass of information. However this information is not really "understandable" by computer programs. On the contrary in the vision of a "semantic web", human and machines share knowledge and data across the web using standard formalisms.

From the beginning the semantic web vision is seen as very promising for many application domains, especially learning. My PhD work focuses on how this can be effectively the case. Relying on W3C standard formalisms and the experience of the Acacia Team in the area of Knowledge Management, I propose in this work a sustainable approach, benefiting from semantic web technologies, to tackle a standard e-learning problem of accessing on-line learning resources.

Some technological aspects of this work are supported by the Corese semantic search engine. This software developed by Acacia, answers SPARQL queries on an RDF base of annotations, and ontologies in RDF(S) and OWL-lite. The integration of this engine allows to quickly deploy high quality semantic web application.

A first experiment of accessing on-line courses, has been conducted in 2005, with a signal analysis introductory course for first year computer engineering students. The experimental application gives access to course content through an "active" reading. This system called QBLS for (Question Based Learning System) is described in several publications and is freely accessible at http://ubaye.inria.fr:8080/exp_weblearn/cours (login:invite,password:invite).

The aim of this project is to set up a learning community about the semantic web. Several scenarios and user profiles have been defined. An on-line repository stores learning material contributed by many partners, and this is to be extended by a demonstration platform (ASPL for Advanced Semantic Platform for Learning) by useful services based on themselves on semantic technology. I offer the QBLS service to ease access to resources on the repository. Resources are annotated by a domain vocabulary and a pedagogical ontology.

A large scale experiment has been conducted from sept05 to jan06 using a java course for computer engineering students. Course content was entirely accessible on-line and annotated by a domain vocabulary expressed in SKOS and a pedagogical ontology. This work exemplifies several contributions on both the methodological and technical aspects of semantic web technologies for learning. The interface can be accessed through http://ubaye.inria.fr:8080/prog101/cours; however in this demo the adaptation features are not available without a login.

In the project Virtual Plants, we are interested in studying plant apical meristem functioning and development. We believe that a detailed analysis of apical meristem  processes, based on advanced mathematical and computational methods and tools, will lead us to get a deeper and better understanding of plant development.

Biological keywords:  Plant development, branching systems, plant architecture analysis, plant geometry and topology, branching patterns, meristems, growth, vegetal tissues, hormones, auxine fluxes, meristem physiological states.

Security. We investigate security issues like confidentiality and resource consumption, using static analysis methods (for the verification of non-interference of programs with respect to given security policies, and of computational complexity), with an emphasis on the issues related to concurrent and mobile code.

Models and languages for reactive programming. We develop several implementations of the reactive approach, in various languages. We have designed, and still develop, an alternative to standard thread systems, called FairThreads. We study the integration of constructs for mobile code in the model of reactive programming.

Functional languages. We develop several implementations of functional languages, mainly based on the Scheme programming language. Our studies focus on designing and implementing a platform for a distributed environment. All our developments on the web rest on these implementations.

Web programming. We design and implement a programming environment for the web 2.0. It relies on a new distributed programming architecture where a program executes simultaneously on a server and a client. We aim at providing a realistic implementation that we constantly validate by developing and using end-users web applications.

School on harmonic analysis and rational approximation, their role in signal, control, and dynamical systems theory, September 14 to 20, 2003 at Porquerolles. Further information by clicking on the image of Porquerolles island.

Meromorphic approximation in the complex domain, with application to frequency identification and design of transfer functions, as well as singularity detection for the 2-D Laplace operator. Development of software for filter identification and the synthesis of microwave devices.

The Acacia project is a multidisciplinary project that aims at offering models, methods and tools in order to help the knowledge engineer to acquire knowledge from multiple expertise sources (experts and documents), for building a corporate memory (i.e. knowledge capitalization), a knowledge server or a knowledge-based system. We offer generic models in order to support the knowledge engineer in interpretation of expertise documents: such models focus on solving problems of multiple expertises and of explanatory knowledge acquisition.

We develop tools relying on our generic models, and based on the CommonKADS methodological framework, on knowledge representation through Sowa's conceptual graphs, XML, RDF and on agent-based modelling. The Corese semantic search engine is now available for download. Corese implements RDF using conceptual graphs and proposes an RDF rule language.

The Everest project concentrates on increasing reliability and security of mobile and embedded software. This is achieved by developing and applying formal methods and language-based techniques, covering both platform and application level.

Geometric computing plays a central role in most engineering activities: geometric modelling, computer aided design and manufacturing, computer graphics and virtual reality, scientific visualization, geographic information systems, molecular biology, fluid mechanics, and robotics are just a few well-known examples. The rapid advances in visualization systems, networking facilities and 3D sensing and imaging make geometric computing both dominant and more demanding of effective algorithmic solutions.

Computational geometry emerged as a discipline in the seventies and has met with considerable success in resolving the asymptotic complexity of basic geometric problems including data structures, convex hulls, triangulations, Voronoi diagrams, geometric arrangements and geometric optimisation. However, in the mid-nineties, it has been recognized that the applicability in practice of the computational geometry techniques was far from satisfactory and a vigorous effort has been undertaken to make computational geometry more effective.

Together with partners in Europe, the former PRISME project-team advanced the state of the art in robustness issues, geometric software engineering and experimental studies. A major outcome of this research has been the development of a large library of computational geometry algorithms (CGAL).

Strong asymptotics is obtained for polynomials orthogonal with respect to varying complex weights on a segment. It is used to derive asymptotics for the error of best meromorphic approximation for Cauchy transforms of complex measures.

We provide a characterisation of the looked for electrostatic potential and we approximate it with the minimum points of a sequence of functionals, which take also in account the error in the measurements. These functionals are related to the so-called Mumford-Shah functional, which acts as a regularizing term and allows us to prove existence of minimizers and Γ-convergence properties.

The unit gathers together 500 persons, including 380 scientists, in its Sophia Antipolis, Marseille and Montpellier sites. The unit boasts about thirty research teams working in partnership with CNRS and several universities and engineering schools. Research concerns the design and programming of high performance computer systems, the representation and handling of complex information, and the creation, modeling and simulation of complex experiments. It results in advances in four major areas: networks and systems; software engineering and symbolic computation; human-machine interaction, images, data, knowledge; simulation and optimization of complex systems.

To carry out such studies, the research unit remains in constant interaction with its partners in universities, engineering schools and research centers all over the world through scientific publications, software and international exchanges. It also hosts the ERCIM consortium services that regroups European research centers in information and communication science and technology.

INRIA Sophia Antipolis maintains partnerships with many local, national and international companies and institutions, within the framework of contracts, research networks and European programs. . Meetings are held on a regular basis to reinforce these partnerships, in the framework of Intech'Sophia, the unit's partners club. In addition, work by INRIA Sophia Antipolis researchers has led to the founding of some ten technology companies.

With their joint concern of excellence and transfer, the unit's researchers participate in training in information and communication science and technology by attracting students, researchers and engineers from all over the world.

A research project is a team of 15 to 20 persons working on a significant theme and precise scientific objectives. The projects manage their budget autonomously. The results obtained and the industrial spin-offs of the results are evaluated on a regular basis.

The Office of External Relations main objective is to increase the value of the scientific research work carried out within the research teams and to transfer the research results to the industry. International, european and industrial relations play a great part in achieving this mission. The partners club Intech'Sophia, created in March 2002, allows the research unit to open towards the socio-economic world.

The computing ressources are in charge of coordinating purchases, administrating computer resources (systems, software, networks, telephone and logistics). They control the connectivity and computer security of the site and assist research projects in their development and expermentation activities.

This thesis will take place within the Heath e-Child European project involving several clinical centers in Europe and a major industrial partner in the field of medical imaging. Within the scope of this project, the Asclepios team will develop macroscopic computational models of pediatric diseases, in particular for congenital cardiac diseases.

Thus, the topic of the thesis will be the electro-mechanical modeling of the specific right ventricular overload and cardiomyopathies involved in this project. It will involve the development of  medical image analysis tools and new modeling methodologies, based on prior work in the Asclepios team. The image processing tasks will mainly consist in providing image segmentation and registration tools on magnetic resonance and ultrasound images, with a particular attention on the right ventricle. The  outcome of this research  will be evaluated and validated in close collaboration with clinical partners located in France, UK and Italy.

The modeling part will concentrate on introducing the specificities of pediatric diseases into the existing electromechanical model of the heart, including the anatomical (hypertrophy, dilation,..., of the myocardium) and the physiological (contractility, conductivity) aspects. Furthermore, it is necessary to estimate the impact of growth on the evolution of those pathologies.

The candidate should have a background in either mathematics or computer science. Good programming (preferably with C++) and mathematical skills are essential. Experience with numerical analysis, modelling, medical image analysis, cardiac physiology or image processing would be an advantage. English written and spoken is necessary.

The objectives of the proposed thesis are twofold. First, it consists in segmenting anatomical structures of the lower limb (muscles, bones, ligaments) from static and dynamic MR images. Because of the variability of those structures, the segmentation will be performed by combining non-rigid image registration with segmentation based on deformable models.

In a second stage, the research activity will consist in developing efficient soft tissue and muscle models that can be validated on rheological datasets. Those models should be based on continuum mechanics and the finite element method and a procedure of estimating mechanical parameters from rheological experiments should be developed within the scope of the thesis.

The candidate should have a background in mathematics, mechanics or computer science. Good programming (preferably with C++) and mathematical skills are essential. Experience with numerical analysis, modelling, medical image analysis, muscle physiology or image processing would be an advantage. English written and spoken is necessary.

Criteria on nationality, age and qualification apply. The candidate must preferably be citizen of the European union but must not be a French citizen or should not have spend more than 12 months in France for the last 3 years.

This master will take place within the Heath e-Child European project involving several clinical centers in Europe and a major industrial partner in the field of medical imaging. Within the scope of this project, the Asclepios team will develop macroscopic computational models of pediatric diseases, in particular for congenital cardiac diseases.

The topic of the master will be the pediatric MR image segmentation with a particular attention on the right ventricle. The integration of dynamic sequences and available clinical data will help in the patient management. The outcome of this research will be evaluated and validated in close collaboration with clinical partners located in France, UK and Italy.

CardioSense3D is a 4-year Large Initiative Action launched in 2005 and funded by the French national research center INRIA which focuses on the electro-mechanical modeling of the heart. Within the CardioSense3D Action, this master will concentrate on the ventricular outflow tracts, in order to study their geometry and rheology. This involves the segmentation of the proximal arteries from MR images, and the study of the time-variation of their sectional area as well as flows. Coupling this data with simplified models of the fluid-structure interaction can allow to estimate the compliance and pressure.

MedINRIA is a free collection of softwares developed within the Asclepios research project. It aims at providing state-of-the-art algorithms dedicated to medical image processing and visualization for clinicians. Efforts have been made to simplify the user interface, while keeping high-level algorithms. Each application is called a module, and can be loaded dynamically from a single main window. MedINRIA is available for Microsoft windows XP, Linux Fedora Core 3, and is fully multithreaded.

The DTI Track module provides all necessary tools for in-deep DT-MRI analysis and fiber tracking. From diffusion tensor field estimation, to FA/ADC computation, tensor smoothing, and fiber extraction, this module will help you to extract a fiber bundle of interest. Moreover, it is now possible to fuse fMRI data with fiber pathways, to determine likely paths linking activated regions. A brief descriptions of the features is given below. This module uses Log-Euclidean metrics to process tensors, protected by a patent (Filing Number 0503483).

The Tensor Viewer is complementary to DTI Track. It allows you to visualize tensor fields obtained with the DTI module. Sometimes, tensors are flipped due to errors in the acquisitions or storing process. With Tensor Viewer, you will be able to check the validity of the diffusion tensors, correct a geometry problem if any by flipping the tensors, and save the result.

Visualize tensors in various ways: tensors are represented as glyphs, such as lines, arrows (principal eigenvector), but also cubes, ellipsoids, etc. The glyphs are colored in RGB (principal eigenvector), and intensity is weighted by the Fractional Anisotropy of the tensor. You can downsample the tensors for faster rendering.

You can overlap an image (e.g. the B0 image) with the tensor field, and control its contrast and windowing. Monoplanar (only one plane) visualization and multiplanar (3 planes) visualization are possible, with or without the image.

The Tensor Viewer provides the possibility of flipping the tensor field among the x,y, and z axes, to tackle some acquisition geometry problems. You can then save the flipped tensors and use it to track fibers with DTI Track.

Brain radiotherapy must achieve two goals: the complete irradiation of the tumor, and the preservation of critical structures (brainstem, eyes, optical tracts, etc.). By customizing the shape of the irradiation beam and modulating the irradiation intensity, conformal radiotherapy allows to optimize the irradiation of the tumor and the critical structures. The planning of conformal radiotherapy requires accurate localizations of the tumor and the critical structures.

This work aims to delineate automatically the critical structures of the brain. In order to do this in a specific patient's image, we use an anatomical atlas containing labels of the structures of the brain. This atlas is registered on the patient image by a global followed by a non rigid registration. The aim of this work is basically to develop a non rigid registration algorithm adapted to anatomical structures registration. The second goal is then to validate the method we propose using quantitative measures on manually delineated patients.

Nervous System (CNS). Predominantly, it is a disease of the "white matter" tissue.  In people affected by MS, patches of damage called plaques or lesions appear in seemingly random areas of the CNS white matter. At the site of a lesion, a nerve insulating material, called myelin, is lost.

The quantification of the number of lesions, as well as their volume, could be of interest to assess the severity of the disease, and the success of a therapy. These lesions are of different types, and can not be all distinguished in one MR image: therefore, to better characterize them, several sequences are acquired (T1 weighted, with and without Gd, T2-weighted, PD-weighted).

In the context of the INRIA national action CARDIOSENSE 3D, this project is about the study of heart segmentation from MRI, using active models and statistical classification. The goal is to achieve the effective segmentation of the atria and proximal arteries in order to complete the current anatomical model where only ventricles are available. The simulation of the electromechanical activity of the heart on this model will participate in diagnosis and therapy of cardiovascular pathologies.

Fibered confocal microscopy (FCM) is a potential tool for in vivo and in situ optical biopsy. FCM is based on the principle of confocal microscopy which is the ability to reject light from out-of-focus planes and provide a clear in-focus image of a thin section within the sample. This optical sectioning property is what makes the confocal microscope ideal for imaging thick biological samples.

CRI aims to study the follicular development in mammals, and proposes mathematical models that allow to follow the granulosa cell population, and then to predict the outcome of the follicular development (ovulation or degeneration) with respect to the hormonal environment.

While our team has been focusing on developping tools adapted to the analysis and registration of multidimensional and multimodal medical images, the LONI has been leading studies to build cerebral atlases of specific diseases (e.g. Alzheimer, schizophrenia) and thus has been collecting anatomical images for years. Today, this amount of images consitutes a unique databasis of more than 500 T1 MRI. Moreover, each images comes with an accurate delineation of 32 pairs of sulci, each sulcal line being segmented by experts who followed a meticulous protocol.

Basically, this work aims at learning the global brain variability from the variability of sulcal lines. The size of the databasis being statistically significant, this work could lead to new results in neuro-anatomy.

In the one hand, a better knowledge of the brain variability among a population could help to early detect neurological pathologies and in the other hand, providing a map of the variability could help to guide non-rigid registration algorithms. Indeed, if we are able to predict in which direction each position of the brain statiscally moves, we will be able to better constrain registration algorithms.

The emergence of diffusion tensor imaging (DTI) in the medical imaging community led to challenges in mathematics in order to manipulate 2nd order symmetric positive-defined matrices, so called tensors. In DT-MRI, each voxel of the brain contains a tensor, which is the 2nd order approximation of the brownian motion of water at this specific location. As water tends to move along oriented tissues (such as white matter neural fibers) diffusion tensors are likely to be aligned with the underlying structures. Due to the noise corrupting the data, the tensor field needs adequate post-processing before any further analysis. However, one cannot manipulate tensors like scalars (the tensor space is not a vector space).

We used results in differential geometry to manipulate tensors while ensuring to remain on the tensor space, i.e. to keep the positive-defined constrain verified at all time. Applications are: tensor field regularization (PDE, etc.) and shape statistics (see the collaboration Epidaure-LONI).

While the main geometrical arrangement of myofibers has been known for decades, its variability between subjects and species still remains largely unknown. Understanding this variability is not only important for a better description of physiological principles but also for the planning of patient-specific cardiac therapies. Furthermore, the knowledge of the relation between the myocardium shape and its myofiber structure is an important and required stage towards the construction of computational models of the heart since the fiber orientation plays a key role when simulating the electrical and mechanical function of the heart. The knowledge about fibre orientation has been recently eased with the use of Diffusion Tensor Imaging (DTI) since there is a correlation between the myocardium fibre structure and diffusion tensors. DTI also has the advantage to provide directly this information in 3D with a high resolution, unfortunately it is not available in vivo due to the cardiac motion. A statistical study of ex vivo cardiac DTI will help in understanding the cardiac fibre structure and in modeling the electromechanical behaviour of the heart.

The goal of this project is the development of model-based methods for automatic 3D segmentation and recognition of anatomical structures in medical images. A statistical shape model is generated using point cloud representation of the instances. In order to avoid typical problems of direct point-to-point correspondences, a correspondence probability approach is realized when registering the instances (see figures 1 and 2).

Symmetric positive-definite matrices (or SPD matrices) of real numbers, also called here `tensors' by abuse of language, appear in many contexts. In medical imaging, their use has become common during the last ten years with the growing interest in Diffusion Tensor Magnetic Resonance Imaging (DT-MRI or simply DTI). SPD matrices also provide a powerful framework to model the anatomical variability of the brain. More generally, they are widely used in image analysis, especially for segmentation, grouping, motion analysis and texture segmentation. They are also used intensively in mechanics, for example with strain or stress tensors.

As a consequence, there has been a growing need to carry out computations with these objects, for instance to interpolate, restore, enhance images of tensors. To this end, one needs to define a complete operational framework. This is necessary to fully generalize to the SPD case the usual statistical tools or PDEs on vector-valued images.

In this work, we have proposed a novel and general processing framework for tensors, called 'Log-Euclidean'. It is based on Log-Euclidean Riemannian metrics, which have excellent theoretical properties, very close to those of the recently-introduced affine-invariant metrics and yield similar results in practice, but with much simpler and faster computations.

This innovative approach is based on a novel vector space structure for tensors. In this framework, Riemannian computations can be converted into Euclidean ones once tensors have been transformed into their matrix logarithms, which makes classical Euclidean processing alogarithm particularly simple to recycle.

In recent years, the need for rigorous frameworks to compute statistics in non-linear spaces has grown considerably in the bio-medical imaging community. First, a number imaging modalities, like diffusion MRI, provide researchers with data which do not live in a linear space, and nonetheless require post-processing (re-sampling, regularization, statistics, etc.).

Second, the one-to-one registration of bio-medical images naturally deals with data living in non-linear spaces, since many types of invertible geometrical deformations belong to groups of transformations, which are not vector spaces. These groups can be finite-dimensional, as in the case of rigid or affine transformations, or infinite-dimensional as in the case of  groups of diffeomorphisms parameterized with time-varying speed vector fields.

Unfortunately, bi-invariant Riemannian metrics do not always exist. In particular, in this work, we have proved the novel result  that such metrics do not exist in any dimension for rigid transformations, which form but  the most simple Lie group involved in bio-medical image registration.

To overcome the lack of existence of bi-invariant Riemannian metrics for many Lie groups, we propose in this article to define a bi-invariant mean generalizing the Frechet mean induced by bi-invariant metrics, even in cases when such metrics do not exist. The intuition of the existence of such a mean was first given by R.P. Woods in 2003 (without precise definition).In this work, we have proposed a general framework  to define rigorously  bi-invariant means,  this time in  any finite dimensional real Lie group. To do this, we rely on a general barycentric equation, whose solution is by definition the bi-invariant mean. We have shown the existence and uniqueness of this novel type of mean, provided the dispersion of the data is small enough, and  the convergence of the classical iterative algorithm of R.P. Woods is also shown. In the case of rigid transformations, we have been able to determine a simple criterion for the general existence and uniqueness of the bi-invariant mean, which happens to be the same as for rotations.

We are working on an electromechanical model of the heart, simple enough to be used in the deformable model framework, in order to extract some ventricular function parameters from cardiac image sequences.  We compute the action potential electrical wave propagation using the FitzHugh-Nagumo approach and this potential triggers the muscle contraction, through an electromechanical coupling based on the Hill-Maxwell model.  This model interacts with 4D cardiac images through external forces applied on the surface nodes and computed from the image features.  We expect that the a priori information provided by the model will help segment sparse and noisy images. Moreover, this model could help simulate some electrical and mechanical pathologies.

In radiotherapy treatment, the constant margin taken around the visible tumor is a very coarse approximation of the invasion margin of cancerous cells. This work tries to solve the problem of adapting the radiotherapy regions to the tumor growth dynamics. The method proposes approximate invasion margins of the tumor based on its growth dynamics. Determining radiotherapy regions based on these invasion margins would increase the effectiveness of the treatment. The low density tumor parts, undetectable by the current imaging techniques, are extrapolated in a magnetic resonance image (MRI). The extrapolation takes into account the underlying tissue structure (grey matter, white matter, fiber directions), the tumor growth dynamics approximated by the Fisher-Kolmogorov model and the segmented tumor in the image.

We propose to model and simulate the growth of glioblastomas, the most aggressive of the glial tumors. The proposed simulation is based on a model coupling the invasion of the glioblastoma and its mechanical interaction with the invaded structures. This model uses a reaction-diffusion equation for the tumor expansion characterization and the usual continuum mechanics laws for the brain parenchyma behavior. In addition, we propose a new equation to couple these two equations to take into account the mechanical influence of the tumor cells on the invaded tissues.

Our model relies upon an anatomical atlas including cerebral structures having a distinct response to the tumor aggression. In addition, we included in this atlas the information from the Diffusion Tensor Images (DTI) to model the tumor preferential growth in the white fibers direction. Finally, the tumor growth model is used to simulate a virtual GBM grow into a patient brain. This in-silico growth is compared to the real GBM growth observed with a second patient MRI taken 6 months later.

The model based control of mechanical systems such as either predictive controller for instance, or the simulation of the motion induced by a given control imput requires the numerical integration of the dynamic model.

The estimated dynamic and geometric parameter values used in these models are not known accurately. Moreover, the torque inputs applied to the systems are not always measured with accuracy. Finally, it is somtimes interesting to simulate the system motion for a given range of inputs. The propagation of all these uncertainties can be performed with techniques based on interval arithmetic. The objective of the work is to evaluate the "interval" Taylor approach on a simplified mechanical system representing the behavior of human walking.

Accurate geometrical models of the head are necessary for solving the forward and inverse problems of magneto- and electro-encephalography (MEG/EEG). Boundary element methods (BEMs) require a geometrical model describing the interfaces between different tissue types. Classically, head models with a nested volume topology have been used. In this paper, we demonstrate how this constraint can be relaxed, allowing us to model more realistic head topologies. We describe the symmetric BEM for this new model. The symmetric BEM formulation uses both potentials and currents at the interfaces as unknowns and is in general more accurate than the alternative double-layer formulation.

Events measurable in EEG and MEG, such as event-related potentials and fields, oscillations or epileptic spikes, often present significant variability across different realizations. This variability may convey useful information, but is lost in the classical procedure of signal averaging. Our goal is to design a general method for modeling and tracking M/EEG events, applicable for both low and high frequencies and taking into account the spatial structure (topography) of the events.  We investigated the extraction of spatial and time-frequency patterns from the data in order to build topography-time-frequency templates.

The scientific focus of the laboratory is the combined study of computer and biological vision. We think that a more detailed knowledge of the visual perception in humans and non-human primates can have a potential impact on algorithm design, performance evaluation and cues on such questions as how to interface an artificial vision system with people, possibly handicapped.

From a more general viewpoint and at another level, biological visual perception, in particular in non human primates and humans is poorly understood and modeled. Making progress in this understanding is a grand scientific and philosophic challenge that frames our work.

Renewal processes, semi-Markovian processes and censoring, hidden Markovian models and analysis of homogeneous zones within sequences and trees, Markov switching (generalized) linear mixed models and modeling of the influence of environmental factors and inter-individual heterogeneity, change-point detection models and algorithms for sequence segmentation.

These two concepts have in common that they rest on an scale analysis of plants. Those techniques and concepts take their source in the developments of the fractal geometry. The aim of this thesis will be to develop methods of quantification for these two fractal's descriptor,whiches are fundamental for comprehension and modeling the plant's architecture.

Two complementary characteristics families from the fractal geometry will be studied. The first being the computation of fractal dimension making it possible to characterize the growth rate of the plant's details according to the scale (on wood and/or foliage in 3 dimensions). Varied estimators will be considered and compared on artificial data bases (for which one knows theoretical dimensions fractales) and real (obtained by digitalization 3D of real plants). The second family of methods will consist in developing algorithms for the lacunarity analysis of 3D plants. These methods will have to make it possible to characterize multi-scaled aggregation of the foliage and the size distribution of vacuums zones.

The models of lights in plant's foliage do the assumption of a homogeneous leaves distribution in space. However, many species present an multi-scaled organization and irregular foliage for which this assumption is not checked. To avoid this problem, empirical parameters are usually added to the initial model to compensate for the errors. We will try to elaborate a modeling approach that will give a geometrical meaning to the model's parameters using fractal geometry tools.

My PhD was about modelling the shoot apical meristem and, more precisely, the positionning of lateral organs around it. We used in our model the latest results of the cellular biology concerning the meristem, involving mainly the plant hormon auxin and its putative efflux transporter PIN1.

For this study, we developped tools to digitize the surface of meristems observed using confocal microscopy in 4D. These tools include automatic reconstruction of the meristem surface image, semi-automatic cell lineage reconstruction with automatic cell division detection and tools to analyse the obtained digitised meristem.

At a macroscopic level, we develop an extensive methodology to analyze the structures produced by meristems. This can be seen as a methodology that aims to solve an inverse problem in which one tries to infer meristem functioning from the complex structures they produce.  This analysis is carried out at different spatial and temporal scales.

At a more microscopic level, we intend to exploit the recent spectacular scientific and technological progresses in developmental biology in order to understand how  physiological and genetic processes control meristem growth at cell scale.

To analyse plant growth and structure, we focus mainly on methods for analysing sequences and tree-structured data. Theses methods range from algorithms for computing distance between sequences or tree-structured data to statistical models.

Plant structures exhibit complex branching organizations of their organs like internodes, leaves, shoots, axes, branches, etc. These structures can be analysed with combinatorial methods in order to compare them or to reveal particular types of organisation. We investigate a family of techniques to quantify distances between branching systems based on non-linear structural alignment (similar to edit-operation methods used for sequence comparison). Based on these techniques, we study the notion of self-similarity of branching structures in order to quantify the degree of redundancy of any tree structure and to quantify in this way critical botanical notions such as the physiological states of a meristem.

Repeated patterns within sequences or trees: The statistical models of interest are variable-order Markov chains and lumped processes constructed from Markov chains. Variable-order Markov chains are in particular applied to identify complex branching patterns resulting from local inhibition phenomena.

Homogeneous zones (or change points) within sequences or trees: Most of the statistical models of interest are hidden Markovian models (hidden semi-Markov chains and Markov switching linear mixed models for sequences and different families of hidden Markov tree models). A complementary approach consists in applying change-point detection models. The branching structure of a parent shoot is often organized as a succession of branching zones while the succession of shoot at the more macroscopic scale exhibit roughly stationary phases separated by marked transitions.

It is unrealistic to design models of plant development at macroscopic scales solely on the basis of biological functions since some patterns are the results of complex interactions between many functions acting at more microscopic scales.

The aim of this project is to propose a set of coherent methods for analyzing tree-structured data and to apply these methods to plant structures. Three main categories of methods or models are investigated: algorithms for computing distances between tree structures, hidden Markov tree models for finding homogeneous zones (or change points) within tree structures and multi-type branching processes with dependencies for analysing the generative growth process. This three-year grant started in Nov. 2004.

In this project, we intend to address the representation of natural scenes made of vegetals (trees, forests, prairies), watercourses (rivers, rivulets, waterfalls) and clouds (clouds, mist, fog). The project develops data structure, techniques and algorithms, in a unifed framework able to adapt both to the content (e.g. the internal representation) and to the navigation context (e.g. view point, devices etc.). We hence focus on the models, the evolution, the adaptive transmission and the visualization, but also on the composition of several natural entities in a complex virtual environment.

The carpel is the precursor of the fruit in the flowering plants. The early phase of carpel development is crucial regarding final morphology. The objective of the project is to understand cellular and molecular mechanisms behind the early phase of carpel development. For this purpose, we combine experimental and modeling approaches.

The aim of this Meristem is twofold. Our first goal is to design  3D visualization technics of the meristems and its molecular components. Second, we aim at developing a generic geometric model of the meristem able to support various  treatments and modelling processes at cell scale (characterization of meristem geometry, cell growth, mechanical forces, circulation of hormone fluxes, ...). This methodology will be carried out and tested on the rice, a model plant for agronomy, and on other perennial species to characterize the state of the meristem at different phenological states or for different environmental constraints.

This network started in January 2005 and gathers 10 european research groups that will use genetic, molecular and cellular approaches, imaging techniques, modeling approaches, as well as large-scale genomic techniques applied to the reference plant Arabidopsis for 4 years. In the project, Virtual Plants is responsible for the development of a 3D dynamic model of the meristem integrating various knowledge sources in a coherent picture of the meristem growth and functioning.

Computer algorithms and tools developed by the Virtual Plants team are integrated in a common software toolkit V-Plants, dedicated to the modeling and analysis of plant development at different scales. V-Plants is a package of ALEA.

This year we have decided to have common Masters and Engineering thesis topics. In the case of engineering thesis, the emphasis will be more on programming and less on research. A successful Master's thesis is expected to lead to a publication.

We are searching for a postdoctoral fellow for the EU IST FET Open project CROSSMOD. The goal of CROSSMOD is to study audio-visual cross-modal perceptual effects and to find ways to apply them to virtual environments. The partners of the project include research groups working in Computer Graphics and Computer Sound, psychoacoustics and neurosciences. The REVES/INRIA research group is coordinating this project.The project started in December 2005. The first phase of the project, which is currently under way, involves experimental work to determine cross-modal effects which are appropriate and promising in the context of selective rendering approaches and attention guidance techniques for virtual environments.

The ideal candidate should have a Ph.D. in computer science, or a multi-disciplinary Ph.D. in an engineering discipline and/or experimental psychology, and must have worked in Computer Graphics and/or Sound, and Virtual Reality research.

The position is available and is for 12 months renewable. Depending on the qualifications of the fellow, the research work may be more focused on the experimental side or on the algorithmic/rendering part of the project.

We exploit limitations of human auditory perception to optimize rendering times for complex scenes while preserving the perceived audio quality [TGD04].We proposed a real-time masking estimator derived from work in perceptual audio coding, which can determine at each frame of a simulation which sound sources are audible to the listener as well as a clustering strategy grouping neighboring sound sources based on spatial proximity but weighted by the energy of the signal emitted by each source. We performed perceptual validation studies which showed that such techniques have minimal impact on perceived audio quality and do not affect user performance in terms of 3D sound localization.

Overall, it is interesting to note the similarity between this work in audio rendering and related techniques in computer graphics: occlusion culling, level of detail and importance sampling for point-based representations or global illumination.

The thesis of A. Reche was on image-based methods for capture and rendering of real objects. The main result was a novel approach for the capture and rendering of real trees [RMD04]. Initially a set of photographs is taken around the tree, and the cameras of these images are calibrated. Then, alpha-mattes are extracted from the images, giving an opacity value to each pixel in each view. In a second step, the opacity values are used to perform a density estimation on a hierarchical grid, resulting the assignment of a density value for each grid cell. In the final step, textures are extracted from the images and assigned to a billboard in each cell.

There is thus one billboard per cell, and one texture per billboard per input camera position.This work is being continued, to allow reduction in texture memory and efficient multi-resolution rendering.

Another result of the thesis [RD03b] was on a method which enables manual intervention in the use of view-dependent texture maps. By introducing a visibility ordering to create visibility layers and by allowing and image editing of each layer (e.g., in GIMP), it is possible to achieve very realistic renderings with a smaller number of input images.

We have developed an approximation for ambient occlusion for trees and grass [HPAD06], in collaboration with K. Hegeman and M. Ashikhmin of Sony Brook Univ. and S. Premoze. This is a classic case of an approximation which is plausible, but does not correspond to physical principles (see Fig. 3).

One important aspect of this project was the decision to work with a real-world application, which was the Tramway construction project in Nice. After presenting a simple demonstrator to the people in charge, we developed a strong working relationship with them. In particular we chose to reconstruct and represent the potential development of a historical square in Nice (place Garibaldi, see left Figure above, which is a view of the VE simulator). We were able to perform an in-depth analysis of our choices for the virtual environment, by studying the usage of our system by the architects who were actually in charge of the real-world project Figure left above. This work has resulted in a paper in the Presence journal [DRTR07], accepted for publication in 2007.

In this work, we developed a general and flexible formalism to describe visibility events based on sets of generators (i.e., vertices and edges). This allowed the computation of the visibility skeleton (the 0 and 1-nodes of the visibility complex) for relatively complex scenes.

The method is based on “fat lines”, which are lines with an epsilon thickness, and consisten treatment of intersections of these lines with the scene. Examples of the results of this methods are shown in 4(left).

A goal of simulation systems for training is to provide users with appropriate sensory stimulation so that they interact in similar ways with the virtual world as in the natural world. Visual fidelity is often a primary goal of computer graphics imagery which strives to create scenes that are perceptually indistinguishable from an actual scene to a human observer. Interaction fidelity refers to the degree the simulator technology (visual and motor) is perceived by a trainee to duplicate the operational equipment and the actual task situation. The research community is challenged to establish functional fidelity metrics for simulations mainly targeting positive transfer of training in the real world.

In this talk, I will explore the effect of visual and interaction fidelity on spatial cognition focusing on how humans mentally build spatial representations. I will then discuss on-going research relevant to the effect of memory schemas on spatial memory and relevant results' application towards a real-time selective rendering engine which endeavors to simulate a cognitive process rather than physics. We will conclude with a brief presentation of other projects relevant to simulation of subjective impressions of illumination and work on determining perceptual sensitivity to tracking latency.

Indirect illumination is a subtle, yet important aspect for realistic rendering. Due to its global nature the computation of indirect illumination is notoriously slow. On the other hand, approximations for indirect light are usually satisfactory.

Reflective Shadow Maps are an efficient means to add one-bounce indirect illumination of diffuse surfaces to dynamic scenes. Recent improvements provide an extension for non-diffuse surfaces and caustics and achieve real-time rendering speed.

Carsten Dachsbacher is a Ph.D. student in computer graphics at the University of Erlangen. His research focuses on interactive, hardware-assisted computer graphics; in particular he is working on interactive global illumination techniques, procedural models for rendering photo-realistic terrains and point-based rendering.

Photo-realistic rendering quality and truly authentic animations can be obtained. Besides offering a solution for realistic rendering applications in computer graphics, research into video-based modeling and rendering algorithms also leads to tools for video editing and may even pave the way towards new forms of visual media.

His research interests in computer graphics include video-based rendering, realistic and interactive visualization, as well as dynamic geometry processing. Beyond graphics, he is working on interdisciplinary research topics such as dynamic scene analysis, multimedia coding and communications, and physics-based modeling.

Eugene has participated in many task forces and reviews of research institutes around the world. He has had a long association with the computer graphics and electronic media industries in Canada and the U.S., notably with Alias|wavefront, where he was Director of Research and Usability Engineering while on leave from the university. He now works with several companies in an advisory capacity on both technological and business issues. He also works with venture capital companies on due diligence and strategy.

Eugene's research interests include most aspects of realistic computer graphics, including computer animation, modelling natural phenomena, and illumination, as well as strong interests in internet based imaging, image repositories, software systems and parallel algorithms.

The last few years have seen dramatic improvements in how much computation power and visual capabilities can be packed into a device small enough to fit in your pocket. Real-time 3D graphics on mobile phones is now a reality, and there are two new standards for a mobile 3D API.

Phones where he heads research activities ensuring that mobile devices allow visually interesting communication and entertainment, from the input (cameras) to the output (displays and graphics). He is also a Docent (adjunct faculty) at University of Oulu, where he teaches computer graphics.

The motion of animated human characters is notoriously difficult to create. Motion synthesis methods must achieve expressiveness, subtlety and realism. The current techniques for creating such quality motions, such as capturing it by observing real performers, can achieve these qualities in short, specific clips of motion. However, while these clips provide examples of what a character can do, a set of clips by itself does not provide sufficient flexibility to animate all of the things we might require of a character. We need methods that are capable of synthesizing new motions that have the qualities of the examples.

Gleicher joined the University in 1998 to start a computer graphics group within the department. The overall goal of his research is to create tools that make it easier to create pictures, video, animation, and virtual environments; and to make these visual artifacts more interesting, entertaining, and informative. His current focus is on tools for character animation and for the automatic production of video. Prior to joining the university, Prof. Gleicher was a researcher at The Autodesk Vision Technology Center and at Apple Computer's Advanced Technology Group. He earned his Ph. D. in Computer Science from Carnegie Mellon University, and holds a B.S.E. in Electrical Engineering from Duke University.

I will also be talking about techniques for true volumetric display in open air and distributed robotic display devices. In addition, time permitting, I will show a number of small web-based interactive art and technology projects.

Then, we present selected MR research applications and discuss in more detail some recent results and ongoing MR research at the VRCC. We illustrate our developments with our "MagicMeeting" system, a collaborative AR system for design review scenarios.

Center in Ulm, Germany. His research interests include interfaces for virtual and augmented environments, virtual reality aided design, perception of virtual reality, collaboration, and AR/VR in the automotive and aerospace industry. Regenbrecht received a doctoral degree from the Bauhaus University Weimar, Germany.

In a computer game, characters exist mainly to provide choices for a player who advances through the experience, testing himself against the game or against other players. Players do not feel that Laura Croft or Mario actually exist as psychological beings.

In contrast, in a play or movie the audience expects to vicariously experience the emotional choices of characters. Those choices have been carefully created by an author, interpreted by a director, and embodied by actors to promote a willing "suspension of disbelief."

Could this dichotomy be turned into a continuous dialectic? Could there be an interactive narrative artform in which agency is amorphous, floating between audience and character? The question is timely, because many of the enabling technologies to make such a medium are only now emerging, much as the enabling technologies to create cinema began to emerge roughly a century ago.

Such a medium would require the equivalent of at least three elements: story, direction, and acting. Of these, the third constitutes a creative bottleneck, since it is not interesting to create interactive story and direction without actors who can breathe life into them.

Dynamic simulation can generate complex and realistic motion automatically, freeing the modeler or animator from worrying about the details. But what if you care about the details? For Pixar's meticulously choreographed animations, pure dynamics simulation alone doesn't necessarily deliver what the director wants. This talk will discuss three different approaches to provide the controls we need for dynamic (or dynamic-seeming) behavior to satisfy production aesthetics.

Barzel joined Pixar in 1993 to work on Toy Story in various roles, in particular as a modeler with an emphasis on ropes, cords & the Slinky Dog, and as a member of the lighting team and engineer of lighting methodology and software. He has since worked on R&D of modeling, lighting and animation tools. He has a bachelor's in math/physics and a masters in computer science from Brown University, and a PhD in computer science from Caltech, where he worked on "dynamic constraints" and physically-based modeling. He is the editor-in-chief of the Journal of Graphics Tools. Starting January 2003 he will be visiting at Ecole Polytechnique, teaching a course about CG animation.

Since the Antiquity, people tried explain the complex phenomenon of color vision. In my talk, I will present different facets of color, as seen by painters and art critics, by computer graphics people, and by experimental psychologists and neuroscientists. We shall overview the basic concepts of modern color science, including the latest standards for color appearance models used in the imaging technology.

This seminar will focus on the problem of 3d reconstruction from multiple images taken from arbitrary point of view. Actually stereoscopic algorithms, who need similar point of view, can not be easily generalized with the case of "arbitrary cameras". The reason is that the occlusions, minor problem in stereoscopic, become an apparently insurmountable obstacle when, for example, two cameras are face to face.

We will describe a generalization of the approach by maximum-flow, able to minimize globally and effectively certain functions of mapping, towards the multiple case of images from arbitrary cameras. It differs from the other methods (space carving, planes sweep...) by its global solution rather than local to the occlusions problem.

The talk will cover some aspects in this environment. First, a modelling method is presented that allows the user to interactively generate plant models using a small set of components. These plants are then combined to form complex ecosystems using interactive tools. Efficient realistic rendering algorithms are given. In the last part of the talk, some non-realistic rendering methods for vegetation are discussed.

Building realistic models of real-world environments is a complex task, involving the recovery of geometric representations of objects and descriptions of surface reflectance and illumination characteristics.

In this talk, I will present several algorithms we are developing to reconstruct such models from sequences of images, and video footage of real scenes. First, I will discuss automatic and semi-automatic methods for camera calibration and geometry reconstruction. Following that, I will give details of a novel and flexible approach to estimating surface reflectance and illumination characteristics that uses high dynamic-range images and sets of virtual light-sources.

Project description: The aim is to develop a Web Crawler for collection and update of images from the Web. The Crawler will interact with the PostgreSQL database. The process of image download should be optimized so that to keep the image collection updated and at the same time to respect the Web site policies and to utilize carefully the network resources.

These objectives essentially fall in the first scientific challenge of INRIA, which is "To master digital infrastructures by being capable of programming, computing, and communicating on the Internet and on heterogeneous networks."

My main research interest is in the performance evaluation of networks using probability theory, queueing theory, and computer simulations. My research focus is on wireless networks like mobile Ad Hoc networks, delay tolerant networks, and sensor networks. My research activities during my PhD, includes, but it was not restricted to, the Medium Access Control (MAC) protocols, the routing and relay protocols, TCP protocol, and the random mobility models.

Mobility has become an important feature of computing systems and networks, and particularly of distributed systems. Our project is more specifically concerned with the notion of a mobile code, a logical rather than physical notion of mobility. An important task in this area has been to understand the various constructs that have been proposed to support this style of programming, and to design a corresponding programming model with a precise (that is, formal) semantics. The models that we have investigated in the past are mainly the π-calculus of Milner and the Mobile Ambients calculus of Cardelli and Gordon. The first one is similar to the λ-calculus, which is recognized as a canonical model for sequential and functional computations. The π-calculus is a model for concurrent activity, and also, to some extent, a model of mobility: π-calculus processes exchange names of communication channels, thus allowing the communication topology to evolve dynamically. The π-calculus contains, up to continuation passing style transforms, the λ-calculus, and this fact establishes its universal computing power.  The Mobile Ambient model focusses on the migration concept. It is based on a very general notion of a domain -- an Ambient --, in which computations take place. Domains are hierarchically organized, but the nesting of domains inside each other evolves dynamically. Indeed, the computational primitives consist in moving domains inside or outside other domains, and in dissolving domain boundaries. Although this model may look, from a computational point of view, quite simple and limited, it has been shown to be Turing complete.  In the past we have studied type systems and reasoning techniques for these models. We have, in particular, used models derived from the π-calculus for the formalization and verification of cryptographic protocols. We are now studying how to integrate the model of reactive programming, described below, into a "global computing" perspective. This model looks indeed appropriate for a global computing context, since it provides a notion of time-out and reaction, allowing a program to deal with the various kinds of failures (delays, disconnections, etc.) that arise in a global network. We have started the design and implementation of a core programming language that integrates reactive programming and mobile code, in the context of classical functional and imperative programming.

We are studying security issues, especially those related to concurrent and mobile programming. In the past we have developed methods and tools for the verification of cryptographic protocols. We also work on secure information flow. This is motivated by the observation that access control is not enough to ensure confidentiality, since access control does not prevent authorized users to disclose confidential information. We use the language-based approach, developing static analyses, and especially type systems, to ensure that programs do not implement illegal flow of information.  We work particularly on specific confidentiality issues arising with concurrent and mobile programming, but we also work on more general questions, like how to allow some pieces of code to declassify some information, while still ensuring some confidentiality policy. We also use static analysis techniques, namely polynomial quasi-interpretations, to ensure that programs do not use computational resources beyond fixed limits. Again, a special effort is put here in finding methods that apply to reactive and/or mobile programs. This could also have applications to embedded code.

We have developed several implementations of reactive programming, integrating it into various programming languages. The first instance of these implementations was Reactive-C, which was the basis for several developments (networks of reactive processes, reactive objects), described in the book [Bou96]. Then we developed the SugarCubes, which allow one to program with a reactive style in Java, see [Bou00]. Reactive programming offers an alternative to standard thread programming, as (partly) offered by Java, for instance. Classical thread programming suffers from many drawbacks, which are largely due to a complicated semantics, which is most often implementation-dependent.

We have designed, following the reactive approach, an alternative style for thread programming, called FairThreads, which relies on a cooperative semantics. Again, FairThreads has been integrated in various languages, and most notably into Scheme via the Bigloo compiler that we develop. One of our major objectives is to integrate the reactive programming style in functional languages, and more specifically Scheme, and to further extend the resulting language to support migration primitives. This is a natural choice, since functional languages have a mathematical semantics, which is well suited to support formal technical developments (static analysis, type systems, formal reasoning).

We also designed a tool to graphically program in the reactive style, called Icobjs. Programming in this case means to graphically combine predefined behaviours, represented by icons and to implement reactive code.

Hop is a new higher-order language designed for programming interactive web applications such as web agendas, web galleries, music players, etc. It exposes a programming model based on two computation levels. The first one is in charge of executing the logic of an application while the second one is in charge of executing the graphical user interface. Hop separates the logic and the graphical user interface but it packages them together and it supports strong collaboration between the two engines. The two execution flows communicate through function calls and event loops. Both ends can initiate communications. The paper presents the main constructions of Hop. It sketches its implementation and it presents an example of a simple web application written in Hop.

Hop, is a language dedicated to programming reactive and dynamic applications on the web. It is meant for programming applications such as web agendas, web galleries, web mail clients, etc. While a previous paper (Hop, a Language for Programming the Web 2.0, available at http://hop.inria.fr) focused on the linguistic novelties brought by Hop, the present one focuses on its execution environment. That is, it presents Hop's user libraries, its extensions to the HTML-based standards, and its execution platform, the Hop web broker.

We define a method to statically bound the size of values computed during the execution of a program as a function of the size of its parameters. More precisely, we consider bytecode programs that should be executed on a simple stack machine with support for algebraic data types, pattern-matching and tail-recursion. Our size verification method is expressed as a static analysis, performed at the level of the bytecode, that relies on machine-checkable certificates. We follow here the usual assumption that code and certificates may be forged and should be checked before execution. Our approach extends a system of static analyses based on the notion of quasi-interpretations that has already been used to enforce resource bounds on first-order functional programs. This paper makes two additional contributions. First, we are able to check optimized programs, containing instructions for unconditional jumps and tail-recursive calls, and remove restrictions on the structure of the bytecode that was imposed in previous works. Second, we propose a direct algorithm that depends only on solving a set of arithmetical constraints.

We study the problems related to querying large, distributed XML documents. Our proposal takes the form of a new process calculus in which XML data are processes that can be queried by means of concurrent pattern-matching expressions. What we achieve is a functional, strongly-typed programming model based on three main ingredients: an asynchronous process calculus in the style of Milner's pi-calculus and existing semantics for concurrent-ML; a model where documents and expressions are both represented as processes, and where evaluation is represented as a parallel composition of the two; a static type system based on regular expression types.

Bimap is a tool for synchronizing IMAP servers. It enables two or more IMAP mirrored servers to be modified independently and later on, synchronized. Bimap is versatile so, in addition to synchronizing emails, it can be used for filtering and classifying emails. For the sake of the example, the paper shows automatic emails classification and white-listing programmed with Bimap. Bimap is implemented in Scheme. The most important parts of its implementation are presented in this paper with the intended goal to demonstrate that Scheme is suited for programming tasks that are usually devoted to scripting languages such as Perl or Python. With additional libraries, Scheme enables compact and efficient implementation of this distributed networked application because the main computations that require efficiency are executed in compiled code and only the user configurations are executed in interpreted code.

Jsigloo compiles Javascript to Scheme. It acts as an frontend to Bigloo which subsequently compiles the intermediate result to one of its backends (C, JVM or .NET). Such a compilation furthermore benefits of the optimizations implemented within Bigloo. Jsigloo hence implements only few optimizations, but tries to produce easily optimizable Scheme code. Scheme is (by design) a relatively minimal language, and some Javascript constructs don't have equivalent expressions in Scheme. This paper presents the difficulties we encountered when mapping these constructs. It furthermore describes the optimizations that have been implemented in Jsigloo.

Skribe is a functional programming language designed for authoring documents, such as web pages or technical reports. It is built on top of the Scheme programming language. Its concrete syntax is simple and it looks familiar to anyone used to markup languages. Authoring a document with Skribe is as simple as with HTML or LaTeX. Because of the conciseness of its original syntax, it is even possible to use it without noticing that it is a programming language. In Skribe, the ratio "markup/text" is smaller than with the other markup systems we have tested.

We present the embedding of ULM in Scheme and an implementation of a compiler and virtual machine for it. ULM is a core programming model that allows multi-threaded and distributed programming via strong mobility with a deterministic semantics. We present the multi-threading and distributed primitives of ULM step by step using examples. The introduction of mobility in a Scheme language raises questions about the semantics of variables with respect to migration. We expose the problems and offer two solutions alongside ULM's network references. We also present our implementation of the compiler, virtual machine and the concurrent threading library written in Scheme.

This paper presents the compilation of the Scheme programming language to .NET. This platform provides a virtual machine, the Common Language Runtime (CLR), that executes bytecode, the Common Intermediate Language (CIL). Since CIL was designed with language agnosticism in mind, it provides a rich set of language constructs and functionalities. As such, the CLR is the first execution environment that offers type safety, managed memory, tail recursion support and several flavors of pointers to functions. Therefore, the CLR presents an interesting ground for functional language implementations. We discuss how to map Scheme constructs to CIL. We present performance analyses on a large set of real-life and standard Scheme benchmarks. In particular, we compare the speed of these programs when compiled to C, JVM and .NET. We show that in term of speed performance of the Mono implementation of .NET, the best implementing running on both Windows and Linux, still lags behind C and fast JVMs such as the Sun's implementations.

This paper presents Fair Threads, a new model for concurrent programming. This multi-threading model combines preemptive and cooperative scheduling. User threads execute according to a cooperative strategy. Service threads execute according to a preemptive strategy. User threads may ask services from service threads in order to improve performance by exploiting hardware parallelism and in order to execute non-blocking operations. Fair threads are experimented within the context of the functional programming language Scheme. This paper also presents the integration in this language. That is, it presents a semantics for Scheme augmented with Fair Threads and the main characteristics of the implementation.

We present in this paper the compilation of the Scheme programming language to .Net platform. .Net provides a virtual machine, the Common Language Runtime (CLR), that executes bytecode, the Common Intermediate Language (CIL). Since CIL was designed with language agnosticism in mind, it provides a rich set of language constructs and functionalities. Therefore, the CLR is the first execution environment that offers type safety, managed memory, tail recursion support and several flavors of pointers to functions. As such, the CLR presents an interesting ground for functional language implementations. We discuss how to map Scheme constructs to CIL. We present performance analyses on a large set of real-life and standard Scheme benchmarks. In particular, we compare the performances of Scheme programs when compiled to C, JVM and .Net. We show that .Net still lags behind C and JVM.

We prove the decidability of the quantifier-free, static fragment of ambient logic, with composition adjunct and iteration, which corresponds to a kind of regular expression language for semistructured data. The essence of this result is a surprising connection between formulas of the ambient logic and counting constraints on (nested) vectors of integers. Our proof method is based on a new class of tree automata for unranked, unordered trees, which may result in practical algorithms for deciding the satisfiability of a formula. A benefit of our approach is to naturally lead to an extension of the logic with recursive definitions, which is also decidable. Finally, we identify a simple syntactic restriction on formulas that improves the effectiveness of our algorithms on large examples.

We define a simple stack machine for a first-order functional language and show how to perform type, size, and termination verifications at the level of the bytecode of the machine. In particular, we show that a combination of size verification based on quasi-interpretations and of termination verification based on lexicographic path orders leads to an explicit bound on the space required for the execution.

We develop new methods to statically bound the resources needed for the execution of systems of concurrent, interactive threads. Our study is concerned with a synchronous model of interaction based on cooperative threads whose execution proceeds in synchronous rounds called instants. Our contribution is a system of compositional static analyses to guarantee that each instant terminates and to bound the size of the values computed by the system as a function of the size of its parameters at the beginning of the instant. Our method generalises an approach designed for first-order functional languages that relies on a combination of standard termination techniques for term rewriting systems and an analysis of the size of the computed values based on the notion of quasi-interpretation. These two methods can be combined to obtain an explicit polynomial bound on the resources needed for the execution of the system during an instant.

We settle the complexity bounds of the model checking problem for the ambient calculus with public names against the ambient logic. We show that if either the calculus contains replication or the logic contains the guarantee operator, the problem is undecidable. In the case of the replication-free calculus and guarantee-free logic we prove that the problem is PSPACE-complete. For the complexity upper bound, we devise a new representation of processes that remains of polynomial size during process execution; this allows us to keep the model checking procedure in polynomial space. Moreover, we prove PSPACE-hardness of the problem for several quite simple fragments of the calculus and the logic; this suggests that there are no interesting fragments with polynomial-time model checking algorithms.

This paper presents Biglook, a widget library for an extended version of the Scheme programming language. It uses classes of a Clos-like object layer to represent widgets and Scheme closures to handle graphical events. Combining functional and object-oriented programming styles yields an original application programming interface that advocates a strict separation between the implementation of the graphical interfaces and the user-associated commands, enabling compact source code. The Biglook implementation separates the Scheme programming interface and the native back-end. This permits different ports for Biglook. The current version uses GTK and Swing graphical toolkits, while the previous release used Tk.

XML documents, and other forms of semi-structured data, may be roughly described as edge labeled trees; it is therefore natural to use tree automata to reason on them. This idea has already been successfully applied in the context of Document Type Definition (DTD), the simplest standard for defining XML documents validity, but additional work is needed to take into account XML Schema, a more advanced standard, for which regular tree automata are not satisfactory. In this paper, we define a tree logic that directly embeds XML Schema as a plain subset as well as a new class of automata for unranked trees, used to decide this logic, which is well-suited to the processing of XML documents and schemas.

We study dynamical properties of PB systems, a new computational model of biological processes, and propose a compositional encoding of PB systems into Petri nets. Building on this relation, we show that three properties: boundedness, reachability and cyclicity, which we claim are useful in practice, are all decidable.

We describe a new class of tree automata, and a related logic on trees, with applications to the processing of XML documents and XML schemas. XML documents, and other forms of semi-structured data, may be roughly described as edge labeled trees. Therefore it is natural to use tree automata to reason on them and try to apply the classical connection between automata, logic and query languages. This approach has been followed by various researchers and has given some notable results, especially when dealing with Document Type Definition (DTD), the simplest standard for defining XML documents validity. But additional work is needed to take into account XML schema, a more advanced standard, for which regular tree automata are not satisfactory. A major reason for this inadequacy is the presence of an associative-commutative operator in the schema language, inherited from the &-operator of SGML, and the inherent limitations of regular tree automata in dealing with associative-commutative algebras. The class of automata considered here, called sheaves automata, is a tailored version of automata for unranked trees with both associative and associative-commutative symbols already proposed by the authors. In order to handle both ordered and unordered operators, we combine the transition relation of regular tree automaton with regular word expression and counting constraints. This extension appears quite natural since, when no counting constraints occurs, we obtain hedge automata, a simple model for XML schemata, and when no constraints occur, we obtain regular tree automata. Building on the classical connection between logic and automata, we also present a decidable tree logic that embeds XML Schema as a plain subset.

We have added a Java virtual machine (henceforth JVM) bytecode generator to the optimizing Scheme-to-C compiler Bigloo. We named this new compiler BiglooJVM. We have used this new compiler to evaluate how suitable the JVM bytecode is as a target for compiling strict functional languages such as Scheme. In this paper, we focus on the performance issue. We have measured the execution time of many Scheme programs when compiled to C and when compiled to JVM. We found that for each benchmark, at least one of our hardware platforms ran the BiglooJVM version in less than twice the time taken by the Bigloo version. In order to deliver fast programs the generated JVM bytecode must be carefully crafted in order to benefit from the speedup of just-in-time compilers.

We describe multitree automata and a related logic on multitrees. Multitrees are extensions of trees with both associative and associative-commutative symbols that may bear arbitrary numbers of sons. An originality of our approach is that transitions of an automaton are restricted using Presburger's constraints. The benefit of this extension is that we generalize, all together, automata with equality and disequalities constraints as well as counting constraints. This new class of automata appears very general as it may encompass hedge automata, a simple yet effective model for XML schemata, feature tree automata, automata with constraints between brothers and automata with arithmetical constraints. Moreover, the class of recognizable languages enjoys all the typical good properties of traditional regular languages: closure under boolean operations and composition by associative and associative-commutative operators, determinisation, decidability of the test for emptiness, ... We apply our automata to query languages for XML-like documents and to automated inductive theorem proving based on rewriting, obtaining each time new results. Using a classical connection between logic and automata, we design a decidable logic for (multi)trees that can be used as a foundation for querying XML-like document. This proposition has the same flavour as a query language for semi-structured recently proposed by Cardelli and Ghelli. The same tree logic is used to yield decidable cases of inductive reducibility modulo associativity-commutativity, a key property in inductive theorem proving based on rewriting.

We show that the typed region calculus of Tofte and Talpin can be encoded in a typed pi-calculus equipped with name groups and a novel effect analysis. In the region calculus, each boxed value has a statically determined region in which it is stored. Regions are allocated and de-allocated according to a stack discipline, thus improving memory management. The idea of name groups arose in the typed ambient calculus of Cardelli, Ghelli, and Gordon. There, and in our pi-calculus, each name has a statically determined group to which it belongs. Groups allow for type-checking of certain mobility properties, as well as effect analyses. Our encoding makes precise the intuitive correspondence between regions and groups. We propose a new formulation of the type preservation property of the region calculus, which avoids Tofte and Talpin's rather elaborate co-inductive formulation. We prove the encoding preserves the static and dynamic semantics of the region calculus. Our proof of the correctness of region de-allocation shows it to be a specific instance of a general garbage collection principle for the pi-calculus with effects. We propose new equational laws for letregion, analogous to scope mobility laws in the pi-calculus, and show them sound in our semantics.

We propose a short bibliographic survey of calculi for mobile processes. Contrasting with other similar exercises, we consider two related, but distinct, notions of mobile processes, namely labile processes, which can exhibit changes of their interaction structure, as modelled in the pi-calculus, and motile processes, which can exhibit movement, as modelled in the ambient calculus of Cardelli and Gordon. A common attribute of the algebraic frameworks presented in this paper is that they all rely on a notion of name as first class value.

We settle the complexity bounds of the model checking problem for the replication-free ambient calculus with public names against the ambient logic without parallel adjunct. We show that the problem is PSPACE-complete. For the complexity upper-bound, we devise a new representation of processes that remains of polynomial size during process execution; this allows us to keep the model checking procedure in polynomial space. Moreover, we prove PSPACE-hardness of the problem for several quite simple fragments of the calculus and the logic; this suggests that there are no interesting fragments with polynomial-time model checking algorithms.

Memory is the performance bottleneck of modern architectures. Keeping memory consumption as low as possible enables fast and unobtrusive applications. But it is not easy to estimate the memory use of programs implemented in functional languages, due to both the complex translations of some high level constructs, and the use of automatic memory managers. To help understand memory allocation behavior of Scheme programs, we have designed two complementary tools. The first one reports on frequency of allocation, heap configurations and on memory reclamation. The second tracks down memory leaks. We have applied these tools to our Scheme compiler, the largest Scheme program we have been developing. This has allowed us to drastically reduce the amount of memory consumed during its bootstrap process, without requiring much development time. Development tools will be neglected unless they are both conveniently accessible and easy to use. In order to avoid this pitfall, we have carefully designed the user interface of these two tools. Their integration into a real programming environment for Scheme is detailed in the paper.

We propose an interpretation of a typed concurrent calculus of objects based on the model of Abadi and Cardelli imperative object calculus. The target of our interpretation is a version of the blue calculus, a variant of the pi-calculus that directly contains the lambda calculus, with record and first-order types. We show that reduction and type judgments can be derived in a rather simple and natural way, and that our encoding can be extended to self-types and synchronization primitives. We also prove some equational laws on objects.

The ambient calculus of Cardelli and Gordon is a process calculus for describing mobile computation where processes may reside within a hierarchy of locations, called ambients. The dynamic semantics of this calculus is presented in a chemical style that allows for a compact and simple formulation. In this semantics, an equivalence relation, the spatial congruence, is defined on the top of an unlabelled transition system, the reduction system. Reduction is used to represent a real step of evolution (in time), while spatial congruence is used to identify processes up to particular (spatial) rearrangements. In this paper, we show that it is decidable to check whether two ambient calculus processes are spatially congruent, or not. Our proof is based on a natural and intuitive interpretation of ambient processes as edge-labelled finite-depth trees. This allows us to concentrate on the subtle interaction between two key operators of the ambient calculus, namely restriction, that accounts for the dynamic generation of new location names, and replication, used to encode recursion. The result of our study is the definition of an algorithm to decide spatial congruence and a definition of a normal form for processes that is useful in the proof of interesting equivalence laws.

Recommendation: This page is better viewed with Mozilla (you may also try Netscape or IE with an up-to-date Java plugin). Otherwise you might prefer to download the .jar archive and use it as a stand-alone application.

Reactive programming (see [2]) is a method of distributed programming, based on immediate broadcasting of messages: time is sliced into instants during which messages can be generated and detected by different processes interacting in parallel. There is also a dynamical aspect: processes can be added or withdrawn from the system (quite) at any time.

Icobjs are created by associating a graphical icon to a behaviour (that is a reactive program). Placed together (in parallel) in a reactive machine, they interact while being displayed at each instant in a window. Examples of possible classical behaviour are: inertia, collision, gravitation, prey-predator...

Ambient calculus (see [3]) is a form of notation devised by Luca Cardelli and Andy Gordon and used to describe and theorise about mobile systems. It is useful to model interactions in such systems as the Internet. The ambient model is elegant and powerful. The three basic ambient primitives, namely in, out, and open are expressive enough to simulate name-passing channels in the pi-calculus. As a theoretical model, it is very interesting to explore the various properties behind this small calculus. During the years, many variants and dialects have been proposed: the original mobile ambients (see[4]), safe ambients (see [5]), robust ambients (see [6]) and controlled ambients (see [7]).

Some implementations had been proposed in the past, but they were all textual only and were suffering from a complex and costly mechanism of lock acquiring and releasing, with difficult theoretical problems to ensure that no deadlock could occur.

The current challenge was to design a completely graphical implementation where one could "see" the boundaries of an ambient. Moreover, we wanted to benefit from the reactive approach and the natural "atomicity" of operations induced by the physical simulation to get rid of these locking problems. The result is a Java program and applet which is able to "physically" simulate any ambient expression in any of the four dialects mentioned above, and see them evolve on the screen.

The capability in c consists of different parts: an anchor which remains in the ambient, an arrow outside which is physically attracted by any ambient with name c, and an elastic linking both parts. When the arrow finds an ambient c, it locks and the elastic shrinks until both ambients a and c get in contact. Then, ambient a is entirely moved inside c.

This is the way mobile ambients react. Concerning the other models with co-capabilities (especially safe ambients), the co-capabilities are represented by "doors" moving around the boundaries of the ambient, which attract the corresponding capabilities.

This example models a city with different sites, cabs and clients willing to go from one site to another. The complete protocol was presented in [7]. This demo is first initialized with three different sites a, b and c, two cabs available in the city, and three clients willing to go repeatedly back and forth from a to b, a to c, and b to c respectively. You can add more clients or cabs by left-clicking on the corresponding constructors on the left.

This example comes from [8], where the encoding is extensively developped. In this demo, you can create channels of name n, outputs and inputs on these channels, and even more complex recursive pi-processes. The corresponding translation in pure ambients is then released and you can let the system evolve.

This applet provides general constructors for four different dialects of ambients: mobile ambients, safe ambients, robust ambients and controlled ambients. Left-clicking on the hand pops up a window asking for an ambient term. A second window asks for a name for the constructor. If the term is valid, a new constructor is created, and by left-clicking on it, we can launch the corresponding ambient as many times as we want.

Then, try to release many copies of the same processes at the same time. See how capabilities are attracted by different ambients concurrently and how the first ambient encountered wins (this, combined with the randomness of shocks between ambients and walls, provides the non-determinism of the system).

The following process creates a new private name n (which should appear in the form "n#10"), creates some intricate ambients named n and an ambient a which has the capabilities to enter or exit n at any time. Theoretically, you should see the ambient a moving around inside and outside any combination of n, and thus indefinitely.

Two ambients x and y contain the same program: each time they encounter an ambient n, they open it, replace it with two fresh ambients n and send them to the other one. An initial n starts the process. The result is that x and y start exchanging an increasing number of ambients n.

Flyspell enables on-the-fly spell checking in Emacs by the means of a minor mode. It is called Flyspell. This facility is hardly intrusive. It requires no help. Flyspell highlights incorrect words as soon as they are completed or as soon as the cursor hits a new word.

Flyspell proposes corrections for miss-spelled words by the means of pop-up menus. Clicking Mouse-2 on a highlighted word will raise a menu that proposes corrections. Alternatively you will be able to store the word in the global dictionary, to add it to the current document dictionary or to ignore the miss-spelling for the current session.

FairThreads offers a very simple framework for concurrent and parallel programming.  Basically, it defines schedulers which are synchronization servers, to which fair threads are linked.  All threads linked to the same scheduler are executed in a cooperative way, at the same pace, and they can synchronize and communicate using broadcast events.Threads which are not linked to any scheduler are executed by the OS in a preemptive way, at their own pace. FairThreads offers programming constructs for dynamically linking and unlinking threads.In the Cooperative variant of FairThreads, all threads are linked to one unique scheduler.  Cooperative FairThreads is deterministic and has a precise and clear semantics.FairThreads is implemented in C; variants of it (basically, Cooperative FairThreads) are also implemented in Java, and Scheme.

The REJO's programming model, which is close to that of Junior, provides reactive instructions that are executed in a reactive machine. The set of reactive instructions implements the instantaneous broadcast events as well as a logic parallelism operator which does not use threads. One of the particularities of Junior reactive instructions is that they have a formal semantic defined by rewriting rules.

In the domain of distributed applications, networks (Internet and intranets), smartcards, and terminals, our goal is to propose fundamental principles, techniques and tools for the building, analysis, validation, verification and maintenance of reliable systems.

Control and structure analysis of non-linear systems: continuous stabilization, linearization, and near optimal control with applications to orbit transfer of satellites, and in a near future to quatum physics.

We take into account the specific requirements of real large-scale scientific programs. Our team is composed of numerical analysis specialists, who bring their knowledge of scientific computing, and of software engineering specialists, who bring their knowledge of program analysis, transformation, and compilation.

There are mathematical questions such as the behavior of A.D. in a neighborhood of program discontinuities (tests...), the convergence of derivatives compared to convergence of initial results, or the complexity of various A.D. strategies. There are computer science problems such as complexity of the computation of derivatives, memory usage for the "reverse" mode, or variable aliasing. We explore new A.D. strategies, looking for compromises between "direct" and "reverse" mode, or studying dedicated strategies for special, yet frequent, situations. A.D. is a relatively young and very interesting domain, as could be seen at the AD2000 conference, that we organized in Nice, France. A book of selected papers is now available from Springer.

Parallelization : We focus on some specific problems. One is loop parallelization, with OpenMP as a target. Another is SPMD parallelization of numerical computations on meshes, using a mesh partition. We also study combination of parallelization and A.D.

Our ideas need to be validated in some testbench. Moreover, we want these researches to be applicable to real-life programs. To this end, we develop a common platform for analysis and transformation of scientific programs. It is written in JAVA.

The ACACIA project (INRIA-Sophia-Antipolis) is a multidisciplinary project composed of computer scientists and cognitive psychologists. It aims at offering methodological and software support (i.e. models, methods and tools) for knowledge management (i.e., for building, managing and distributing a corporate memory).

We study technical memory, profession memory and project memory, in particular in concurrent design. We study the case where the building of a corporate memory relies on exploitation of knowledge underlying documents, on the management of links between documents and knowledge bases or on the modelling of multiple viewpoints. We study knowledge acquisition, modelling and management from multiple expertise sources (experts and documents).

We study the problems involved in the dissemination of knowledge through a knowledge server and via an intranet or the internet: we regard the semantic Web as a privileged means of assistance for the management of knowledge distributed within or between firms. Then, a knowledge server enables searching for information in a heterogeneous corporate memory, this search being intelligently guided by ontologies or knowledge models.

This work is a contribution to the construction of a semantic Web for a company or a community. We study the exploitation of XML as a pivotal technology between knowledge modeling and corporate memory.

Our goal is to develop new computer algebra methods for solving functional equations, i.e. equations where the unknowns represent functions rather than numerical values, and to further the use of such methods in engineering by producing the programs and tools necessary to apply them to industrial problems.

The equations are presented as they are solved without any further pre-processing (except maybe for a conversion into Horner form) although in some cases a specific pre-processing may have clearly led to simpler system of equations (or equations that will be more appropriate for interval analysis).

Information flow type systems: we develop information flow type systems for the Java Virtual Machine, and establish type-preserving compilation results between our type system and information flow type systems for Java source code programs.

Security by logic:  we devise methods that use program logics to enforce security policies such as non-interference, resource control, or high-level security rules found in industrial security policies. Further, we also study compositional verification techniques.

Certificate translation: we provide means to bring the benefits of source code verification to code consumers, via certificate translators that transform certificates (as in Proof Carrying Code) of source code programs into certificates of byte code programs. Our certificate translators apply to non-optimizing compilers as well as to compilers that perform standard program optimizations.

Verification of multi-threaded programs: specification languages and program logics are extended to multi-threading. We pay particular attention to techniques that allow to simplify reasoning, preferably by reducing it to sequential verification problems. As a first point of interest we study immutable objects, thread-local objects and atomicity properties.

Machine checked type systems and static analyses. We develop certified static analyses for the Java Card platform; in order to facilitate our work, we also develop the Jakarta toolset, that provides automatic tool support for large parts of the verification task.

Verification of cryptographic algorithms. We develop machine checked formalisations of provable security to show the security of cryptographic schemes. In particular, we use the Generic Model and Random Oracle Model to prove security bounds for cryptosystems based on the discrete logarithm.

Earlier work includes the formalization of the JavaCard platform, and of the GlobalPlatform specifications. We also participated in a collaborative effort to verify a moderately optimizing compiler for C--.

The tool takes the Java Card Virtual Machine specification that is developed in Coq - in the context of the CertiCartes project - as input. This is a defensive virtual machine, and by abstraction it can be transformed into a byte code verifier plus an offensive virtual machine.

We developed a secure auditing assistant that generates JML annotations from high-level security properties. The assistant has been successfully applied to industrial case studies. Its implementation has been integrated into  JACK.

Your application should contain a curriculum vitae and a motivation letter explaining your interests in the research topics of the Everest team. Please mention also who will act as a reference for you. Applications that do not contain this information, or that are clearly off-topic will not be considered.

It is not necessary to speak French to work in our team. However, a basic knowledge of French will be needed for your daily life, if you intend to stay for an extended period of time, in particular for a PhD. To ensure that you can achieve this basic level, INRIA provides French courses to PhD students and Post-docs.

Shape approximation. Complex shapes are ubiquitous in numerical analysis, computer graphics, robotics and many other fields. In most cases, they need to be approximated, with various needs and constraints though.

Conversely, surface reconstruction requires to interpolate shapes from samples. GEOMETRICA aims at developing a theory of geometric approximation and works on sampling, discrete differential geometry, approximations with topological and geometrical guarantees, multi-scale representation. GEOMETRICA works also on compression and progressive transmission of geometric models.

The goal of the the Marelle project is to study and use techniques for verifying mathematical proofs on the computer to ensure the correctness of software.  The targeted domains consist in software for scientific computation (computer algebra, computer aritmetics).  The project develops methods and tools to help producing correct program from precise descriptions of the data, the algorithms, their properties, and the proofs of these properties.

What can large collections of stochastic automata do? I have been investigating systems governed by a "law of mass interaction" that is inspired by chemistry and is incorporated in stochastic pi-calculus in the form of the Gillespie simulation algorithm. The collective dynamics of even just two-state automata can be quite puzzling. To investigate those behaviors more systematically, I describe a simple technique for translating stochastic programs to systems of ordinary differential equations, via chemical reactions.

Because of information ubiquity, one observes an important trend towards transferring information management tasks from database systems to networks. We introduce the notion of Data Ring that can be seen as a network version of a database or a content warehouse. A main goal is to achieve better performance for content management without requiring the acquisition of explicit control over information resources. The collaborating peers that form the Data Ring are autonomous, heterogeneous and their capabilities may greatly vary, e.g., from a sensor to a large database.

The confluence of virtual reality and artificial life, an emerging discipline that spans the computational and biological sciences, has yielded synthetic worlds inhabited by realistic, artificial flora and fauna. Artificial animals are complex synthetic organisms that possess functional biomechanical bodies, perceptual sensors, and brains with locomotion, perception, behavior, learning, and cognition centers.

Artificial humans and lower animals are of interest in computer graphics because they are self-animating graphical characters that will dramatically advance the state of the art of production animation and interactive game technologies. More broadly, these biomimetic autonomous agents in realistic virtual worlds also foster deeper computationally oriented insights into natural living systems. In addition, they engender interesting applications in computer vision, sensor networks, and other domains.

Robots are currently exploring many environments that are difficult if not impossible for humans to reach, such as the edge of the solar system, the planet Mars, volcanoes on Earth, and the undersea world. The goal of these robotic explorers is to obtain knowledge about our universe and to answer fundamental questions about life and human origins. Microrobotics has entered this field by exploring life at a much smaller scale and more fundamental level. Microrobotic systems for physically exploring the structures of biological cells are being developed, and robotic motion planning strategies are being used to investigate protein folding. Microrobotic mechanisms have been used to investigate organism behaviors, such as the flight dynamics of fruit flies as well as the neurophysiology that govern many other biologically interesting behaviors. These recent research efforts and others like them illustrate how several areas of robotics research are rapidly converging to create this new discipline I refer to as BioMicroRobotics. These new directions in robotics represent only a beginning and indicate that robotics research, and biomicrorobotics in particular, has the capability of making significant contributions in the understanding of life. In moving from the micro domain to nanometric scales, completely different issues in developing nanorobotic systems and in their application arise. The second part of the talk will present recent efforts at the Institute of Robotics and Intelligent Systems at ETH-Zurich in fabricating nanometer scale robotic components.

Automated quality control for production lines in industry sectors such as Automotive, Chemicals, Electronics, increasingly rely on real time analysis of multi-sensors dataflows to detect and identify abnormal situations or to anticipate critical risks.

Explicit models for multi-sensors behaviour or for their functional dependence on contextual features are too costly or unfeasible, hence Automatic Learning of empirical models play a crucial role to generate multi-sensors anomaly diagnosis, detect causes of defects, and anticipate critical events.

Learning algorithms and evaluation of their generalization capacities can now rely on efficient approaches: empirical complexity estimates, improved Support Vector Machines, diagnosis boosting by convex combination of classifiers, variables selection by robust conditional entropy techniques.

But on line decision algorithms calibrated by automated learning present more challenges to autonomously maintain their pertinence. Indeed contextual and performance changes need to be detected on line in order to launch corrective upgrades of the learned internal parameters.

We describe concrete data driven empirical modelization methodologies for automated decision based on multi-sensors. We present a few applications such as sounds identification in highly noisy backgrounds, reliability of robotized welding, etc.

The rapid proliferation of structural molecular data of the living cell in recent decades obviates the need for adequate computational analytics to represent, manipulate and analyze these in ways that maximize their scientific utility. Biologically active molecules (proteins, nucleic acids, and their combination in macromolecular complexes) have distinct three-dimensional structures that match and fit, and thereby determine their behavior and interactions with other molecules within their native cellular environment. Moreover, in order to successfully apply molecular structural information in areas such as drug discovery, and disease therapy, one must also be able to take into account energetic factors such as electrostatic potentials and hydrophobicity for more comprehensive biomolecular interactions. Complicating the analytics still further is the fact that most molecules are flexible, being able to adopt a number of different conformations that are of similar energy. For this reason, the rigid-model approximations once used to represent molecules are no longer elaborate enough to provide adequate predictions of chemical and physiological activity. Advances in the computational power, on the other hand, now allows less restrictive and more dynamic models of biomolecular complexes to be employed in computations and simulations. In this talk I shall cover several geometric and signal processing algorithms that are required to support both the elucidation of atomic and quasi-atomic models of macromolecules from electron microscopy, and the validation of flexible and dynamic models of bio-molecular and macromolecular interactions.

However, in spite of the popularity of the term, there is often confusion as to what the Grid is and what problems it solves. Is there any "there there" or is it all just marketing hype or (perhaps worse) a 10-year research project?

In this talk, I will address these questions, reviewing what the Grid is, what problems it solves, what technology has been developed to build Grid infrastructure and create Grid applications. I will describe the current status of Grid infrastructure and deployment and give examples of where Grid technology is being used not only to perform current tasks better, but to provide fundamentally new capabilities that are not possible otherwise.

The development of a discrete differential geometry has provided an effective new source for the analysis and optimization of geometric shapes in recent years. Discrete differential operators on meshes offer a parametrization independent approach at the intersection of geometry, partial differential equations and computer graphics.

In this talk we will give an overview of geometric properties of polyhedral shapes and show recent applications in computer aided design. We will conclude with an outlook on geometric properties of other discrete shapes such as non-conforming simplicial meshes and statistical manifolds.

In 1973, Jacques Morgenstern published an elegant paper entitled "Lower Bound on the Linear Complexity of the fast Fourier Transform". While an optimal bound for computing the Discrete Fourier Transform remains an open problem, Jacques was able to establish an optimal Omega(nlogn) lower bound for a very natural class of algorithms, namely linear arithmetic programs where the scalars all have a bounded modulus. This paper was one of a number of papers that Jacques wrote concerning restricted models of computation. My goal today is to continue this tradition and consider the limitations of “natural” classes of algorithms with regard to search and optimization problems.

Many algorithm design and analysis courses and texts often organize the material in terms of well known “algorithmic paradigms”, such as greedy algorithms, backtracking, dynamic programming, local search, primal-dual/local ratio, etc. We seem to be able to intuitively describe what we have in mind when we discuss these classes of algorithms but rarely (if ever) do we (or any of the standard texts) attempt to define precisely what we mean by greedy, dynamic programming, etc.

Based on work with co-authors, I would like to offer some precise definitions for a few of these paradigms; namely, greedy algorithms, (simple) dynamic programming, backtracking, and primal-dual/local ratio algorithms.

What is a good algorithmic model? The model should be able to capture most known algorithms (within the given paradigm), have some mathematical appeal, be amenable to analysis, and (at least eventually) lead to new insights and algorithms. I will leave it to the audience's judgment if we have any chance of being successful in this regard.

In particular, a programmer can spend a whole career doing work in embedded systems or data analysis without a need to gain expertise in other fields. Would such programmers be best served by completely different special-purpose languages? What are the fundamental and commercial factors that drive language evolution? What are the roles of program development environments, libraries, and tools? I think that general-purpose languages will have a key role in the programming world, but that the role will evolve and differ from what most people think of today. To make the discussion a bit concrete, I'll base some of my observations on examples from current C++ and its possible future developments.

All information processing that is currently performed, and even within such futuristic ideas as DNA computing and molecular computing, is actually done within the framework of classical physics. Information is stored, processed and transmitted using the elements, sources, processes, laws and limitations of the classical physics.

A new dimension to information processing and communication has appeared recently and it is currently very vigorously explored. The basic aim is to find out how to make use of elements, phenomena, resources, processes, laws and limitations of the quantum microworld to store, process and transmit information in a more efficient and more secure way as currently. Various methods and tools have been already found how to utilize laws and limitations of quantum Nature, and of the information processing that is going on in the quantum world, to make quantum computations and communications more efficient, (quantum) channels to have larger capacity, and (quantum) cryptography to be more secure than the classical one.

The research in this area was curiosity-driven one for a couple of years. Nowadays it is increasingly believed that such a research can be a basis of an important new science and also new -- quantum -- information processing technology.

In the first part of the talk, the most basic properties of the classical and quantum information will be introduced and compared, and an introduction will be made into new concepts, principles and limitations on which quantum information processing and communication are based.

In the second, and the main part of the talk, several main outcomes and challenges of the quantum information processing research will shortly be presented and discussed in several basic areas: quantum algorithms, quantum cryptography, quantum entanglement, quantum communication, quantum decoherence fighting and quantum processors.

Increasingly, however, the "real world" is full of interconnected computers in critical roles. Accordingly, computer security becomes more essential but also harder to define and even harder to achieve.

Twenty years ago, Informatics was seen as a component part of the problem in delivering effective healthcare at affordable cost, not least because of a number of hugely costly and embarrassing software system failures. Nowadays, Informatics is seen as part of the solution.

We begin the presentation by discussing the challenges and opportunities for Healthcare Informatics, then illustrate some of the many ways in which Informatics is impacting healthcare delivery. These include (intelligent) signal and image analysis; planning, monitoring and assisting minimally-invasive procedures; and AI systems that support patient management (for example, advice on chemotherapy or pain relief).

We then speculate on some of the trends that we expect to see develop over the next twenty years (ever mindful of the observation by that philosopher of our age : "prediction is never easy, especially when it concerns the future"). These are certain (!) to involve many of the following technologies: image analysis, modelling (eg geometry, biomechanics), robotics, large-scale software development, and the Grid.

This talk will provide an overview of the emerging technology of computational visual surveillance. Typical application scenarios will be explored, the requirements for a typical surveillance system given, and an overview presented of current research achievements in the area.

Limitations of current systems will be discussed and emerging research areas introduced. The talk will conclude with an overview of future work and performance evaluation of tracking and surveillance systems.

WiTness aims at enabling secure mobile applications of third-party application providers in 3G wireless networks by providing technology for application level security. This project brings together mobile operators, smart card manufacturers, mobile device manufacturers, application providers, and research institutions to define and develop a framework for the development and deployment of secure mobile business applications in a business to-employee, i.e. corporate environment. WiTness focuses on technology that allows application providers to set up their own security solutions for mobile applications.

Open architectures require security not least because of the threat of viruses but also because malicious software can compromise the intended commercial use of the phone and the deployment of value added services.

As the supplier of the basic architecture that is used in the vast majority of 2G wireless devices, TI has the depth of knowledge and real-world experience that is imperative for understanding how critically important security will be to the success of 2.5G and 3G.

This architecture relies on intimate interleaving of hardware-based and software-based mechanisms that together enforce the security policy, and provide secure functionalities to the platform within a Public Key Infrastructure. The majorities of the principles are equally valid for application services and modem integrity.

Travel distribution. Amadeus delivers travel solutions to travel agents and airlines sales offices. Its data center data processing center serves 60,000 travel agency locations and more than 10,000 airline sales offices, which together total more than 260,000 terminals located in over 200 markets worldwide.

These tools, which have been developed independently, mainly at DOE laboratories, make it easier for scientific code developers to write high performance applications for parallel computers. They tackle a number of computational issues that are common to a large number of scientific applications, mainly implementation of numerical algorithms, and support for code development, execution and optimization. The DOE ACTS Collection Project enables the use of these public domain tools by a much wider community of computational scientists, and promotes code portability, reusability, reduction of duplicate efforts, and tool maturity.

Achieving scalable performance for dynamic irregular applications is eminently challenging. Traditional message-passing approaches have been making steady progress towards this goal; however, they suffer from complex implementation requirements.

The use of a global address space greatly simplifies the programming task, but can degrade the performance of dynamically adapting computations. This work examines the implementation of two typical adaptive applications, Dynamic Remeshing and N-Body, across five programming paradigms and four leading parallel architectures. We compare several critical factors of the parallel code development, including performance, programmability, scalability, algorithmic development, and portability.

We show that it is possible to achieve message-passing performance using shared memory programming techniques by carefully following the same high level strategies. The overall results demonstrate that multithreaded systems offer a tremendous potential for quickly and efficiently solving some of the most challenging real-life problems on parallel computers.

The availability of  Grid resources will give rise to  dramatically new   classes  of applications,  in which   computing resources are no longer localized, but distributed, heterogeneous, and dynamic;  computation      is       increasingly   sophisticated   and multidisciplinary; and computation is integrated into our daily lives, and hence subject to stricter  time  constraints than at present.  The impact of these  new applications will be  pervasive, ranging from new systems for scientific inquiry,  through computing support for  crisis management, to the use of ambient computing to enhance personal mobile computing environments.

Abstract (english) :I will explain how a maxflow formulation can optimally minimize submodular energy functions of binary variables. Then I will review the existing algorithms for Graph Cuts in Vision (Graph Cuts, Banded Graph Cuts, ...) and show their pluses and minuses. Finally I will show an interesting application to Motion Layers Segmentation: segmenting both visible and hidden layers.

In this talk we investigate the class of the hybrid feedbacks. We show how it is possible to stabilize in (quasi)-minimal-time the Brockett system with a robustness with respect to small mesurement noise.

In this talk, I will describe new computational algorithms to analyze symmetry groups, both finite- and infinite-dimensional, of differential equations and variational problems.  The key tool is a new generalization of the equivariant moving frame method for Lie pseudo-groups.   I will focus on methods for directly determining the structure of the symmetry group, as well as the structure of its algebra of differential invariants.

In this talk we show, by means of numerical examples, how a domain decomposition method (DDM) can be used, in conjunction with available numerical conformal mapping software, for the efficient computation of the conformal map $f$, in cases where $Q$ is elongated.

In particular, we discuss the available theoretical error estimates for the various DDM errors, and show the high accuracy that can be achieved by the DDM. We also illustrate the application of the method for the efficient solution of certain harmonic problems in the complex plane.

For a compact set A in Euclidean space we consider the asymptotic behavior of optimal (and near optimal) N-point configurations that minimize the Riesz s-energy (corresponding to the potential 1/t^s) over all N-point subsets of A, where s>0.

For a large class of manifolds A having finite, positive d-dimensional Hausdorff measure, we show that such minimizing configurations have asymptotic limit distribution (as N tends to infinity with s fixed) equal to d-dimensional Hausdorff measure whenever s>d or s=d. In the latter case we obtain an explicit formula for the dominant term in the minimum energy. Our results are new even for the case of the d-dimensional sphere and are related to best-packing problems. The talk is aimed at a general audience and should also be of interest to chemists, physicists, as well as biologists.

Control problems for hybrid systems are motivated by the use of computers for control of engineering systems and by the occurence of discontinuous systems. The class of continuous piecewise-affine hybrid systems consists at the discrete level of a finite-state automaton and at the continuous level of, at each state of the automaton, an affine system on a polytope.

The problem of control synthesis for this class of systems is in general undecidable. Sufficient conditions for existence and the computation of a control law will be stated. This leads to the problems: (1) control-to-facet, (2) domains of attraction for an affine system on a polytope, and (3) to the construction of a reachability automaton. An application to idle speed control of a car engine illustrates the results.

The case n=5 (the first case containibg functional parameters) was treated by E. Cartan in 1910 by ingenious use of his "reduction-prolongation" procedure.  In particular, he found the covariant fourth-order tensor invariant (Cartan tensor) for such distributions.  After the work of E.

Cartan the following questions remained open: first the geometric reason for existence of Cartan's tensor was not clear (the tensor was obtained by very sophisticated algebraic manipulations) and the true analogs of this tensor in Riemannian geometry were not found; secondly it was not clear how to generalize this tensor to other classes of distributions ; finally there were no explicit formulas for computation of Cartan's tensor (in order to compute this tensor for concrete distribution, one had to repeat Cartan's "reduction-prolongation"  procedure for this distribution from the very beginning, which is rather difficult task).

In the talk I will present alternative approach to equivalence problem, which allows to give the answers to the questions mentioned above. This approach is based on the theory of curves in the Lagrange Grassmannian, developed in our previous works with A. Agrachev.  In this way I construct the fundamental form and the projective Ricci curvature of (2,n)-distributions for arbitrary n>4.  In the case n=5, I will present explicit formulas for computation of these invariants, while, for n>5, I will analyze the algebraic structure of them. It turns out that in the case n=5 the fundamental form coincides with Cartan's tensor.

Also I plan to give a classification of germs of (2,5)-distributions with constant projective Ricci curvature, 6-dimensional group of symmetries, and fundamental form, which is equal, up to the sign, to the square of a quadratic form.

Necessary and sufficient conditions for flatness of control systems are obtained by using geometry of differential equations and deformation theory. The necessary conditions coincide with sufficient ones if some regularity condition holds. An example is considered to illustrate the approach.

Both retarded type and neutral TDS are considered. There are two interesting propositions, which give rise to this approach.  They are under an umbrella paradigm called the 'cluster treatment of characteristic roots'.  Proposed methodology brings a resolution on the subject, which has been investigated since the 80s.  It suggests some systematic steps for assessing the number of unstable roots for a time delayed LTI system as an explicit function of the delay.  Real time control issues will also be discussed.

Several practical cases are considered. a) Time delayed target tracking using full state feedback, b) A recent concept of actively tuning vibration absorbers, named "Delayed Resonator", is explained.  The simplicity of the control law (which is a time delayed proportional control) is the prime contribution of this work.  Two patented implementations are included, one is for transverse oscillation absorption on a beam, and the other is on a torsional vibration absorber, which uses a nonlinear 'Centrifugal Delayed Resonator ' structure.  Animations and videos of the experimental studies are included.

An overview of recent progress in using generalizations of the maximum entropy approach to solve the rational covariance extension problem is given. This leads by duality theory to nice convex optimization problems which we solve by homotopy methods.

Riemannian surfaces such that any two points can be joined with a curve of arbitrarily small geodesic curvature, being tangent, at the initial and at the final position, to two prescribed directions. A formulation of the problem in control terms can be given in the form studied in the first part of the talk.

We study the motion planning problem for generic sub-Riemannian metrics of co-rank one.  Using the normal form for the sub-Riemannian metric, we give explicit expressions for the metric complexity, in terms of the invariants of  the problem. We propose and explicitly calculate the the asymptotic optimal syntheses, which are syntheses in a small cylinder around the curve data, where the asymptotics of the metric is valid.

If you plan to write more than a few hundred lines, of code, we would like you to consider reading a bit about software engineering. We believe that a few of the books listed below will give you a great background on this topic and are well worth the few hours you will spend reading them.

Software : refers to any derivative or composite software to be created for research purposes by the User, by any and all act of reproduction, translation, adaptation, integration and modification from the Software.

The User undertakes to mention the name of the Software and to mention that the Software originates from INRIA at any time it is publicly mentioned or used and notably in any and all publication referring to some use of the Software.

At the end of this period of two years, the User undertakes to stop any use of the Software and undertakes to destroy the Software according to article 10 below, unless renewal of the agreement by the way of a new downloading.

Agreement are held to be invalid or declared as such under a law, a regulation or as a result of a final decision by a competent court of justice, the other stipulations of this Agreement will retain their whole effect and scope.

This Agreement constitutes the entire agreement between the parties in respect of its purpose, and supersedes all previous negotiations and writings concerning the terms of this Agreement, unless the parties enter into a specific agreement duly signed by authorised representatives.

The parties shall endeavour to settle amicably any dispute relating to the interpretation or the performance of the license herein, within thirty (30) days from a written notice describing the matter of the dispute made by one party to the other party.

Here is an example of SPARQL query. It retrieves the students of a university which web site is http//www.mit.edu  or http//www.stanford.edu. It requests their name and optionally their firstname if available. These students must be older than 21. The result will be sorted by their names and only the first twenty results are requested.

Depending on the configuration of your operating system, double-clicking on the file might be enough to start the simplified interface. Otherwise open a shell window move to the directory where the .jar file is and use the command java - jar <NAME OF THE FILE.jar> to start the application.

Man is a common subclass of Male and Person, thus all instances of Man are both Male and Person, but here we construct the inverse relation: all instances of Male and Person are also instances of Man.

TokenMgrError: This is generated by JavaCC (the parser generator); it is used when errors are detected by the lexical analyser JavaccParseException: This exception is thrown when there is an error in the syntax of the query; it is possible to get the token which has produced the exception (e.getEncouteredToken()) and a vector that contains the list of all tokens that are expected instead (e.getExpectedToken()).

Presentation : The objective of this winter school is to motivate the participation and interaction of different students from different Universities , to share their experience. In additional, invited guests speakers will be giving special talks on selected topics.

Inria Sophia Antipolis also plays an important teaching role in degree courses given at universities (Paris, Nice, Marseille) and engineering schools (ESSI, Ecole Centrale, Ecole des Mines, ENSTA, ENS, X etc.). In addition, many research projects are host laboratories for PhD students in these areas. This high level of synergy between teaching and research is the key for the spread of knowledge and the discovery of talented students who represent a natural rich source of young researchers.

Yet collaboration with the rest of the world is just as extensive and active: the more advanced countries in the field of information technology first - such as the USA, Canada and Japan - central and Eastern European countries, the new independent states that were formely part of the Soviet Union, China, and south-East Asia, as well as Africa and countries surrounding the Mediterranean (whose geographical proximity to our Research Unit is a natural reason for cooperation), and finally Latin America and Australia.

Contacts with these countries take various forms: bilateral cooperation programmes resulting from agreements with research organizations, national or European Community programmes or individual cooperation initiatives, which can be equally effective, with prestigious laboratories.

In addition to these various scientific activities, a number of researchers at our Research Unit are members of the editorial boards of internationally renowned scientific reviews. The research unit is also involved in the organization of some of the most important international conferences in the field.

In a context where technological innovation is a fast process, INRIA Sophia Antipolis hands over its know-how and knowledge in computing, automation, and scientific calculus to the industrial world. As a complement to its activities of fundamental and applied research, the institute provides to its industrial partners the results coming from very high level research works within very small delays.

It is in this framework that the Sophia research unit initiates and negotiates research contracts as well as commercial or consulting agreements. These joint efforts of industrial and scientific qualifications are illustrated by the achievement of numerous contracts both at the national and international levels.

In order to increase its contractual relations and to optimise the technology transfer towards small and medium industrial companies, INRIA has introduced, with a great success, the concept of "industrial post-doc".

Bolstered by its successes, the Sophia research unit adds to these various collaborations a constant production of patents and provides a set of helping tools for companies creation that has led since 1984 to the founding of some ten technology startups.

I am a permanent researcher at ENPC, in the  CERTIS lab, and I am also a member of the Odyssee team in INRIA. My current research interests concern the mathematical and statistical study of certain types of nonstationary processes, the shape from texture problem in computer vision, and the recovery of the electrical activity in the brain from electromagnetic field measurements outside the head.

The goal (de circonstance!) is the design of new tools to help the clinicians to detect and locate new lesions, and also to measure objectively their evolution through time. To achieve this, we develop several approches (cf. publications). This work is done in collaboration with Harvard Medical School (Pr. Ron Kikinis) and with CHU of Nice (Pr.

Our work on automatic detection and quantification of evolving lesions deals essentially with: preprocessings on MRI series (registration, intensity corrections, interpolation ...) analysis of MRI evolutions. 2 methods have been developped: one based on the computation and on the analysis of a vector field of apparent displacement between 2 MRIs; the other based on a statistical analysis of the intensity evolution of each anatomical point over time.

In order to improve surgical accuracy, radiologists and surgeons can use a new imaging tool : Augmented Reality. It deals with superimposing a virtual model built from the pre-operative image on a video image of the patient .

In collaboration with IRCAD (Institut de Recherche contre les Cancers de l'Appareil Digestif), we aim at creating an augmented reality system for the destruction of liver tumors with the use of radio-fequency. The purpose is to superimpose on extern video images several tridimensional reconstructions of the liver, the tumors and some other organs.

We have developed a new point-based 3D/2D registration method and a visualisation software which lead us to our first result (see image). The 3D models come from segmented CT-scans and the registration is made thanks to radio-opaque fiducials on the patient's skin.

In order to allow accurate pre-operative localisation of functional targets in functional neurosurgery, we aim at constructing a three dimensional registrable cartography of the basal ganglia, based on histology. For doing this, a {\em post mortem} MR study was conducted on a cadaver's head, and the brain was then extracted and processed for histology.  The post mortem MR image will allow to report the cartography on the patient's anatomy, by its registration with the patient's MR image.

Motion compensation during an fMRI acquisition sequence. It is important to compensate very accurately (or at least detect) for the subject motion between images as a very small registration error may lead to spurious activation detections.

Inter-subject registration to fuse functional information from different subjects. There is currently no satisfying method to establish point to point correspondences between two brains. The main idea developed here is to enrich iconic (i.e. intensity-based) methods with geometric constraints based on anatomical sulcal correspondences.

The validation of this inter-subject registration. As there is no ground truth, the evaluation of the previous algorithms is very difficult. One interesting idea is to estimate the variability of anatomically stable functional activations across subjects and to show the the inter-subject registration drastically reduce this variability, hopefully removing all the anatomical variability to leave only the functional one.

Thus, automated segmentation system are powerful tools to help in drawing consistent diagnosis from a number of images, to classify pictorial data, or collect statistical information on anatomical variability.

In this study, we develop a method for registration of macroscopic optical images with MR images of the same patient. This forms a key part of a series of procedures to allow post mortem findings to be accurately registered with MR images, and more generally provides a method for 3D mapping of the distribution of pathological changes throughout the brain. The first stage of the method involves a 3D reconstruction of 2D brain slices. The second stage consists in the registration of the reconstructed volume with corresponding MR images.

The purpose of this work is the estimation and analysis of displacement fields of the myocardium. The motion will be estimated in 2D and 3D echocardiographic images with variational techniques. The analysis is performed with level sets methods. First estimations were obtained with 2D echocardiographic images using Doppler Tissue Imaging. Then motion analysis will  be improved by using a priori information such as a biomechanical model of the heart.

In MR image guided brain surgery, the techniques are often based on the use of volumetric pre-operative MR acquisitions.  This implicitely assumes that a pre-operative acquisition gives a faithful and precise representation of the brain anatomy during the intervention. Thus a major limit of these techniques is the development of brain deformation during the surgical intervention, leading to anatomical differences, which can be significative, with the pre-operative MR images.

This work is part of an industrial computer-guided surgery project dedicated to oral implantology surgery. Briefly, The operation is planned on a pre-operative CT-Scan and the purpose of such a system is to help the dentist to drill the implant in the predefined position and orientation.

We investigated several points-surfaces registration techniques and developped tools to compare their speed, robustness and accuracy. We formalised the well-known ICP algorithm and its numerous variants in a statistical framework, and finaly focused on an EM variant and proved it has a multi-scale behaviour. Using a coarse-to-fine approach we resolved robustness problems while improving its accuracy. Using a simple decimation technique, we down-sampled our sets of points and increased the algorithm speed while preserving its properties.

Another part of this work is about the probabilistic modeling of noisy curves and surfaces. We are currently trying to explain the tensor-voting techniques developped by Medioni and his team, and hope to develop a statistical framework useful for surface reconstruction, fusion and registration.

The geometry of such a 3-D may not exactly match the true anatomy of the imaged material. To address this issue, we have also develop a specific methodology that allows to fuse this reconstruction with a 3-D image (e.g. a pre-mortem MR image).

Alzheimer's disease (AD) is a neuro-degenerative disease that produces among others memory loss, behavioral changes and cognitive impairment. It affects mainly elderly. Because of the aging populations the number of patients will probably rise in the coming years. Therefor powerful diagnostical tools are increasingly important for this disease.

Single photon emission computed tomography (SPECT) is being largely used for the study of cerebral blood flow (CBF). These studies provide unique information for the identification of functional abnormalities relevant to Alzheimer's disease.

In collaboration with Professor J. Darcourt of the University of Nice, we are working on the development of diagnosis assisting tools for this type of images. Most of our tools work by comparing images to images of which we already know the diagnosis, and are statistically based.

We have developped a simulator for the resection of the liver that includes soft tissue deformation and force-feedback. Among the different scientific difficulties raised by this project, we have focused on the real-time computation of linear and non-linear elastic soft tissue (with  transversal anisotropy) but also on the geometric and mechanical aspects of tissue cutting simulation.

The performances of an automatic registration algorithm can be characterized by the accuracy of the result (when the algorithm has converged to the right solution), and the probability of convergence to this correct solution (robustness). Most often, the registration algorithm needs an initial transformation  and one prefers to determine a convergence basin in the space of initial transformations where the probability of convergence to the right solution is close to 100%. Within the accuracy, one can further distinguish between repeatability (or precision) (the error due to the presence of multiple local minima in the immediate vicinity of the optimal solution) and the external error due to the noise on the data.

One of the special aspects of this work is the development of methods to evaluate a lower bound on the registration accuracy without any gold standard, using consistency studies via registration loops.

It is usually the case in neurosurgery that pre-operative planning is based on the assumption that anatomical structures do not move between the image acquisition time and the operation time. In reality, the position of brain tissues changes during the operation and significantly decreases the accuracy of the planning made on the pre-operative image.

We propose a biomechanical approach based on a finite element model (FEM) of the brain to model this deformation. It takes into account the patient specificity and anatomical cerebral structures to predict the brain deformation.

The purpose of this study is to analyse vascular networks which are recorded using 3D confocal microscopy or other suitable 3D imaging techniques. This includes analysis of the network's topology, morphometry of individual vessels, and statistical analysis of morphometric properties on the network. To perform such analysis, we must extract a suitable discrete representation of the vascular network from the image data.

Connected components extraction: with the   edge detection library comes already a hysteresis thresholding software. Other calls (counting and labeling connected components in 2D or in 3D) are available.

I have previously been holding a research assistantship position under the supervision of Prof. Xiaodong Wang in the department of Electrical Engineering at Columbia University. During that period, I have mainly been working on Sequential Monte Carlo methods.

This little software has been built in the same spirit than bib2html of Eric Marchand which kindly provides me with its sources (in C++). As I was not smart enough to modify it to obtain some desirable features (as links between pages), I have prefered to develop a new code (in C).

Note for Windows users bibtex2html can only be used from a MS-DOS windows. Thus, open such a windows, you will be allowed to type on-line commands. By specifying the full path towards bibtex2html.exe, i.e.

The option -copy-icons will copy the icon files from the distribution (according that the preprocessor macro ICONSDIR has been set properly, see the section 2.2 about compilation) to the local subdirectory ./Icons/, that will be created if necessary thanks to the -force option.

In addition to the formatted entry, year.complete.html contains the following fields (if given): annote, comments, abstract, and the original BibTeX entry. They can be reached by links from other pages.

There are two different kinds of title: the one that appears on the top of the navigator window (between <title> and </title> in the html syntax) and the one that will appear at the top of the display page (and that takes place after the <body> declaration in the html syntax).

The page title of each page is enclosed between the page_title_tag.start key and the page_title_tag.end key, while the subtitles if pages are enclosed between the page_subtitle_tag.start key and the page_subtitle_tag.end key.

The default behavior of bibtex2html should correspond to some consensual expectation of such a tool. However, one may want to adapt it to more specific need. The aim of this section is to explain how things can be changed.

In the following, we will first present how the standard fields of BibTeX items are displayed, how links towards distant pages are displayed, how keywords (if any) are displayed, and how the remaining (additional) fields are displayed.

For each of these four places, there is a common part for all the generated files, and a specific part, prefixed by ******, that depends of the files' type and will be written in all the files of the same type.

There exists many specific files, and then a lot of specific customization keys. However, one may want to change all the same keys in all the specific files. This can be achieved by using the default key as ******. This only works for the NULL strings.

See the LATEX book for how to type titles. For book entries, use the title field instead. chapter A chapter (or section or whatever) number. crossref The database key of the entry being cross referenced. edition The edition of a book (for example, Second).

This should be an ordinal, and should have the first letter capitalized, as shown here; the standard styles convert to lower case when necessary. editor Name(s) of editor(s), typed as indicated in the LATEX book. If there is also an author field, then the editor field gives the editor of the book or collection in which the reference appears. howpublished How something strange has been published.

The first word should be capitalized. institution The sponsoring institution of a technical report. journal A journal name. Abbreviations are provided for many journals; see the Local Guide. key Used for alphabetizing, cross referencing, and creating a label when the author information is missing. This field should not be confused with the key that appears in the \cite command and at the beginning of the database entry. not implemented yet. month The month in which the work was published or, for an unpublished work, in which it was written. You should use the standard three-letter abbreviation, as described in Appendix B.1.3 of the LATEX book. note Any additional information that can help the reader.

The first word should be capitalized. number The number of a journal, magazine, technical report, or of a work in a series. An issue of a journal or magazine is usually identified by its volume and number; the organization that issues a technical report usually gives it a number; and sometimes books are given numbers in a named series. organization The organization that sponsors a conference or that publishes a manual.

With MedINRIA, you can output statistics based on the extracted bundles such as histograms of scalar values like FA/ADC, but also statistics of fiber length. Thus, you can compare different bundles of interest statiscally.

MedINRIA provides a tool that allows you to consider activated regions from fMRI as Regions of Interest. You can see on this screenshot that the colored activated regions are covered by their corresponding ROIs. You can then track the fibers that go from an activated region to another.

The software also provides a powerfull tensor visualization tool. Tensors are represented as glyphs, such as lines, arrows (principal eigenvector), but also cubes, ellipsoids, etc. The glyphs are colored in RGB (principal eigenvector), and intensity is weighted by the Fractional Anisotropy of the tensor.

You can also flip the tensor field to tackle some acquisition geometry problems. You can then save the tensor field and use it to track fibers in the DTI-Module. This screenshot shows a part of the axial view. "cube" visualization mode has been chosen.

In the Tensor viewer module, you also have the possibility to overlap an image (e.g. the B0 image) to the view and visualize it with its corresponding tensor field. In this screenshot, tensors are represented as ellipsoids.

Redistribution and use in source and binary forms, with or without modification, is NOT ALLOWED without the previous authorization of the developers. The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software for any purpose (e.g. publication), a reference to the program and the authors must be included.

My current research interests are in biomedical image analysis and simulation. This includes the analysis of medical and biological images with advanced geometrical, statistical, physical and functional models, the simulation of physiological systems with computational models built from biomedical images and other signals, and the application of these tools to medicine and biology to better assist prevention, diagnosis and therapy of diseases. For past and current results please refer to my publications and research reports.

Modelling based on a physical description of the system lets appear meaningful parameters that, when identified on a real person, give objective and quantitative data that characterize the system. Thus, they can be used for diagnosis.

Modelling provides a way to simulate movements for a given patient so that through an identification process it becomes possible to analyse and then understand his pathology. But to describe complex pathology such as spasticity that appears on paraplegic patients, you need not only to model the biomechanics parts - including muscles -, but also parts of the peripheral nervous system - including natural sensors - to assess reflex problems. One important application is then to explore deficiencies globally due to both muscles and peripheral neural nets disorders.

Functional electrical stimulation is one of the possibility to restore or control motor functions in an evolutive and reversible way. Pacemaker, Cochlear implants, Deep Brain Stimulation are successful examples. DEMAR focuses on the movement disorder restoration in paraplegic and quadriplegic patients, enhancements in hemiplegic patients, and some other motor disorders such as bladder and bowel control.

Restoring motor function such as grasping for quadraplegic patient, standing and walking for paraplegic patient, foot drop for hemiplegic patients. These applications can be firstly used in a clinical environment to provide to physiotherapits a new efficient FES - mainly surface - based therapy in the rehabilitation process. Secondly, with a more sophisticated technology such as implanted neuroprostheses, systems can be used at home by the patient himself without a clinical staff.

Modulating motor function such as tremors in Parkinsonian patient using DBS (Deep Brain Stimulation). Techniques are very similar but for the moment, modelling is not achieved because it implies the central nervous system modelling. Nevertheless, the application is possible for a daily use by the patient.

Sensing the afferent pathways such as muscle's spindles, will be use to provide a closed loop control of FES through natural sensing and then a complete implanted solution. Sensing the neural system is a necessity in some complex motor controls such as the bladder control. Indeed, antagonist muscle's contractions, and sensory feedbacks interfere with FES when applied directly on the sacral root nerve concerned. If we want to avoid neurectomy or complex electrode placements, enhance activation waveforms and sensing feedback or feedforward signals are needed to perform a highly selective stimulation.

Such a complex system needs advanced control theory tools coupled with a deep understanding of the underlying neurophysiological processes. This major area of research will be also an important part of the DEMAR objectives. Very few teams (for instance Robert Riener, ZTH in Switzerland) work on this topic because it needs a great amount of interactions between completely different disciplines such as neurophysiology, biomechanics, automatic control theory, and advanced signal processing. Besides, animal experiments performed in order to validate and identify models are particularly difficult to manage. Control schemes on such a complex non linear, under-actuated system, not completely observed and perturbed by the voluntary movements of the patient are quite difficult to study due to the lack of precise simulations platforms (for practical evaluation before experimentation) and the lack of theoretical results on such systems.

Quantitative characterization of the human sensori motor system firstly for motor disorders diagnosis and objective quantification, and secondly in order to help the design of neuroprosthetic devices.

Designing efficient control schemes and performing realistic simulations need for modelling. The scientific approach is to develop multi scale models based on the physiological microscopic reality up to a macroscopic behavior of the main parts of the sensori motor system : muscles, natural sensors and neural structures. We also aim at describing multi scale time models to figure out impulse synchronized responses that occur in a reflex or with FES, up to a long term fatigue phenomenon. All these models have a control input that allows them to be linked as different blocks of the sensori motor system.

Besides, we have to deal with problems related to the identification protocols. Identification is then based on the observation of signals such as EMG, output forces, and movement kinematics, while the medical imaging gives the geometrical parameters and mass distributions. The success of the identification process is highly sensitive to the quality of the experimental protocols on animals and humans.

Simulation platforms have been largely developed for biped system, including advanced impact models (using non regular equation, work carried out in collaboration with BIPOP). Given that kinematics and dynamics are described using Denavit-Hartenberg parameters and the Lagrangian formulae, such tools can be used. Nevertheless, important differences rely on the actuators and their associated model and in the global architecture of the high level command. Thus, based on this platform, a new one can be developed including the complex muscle's dynamics. In particular, muscle's dynamics contain discontinuous switching modes (contraction - relaxation, extension - shortening), strong non linearities, length and shortening speed dependencies that imply complex numeric resolutions.

Some tasks can not be performed by using open loop strategies. Keeping standing position with a balance control can be improved as regard the fatigue effect using ankle / knee / hip angle sensors feedback. Muscle's contraction is then controlled to ensure the minimum of fatigue with the maximum stability. Cycling, walking on long distance pathways, need some control to be achieved with a higher level of performance. Modelling and simulation will be used to design control strategies while theoretical studies of performances (robustness, stability, accuracy) will be carried out. The system is highly non linear and not completely observable. New problems arise so that new strategies have to be designed. Finally a compromise between complexity, efficiency, robustness, easy usage of the system has to be found. Thus, the success of a control strategy design will be evaluated not only through its intrinsic performances but also regarding its ergonomic.

Advanced control strategy such as high order sliding modes for the low level control of the co-contraction will be studied because of its robustness towards model uncertainty. Trajectory free predictive control will be also investigated for a movement phase such as swing phase during gait, because the movement can be described as intuitive constraints such as the center of mass need not to fall. Finally high level hybrid approaches based on continuous control and event triggered commutation of strategies will studied using a formal representation of the architecture.

FES will be thus performed by means of distributed small stimulation units which are driven by an external controller in charge of the coordination of stimulation sequences [26]. Each stimulation unit (called DSU, Distributed Stimulation Unit) is in charge of the execution of the stimulation pattern, applied to the muscle by means of a neural multipolar electrode. A DSU is composed of analogue and digital parts ( 6.2.1).

The SENIS architecture therefore relies on a set of DSU which communicates with an external controller. So we studied the communication architecture and defined an adequate protocol ( 6.2.4), assuming firstly that the communication should be performed on a wireless medium and secondly that this architecture can also contain distributed measurement units (sensors  6.2.2).

Natural sensors that means interfacing with afferent nerves and ENG recordings. The same theoretical tools and technology as for implanted stimulators will be used. Nevertheless, advanced signal processing applied to biosignals will be used such time-frequency techniques.

The way how the system integrates all these events is not trivial. This field of research can learn from tele-operation and Human Machine Interfaces research fields. The patient needs also to get pieces of information of the current state of the system. Sensory feedback have to be implemented onto the system like screen, sound, tactile vibrations, electrical stimulation,... Choosing meaningful pieces of information such as heel contact, and the way to encode it, will be addressed.

Activating the system through stimulators, sensors, and analysing patient behavior need for multiple devices that communicate and demand energy. Interfacing natural and artificial parts imply to address problems such as networking, data transfer, energy storage and transfer through wireless links. On such a complex system, supervision is necessary to ensure security at the different involved levels. Fault tolerance and reflex behavior of the system will be studied to improve system reliability particularly when the patient uses it at home without any medical person support. The theoretical approach is based on Petri Nets to design and then analyse the behavior of the whole distributed system. More technological aspects related to RF transmission will be studied.

Q-Ball Imaging and HARDI processing methods to infer the white-matter wiring of the brain to understand functional coupling between certain cortical regions as well as the connectivity properties of cerebral tissues. I obtained my Masters degree from McGill University under the supervision of  K. Siddiqi  in the Shape Analysis Group .

Many techniques from computer vision (e.g., image restoration, enhancement and segmentation, motion analysis, warping) are important tools in the field of neuroimaging. Conversely, the measurement of brain activity via fMRI and E/MEG, and especially the inverse problem of E/MEG bring up new problems in computer vision such as restoring and filtering images defined on non-flat surfaces, and whose values may belong to certain manifolds.

On this basis, our research activity is structured on variational methods and PDEs for vision in order to develop the first point, and on functional imaging for observing brain activity to contribute to the second point.

Moreover, there is an important interaction between brain imaging and cortical activity modelling. Brain imaging provides data which may be used as input in modelling the computational architecture of the brain in visual perception tasks. This modeling may in turn suggest constraints to impose on the sets of solutions for fMRI or E/MEG. The neural networks participating in visual perception can also be related to the PDEs which are used in computational vision.

In particular, we have studied the different models of random walks and related diffusion processes on the dual graphs of compact cities. Analysis of access times between streets and certain city districts helps to detect the city modularity. The certain modes of a diffusion process which describes the dynamics of a large number of random walkers are localized on the definite groups of streets. The flows of random walkers along the streets belonging to the same group are strongly correlated. To investigate the spectrum of diffusion problem, we use the methods of statistical mechanics.

The influence of fixational eye movements on neural correlated activity in the first stages of the visual system Under natural viewing conditions, the physiological instability of the eye keeps, even during fixation, the retinal projection of the visual input in constant motion. In this talk I will examine the impact of these microscopic eye movements on cell activities at the first stages of the visual system.

Using a quasi-linear model of LGN (Lateral Geniculate Nucleus) units and V1 simple cells I will derive a general analytical expression for the second-order statistics of thalamo-thalamic and thalamo-cortical correlated activity.

It will be shown that, in the presence of natural visual input, the natural jiittering of the eye introduces in the retinal signals a spatially uncorrelated term which strongly influences correlated activity in our model. Furthermore, during thalamo-cortical development this uncorrelated term produces, a regime of thalamo-cortical activity similar to that present before eye opening and compatible with the Hebbian maturation of simple cell receptive fields. Finally, during normal visual behavior, fixational eye movements contribute to diminishing the correlation between neighboring LGN units thus leading to a more efficient coding of the visual information.

Diffuse Optical Imaging (DOI) is a relatively new noninvasive modality to image cerebral activity and hemodynamic response. Although limited to the surface of the cerebral cortex, the technique has several advantages, for instance low cost, functional information and portability, often not available in other established modalities, such as X-ray and Magnetic Resonance Imaging (MRI). The feasability of the DOI technique is due to the optical properties of near infrared light (NIR) in biological tissues. Because of its relatively poor spatial resolution, combining DOI with other imaging techniques can provide significant benefits when imaging specific functional cortical areas where spatial guidance is needed. For example the simple problem of probe positionning is an issue and high-resolution structural information could help solving the localization and positionning problem.

Although neurons as computational elements are 7 orders of magnitude slower than their artificial counterparts, the primate brain grossly outperforms robotic algorithms in all but the most structured tasks. Parallelism alone is a poor explanation, and much recent functional modelling of the central nervous system focuses on its modular, heavily feedback-based computational architecture, the result of accumulation of subsystems throughout evolution. We discuss this architecture from a global stability and convergence point of view. We then study synchronization as a model of computations at different scales in the brain, such as pattern matching, temporal binding of sensory data, and mirror neuron response. Finally, we derive a simple condition for a general dynamical system to globally converge to a regime where multiple groups of fully synchronized elements coexist.

Colorization, the task of coloring a gray-scale image or video, involves assigning from the single dimension of intensity or luminance a quantity that varies in three dimensions, such as red, green, and blue channels. Mapping between intensity and color is therefore not unique, and colorization is ambiguous in nature and requires some amount of human interaction or external information.

A computationally simple yet effective approach of colorization is presented in this talk. The method is fast and it can be conveniently used ``on the fly,'' permitting the user to interactively get the desired results promptly after providing a reduced set of chrominance scribbles. Based on concepts of luminance-weighted chrominance blending and fast intrinsic distance computations, high quality colorization results for still images and video are obtained at a fraction of the complexity and computational cost of previously reported techniques. Possible extensions of the algorithm here introduced included the capability of changing colors of an existing color image or video as well as changing the underlying luminance, and many other special effects here demonstrated.

Computational Sensor Networks (CSNs) are proposed as a high-level paradigm for the development and application of sensor networks. The components of this approach include (1) models of phenomena to be monitored, (2) models of sensors and actuators, and (3) models of sensor networks. These are used to develop specific methods to determine the state or structure of the phenomenon or sensor network itself. This is called computational modeling. These methods are then incorporated into the operational system of the sensor network and other available processors and adapted to system performance requirements to produce a mapping of the computation onto the system architecture. This is called computation mapping. CSNs represent a scientific computing approach, and this includes the Verification and Validation (V & V) methodology of that discipline that is, model implementations must be verified (e.g., for numerical properties like error and convergence), and appropriate tests embedded in the system to monitor system correctness during execution. However, an important new aspect of this approach is that a CSN has the ability to sense and interact with the environment, and thus can run its own validation experiments to confirm or refute model structure or parameter values. Another intrinsic capability offered by CSNs is that models can be used to determine unknown aspects of the structure of the measurement system itself given a known state of the physical phenomenon.

Inspired by the work of Chan-Esedoglu-Nikolova and using the weighted total variation norm, a global minimization framework for the active contour model based on the Rudin-Osher-Fatemi model and the Mumford-Shah functional is proposed. Besides the global minimization process is fast using the approach of Chambolle. The current work consists of generalizing this model to natural images containing smooth regions and textures using the image decomposition paradigm. The second model will present an evolution equation for active contour embedded on parametric Riemannian manifolds. A first application of this equation, called "multiscale active contours", allows to segment multiscale structures in general scale spaces s.a. the linear scale space and also the curvature or the Beltrami scale spaces. A second application leads to the segmentation of structures on omnidirectional images defined on spherical, hyperbolic and parabolic manifolds.

Renaud Keriven is in charge of the main Computer Science course and of the two specialisation modules "Probabilities, Numerical Analysis and Computer Science" and "Computer Vision and Image Processing".

Researchers in psychophysics have designed precised parametrized visual stimuli to evaluate some specific performances of the visual systems. These stimuli are also important to compare the results obtained by artificial systems with respect to human performances. For these reasons, a software has been developed in order to generate easily these stimuli, which will be used to evaluate future vision tasks.

VisStim, alias Visual Stimuli, is the name of the open-source plateform which allows to generate standart animated visual stimuli. These stimuli are video sequences containing geometric features moving or deforming. Depending on the choice of the parameters, on may observe some biais in the perception of the motion induced. This property makes these stimuli challenging for the experimental and theoretical analysis of biological and artificial vision.

This plateform is opened and can be completed by additional stimuli. It is based on JAVA and SVG language for the sequence generation, which is very efficient for images with geometric figures. Main stimuli parameters concern shape, motion and masks.

The researchers involved in the area 3 of the project (modeling of the brain activity) belong the cortyxee working group common to the CORTEX project: this every two weeks seminar allows to share scientific inputs, cooperate on bibliographical material, etc..

Automatic generation of the Rapact (activity report): No need any more to maintain updated webpages AND to some cut and paste in the activity report. If web pages are updated, then activity report will be also done.

The content is given in xml files, so that html files are then automatically generated from that content. Another advantage is that we can also generate some latex from them, and in particular the research report. Follow this link to know more on kraken organization.

With the increasing popularity of XML, the number of XML editors is growing exponentially and it can be extremely diffcult to choose the convenient editor that suits "Kraken" users. Considering a long list of criteria we've chosen <oXygen/> for many reasons.

Those two pages (index.en.html & index.fr.html) must exist. Don't erase the index.html file for different security reasons. If those files are not installed in your folder just copy and paste them from anyone else folder be sure you personalise the 2 language indexes after C&P.

Antipolis. So the easiest solution is to connect yourself via ssh, on the machine terreneuve, through taquilee, i.e., prompt> ssh -A -X taquilee.inria.fr prompt> ssh -A -X terreneuve Then everything should be the same.

So please if you notice that something is missing, please consider to add an item in the proper subcategory (if you do not know what is the proper subcategory, contact Pierre Kornprobst or Theo Papadopoulo).

High angular resolution diffusion imaging (HARDI) has recently been of great interest in characterizing non-Gaussian diffusion processes. In the white matter of the brain, non-Gaussian diffusion occurs when fiber bundles cross, kiss or diverge within the same voxel. Due the well-known limitations of diffusion tensor imaging (DTI), HARDI is currently of great interest to characterize voxels containing multiple fiber crossings. In particular, Q-ball imaging (QBI) is now a popular reconstruction method to obtain the orientation distribution function (ODF) of these multiple fiber distributions. The latter captures all important angular contrast by expressing the probability that a water molecule in the white matter of the brain will diffuse into any given solid angle. However, QBI and other high order spin displacement estimation methods involve non-trivial numerical computations and lack a straightforward regularization process.  In this work, we'll be interested in studying fast and efficient solutions for the Q-ball reconstruction of the ODF. A first step toward this objective has already been initiated within our research group (see  our research report and the upcoming report late november 2005). We'll be interested during this internship, to pursue this effort and compare its results to the state-of-the-art.

Shape  : we study the problem of the acquisition of geometric models from image sequences from the computational and biological viewpoints and propose mathematical formulations. The representation of 3D shapes, deterministic and stochastic, the learning of these representations and, in connection with our work on feature integration, their use for segmentation and recognition are research that we currently actively pursue.

Partial differential equations and variational methods were introduced into image processing about 15 years ago, and intensive research has been carried out since then. The main goal of this work is to present the variety of image analysis applications and the precise mathematics involved. It is intended for two audiences. The first is the mathematical community, to show the contribution of mathematics to this domain and to highlight some unresolved theoretical questions.

During the four years since the publication of the first edition, there has been substantial progress in the range of image-processing applications covered by the PDE framework. The main goals of the second edition are to update the first edition by giving a coherent account of some of the recent challenging applications, and to update the existing material. In addition, this book provides the reader with the opportunity to make his own simulations with a minimal effort. To this end, programming tools are made available, which will allow the reader to implement and test easily some classical approaches.

In this paper, we focus on geometric image inpainting for which several PDE based models have been proposed. Most of them rely on a transport or/and a diffusion equation of the intensity inside Omega.

Instead, we propose in this paper a two step approach. First we estimate the tangents of the missing isophotes using a tensor field diffusion process. Then we simply recover the gray levels by integrating along integral curves of the tensors principal eigenvectors. Such an approach has very few parameters to tune and we illustrate its performance on several synthetic and real examples.

Most optical flow algorithms provide flow fields as single valued functions of the image sequence domains. Only a very few of them attempt to recover multiple motion vectors at given location, which is necessary when some transparent layers are moving independently. In this report we introduce a novel framework for modeling multivalued motion fields, and propose an energy minimization formulation with smoothing terms and terms implementing velocity model competition.  We illustrate the capabilities of this approach on synthetic and real sequences.

For example, this is very useful in medical imaging where organs or structures of interest are often characterized by smooth intensity regions. This problem has been formulated as the minimization of an energy by Mumford and Shah.

In this work, we propose a fast and robust segmentation model for piecewise smooth images. Rather than modeling each region with global statistics, we introduce local statistics in an energy formulation. The shape gradient of this new functional gives a contour evolution controlled by local averaging of image intensities inside and outside the contour. To avoid the computational burden of a direct estimation, we express these terms as the result of convolutions. This makes an efficient implementation via recursive filters possible, and gives a complexity of the same order as methods based on global statistics. This approach leads to results similar to the general Mumford-Shah model but in a faster way, without solving a Poisson partial differential equation at each iteration.

In many medical computer vision tasks the relevant data is attached to a specific tissue such as the colon or the cortex. This situation calls for regularization techniques which are defined over surfaces. We introduce in this paper the Beltrami flow over manifolds. This new regularization technique overcomes the over-smoothing of the L_2 flow and the staircasing effects of the L_1 flow, that were recently suggested via the harmonic map methods. The key of our approach is first to clarify the link between the intrinsic "Polyakov action" and the implicit "Harmonic energy functional" and then use the geometrical understanding of the Beltrami Flow to generalize it to images on explicitly and implicitly defined non flat surfaces. It is shown that once again the Beltrami flow interpolates between the L_2 and L_1 flows on non-flat surfaces. The implementation scheme of this flow is presented and various experimental results obtained on a set of various real images illustrate the performances of the approach as well as the differences with the harmonic map flows. This extension of the Beltrami flow to the case of non flat surfaces opens new perspectives in the regularization of noisy data defined on manifolds.

In this work we integrate colour, texture, and motion into a segmentation process. The segmentation consists of two steps, which both combine the given information: a pre-segmentation step based on nonlinear diffusion for improving the quality of the features, and a variational framework for vector-valued data using a level set approach and a statistical model to describe the interior and the complement of a region. For the nonlinear diffusion we apply a novel diffusivity closely related to the total variation diffusivity, but being strictly edge enhancing. A multi-scale implementation is used in order to obtain more robust results. In several experiments we demonstrate the usefulness of integrating many kinds of information. Good results are obtained for both object segmentation and tracking of multiple objects.

Nonlinear diffusion equations are now widely used to restore and enhance images. They allow to eliminate noise and artifacts while preserving large global features, such as object contours. In this context, we propose a differential-geometric framework to define regularizing PDEs acting on manifold constrained datasets. We consider the case of images taking value into matrix manifolds defined by orthogonal and spectral constraints. We directly incorporate the geometry and natural metric of the underlying configuration space (viewed as a Lie group or a homogeneous space) in the design of the corresponding flows. Our numerical implementation relies on structure-preserving integrators that respect intrinsically the constraints geometry. This approach was applied to the anisotropic smoothing of diffusion tensor volumes in medical imaging.

In this paper, we propose a novel and efficient approach for active unsurpervised texture segmentation. First, we show how we can extract a small set of good features for texture segmentation based on the structure tensor and nonlinear diffusion. Then, we propose a variational framework that incorporates these features in a level set based unsupervised segmentation that adaptively takes into account their estimated statistical information inside and outside the region to segment. The approach has been tested on various textured images, and its performance is favorably compared to recent studies.

Recent works on curve propagation were able to incorporate stochastic informations and prior knowledge on shapes. The information inserted in these studies is most of the time extracted offline. Meanwhile, other approaches have proposed to extract region information during the segmentation process itself. Following these new approaches and extending the work in to vector-valued images, we propose in this paper an entirely variational framework to approach the segmentation problem. Both, the image partition and the statistical parameters for each region are unkown. After a brief reminder on recent segmenting methods, we will present a variational formulation obtained from a bayesian model. After that, we will show two different differentiations driving to the same evolution equations. Detailed studies on gray and color images of the 2-phase case will follow. And we will finish on an application to tracking which shows benefits of our dynamical framework.

Object extraction is then equivalent with seeking a linear/non-linear transformation that projects/ deforms this geometric form to an image region with the desired visual properties. The definition of the image term is the most challenging component of such an approach. Level set methods is a powerful optimization framework, that can be used to recover objects of interest by the propagation of curves. They can support complex topologies, considered in higher dimensions, are implicit, intrinsic and parameter free. Furthermore, one can introduce various image terms when seeking an object of particular form/visual properties. In this work we re-visit active shape models and introduce a level set variant of them. Such an approach can account for prior shape knowledge quite efficiently as well as use data/image terms of various form and complexity while being able to deal with important local deformations and changes of topology. Promising experimental results demonstrate the potential of our approach.

We address the problem of regularizing fields of diffusion tensors (i.e symmetric and positive-definite matrices) using PDE's and variational tools. We consider the minimization of a general regularizing functional under orthonormal constraints, introduced with Lagrange multipliers. Accurate numerical schemes are then provided and we compare this approach with a classical reprojection-step method. The application of interest considered here is the regularization of noisy DT-MRI images, in order to construct a coherent fiber network of the whitte matter.

Equations) and their application to color image processing. The analysis of classic scalar diffusion PDE's leads to a new multivalued regularization equation which is coherent with a local vector image geometry. Then, we are interested in constrained regularization problems, where vector norm constraints have to be considered. A general extension for unit vector regularization is then proposed. Finally, experimental results of color image restoration are presented.

This work proposes a variational based approach to regularize fields of orthonormal vector sets, using constraint-preserving anisotropic diffusion PDE's. Each point of these fields is defined by multiple orthogonal and unitary vectors and can indeed represent a lot of interesting orientation features such direction vectors or orthogonal matrices (among other examples). We first develop a general variational framework that solves this regularization problem, thanks to a constrained minimization of Phi-functionals. This leads to a set of coupled vector-valued PDE's preserving the orthonormal constraints. Then, we focus on particular applications of this general framework, including the restoration of noisy direction fields, noisy chromaticity color images, estimated camera motion and DT-MRI (Diffusion Tensor MRI) datasets.

We address the problem of vector-valued image regularization with variational methods and PDE's. From the study of existing global and local formalisms, we propose a new framework that unifies a large number of previous methods within a generic local formulation. On one hand, resulting equations are more adapted to analyze the local geometric behaviors of the diffusion processes. On the other hand, it can be used to design a new regularization PDE that takes important local smoothing properties into account. Specific numerical schemes are also naturally emerging from this formulation. Finally, we illustrate the capability of our approach to deal with classical image processing applications, such as color image restoration, inpainting, magnification and flow visualization.

Regularization and fiber bundle Visualization. We first review related algorithms existing in the literature and propose then alternative variational formalisms that lead to new and improved schemes, thanks to the preservation of important tensor constraints (positivity, symmetry). We illustrate how our complete DT-MRI processing pipeline can be successfully used to construct and draw fiber bundles in the white matter of the brain, from a set of noisy raw MRI images.

In this work de-luis-garcia-deriche-etal:05, we propose an original approach for texture and color segmentation based on the tensor processing of the nonlinear structure tensor. While the tensor structure is a well established tool for image segmentation, its advantages were only partly used because of the vector processing of that information. In this work, we use more appropriate definitions of tensor distance grounded in concepts from information theory and compare their performance on a large number of images. We clearly show that the traditional Frobenius norm-based tensor distance is not the most appropriate one. Symmetrized KL divergence and Riemannian distance intrinsic to the manifold of the symmetric positive definite matrices are tested and compared. Adding to that, the extended structure tensor and the compact structure tensor are two new concepts that we present to incorporate gray or color information without losing the tensor properties. The performance and the superiority of the Riemannian based approach over some recent studies are demonstrated on a large number of gray-level and color data sets as well as real images.

We study in this work shafrir-sochen-etal:05 the problem of regularization of mappings between manifolds of arbitrary dimension and codimension using variational methods. This is of interest in various applications such as diffusion tensor imaging and EEG processing on the cortex.

We consider the cases where the source and target manifold are represented implicitly, using multiple level set functions, or explicitly, as functions of the spatial coordinates. We derive the general implicit differential operators, and show how they can be used to generalize previous results concerning the Beltrami flow and other similar flows. As examples, we show how these results can be used to regularize gray level and color images on manifolds, and to regularize tangent vector fields and direction fields on manifolds.

In this paper  tschumperle-deriche:05, we focus on techniques for vector-valued image regularization, based on variational methods and PDEs. Starting from the study of PDE-based formalisms previously proposed in the literature for the regularization of scalar and vector-valued data, we propose a unifying expression that gathers the majority of these previous frameworks into a single generic anisotropic diffusion equation. On one hand, the resulting expression provides a simple interpretation of the regularization process in terms of local filtering with spatially adaptive Gaussian kernels. On the other hand, it naturally disassembles any regularization scheme into the smoothing process itself and the underlying geometry that drives the smoothing. Thus, we can easily specialize our generic expression into different regularization PDEs that fulfill desired smoothing behaviors, depending on the considered application: image restoration, inpainting, magnification, flow visualization, etc. Specific numerical schemes are also proposed, allowing us to implement our regularization framework with accuracy by taking the local filtering properties of the proposed equations into account. Finally, we illustrate the wide range of applications handled by our selected anisotropic diffusion equations with application results on color images.

Motion analysis in computer vision is a well-studied problem with numerous applications. In particular, the tasks of optical flow estimation and tracking are of increasing interest. In this paper paragios-deriche:05 we propose a level set approach to address both aspects of motion analysis. Our approach relies on the propagation of smooth interfaces to perform tracking while using an incremental estimation of the motion models. Implicit representations are used to represent moving objects, and capture their motion parameters. Information from different sources like a boundary attraction term, a background subtraction component and a visual consistency constraint are considered. The Euler-Lagrange equations within a gradient descent method lead to a flow that deforms a set of initial curve towards the object boundaries as well an incremental robust estimator of their apparent motion. Partial extension of the proposed framework to address dense motion estimation and the case of moving observer is also presented. Promising results demonstrate the performance of the method.

Level set based segmentation has been used with and without shape priors, to approach difficult segmentation problems in several application areas. This work, published in ACCV 2006, addresses two limitations of the classical level set based segmentation approaches: They usually deliver just two regions - one foreground and one background region, and if some prior information is available, they are able to take into account just one prior but not more. In these cases, one object of interest is reconstructed but other possible objects of interest and unfamiliar image structures are suppressed.

The approach we propose in this work can simultaneously handle an arbitrary number of regions and competing shape priors. Adding to that, it allows the integration of numerous pose invariant shape priors, while segmenting both known and unknown objects. Unfamiliar image structures are considered as separate regions. We use a region splitting to obtain the number of regions and the initialization of the required level set functions. In a second step, the energy of these level set functions is robustly minimized and similar regions are merged in a last step. All these steps are considering given shape priors.

Tracking of regions and object boundaries in an image sequence is a well studied problem in image processing and computer vision. So far, numerous approaches tracking different features of the objects (contours, regions or points of interest) have been presented. Most of these approaches have problems with robustness. Typical reasons are noisy images, objects with identical features or partial occlusions of the tracked features.

In this work, published in ACCV:2006, we propose a novel level set based tracking approach, that allows robust tracking on noisy images. Our framework is able to track multiple regions in an image sequence, where a level set function is assigned to every region. For already known or learned objects, transformation invariant shape priors can be added to ensure a robust tracking even under partial occlusions. Furthermore, we introduce a simple decision function to maintain the desired topology for multiple regions. Experimental results demonstrate the method for arbitrary numbers of shape priors. The approach can even handle full occlusions and objects which are temporarily hidden in containers.

Given an image, digital matting consists in extracting a foreground element from the background. Standard methods are initialized with a trimap, a partition of the image into three regions: a definite foreground, a definite background, and a blended region where pixels are considered as a mixture of foreground and background colors. Recovering these colors and the proportion of mixture between both is an under-constrained inverse problem, sensitive to its initialization: one has to specify an accurate trimap, leaving undetermined as few pixels as possible. First, we propose a new segmentation scheme to extract an accurate trimap from just a coarse indication of some background and/or foreground pixels. Standard statistical models are used for the foreground and the background, while a specific one is designed for the blended region. The segmentation of the three regions is conducted simultaneously by an iterative Graph Cut based optimization scheme. This user-friendly trimap is similar to carefully hand specified ones. As a second step, we take advantage of our blended region model to design an improved matting method. Based on global statistics rather than on local ones, our method is much faster than standard Bayesian matting, without quality loss, and also usable with manual trimapsjuan-keriven:05juan-keriven:05b.

We propose a new approach to deal with the first and second order statistics of a set of images. These statistics take into account the images characteristic deformations and their variations in intensity. The central algorithm is based on non-supervised diffeomorphic image matching (without landmarks or human intervention). As they convey the notion of the mean shape and colors of an object and the one of its common variations, such statistics of sets of images may be relevant in the context of object recognition, both in the segmentation of any of its representations and in the classification of them. The proposed approach has been tested on a small database of face images to compute a mean face and second order statistics. The results are very encouraging since, whereas the algorithm does not need any human intervention and is not specific to face image databases, the mean image looks like a real face and the characteristic modes of variation (deformation and intensity changes) are sensible. This work appeared in charpiat-keriven-etal:05ccharpiat-audibert-etal:05.

Subsequently, we consider shape optimization techniques, which are a common framework to address various applications in Computer Vision, like segmentation, tracking, stereo vision etc. The objective of our approach is to improve these methods through the introduction of stochastic motion principles.

The extension we propose can deal with local minima and with complex cases where the gradient of the objective function with respect to the shape is impossible to derive exactly. Finally, as an application, we focus on image segmentation methods, leading to what we call Stochastic Active Contours.

In this work, we overcome a major drawback of the level set framework: the lack of point correspondences. We maintain explicit backward correspondences from the evolving interface to the initial one by advecting the initial point coordinates with the same speed as the level set function. Our method leads to a system of coupled Eulerian partial differential equations. We show in a variety of numerical experiments that it can handle both normal and tangential velocities, large deformations, shocks, rarefactions and topological changes. Applications are many in computer vision and elsewhere since our method can upgrade virtually any level set evolution. We complement our work with the design of non zero tangential velocities that preserve the relative area of interface patches; this feature may be crucial in such applications as computational geometry, grid generation or unfolding of the organs' surfaces, e.g. brain, in medical imaging (to appear in the Journal of Computational Physics).

The choice of the Hausdorff distance between shapes is itself not fundamental since the same framework could be applied with another distance. We first define a smooth approximation of the Hausdorff distance and build non-supervised warpings between shapes by a gradient descent of the approximation.

Local minima can be avoided by changing the scalar product in the tangent space of the shape being warped.When non-supervised warping fails, we present a way to guide the evolution with a small number of landmarks. Thanks to the warping fields, we can define the mean of a set of shapes and express statistics on them. Finally, we come back to the initial distance between shapes and use it to represent a set of shapes by a graph, which with the technic of graph Laplacian leads to a way of projecting shapes onto a low dimensional space.

We propose a framework for dealing with two problems related to the analysis of shapes: the definition of the relevant set of shapes and that of defining a metric on it. Following a recent research monograph by Delfour and Zolesio, we consider the characteristic functions of the subsets of the plane and their distance functions. The L2 norm of the difference of characteristic functions, the L1 and the W1,2 norms of the difference of distance functions define interesting topologies, in particular that induced by the well-known Hausdorff distance. Because of practical considerations arising from the fact that we deal with image shapes defined on finite grids of pixels we restrict our attention to subsets of the plane of positive reach in the sense of Federer, with smooth boundaries of bounded curvature. For this particular set of shapes we show that the three previous topologies are equivalent. The next problem we consider is that of warping a shape onto another by infinitesimal gradient descent, minimizing the corresponding distance. Because the distance function involves an inf, it is not differentiable with respect to the shape. We propose a family of smooth approximations of the distance function which are continuous with respect to the Hausdorff topology, and hence with respect to the other two topologies.

We compute the corresponding Gateaux derivatives. They define deformation flows that can be used to warp a shape onto another by solving an initial value problem. We show several examples of this warping and prove properties of our approximations that relate to the existence of local minima. We then use this tool to produce computational definitions of the empirical mean and covariance of a set of shape examples. They yield an analog of the notion of principal modes of variation.

This paper proposes a framework for geometric shape warping based on both shape distances and landmarks. Our method is compatible with implicit representations and a matching between shape surfaces is provided at no additional cost. It is, to our knowledge, the first time that landmarks and shape distances are reconciled in a pure geometric level set framework. The feasibility of the method is demonstrated with two- and three-dimensional examples.

We propose a robust method for extracting motion layers in video sequences. Taking advantage of temporal continuity, our framework considers both the visible and the hidden parts of each layer in order to increase robustness. Moreover, the hidden parts of the layers are recovered, which could be of great help in many high level vision tasks. Modeling the problem as a labeling task, we state it in a MRF-optimization framework and solve it with a graph-cut algorithm.

We show the importance and feasibility of much faster multi-view stereo reconstruction algorithms relying almost exclusively on graphics hardware. Reconstruction algorithms have been steadily improving in the last few years and several state-of-the-art methods are nowadays reaching a very impressive level of quality. However all these modern techniques share a very lengthy computational time that completely forbids their more widespread use in practical setups: the typical running time of such algorithms range from one to several hours. One possible solution to this problem seems to lie in the use of graphics hardware: more and more computer vision techniques are taking advantage of the availability of cheap computational horsepower and divert graphics hardware from its original purpose to accelerate the early stages of some algorithms.  We present here an almost full implementation on graphics hardware of a multi-view stereo algorithm based on surface deformation by a PDE: this algorithm tries to minimize the error between input images and predicted ones by reprojection via the surface. As it mainly works on whole images, it is well suited for graphics hardware. We show how we succeeded to bring the whole reconstruction time within minutes. Results for synthetic and real data sets are presented with computational times and compared with those of other state-of-the-art algorithms.

Thanks to their high performance and programmability, the latest graphics cards can now be used for scientific purpose. They are indeed very efficient parallel Single Instruction Multiple Data (SIMD) machines. This new trend is called General Purpose computation on Graphics Processing Unit. Regarding the stereo problem, variational methods based on deformable models provide dense, smooth and accurate results. Nevertheless, they prove to be slower than usual disparity-based approaches.

In this paper, we present a dense stereo algorithm, handling occlusions, using three cameras as inputs and entirely implemented on a Graphics Processing Unit. Experimental speedups prove that our approach is efficient and perfectly adapted to the GPU, leading to nearly video frame rate reconstruction.

We have designed a new variational method for multi-view stereovision and non-rigid three-dimensional motion estimation from multiple video sequences. Our method minimizes the prediction error of the shape and motion estimates. Both problems then translate into a generic image registration task. The latter is entrusted to a similarity measure chosen depending on imaging conditions and scene properties. In particular, our method can be made robust to appearance changes due to non-Lambertian materials and illumination changes. Our method results in a simpler, more flexible, and more efficient implementation than existing deformable surface approaches. We have implemented our stereovision method in the level set framework and we have obtained results comparing favorably with state-of-the-art methods, even on complex non-Lambertian real-world images including specularities and translucency. Using our algorithm for motion estimation, we have successfully recovered the 3D motion of a non-rigid event and we have synthesized time-interpolated 3D sequences. To appear in IJCV.

Functional Magnetic Resonance Imaging(fMRI) provides a measure of part of the brain activity causing variations in the blood flow and correlated to neuronal activity. The spatial resolution is, in the best cases, of the order of one millimeter, the temporal resolution of the order of a tenth of a second.

Diffusion Magnetic Resonance Imaging (dMRI) provides a measure of the amount of water molecules in biological tissues which relates to the structure of nervous fibers connecting different brain structures and, probably, to the electrical conductivity of the tissues.

EEG and MEG which we collectively call MEEG provide measurements which are very directly correlated to the electrical activity of the brain with a spatial resolution of the order of one centimeter and temporal resolution of the order of one millisecond. The three modalities appear as complementary in terms of their resolutions and of the information they can recover.

The analysis of the existence and uniqueness of a solution to the MEEG inverse problem, i.e. the problem of the computation of the electrical activity of the brain that best explains the measurements.

Simulation of pituitary gland surgery raises many interesting challenges since a precise classification of all tissues (soft tissues, vessels, bones) in the pituitary gland area is needed to create a realistic simulator for endoscopic surgery.

In particular, bone structures are very thin and have diffusive edges in the CT dataset.  Thus, the common method of thresholding the data is insufficient and produces incomplete segmentations that have many holes.

We present a novel multi-scale bone enhancement measure that can be used to drive a geometric flow to segment any sheet-like structure.  The measure is designed to capture sheet-like structure using the local shape information from the eigenvalue decomposition of the Hessian matrix.  It is maximum on the center sheet of the bone structure and provides local estimates of the width and orientation of the bone structure.  These can be used to create a vector field which is orthogonal to the bone boundaries so that the flux maximizing flow algorithm can be applied to recover the bone structure.  Hence, the sheetness measure has the essential properties  to be incorporated in the computation of anatomical models for the simulation of pituitary surgery, enabling it to better account for the presence of sinus bones.

We propose methods to adapt the usual fMRI analysis tools to infere the cerebral activity from a linear context to the larger framework of nonlinear dynamical models. More specifically we use a model parameter estimation scheme relying on the integration of differential systems, and define a statistic Fisher test for testing the existence of a response to an experimental condition.

We propose a new approach to integrate multimodal functional data, and in particular simultaneous functional Magnetic Resonnance Imaging (fMRI) and Electroencephalography (EEG) acquisitions. Our method relies on biophysiological models that relate the different modalities measures to a common neural activity. The EEG model is based on the propagation of currents through the different head tissues, and can be formalized as a linear transformation, whose matrix is computed via the Boundary Elements Method.

The fMRI model we used is the so-called "Balloon Model", which summarizes the energy demand, blood and blood oxygen dynamics implied in the measures. The fusion algorithm relies on Kalman filtering techniques; its novelty is to allow integration of both spatial and temporal aspects of the EEG and fMRI.

We consider the problem of increasing the resolution of fMRI series acquired with given relative shifts. Main contributions are: (1) The definition of the protocol to acquire shifted images in order to be able to obtain increased resolution images (2) The use of discontinuity preserving regularization methods to solve the problem of superresolution. (3) An evaluation of the results based on human fMRI time series. Activated areas from low, high and superresolved images are compared. We conclude on the interest of using superresolution for task related activation detection.

Diffusion magnetic resonance imaging probes and quantifies the anisotropic diffusion of water molecules in biological tissues, making it possible to non-invasively infer the architecture of the underlying structures. In this work deriche-tschumperle-etal:05, we present a set of new techniques for the robust estimation and regularization of diffusion tensor images (DTI ) as well as a novel statistical framework for the segmentation of cerebral white matter structures from this type of dataset. Numerical experiments conducted on real diffusion weighted MRI illustrate the techniques and exhibit promising results.

Our approach is grounded on the theoretically well-founded differential geometrical properties of the space of multivariate normal distributions. We introduce a variational formulation, in the level set framework, to estimate the optimal segmentation according to the following hypothesis: Diffusion tensors exhibit a Gaussian distribution in the different partitions. Moreover, we must respect the geometric constraints imposed by the interfaces existing among the cerebral structures and detected by the gradient of the diffusion tensor image.

We validate our algorithm on synthetic data and report interesting results on real datasets. We focus on two structures of the white matter with different properties and respectively known as the corpus callosum and the corticospinal tract.

Diffusion Tensor MRI evaluates, from a set of diffusion weighted images, the covariance matrix of the water molecules Brownian motion. In other words, it approximates the probability density function of the molecular motion by a multivariate normal distribution of zero-mean vector. In this work lenglet-deriche-etal:05, we address the issues of diffusion tensors estimation and streamline-based fiber tracking by using the geometrical properties of the manifold of multivariate normal distributions.

Previous studies suggested that associative striatal regions are involved during the acquisition of new motor skills, whereas sensorimotor regions may be critical for long-term storage. Using fMRI and DTI fiber tracking, we tested in this work lehericy-lenglet-etal:05 the hypothesis that motor representations shift from the associative to the sensorimotor compartment of the basal ganglia during the explicit learning of a sequence of finger movement over a month of training.

There are 4 main criteria to define visual cortical areas: histology, connectivity, global functional properties and retinotopy. Through fMRI, we used the last two criteria to delineate various occipital and mid-temporal areas.

Based on diffusion tensor images, we then studied the connectivity patterns among these areas within and across both hemispheres. The goal of this work is twofold: (i) validate the methodology of merging fMRI and DTI and (ii) refine non-invasively our knowledge of the low level human visual cortex.

During each scanning session of less than 1.5 hour performed on a 3T MR scanner, subjects underwent three different kinds of runs. A phase-encoded retinotopic mapping was first performed to reveal the locations and borders of the occipital visual areas V1, V2, V3, hV4 and V3A. Secondly, a classical block design substraction procedure was completed to reveal the hMT+ complex (the human equivalent to macaque's MT, MST and adjacent areas), contrasting random dots pattern in coherent motion with a dynamic noise or a static condition. Finally, DTI data were obtained. For fiber tracking analysis, diffusion tensors were used as a metric to first compute the geodesic distance and then the shortest paths between the above stated areas of the visual cortex. A measure of likelihood for each computed path was derived by examining the properties of the geodesic distance function. Images were realigned and coregistered on the subject high resolution anatomical scan acquired within the scanning session. The results are analyzed on this anatomical image or a cortical surface model extracted from the latter.

Tensors are nowadays an increasing research domain in different areas, especially in image processing, motivated for example by diffusion tensor magnetic resonance imaging (DT-MRI). Up to now, algorithms and tools developed to deal with tensors were founded on the assumption of a matrix vector space with the constraint of remaining symmetric positive definite matrices. On the contrary, our approach is grounded on the theoretically well-founded differential geometrical properties of the space of multivariate normal distributions, where it is possible to define an affine-invariant Riemannian metric and express statistics on the manifold of symmetric positive definite matrices. In this paper, we focus on the contribution of these tools to the anisotropic filtering and regularization of tensor fields. To validate our approach we present promising results on both synthetic and real DT-MRI data.

Diffusion tensors exhibit a Gaussian distribution in the different partitions. We must also respect the geometric constraints imposed by the interfaces existing among the cerebral structures and detected by the gradient of the DTI. We show how to express all the statistical quantities for the different probability metrics. We validate and compare the results obtained on various synthetic data-sets, a biological rat spinal cord phantom and human brain DTIs.

This work is dedicated to the statistical analysis of the space of multivariate normal distributions with an application to the processing of Diffusion Tensor Images (DTI). It relies on the differential geometrical properties of the underlying parameters space, endowed with a Riemannian metric, as well as on recent works that led to the generalization of the normal law on Riemannian manifolds. We review the geometrical properties of the space of multivariate normal distributions with zero mean vector and focus on an original characterization of the mean, covariance matrix and generalized normal law on that manifold. We extensively address the derivation of accurate and efficient numerical schemes to estimate these statistical parameters. A major application of the present work is related to the analysis and processing of DTI datasets and we show promising results on synthetic and real examples.

We propose a novel, fast and robust technique for the computation of anatomical connectivity in the brain. Our approach exploits the information provided by Diffusion Tensor Magnetic Resonance Imaging (or DTI) and models the white matter by using Riemannian geometry and control theory. We show that it is possible, from a region of interest, to compute the geodesic distance to any other point and the associated optimal vector field. The latter can be used to trace shortest paths coinciding with neural fiber bundles. We also demonstrate that no explicit computation of those 3D curves is necessary to assess the degree of connectivity of the region of interest with the rest of the brain. We finally introduce a general local connectivity measure whose statistics along the optimal paths may be used to evaluate the degree of connectivity of any pair of voxels. All those quantities can be computed simultaneously in a Fast Marching framework, directly yielding the connectivity maps. Apart from being extremely fast, this method has other advantages such as the strict respect of the convoluted geometry of white matter, the fact that it is parameter-free, and its robustness to noise. We illustrate our technique by showing results on real and synthetic datasets. OurGCM(Geodesic Connectivity Mapping) algorithm is implemented in C++ and will be soon available on the web.

Due to the well-known limitations of diffusion tensor imaging (DTI), high angular resolution diffusion imaging is currently of great interest to characterize voxels containing multiple fiber crossings. In particular, Q-ball imaging (QBI) is now a popular reconstruction method to obtain the orientation distribution function (ODF) of these multiple fiber distributions. The latter captures all important angular contrast by expressing the probability that a water molecule will diffuse into any given solid angle. However, QBI and other high order spin displacement estimation methods involve non-trivial numerical computations and lack a straightforward regularization process. In this work, we propose a simple linear and regularized analytic solution for the Q-ball reconstruction of the ODF. First, the signal is modeled with a physically meaningful high order spherical harmonic series by incorporating the Laplace-Beltrami operator in the solution. This leads to an elegant mathematical simplification of the Funk-Radon transform using the Funk-Hecke formula. In doing so, we obtain a fast and robust model-free ODF approximation. We validate the accuracy of the ODF estimation quantitatively using the multi-tensor synthetic model where the exact ODF can be computed. We also demonstrate that the estimated ODF can recover known multiple fiber regions in a biological phantom and in the human brain. Another important contribution of the paper is the development of ODF sharpening methods. We show that sharpening the measured ODF enhances each underlying fiber compartment and considerably improves the extraction of fibers. The proposed techniques are simple linear transformations of the ODF and can easily be computed using our spherical harmonics machinery.

High angular resolution diffusion imaging has recently been of great interest in characterizing non-Gaussian diffusion processes. One important goal is to obtain more accurate fits of the apparent diffusion processes in these non-Gaussian regions, thus overcoming the limitations of classical diffusion tensor imaging. This paper presents an extensive study of high-order models for apparent diffusion coefficient estimation and illustrates some of their applications. Using a meaningful modified spherical harmonics basis to capture the physical constraints of the problem, a new regularization algorithm is proposed. The new smoothing term is based on the Laplace-Beltrami operator and its closed form implementation is used in the fitting procedure. Next, the linear transformation between the coefficients of a spherical harmonic series of order L and independent elements of a rank-L high-order diffusion tensor is explicitly derived. This relation allows comparison of the state-of-the-art anisotropy measures computed from spherical harmonics and tensor coefficients. Published results are reproduced accurately and it is also possible to recover voxels with isotropic, single fiber anisotropic, and multiple fiber anisotropic diffusion. Validation is performed on apparent diffusion coefficients from synthetic data, from a biological phantom, and from a human brain dataset.

Q-Ball Imaging (QBI) is a high angular resolution diffusion imaging (HARDI) reconstruction method to infer fiber bundles with crossing, kissing or diverging configurations, with advantages over diffusion tensor imaging (DTI) in these situations. QBI seeks to reconstruct the orientation distribution function (ODF) of the underlying fiber population. We present a fast analytic solution to the ODF reconstruction and compare the ODF reconstructions using the original QBI technique of D. Tuch  on a biological phantom and on in-vivo human brain data. This abstract shows that the analytic solution and the standard QBI qualitatively agree with ground truth as evidenced by the crossings in the phantom and our knowledge of human anatomy.

When recording the membrane potential of a neuron through a single-electrode, current injection induces a voltage drop across the electrode which biases the measurement. Compensating for the electrode resistance ( bridge compensation ) leaves capacitive transients which prevent its use in protocols with fast currents and feedback, such as the dynamic clamp or the voltage-clamp. The only option is to record in discontinuous mode, alternatively injecting and recording, but besides being limited to a low sampling rate (typically as low as 3 kHz with sharp electrodes) and introducing considerable noise, this technique produces artefacts when recording fast phenomena, such as spikes or fast fluctuations of the membrane potential. We have developed a digital on-line compensation method which allows faithful recording in continuous mode, with sampling frequency only limited by hardware constraints, and have demonstrated its use by injecting noisy synaptic conductances with a sharp electrode, using the dynamic-clamp technique (experiments done at UNIC, Gif-sur-Yvette).

Knowledge of precise conductivity values of head tissues is important for inverse source problem in MEG/EEG : significant error on conductivities can largely affect accuracy of a source estimate.  The three-layer isotropic conductivity model is one of the most common for source reconstruction in EEG and MEG.  Although it is very simple, as it describes the head as three nested regions (brain, skull, scalp) with constant and isotropic conductivities, the classical normalized conductivity values of 1, 0.0125, 1 for brain, skull and scalp are being abandoned.  Indeed, methods of conductivity estimation in vivo such as EIT show a wide variability among subjects, especially for skull conductivity.

In EIT, a small electric current is injected on the scalp while the subject is idle, and EEG data is recorded in the same time.  Then conductivity values are inferred from knowledge of current sources and scalp potential. In this work, we study a new approach to estimate conductivities in vivo.  We hope to avoid several drawbacks of EIT methods : first the current injection is slightly invasive, and moreover the skull has a reflecting effect. The greater part of injected current remains in the scalp, and therefore the corresponding EEG data is not very relevant for brain conductivity estimation.  This is why we consider a current source localized inside the brain, and coming from a sensory stimulus, such as finger stimulation. This type of primary sensory response is well modeled by a single current dipole.  The advantage of this model is that the inverse source problem is well-posed, without having to add regularization or a priori hypothesis. So our approach is to estimate simultaneously a single dipolar source and the conductivity values from EEG data only. Such a method has already been proposed for spherical head models, and with additional MEG data. The use of EEG data only makes our approach much simpler ; and in order to improve accuracy we work with a realistic head model.

We study the method with simulations of EEG evoked potentials computed on real meshes, using a symmetric BEM formulation for the forward problem.  The inverse problem, corresponding to dipolar source and conductivity reconstruction, is modeled as the minimization of least square error between the EEG measurements and the prediction of the forward problem.  The robustness of the method is tested by adding noise to EEG measurements simulations.  Finally, to validate the method, we plan to realize a real experiment, and to compare the results to conductivity estimates given by EIT on the same subjects.

We compare two different methods for the resolution of this problem, from the point of view of computational complexity and accuracy. First, the finite element method (FEM), based on the discretization of the PDE in the entire head volume. Second, the boundary element method (BEM), discretizing the equivalent integral equations on the surfaces separating volumes with different electrical parameters. We also study the behaviour of BEM and FEM for the sources approaching the discontinuity in conductivity. We conclude that at the current state of investigation, for equivalent meshes, the FEM is significantly faster than BEM and provides similar or better accuracy.

Reconstructing neuronal activity from MEG and EEG measurements requires the accurate calculation of the electromagnetic field inside the head. The boundary element formulation of this problem leads to a dense linear system which is too large to be solved directly. We propose to accelerate the computations via the fast multipole method. This method approximates the electromagnetic interaction between surface elements by performing multipole expansions at coarse resolutions. It significantly reduces the computational burden of the matrix-vector products needed for the iterative solution of the linear system, and avoids the storage of its matrix.

One of the main problems in the volumic EEG forward and inverse problems is the obtention of the mesh discretizing the head. Because the cortex is a very thin layer separated by surfaces with high curvatures, meshes describing these surfaces involve a great number of triangles. Mesh decimation is also quite difficult here because the two close surfaces need to be decimated simultaneously in order to preserve a proper topology so as to feed a 3D mesh generator with consistent data. Overall, the effort required to obtain descent mesh models of the head is several orders of magnitude more complicated than solving the EEG problem. On the other hand, it is quite easy to obtain a very accurate head segmentation using levelsets (see ). We have thus developped a volumic finite element method that is directly based on the implicit description of the surfaces provided by the levelset segmentation.

This ``implicit mesh'' construction is very simple and quite fast compared to the many operations needed to construct a standard mesh. Besides, this mesh representation is very compact and has a bounded complexity with respect to the image data. It allows quite a few standard algorithmic improvements such as multigrid which were previously ruled out because of the complexity of the process of creating a mesh.

The accurate solution of the forward electrostatic problem is an essential first step before solving the inverse problem of magneto- and electro-encephalography (MEG/EEG). The symmetric Galerkin boundary element method is accurate but cannot be used for very large problems because of its computational complexity and memory requirements. We have designed a fast multipole-based acceleration for the symmetric boundary element method (BEM). It creates a hierarchical structure of the elements and approximates far interactions using spherical harmonics expansions. The accelerated method is shown to be as accurate as the direct method, yet for large problems it is both faster and more economical in terms of memory consumption kybic-clerc-etal:05b.

Boundary Element Method. We have demonstrated the far superior accuracy of this method over the existing methods in the case of dipolar sources and a head model made of concentric spheres, for which the analytical solution is known kybic-clerc-etal:05. The symmetric BEM is used to solve the source localization problem of MEG-EEG, with so-called imaging techniques, which model the sources as distributed over the cortical surface adde:05, adde-clerc-etal:05.

Cortical imaging refers to the mapping of the electric potential on the surface of the brain, from EEG measurements on the scalp. It is related to the "Cauchy problem" in functional analysis, which concerns the transmission of Cauchy data the value of a harmonic function and its normal derivative on the boundary of a conducting volume. In collaboration with our colleagues Juliette Leblond from APICS project (INRIA) and Jean-Paul Marmorat from Ecole des Mines, we propose to compare two cortical imaging methods, one based on a bounded extremal problem, and one based on a boundary element discretization and applicable to domains of arbitrary shape. The bounded extremal problem method consists in solving an approximation issue for 3D Hardy classes of analytic functions in spherical domains. Here, the (quadratic) criterion is minimized on the part of the boundary where data is available, while a constraint is put on the other part, playing the role of a regularization parameter. The symmetric boundary element method uses as unknowns both the potential and the normal current on all surfaces, making it possible to estimate the potential as well as its normal derivative on the surface of the cortex. Regularization is compulsory, due to the ill-posedness of the Cauchy problem.

OBJECTIVE: 3D Finite Element (FE) methods for EEG and MEG can cope with very realistic head models including the anisotropic effects of compartiments such as skull and white matter. Their use is limited in practice because of their computational cost and the complexity of the steps required for constructing accurate mesh representations of the head. This work proposes a method that builds FE matrices directly from segmentations without relying on such intermediate representations, which greatly simplifies volumic FE matrix assembly computations.

These methods encode interfaces implicitly as zero-crossings of an image whose values are the signed distances to the interface. Manipulating the interface is achieved by changing the image values. The interfaces obtained by segmenting MR images can be represented in such a way (e.g., the grid associated to the MR image can be used). We assume that the continuous image space is obtained from the discrete space using Q1 elements (piecewise trilinear interpolation over voxels).

METHOD: With the levelset segmentation, every voxel is labeled with the tissues it contains and for voxels that overlap two head compartments, the levelset provides an implicit mathematical model of the interface. The FE matrix coefficients for each compartment are computed directly by integrating the proper polynomial functions over the respective domains delimited by the levelset function. This leads to discretizations that are regular (the image grid is used), compact (if $S$ is the number of voxels of the MR image, the size of the data structure for the mesh cannot exceed $N \times S$, where $N=7$ for isotropic meshes and $N=13$ for anisotropic grids or conductivities) and easy to handle (solutions are simply 3D images). Furthermore, many numerical optimization schemes such as parallelization or multiscale techniques become much simpler than with traditional tetrahedral meshes.

Dipolar source models allow to express the source with a small number of parameters, and  dipole fitting methods are routinely used in many applicative settings. The main drawback of such methods resides in their instability according to the number of dipoles in the model, particularly when the different sources present coherent time-courses.  We are studying the applicability of Best Rational Approximation techniques to dipolar source estimation. This should lead to a new method, which does not require any assumption on the number of sources nor on the decorrelation of their time-courses.

In a first step, we assume the geometry to be spherical, and the electric potential and normal current flow to be known on the sphere delimiting the brain compartment. This requires to solve a cortical mapping problem, a difficult  issue for which we have recently proposed two novel solutions (one based on Boundary Elements, and the other on Best Constrained Approximation).  The source localization inside the sphere relies on a Best Rational Approximation technique on circular slices.  Using the values of the potential and the normal current on the boundary, a projection of the potential on spherical harmonics allows to filter outside sources. This procedure is related to the Source Signal Separation in MEG. This provides a function V-.  The squared function V-^2, considered on a disk sliced out of a sphere, is rational with a triple pole at a position, related to the dipolar parameters.

From the values of V-^2 on the boundary, compute the positions of its triple pole on a set of parallel disks.  This is where best rational approximation schemes can efficiently be used.  A careful analysis of the respective positions of the poles across the disks provides the position and moment of the dipolar source.

Applied in the case of several sources, V-^2 is no longer rational in the disks but admits branching singularities.However, the method still provides us with poles that converge to their positions, from which the dipole positions can be recovered.  Dipolar moments may also be estimated using residues computations.

Imaging (fMRI) involve a number of intermediary quantities such as oxygen metabolism, vascular blood flow, blood volume and hemoglobin oxygenation. Thanks to our collaboration with the Cognitive Vision team in the INCM, CNRS Marseille, laboratory head Guillaume Masson, and in particular with Ivo Vanzetta, who set the first Optical Imaging center on the behaving monkey in Europe, we were able to improve so-called "hemodynamic" models.

We propose a new method to estimate blood velocity in the vessels on the surface of the brain, based on intrinsic Optical Imaging, instead of the costly laser-doppler probe technique commonly used. The method relies on the fact that blood isn't homogeneous at a short scale; rather its hemoglobin concentration fluctuates along single vessels, since hemoglobin molecules are packed in red blood cells (or clusters thereof). When recording the blood volume at the surface of the brain at a high sampling rate (200Hz), particle motion can be observed. We have developed an algorithm that estimates these motions, based either on the structure tensor or on the Gabor filter in 2D spatio-temporal images. This is also a collaboration with Ivo Vanzetta, at the INCM, CNRS Marseille.

The use of models of cortical columns in analyzing the fMRI and MEEG activities goes beyond the classical electric dipole model and allows to put forward the computational aspect of this activity. It may also help us to better constrain the inverse MEEG problem.

Such a description also ties in naturally with dynamical systems and possibly partial differential equations. There is a fascinating potential for coupling this line of research with the one in area I.

In order to initiate this activity we now study, considering a few general computational mechanisms (classification and categorisation, trajectory generation), to which extend it is possible to develop biologically plausible mechanisms which implement such functionnalities.

If biological neural network information is mainly related to the synaptic input (thus to the membrane potential in this case), it is however usually modeled with high-level representation of the related processing (e.g. variational specification of neural-map computation in relation to local diffusion mechanisms in neural networks), allowing to relate the observed activity with certain classes of underlying computations (e.g.: early-vision processes, winner-take-all mechanisms, etc.).

Neuronal activity diffusion estimation seems feasible, given the proposed assumptions and actual data sets. Further investigation on diffusion map recovery are in progress. Using real data we have been able to recover some diffusion estimation and have observed that estimating diffusion under restricted assumptions.

Computational neuroscience relies heavily on the simulation of large networks of neuron models. There are essentially two simulation strategies: 1) using an approximation method (e.g. Runge-Kutta) with spike times binned to the time step; 2) calculating spike times exactly in an event-driven fashion. In large networks, the computation time of the best algorithm for either strategy scales linearly with the number of synapses, but each strategy has its own assets and constraints: approximation methods can be applied to any model but are inexact; exact simulation avoids numerical artefacts but is limited to simple models. Previous work has focused on improving the accuracy of approximation methods. In this paper we extend the range of models that can be simulated exactly to a more realistic model, namely an integrate-and-fire model with exponential synaptic conductances.

We introduced a two-dimensional integrate-and-fire model that combines an exponential spike mechanism with an adaptation equation, based on recent theoretical findings. We developed a systematic method to estimate its parameters with simple electrophysiological protocols (current-clamp injection of pulses and ramps) and applied it to a detailed conductance-based model of a regular spiking neuron. Our simple model predicts correctly the timing of 96% of the spikes () of the detailed model in response to injection of noisy synaptic conductances.

We show that replacing perfect integrators by the classic leaky integrate-and-fire models used in the computational neuroscience community (used e.g. in Brunel and Hakim 1999) amounts to replacing state-independent interactions by state-dependent interactions in the stochastic network analyzed in Fricker et al (1994).

Within this framework, we exhibit Markov processes representing the state of the network. We extend the ergodic theory to this new model and find that the non-ergodic case disappears in the leaky integrate and fire network. We study various network topologies and we examine the limit of large networks using scaling limits (also called fluid limits). We show that synaptic delays can also be included in this framework.

This paper describes some preliminary results of a research program for characterizing the statistics of spikes trains for a variety of commonly used neuron models in the presence of stochastic noise and deterministic input. The main angle of attack of the problem is through the use of stochastic calculus and ways of representing (local) martingales as Brownian motions by changing the time scale. Alternatively, Gaussian properties of the noise, when relevant, can also be used.

In this contribution, we present a mathematical analysis of a simple model of a cortical column. We first recall some known biological facts about cortical columns. We then present a mathematical model of such a column, developed by a number of people including Lopes Da Silva, Jansen, Rit. Finally we analyze some aspects of its behaviour in the framework of the theory of dynamical systems using bifurcation theory and the software package XPP-Aut developed by B. Ermentrout. This mathematical approach leads us to a compact representation of the model that allows to finally discuss its adequacy with biology.

We present a mathematical model of a neural mass developed by a number of people, including Lopes da Silva and Jansen. This model features three interacting populations of cortical neurons and is described by a six-dimensional nonlinear dynamical system. We address some aspects of its behavior through a bifurcation analysis with respect to the input parameter of the system. This leads to a compact description of the oscillatory behaviors observed in Jansen and Rit (1995) (alpha activity) and Wendling, Bellanger, Bartolomei, and Chauvel (2000) (spike-like epileptic activity). In the case of small or slow variation of the input, the model can even be described as a binary unit. Again using the bifurcation framework, we discuss the influence of other parameters of the system on the behavior of the neural mass model.

Neural network information is mainly conveyed through (i) event-based quanta, spikes, whereas high-level representation of the related processing is almost always modeled in (ii) some continuous framework. Here, we propose a link between  (i) and (ii) which allows to derive the spiking network parameters given a continuous processing and also obtain an abstract interpretation of the related processing.

In event based neural network models, the output of a neuron is entirely characterized by the sequence of spike firing times and the Gerstner and Kistler Spike Response Model of a biological neuron defines the state of a neuron via a single variable.

At the computational level, using piece-wise linear profiles yields a closed-form calculation of the spiking events, thus allows to obtain an efficient and exact implementation of (1) in event-based massive neuronal simulators such as MVASPIKE.

This relationship is valid only in a given temporal window, with saturation outside, as for analog networks. Here it appears that fast adaptive delays (as observed in recent intra-cellular experiments of e.g. Fregnac et al.) is a crucial element in this model.

It also corresponds to what is obtained from a variational framework relating the neuronal weights to a continuous diffusion operator, as introduced by Cottet. This last formulation is in direct relation with a sub-class of Cohen-Grossgerg dynamical systems.

We illustrate the previous derivation with an event-based implementation of an early-vision processing layer, for a 1D spiking neural network, correspond to an edge-preserving smoothing of the input, using a non-linear diffusion operator.

Self organizing-maps, as e.g. introduced by Kohonen, are artificial neural networks characterized by competitive learning of the processing elements. They thus can be used for the pattern analysis of input signal. Here we consider, as a working example, the self-organization of visual receptive fields, as it occurs in V1 and study to which extend using a variational approach may help specifying such a mechanism.

This formulation includes non-linear formulation of self-organizing maps as proposed by Fort and Pages, while unusual non-linear profiles allowing edge preserving smoothing, via non-linear diffusion are introduced.

The assumption is that they contribute to regularize the learning process. As such, they likely speed-up the convergence. They however constraint the solution to be taken in a more restrictive space of smoother functions. Experimental results are going to confront these assumptions to the ground truth.

A step ahead, the ``arg max'' rule itself is implemented by a winner-take-all mechanism, given an initial condition, the formulation leading to a local distributed implementation and guaranties the convergence towards a local minimum of the criterion.

This study aims at proposing an implementation of regularization mechanisms compatible with biological operators. More precisely, cortical maps code vectorial parametric quantities, computed by network of neurons.

This work is realized within the scope of a general attempt to understand parametric adaptation, regarding visual perception. The key idea is to analyze how we may use multi-model parametric estimation as a 1st step towards categorization (refer to Appendix F of Vieville et al 2000 for a discussion). More generally, the goal is to formalize how the notion of ``objects'' or ``events'' in an application may be reduced to a choice in a hierarchy of parametric models used to estimate the underlying data categorization. These mechanisms are to be linked with what occurs in the cerebral cortex where object recognition corresponds to a parametric neuronal estimation (see for instanced Page 2000 for a discussion and Freedman et al 2001 for an example regarding the primate visual cortex). We thus hope to bring here an algorithmic element in relation with the ``grand-ma'' neuron modelization. We thus revisit the problem of parameter estimation in computer vision, presented here as a simple optimization problem, considering (i) non-linear implicit measurement equations and parameter constraints, plus (ii) robust estimation in the presence of outliers and (iii) multi-model comparisons. Here, (1) a projection algorithm based on generalizations of square-root decompositions allows an efficient and numerically stable local resolution of a set of non-linear equations. On the other hand, (2) a robust estimation module of a hierarchy of non-linear models has been designed and validated. A step ahead, the software architecture of the estimation module is discussed with the goal of being integrated in reactive software environments or within applications with time constraints.

The use of impulse neural networks to solve problems of computer vision derives from the aim to bring together computer vision and biological vision. Impulse neural networks, studied in computational neurosciences, are unfortunately slow to simulate. The goal of this work is to evaluate the relevance of using modern graphics hardware to accelerate the simulation of impulse neural networks, as well in the domain of computer vision as more generally in computational neurosciences.

This stage is modelled as a dynamical shunting feedback by amacrine cells onto bipolar cells; the resulting model reproduces contrast-dependent amplitude and phase non-linearities, as measured in real mammalian retinas by Shapley and Victor 78.

The validity of the whole model has been tested by reproducing different experimental intra-cellular recordings on mammalian ganglion cells, and provides a good fit to these recordings. The contrast gain control stage (2) was found particularly mandatory to obtain this fit. Thus, "RetinaSpike" can produce reliable input to other neuronal simulators modeling visual processing in the cortex.

Implementation of spike-based synchronies between neighboring ganglion cells, as observed in real mammalian retinas. At the implementation level, such addition is straightforward, thanks to the underlying event-orientated formalism and its related software, "MvaSpike". This work was partially supported by the FACETS European Project.

Regarding biological visual classification, recent series of experiments have enlighten that data classification can be realized in the human visual cortex with latencies of about 100 ms, which, considering the visual pathways latencies, is only compatible with a very specific processing architecture, described by the so-called Thorpe model. Surprisingly enough, this experimental evidence is in coherence with algorithms derived from the statistical learning theory, following the work of Vapnik. More precisely, there is a double link: on one hand, the Vapnik theory offers tools to evaluate and analyze the Thorpe model performances and on the other hand, this model is an interesting front-end for algorithms derived from the Vapnik theory. The present contribution develops this idea and experiments its performances using a tiny sign language recognition experiment.

Our system has two main contributions. We propose a bio-inspired spiking V1 model that transforms a video sequence into spikes train according to local motion detectors. The motion detectors are directionally spatial-temporal filters properly tuned for a certain range of velocity. At the same time we propose a method to obtain a histogram map representation for the velocity distribution of V1 output. This histogram map acts as a MT-like model containing the spatial-temporal information of an event. We also propose a distance between histogram maps to realize motion categorization. In order to evaluate the performance of our approach, we ran our system in Giese database which contains 40 sequences and two actions, walk and march. The results reveal that motion categorization can be reliably estimated from the analysis of spike trains together with a coarse estimation of their spatial position.

Biological motion recognition refers to our ability to recognize a scene (motion or movement) based on the evolution of a limited number of points acquired for instance with a motion capture tool. Much work has been done in this direction showing how it is possible to recognize actions based on these points. Following the reference work of Giese and Poggio (giese-poggio:03), we propose an approach to extract such points from a video based on spiking neural networks with rank order coding. Using this estimated set of points, we verify that correct biological motion classification can be perfomed. We use some recent results of Thorpe et al.

Considering the biological or artificial control of a trajectory generation, we propose a biologically plausible model based on harmonic potentials. Such methods assume that obstacles to avoid (or constraints not to violate) correspond to maxima of the potential, while the goal corresponds to a unique minimum. The corresponding algorithm thus behaves as if one throws a sheet onto this state space, this hyper-surface relief being elevated on obstacles, with a hole at the goal location, so that finding a trajectory reduces to ``roll down'' along this relief towards the minimal height location. The originality of the present work is to build an harmonic potential (thus without local minimum) as a finite linear combination of elementary harmonic functions. The set of these components samples the border of the admissible domain bounded by obstacles or constraints. This leads to an internal representation of the problem as a non-topographical map incrementally builded during the system exploration and non-linearly linked to the real problem geometry. As such, it provides a biologically plausible quantitative model of some hippocampus mechanisms and of the related cognitive maps, in coherence with usual biological assumptions about such behavior.

The software interface also includes a visual stimulus generator corresponding to what is usually used in neuro-physiological experiments with the goal of performing future comparisons with effective experimental data.

More precisely, in computer vision, efficient computations using implementations of regularization processes allows to obtain well-defined and powerful estimations. Having a biologically plausible representation of such mechanisms is thus a challenging issue.

Reviewing recent ideas about brain activity representation, we show how the key idea is to (i) represent what is to be done as an optimization problem, (ii) considering regularization mechanisms (implemented using so-called partial-differential-equations) and (iii) ``compiling'' the related analog or spiking neural network parameters.

The basement of the present contribution is the development of an unbiased approximation of a diffusion operator used in regularization mechanisms (introducing a summation property). A direct link between continuous formulation and the related sampled implementation is obtained. It also provides convergence properties for the related network.

Not only analog networks but also deterministic spiking neural network can implement the present specifications, using here piece-wise approximations in the so called Spike Response Model, also leading to a fast event-based simulation of such networks.

This type of data is in particular illustrated by the development of plants where one usually distinguishes a phase from establishment, an adult phase corresponding to the maximum growth, and a phase of senescence. In addition, the growth of a plant is affected by environmental factors like pluviometry.

The estimate of such models, called thereafter multiphasic linear mixed models, is a difficult problem insofar as that requires to take into account two types of hidden structures:  states of Markov chain on the one hand, and random effects of the linear mixed models on the other hand.

For that, we studied iterative algorithms of type "restoration-maximization-prediction" which generalize EM and SEM algorithms, those which can be seen like simple algorithms of "restoration-maximization".

Today, developmental regularities of the aerial parts of plants are well known and extensively studied at all scales. However, developmental mechanisms of the other half of plants, of their dark side, is still pretty much incomplete.

It is indeed much more difficult to access and to observe the roots than the stem and the leaves. It is not well know if roots may exhibit regular developmental patterns, underlying regular physiological mechanisms, or if their growth is purely chaotic.

In the first one, which can be perceived as a rather practical approach, we want to gather biological data about lateral root development and to screen these data in search of developmental regularities that could be used as a base for an integrative model of lateral root development.

In order to gather the biological data needed for our first approach, we devised various protocols of experiment and observation based on the model plant Arabidopsis thaliana, with accuracy ranging from macroscopical to cellular levels. We thus obtained very complete data about the developmental sequence in the primary root and its laterals. This extensive database is currently explored via large-scale data mining methods and by others more specific exploratory analysis.

The theoretical part of our work was initiated on the basis of bibliographical data and hypothesis concerning root development. We developed a first serie of dynamic branching growth models, and began the theoretical analysis of such models. These exploitations are still being undertaken and have already allowed us to validate or dismiss a certain number of classical biological hypothesis.

These methods are based on direct measurements of position and shape of every plant organ in space. Although they provides accurate results, these methods are particularly time consuming. In this work, we design a method to reconstruct the 3D leaf density of the plant based on horizontal photographs of the plant crown and on foliage aggregation assumptions. The problem is formulated as an inverse problem were the model is based on different variants of Beer-Lamber model for light interception. This results in a large number of non-linear equations, which depends on several  structural parameters (discretization of the image, discretization of the canopy, number of "black zones" on the image, etc.).

Comparisons were made between the actual leaf foliage density of plants digitized leaf by leaf and results of our methods. They show that optimal experimental parameter can be defined depending on the type of plant crown (number of photographs, size of the image zones used for discretization, size of the voxels, ...).

Other estimators of the fractal dimension were also considered, based on the so called "two-surface" method and on mass estimators. These latter estimators are connected with the notion of lacunarity, used in fractal geometry to characterize the texture of the studied object as a function of scale. Here, we defined a notion of "centered" lacunarity that can be used to characterise the typical size of gaps at different scales in the object.

The objective of this work was to assess the effect of three possible sources of non-randomness in tree canopies on light interception properties. For this purpose, four three-dimensional (3D) digitized trees and four theoretical canopies - one random and three built from fractal rules - were used to compute canopy structure parameters and light interception, namely the sky-vault averaged STAR (Silhouette to Total Area Ratio).

STAR values were computed from (1) images of the 3-D plants, and (2) from a 3-D turbid medium model using space discretization at different scales. For all trees, departure from randomness was mainly due to the spatial variations in leaf area density within the canopy volume.

Taking into account a non-infinitely small leaf size, whose effect is theoretically to shorten self-shading, had a minor effect on STAR computations. STAR values computed from the 3-D turbid medium were very sensitive to plant lacunarity, a parameter introduced in the context of fractal studies to characterize the distribution of gaps in porous media at different scales. This study shows that 3-D turbid medium models based on space discretization are able to give correct estimation of light interception by 3-D isolated trees, provided that the 3-D grid is properly defined, that is, discretization maximizes plant lacunarity.

In several species exhibiting a rhythmic aerial growth, the existence of an alternation between root and shoot growth has been demonstrated. We investigated the respective involvement of the emergence of new organs and their elongation in this phenomenon and its possible genotypic variation in young apple plants. We proposed a biological model of dynamics that summarises the interactions between processes and includes the assumption of a feedback effect of lateral root emergence on leaf emergence.

The objective of this study is to model the changes in growth unit branching structures during tree ontogeny. A single statistical model was estimated from around 700 branching sequences measured on two six-year-old apple trees, cultivar "Fuji". This statistical model is a hidden semi-Markov chain were the underlying semi-Markov chain represents the succession and the lengths of branching zones along the growth units while the observation distributions represent the branching type composition within each zone. The main output of this study is to show that while the succession and the lengths of branching zones change during ontogeny, the compositions of branching zones remain unchanged.

Plant architecture is the result of repetitions that occur throughout growth and branching processes. During plant ontogeny, changes in the morphological characteristics of plant entities such as growth units or annual shoots, are interpreted as the indirect effect of the meristems being in different physiological states. Thus, connected entities can exhibit either similar or very contrasted characteristics. We design a statistical model to reveal and characterise homogeneous zones and transitions between zones within tree-structured data: the hidden Markov tree (HMT) model. This model leads to a clustering of the entities into classes sharing a same "physiological state".

We are investigating multitype branching processes with dependences as a new analysis tool for plant structures. This research theme is closely connected to the preceding one concerning hidden Markov tree models since, in most cases, the types are the states restored for each entity using a previously estimated hidden Markov tree model. Our objective is twofold: First, we are testing various sub-families of branching processes (with different parameterizations and dependencies) using a set of reference data sets in order to determine the most useful ones. Second, branching processes focus on an unusual way of studying plant development and this generates new biological questions concerning the rules governing the generation of offspring entities from a parent entity.

Self-similarity of plants has attracted the attention of biologists for at least 50 years, yet its formal treatment is rare, and no measure for quantifying the degree of self-similarity currently exists. In this work, we introduce a formal definition and measures of self-similarity, tailored to branching plant structures. To evaluate self-similarity, we make use of an algorithm for computing topological distances between branching systems, developed in computer science. The formalism was illustrated using theoretical branching systems, and applied to analyze self-similarity in two sample plant structures: inflorescences of Syringa vulgaris (lilac) and shoots of Oryza sativa (rice).

In the classical approach, the problem of formulating lumpability hypotheses for a Markov chain can be viewed as the determination of an appropriate state space (smaller than the original state space) such that the lumped chain defined on this state space retains the Markov property. We propose a different perspective on lumpability where the state space is fixed and the partitioning of this state space is represented by a one-to-many probabilistic function within a two-level stochastic process. Three nested classes of lumped processes can be defined in this way as sub-classes of first-order Markov chains. These lumped processes enable parsimonious reparameterizations of Markov chains that help to reveal relevant partitions of the state space. Characterizations of the lumped processes on the original transition probability matrix are derived. Different model selection methods relying either on hypothesis testing or on penalized log-likelihood criteria are investigated and extensions to lumped processes constructed from high-order Markov chains are proposed. These lumped processes enable to highlight differences between intronic sequences and gene untranslated region sequences in human DNA sequences.

The elongation of leafy axes is influenced by environmental conditions such as for instance rainfall. In the context of plant growth follow-up, measurement is made of the number of newly elongated leaves during successive observation periods. These count data are often underdispersed with reference to the Poisson distribution. Incorporating the rainfall covariate within a statistical model requires to take into account both the delayed response of the plant to a water stress and the difference in time step between the rainfall covariate (daily data) and the plant response (observation period of several days). Statistical models studied for analysing these longitudinal count data belong to the classes of generalized linear mixed models.

The observed growth as given for instance by the lengths of successive annual shoots along a tree trunks is mainly the results of two components: an ontongenic component and an climatic component. An open question is whether the ontogenic component along an axis at the growth unit or annual shoot scale takes the form of a trend or of a succession of phases.

Various methods of analysis ranging from exploratory analysis (symmetric smoothing filters, sample auctocorrelation functions) to statistical modeling (change-point detection models, hidden semi-Markov chains and hidden hybrid model combining Markovian and semi-Markovian states) were applied to extract and characterized the ontogenic growth component. This has led us to highlight phase changes in unexpected situations (for instance in the decreasing growth phase).

Incorporating both the influence of explanatory variables and inter-individual heterogeneity in a hidden Markovian model is a challenging problem. We are studying Markov switching linear mixed models, i.e. models that combine linear mixed models in a Markovian manner. The underlying Markov chain represents the succession of growth phases while the linear mixed models attached to each state of the Markov chain represent both the trend, the influence of the explanatory variables (mainly climatic variables which are time-dependent explanatory variables measured at a scale different from the scale of the plant response) and the inter-individual heterogeneity within a given growth phase. The EM algorithm cannot be applied for estimating Markov switching linear mixed models. As an alternative to the EM algorithm, we are studying iterative algorithms which decompose in three steps: restoration, maximization and prediction. The restoration step can be viewed as a Markovian restoration step (restoration of the state sequences) while the prediction step can be viewed as a restoration step for the linear mixed models (restoration of the random effects).

Plant development is controlled by the combined effect of gene activity and environmental constraints. At a given date, a plant architecture is thus the outcome of this combination. The question of identifying the genetic and environmental components of plant development can be addressed by studying the heritability of architectural traits. We started to investigate this issue in the context of two agronomic applications, respectively on coffee and apple tree. In these studies, architectural parameters were used to predict target traits for breeding programs: (i) yield capacity for coffee trees; (ii) adequate forms for an easy and low cost training in the field and regular bearing behaviour, for apple trees. Observation protocols for describing the architecture were applied to six clones of Coffea canephora in a comparative trial on the one hand, and on an apple progeny whose parents were chosen for their contrasted architecture, on another hand. Architectural traits, including both topological and geometric traits, were collected at different scales (trees, branching systems, axes and nodes) and were included in architectural databases which were explored using the V-Plants software (formely AMAPmod). Several traits exhibited high heritability values, for instance branching, internode length and branch orientation in apple tree. In the case of coffee tree, some of the traits displayed strong genetic correlations with cumulated yield over two cycles (14 years). In the apple tree progeny, since a genetic map was built in UMR GenHort in Angers, correlations between the phenotypic variation of a given trait and allelic variations observed in the population are currently under investigation to seek for quantitative trait loci (QTL).

This protocol uses both classical techniques from image processing (topological closure, watersheds) and specially designed algorithms, in particular to automate the detection of cell lineage throughout time in temporal series corresponding to meristem development. These tools were integrated the software platform ALEA for plant modelling and analysis and are freely available for the scientific community.

The active transport of the plant hormone auxin plays a major role in the initiation of organs at the shoot apex. Polar localized membrane proteins of the PIN1 family facilitate this transport and recent observations suggest that auxin maxima created by these proteins are at the basis of organ initiation. This hypothesis is based on the visual, qualitative characterization of the complex distribution patterns of the PIN1 protein in Arabidopsis. To take these analyzes further, we investigated the properties of the patterns using computational modeling and extensive sensitivity analysis of the model.

We integrated the previous results (organization of the PIN transporters, auxin fluxes, accumulation of auxin in the meristem center) in a dynamic model of the meristem development. The meristem structure is represented by a Voronoi diagram and the changes over time of the meristem structure were described using declarative rules using the \emph{MGS} language (language dedicated to the modeling of dynamic systems with dynamic structures (DS)2, developed at the University of Evry by J.L. Giavitto and O. Michel). The complete model relies on i) a model of cell growth and division, ii) a spring-mass description of the mechanical interaction between cells, iii) a magnetic polarisation of PIN transporters towards the primordia and the center iv) assumptions for auxin transport identical to the static case.

Based on these models and assumptions, we showed that phyllotactic patterns emerge from cell growth and cell-cell interactions \cite{barbier05}. This cell-centered model is a first step towards the development of a 3D mechanical and dynamic model of the Arabidopsis meristem based on cell-cell interaction.

Arabidopsis thaliana. As in the case of primordia initiation of the shoot apical meristem, auxin plays a crucial role in root initiation. Organ initiation is correlated to high concentrations of auxin. However, in both systems, organ initiation is very different. In particular, in the root development, lateral organs initiation is observed at a long distance from the root meristem, with no apparent spatial or temporal structure. Our main assumption is that this system is governed by a mechanism of competition for auxin while the root system is developing. To understand this complex dynamic interaction, we develop a sink-source dynamic model of the root system development in which the transport of auxin is controlled by active carriers of the PIN family (a first prototype has been developed using L-Systems).  First experimental protocols were carried out on Arabidopsis thaliana, with accuracy ranging from macroscopic to cellular levels. We obtained complete data about the developmental sequence in the primary root and its laterals. This extensive database is explored using tools for sequence analysis (distance between sequences, different types of Markovian models). First results show structures and correlations between positions and stages of development of lateral organs which can now be exploited for the design of the dynamical model.

Methodological and software support in design management of adaptive Web sites (viewed as complex systems), i.e. for supporting viewpoint management and the redesign of such Web sites/services based on an usage analysis. This topic uses the results of the first two ones.

We start to study mainly Web sites offering a big quantity of information and to which the need of a service supporting information retrieval is relevant: for example, thematic repertory/portal, institutionnal site.

The ASTHMA european project aims at building an integrated, multi-disciplinary system in order to provide near real time accurate information on aeroallergens and air quality to the sensitive users on an individual basis and at specific locations to help them in optimising their medication and improve their quality of life.

In order to provide an accurate near-real time information to the end-users, the forecast computation must rely on near real-time pollen concentration measurements. At current date, several days may separate the measurements and the pollen count task. The accuracy requested by the forecast system may lead to an increase of the measurements sites and a decrease of this time. This implies the processing of more measurements and therefore the training of more technicians for the pollen analysis. To reduce the inherent cost of such improvement, it is necessary to investigate towards an automated processing of the measurements as well as to help in the training of the technicians.

A semi-automatic system for pollen recognition is studied for this task. The goal of such a system is to provide accurate pollen concentration measurements.  This information can be used as well by the palynologists, the clinicians or a forecast system to predict pollen dispersion.

PEGASE+ is an engine dedicated to program supervision knowledge-based systems, which can automate the choice and execution of programs from a library to accomplish a processing objective. The Pegase+ engine provides a HTN (hierarchical-task network) planner, an execution module, some evaluation facilities and a repair mechanism using repair and adjustment criteria. It works as a trial and error mechanism until the results are correct.

Instead of developing each system from scratch, we design engines, independent rom specific applications, but yet dedicated to the particular task of program supervision. A program supervision environment, provided by a software platform (named Lama) is used by a specialist of a library of programs to build a knowledge base.

The result (obtained by the integration of the engine plus the knowledge base plus the library of programs) is a knowledge-based system for program supervision which can be utilised by an end-user to run an application.

The Pegase+ engine provides a HTN (hierarchical-task network) planner, an execution module, some evaluation facilities and a repair mechanism using repair and adjustment criteria. It works as a trial and error mechanism until the results are correct.

A knowledge base for Pegase+ mainly contains operators which are representations of programs (with descriptions of their data and parameters) and of typical combinations of programs, as well as criteria to guide the reasoning process. The criteria are implemented in Pegase+ by specialised rule bases which are local to operators.

Experts can express their knowledge at the expertise level, guided by a supervision-oriented description language named Yakl.This language is used both as a common storage format for knowledge bases and as a human readable format for writing and consulting knowledge bases. It allows experts to express all the different types of knowledge involved in program supervision.

Pegase+ engine uses a hierarchical planning technique for its construction phase. A program supervision hierarchical planner works on a hierarchy representing abstraction levels between operators (abstract/composite and real/primitive ones). A hierarchical planner first constructs an abstract plan, then refines it for a particular situation. Hierarchical planning is preferred in program supervision, mainly because the expert often thinks in terms of abstract plan schemes.

Given a user's request and a knowledge base, the engine develops an execution plan\index{plan}, which correspond to the successive expansions of composite operators and execution of primitive ones. In fact it develops several tentative plans, some of them may be aborted, due to problems detected during reasoning. The solution plan, if it exists, is produced as a result of program supervision, as well as the output data.

These are the KBUP home pages, on which we collect all useful information concerning knowledge based (re)use of program libraries. The pages are under construction, and far from being complete. Send us your WWW addresses and comments on these pages by email to kbup@sophia.inria.fr.

KBUP consists of the management of libraries containing a large number of programs. This problem is interesting in two cases: first to facilitate the development by a programmer of new code based on existing components, second to allow a non-specialist to optimize the use of an existing program library.

Many different libraries of programs have been developed in very different domains. The programs are written by specialists, and it is usually very hard to (re)use them. Knowledge based techniques can be used for the management of the programs in different working environments. KBUP systems can range from an advisory guide up to fully automatic systems.

Our goal is to develop novel algorithms to improve the speed and quality of computer-generated images and spatialized audio, as well as that of virtual and augmented environments. We are specifically interested in the interaction between the two media, since it is well established that the sense of immersion and presence is greatly enhanced in virtual environments when combining them.

"plausible rendering" approaches, for both images and sound, which are typically approximate but efficient techniques. We also develop algorithms for slower, but accurate rendering approaches, which are often based on simulation of the underlying physical phenomena. Developing smooth transitions between the two extremes is an important concern in our research.

We develop relighting methods which allow us to virtually change lighting conditions, striving to make them efficient and usable. We also investigate how to enrich 3D scenes with sound, and appropriate representations to improve interaction in these environments.

We also introduced a fully scalable pipeline for real-time processing of massive numbers of signals using our masking algorithm and a calculated importance value of the various sound streams [TSI05, GLT05].

This paper presents an interactive watercolor rendering technique that recreates the specific visual effects of lavis watercolor. Our method allows the user to easily process images and 3d models and is organized in two steps: an abstraction step that recreates the uniform color regions of watercolor and an effect step that filters the resulting abstracted image to obtain watercolor-like images. In the case of 3d environments we also propose methods to produce temporally coherent animations that keep a uniform pigment repartition while avoiding the shower door effect.

Sophia-Antipolis. My research interests are in rendering for computer graphics. My recent work is on shadows, lighting, relighting, reconstruction from images and interactive rendering. My responsibilities include managing the group, supervising graduate students and coordinating/managing research projects.

My current research interests are focused on simulating virtual sound fields for interactive applications and computer graphics rendering simulations. I am thus interested in virtual acoustics but also in geometrical techniques used in computer graphics for global illumination problems.

The model allows hierarchical access to the visibility and radiometric information of any number of primitives represented in a LDI. This representation is used to speed-up ray-intersection tests and also carries radiometric information in a manner similar to a 'photon map'.

Click on the pictures for more details on Beam Tracing for Acoustics, Geometrical Theory of Diffraction and Monte-Carlo techniques in the context of interactive acoustics simulations and computer graphics.

We present a system for sketching in 3D, which strives to preserve the degree of expression, imagination, and simplicity of use achieved by 2D drawing. Our system directly uses user-drawn strokes to infer the sketches representing the same scene from different viewpoints, rather than attempting to reconstruct a 3D model. This is achieved by interpreting strokes as indications of a local surface silhouette or contour. Strokes thus deform and disappear progressively as we move away from the original viewpoint. They may be occluded by objects indicated by other strokes, or, in contrast, be drawn above such objects. The user draws on a plane which can be positioned explicitly or relative to other objects or strokes in the sketch. Our system is interactive, since we use fast algorithms and graphics hardware for rendering. We present applications to education, design, architecture and fashion, where 3D sketches can be used alone or as an annotation of an existing 3D model.

We present a new sampling method for procedural and complex geometries, which allows interactive point-based modeling and rendering of such scenes. For a variety of scenes, object-space point sets can be generated rapidly, resulting in a sufficiently dense sampling of the final image. We present an integrated approach that exploits the simplicity of the point primitive. For procedural objects a hierarchical sampling scheme is presented that adapts sample densities locally according to the projected size in the image. Dynamic procedural objects and interactive user manipulation thus become possible. The same scheme is also applied to on-the-fly generation and rendering of terrains, and enables the use of an efficient occlusion culling algorithm.

Objects are presented by a point set. Each point consists of its 3D-coordinates, its normal and material properties. By adapting point densities, a very fine level-of-detail control is possible. The following left image shows a small forest of 30 trees. For each tree, we gemerated a random set of sample points, where the number of samples depends on the tree's image size. The shown image was generated from 200.000 points only, rendered with the standard OpenGL GL_POINT primitive at 28 frames per second The right figure shows a side view of the sample set generated for the displayed viewing frustum.

The powerful level-of-detail of the point sets can also be used for dynamic objects. For the following objects, we simulated movement of the trees in a turbulent breeze, by moving the single points according to the local wind and the point's distance to the stem. We still obtain 20 frames per second.

This simple example shows the power of point representations: Visually complex objects can be rendered and modified interactively, with only little precomputation and memory requirements. By adapting the point number (and the point size accordingly), frame rate constraints can easily be met.

The advantages for rendering also apply to many other problems related to interactive applications and computer games, like dynamics computations, collision detection, visibility determination etc., where the required accuracy mainly depends on the distance to the user(s). Furthermore, as we will show in the following, points are very efficient with procedural models. All changes to a virtual world that cannot be precomputed because they happen due to user input (impacts or bullet holes on a wall, deformed objects, interactively modelled objects, ripples in a lake created by the user, see application scenario section), are usually described procedurally, with user interactions as parameters. Transforming this procedural description to an appropriate polygonal representation, e.g. for rendering, can be difficult. We believe that points are often a better means in these cases.

Of course points are not always the best solution. Big rectangles should remain rectangles and it will take a long time before home computers are fast enough so that all image textures can be replaced by "real" texture geometry. However, points are obviously a good means whenever triangles become smaller than a pixel. It does not really make sense to render triangles of subpixel size, and in particular not at 50 Hz.

In this context the analogy to ray tracing is interesting: even an oversampling ray tracer can only sample a few triangles per pixel. That's why for very complex scenes ray tracing becomes faster than scanline rendering. It is very fast to ray trace a scene with 100,000,000 triangles if 99,999,990 of them are within a single pixel, whereas each scan-line renderer will spend all its time on this one particular pixel. For the remaining pixels, however, scanline rendering will be ways faster. Point-based rendering is in between. It uses sample sets with a density fitting to image resolution like ray tracing, but it projects object points from world to image space like scanline renderer, so it does not require the costly ray casting operations.

Virtual reality applications can well benefit from the capabilities of point based rendering. We applied the technique to an active stereo viewing system. By this, interactive stereo viewing of scenes initially described by more than a million small polygons becomes possible with standard PC hardware. Note that with standard VR installations like a CAVE usually not more than 50.000 triangles can be displayed at sufficient rates (on multiple screens, though). In our subjective experiments, the point representations did not lead to decreased stereo perception.

First, they offer very simple level-of-detail control, so the costly surface sample generation can be restricted to a minimum. Second, the lack of topology allows easy adaptive refinement. In the example shown in the following image, we started by a uniform point set representing a rectangle and applied a procedural displacement. Due to the displacement and perspective distortions, holes appear (left half image). Simple local considerations allow to predict holes in the image neighborhood of a sample, which are then filled by recursively inserting additional samples (right half image).

The lack of topology information in point sets makes interesting geometric modifications possible. Wa can add a "point filter" that gets points as input and displaces them, discards them or even generates several new points.

Consider the examples below: the rock on the left is a sphere with a displacement modifier applied. The object in the center is obtained from a sphere, with a Holes-modifier that discards points in holes defined by a noise function and that displaces points near the holes' boundary. The basket on the right is obtained from a truncated cone. According to the position within the wickerwork, zero, one or two displaced points are generated per input point.

As discussed above, procedural object descriptions are essential for all applications that allow user interaction. One can think of many examples, from users modelling objects in a virtual reality environment to players shooting holes into walls.

Point sampling can also be applied to infinte objects like terrains. We consider terrains defined by a procedural displacement of the infinite base plane z=0 We define a paramerization of the visible sector of the base plane, that is dense close to the viewer and becomes coarser towards the horizon. An initial point set on the base plane is created according to this parameterization and the points are displaced. Using local considerations (which require the terrain gradient in a point), undersampling in the region around a point can be predicted. We avoid holes by adaptively inserting additional samples using the sqrt5-scheme in undersampled regions. Additionally, our approach makes occlusion culling simple: by rendering from front to back we can predict base plane points that will be hidden, so that their elevation does not have to be computed. The following figure shows an example terrain rendered with only 30.000 points. This allows rendering the terrain at about 8 frames per second, where by far most time is spent on the terrain elevation computation. Taking the elevation values from a precomputed height field texture makes the rendering significantly faster. Since all elevations are recomputed per frame, the procedural terrain parameters can be changed on the fly. No computation time or memory is spent for precomputations.

The image on the right shows the same point set used for the left image from another perspective. Note the decreasing sampling density towards the horizon and the large unsampled regions detected by occlusion culling.

Consider as example clouds,represented by a procedural density distribution defined by a 3D turbulent noise function. We generate random sample points in the volume and compute the density at the point. We then render the points with a transparency accordintg to the point's density. With a z-buffer renderer like OpenGL this requires to sort the points from back to front.

Shadows are a visually essential lighting detail. Obtaining shadows, however, is usually costly, in particular for dynamic scenes, when shadows change constantly so that no precomputation is possible. A typical approximation for dynamic scenes are thus faked shadows, strongly simplified shadows that are for example drawn on the floor somewhere under the player. This needs to be done for all objects that should cast a shadow, and it becomes difficult if the player is not moving on plane floor. A much more general approach that allows interactive rendering are shadow maps, where the scene is rendered in a first pass from the view of a light source. All points visible in that view are lit. Such shadow maps can be applied to rendered objects using texturing capabilities of modern graphics hardware.

Shadow maps are well known for aliasing artifacts. In particular in large outdoor scenes, close shadows will show severe pixelization artifacts; the shadow map resolution will be too small for nearby objects and too high for distant objects. We solve this perspective aliasing problem by computing the shadow map in post-perspective space. That is, we first transform the content of the viewing frustum using the current camera and projection transformations to the unit cube [-1,1]^3. The final image is a parallel projection of this post-perspective space along the z-axis. All objects in post-perspective space are as big as they will be in the final image. So if we generate a standard shadow map in this post-perspective space, perspective aliasing is reduced, if not avoided. Note that since all involved transformations can be represented by a 4x4-Matrix, also their product can, i.e. perspective shadow maps are fully supported by graphics hardware. The only difference to uniform shadow maps is that since the perspective shadow map is view dependent it needs to be regenerated when the camera moves. So it is a two pass method, whereas for uniform shadow maps of static scenes one pass suffices. For dynamic scenes, perspective shadow maps only have a minimal overhead for the slightly more complex shadow map projection matrix computation.

The ideal case is depicted in the following image. The viewing frustum (left) becomes a cube in post-perspective space (right). When projecting the shadow map pixels on the ground and then on the image, they all exhibit the same image size, so we have a perfect match between image and shadow map resolution for the ground.

Note that this is the ideal case, because the parallel light source remains parallel in post-perspective space. In general, parallel light sources can become point lights in post perspective space and vice versa. Other possible case for parallel light sources are depicted in the following image. Light sources from the front or the back become point lights on the infinity plane in post-perspective space, where the depth ordering is reversed in the letter case.

An example for a point (spot) light source is shown in the following images. The upper row shows the light source view for a uniform shadow map (left), its depth buffer (center) and the resulting view (right) with strong aliasing artifacts. The lower row shows the same for our non-uniform shadow map.

We present a new algorithm which chooses between reconstructing specular effects such as caustics on the diffuse radiosity mesh, or special purpose caustic textures, when high frequencies are present.

Since 2000 he has been in charge of the Master program on Networking and Distributed Systems at the University of Nice Sophia Antipolis, France. For over twenty years he has been teaching courses in modeling and performance evaluation of discrete-event systems and in operations research in various graduate schools.

Free University at Amsterdam: I was a lecturer in two courses: the first (with Ger Koole), entitled Optimization of Business Processes, concerned yield management and inventory theory, and the second dealt with Performance Analysis of Communications Networks. Both courses were in english. I was also in charge of correcting the homeworks in both courses.

The wireless channel seems to be a scarce common resource which poses challenging problems not encountered in wireline networks. Both probabilistic models as well as control theory can be quite useful in the physical and in the link layers of wireless networks. The characteristics of wireless links have also an impact on higher network layers and transport protocols which we study.

Different agents might typically have different objectives. The theoretical framework for analysing this situation is game theory, and several optimality concepts (Nash equilibrium, Wardrop Equilibrium) are required. We have been working on games that occur both in routing as well as in flow control.

Many systems subject to frequent unpredictable structural changes can be adequately modelled as piecewise deterministic systems, where the system dynamics takes on different forms depending on the value of an associated Markov  process, which is known as form or indicant process associated with the controlled systems. In the linear case, these systems are also known as jump linear system. Such a system model is useful particularly since it allows the decision maker to cope adequately with the discrete events that disrupt and/or change significantly the normal operation of a system by using the knowledge of their occurrence and the statistical information on the rate at which these events take place. We are interested in situations of stochastic control with more than one controller and Markov jump parameters change much faster than the continuous time part. The objective of the controllers might be different, which leads to the framework of stochastic games, or  might be same, which leads to the framework of stochastic teams.

Multicast allows an application to efficiently send data from one user to many other users. Hence, multicast enables the Internet to be used for a wide variety of applications that depend on group communication, such as large-scale video-conferencing, transmitting stock market updates, and even television broadcasts. My research in this area is to study the multicast routing in Ad-Hoc wireless networks.

Since its inception in late 1970s, cellular mobile communication technology evolves, shortly in two decades, from its first generation to its second generation employing digital voice transmission.  It is now at the transition to its 3rd generation (3G), which will employ wideband CDMA technology and provide multimedia services.

This course aims to provide an advanced discussion on mobile communication systems, Mobile Communications. This course will provide in-depth discussions on several selected areas, namely, error control methods, antenna diversity techniques and capacity comparisons of various systems, which are of particular importance in the current and future mobile systems.

The aim of this course is to provide performance evaluation and designs of telecommunication networks under required Quality of Service guarantee. Special emphasizes will be made on Internet (TCP/IP) based networks. The course will contain a brief review of important probability concepts. Basic ideas from queueing theory will be presented such as single server and multiple server systems. Queueing networks will be studied using analytic, computational and approximate methods. Special models involving Markov-modulated and fluid flow inputs will be discussed. Numerous applications will be presented such as TCP protocol   and computer networks.

The motivation for BIONETS comes from emerging trends towards pervasive computing and communication environments, where myriads of networked devices with very different features will enhance our five senses, our communication and tool manipulation capabilities.

Traditional communication approaches are ineffective in this context, since they fail to address several new features: a huge number of nodes including low-cost sensing/identifying devices, a wide heterogeneity in node capabilities, high node mobility, the management complexity, the possibility of exploiting spare node resources. BIONETS aims at a novel approach able to address these challenges.

ERS is a package under development. It is made available to researchers interested in Discrete Event Systems in order to obtain feedback on (possible) bugs, suggestions for improvements, and even contributions in the form of code improvements or additional tools.

It comprises a generator of Web traffic, tools for statistical analysis and a monitoring tool. It can generate different types of traffic requests, which, in turn, can be sent out to the server from different client machines with different (simulated) propagation delays and bandwidths.

Concurrent programming is the use of several programs, running together in the same application.  It is opposed to traditional sequential programming, in which there is one unique program, which thus coincides with the whole application.  Concurrent programming is usually considered to increase modularity, as one can often naturally decompose a complex application in several cooperating programs which can be run concurrently. This is for example the case of servers in which each user request can quite logically be mapped to a specific program processing it. With concurrent programming there is no more need to code a complex application made of many distinct parts in one single program, as it is the case in sequential programming.

There are two main variants of concurrent programming: the one in which the programs, called threads, are sharing a common memory; and the one in which programs are basically processes which have their own memory. The presence of a shared memory eases communication between threads, as threads can directly use shared data to communicate, while processes have to use specialized means, for example sockets, for the same purpose. But, the counterpart is that shared data may have to be protected from concurrent accesses from distinct threads. Of course, this is not necessary with processes in which, by definition, data are fully protected from being accessed by other processes.

Parallelism is the possibility to simultaneously use several computing resources.  It is available with multiprocessor machines, or more generally, when several machines are distributed over a network.  It is well-known that parallelism is not the best solution in all cases, and there are systems which are more efficiently run by a single processor machine than by a multiprocessor one.  Parallelism is now directly available, with no special effort, in standard OS such as Linux which can operate hardware mapped on Symmetric Multi-Processor (SMP) architectures.  Parallelism appears quite natural in concurrent programming, as generally there is no logical need that concurrent programs should be run by one unique processor.

Concurrent programming is largely recognized as being, in the general case, much more difficult than sequential programming. Some problems, such as deadlocks, are specific to it. Moreover, concurrent programs are most of the time nondeterministic, and thus more difficult to debug. For these reasons, concurrent programming is often considered as an activity which must be left to specialists. This seems of course largely justified in domains such as the programming of OS kernels. But the question remains of designing a set of concurrent primitives that can be not too difficult or painful to use, and to provide general users with it.

Most of the time, programming languages do no offer any primitive for concurrent programming. This is the case of C and C++, in which concurrent programming is only available using system calls (for example fork or exec) or through libraries of threads (for example, the pthread library). Parallelism is also most of the time uncovered by programming languages primitives. The way to benefit from parallelism is either to use threads in a SMP context, or to design distributed systems where programs (often considered as distributed objects) communicate and synchronize through the network.

Amongst the languages that have primitives to deal with concurrency, some use message passing such as Erlang, others propose "rendez-vous" such as Ada and Occam, and several, as CAML, directly include threads.

Java[8] in which threads are first-class objects and data can be protected using locks and monitors, as defined by E.W. Dijkstra in the sixties (see [14] for reference papers on concurrent programming). In Java, threads are supposed to be used in almost every context (the simplest applet involves several threads, one of them being for example dedicated to graphics). However, Java does not give particular means to ease thread programming, which remains difficult and error-prone (see [23] for a discussion on this point).  Concerning parallelism, Java proposes the RMI mechanism to define distributed objects, methods of which can be invoked through the network.  Remote method invocations basically use specialized threads dedicated to communications.

Synchronous languages[19] propose concurrent programming primitives in the special context of reactive systems[20]. In this context, which is roughly the one of embedded systems, concurrent programs are deterministic and can be formally verified. However, synchronous languages suffer several limitations which limit their use.  Amongst these is the limitation to static systems, in which the number of concurrent programs is known at compile time, and to mono-processor architectures.

In this text, one proposes a language for concurrent programming inspired by the reactive approach and based on special threads, called fair threads. One major point is that the language contains primitives that allows multiprocessing. The rest of the section considers threads and presents the basics of the language proposal.

In sequential programming, a program is basically a list of instructions run by the processor. The program has access to the memory in which it can read and write data. Amongst the instructions are tests and jumps which are the way to control the execution flow. In this standard computing model, a program-counter points to the current instruction executed by the processor.

The model of threads extends the previous sequential model by allowing the presence of several programs, the threads, sharing the same memory. There are thus several program counters, one by thread, and a new component, the scheduler, which is in charge of dispatching the processors to the threads. The transfer of a processor from one thread to another is called a context-switch, because it implies that the program-counter of the thread which is left must be saved, in order to be restored later, when the thread will regain the processor.  When several threads can be executed, the scheduler can choose arbitrarily between them, depending on implementation details, and it is thus generally unpredictable to determine which one will finally get the processor. This is a source of nondeterminism in multi-threaded programming.

The strategy of the scheduler is said to be preemptive when it is able to force a running thread to release a processor executing it, in which case one says that the thread is preempted.  With a preemptive scheduler, situations where a non-cooperative thread prevents the others from any execution, are not possible. A preemptive scheduler can withdraw a processor from a running thread because of priority reasons (there exist threads with higher priorities in the system), or for other reasons. This is also a source of nondeterminism.  In a preemptive context, to communicate or to synchronize generally implies the need to protect some shared data involved in the communication or in the synchronization. Locks are often used for this purpose, but they have a cost and are error-prone as they introduce possibilities of deadlocks, that are situations where two threads cannot progress because each one owns a lock needed by the other.

Preemptive threads are generally considered to be well adapted for systems made of heavy-computing tasks and needing few communications and synchronizations.  This is typically the case of Web servers, in which a thread (usually picked out from a pool of available threads) is associated to each new user request. Advantages are clear: first, modularity is increased, because requests do not have to be split in several small parts, as it would be the case with sequential programming. Second, servers can be run by multiprocessor machines without any change, and for example they can immediately benefit from SMP architectures. Finally, blocking I/Os, for example reading from a file, do not need special attention. Indeed, as the scheduler is preemptive, there is no risk that a thread blocked forever on an I/O operation will also block the rest of the system.

The strategy of the scheduler is said to be cooperative if the scheduler has no way to force a thread to release the processor it owns. With this strategy, a running thread must cooperate and release by itself the processor from time to time, in order to let the other threads the possibility to get it. Cooperation is of course absolutely mandatory if there is only one processor: a running thread which would never release the processor would indeed forbid any further execution of the other threads. Cooperative threads, sometimes called green-threads, are threads that are supposed to run under the control of a cooperative scheduler.  Cooperative threads are adapted for tasks that need a lot of communications between them. Indeed, data protection is no more needed, and one can thus avoid to use locks. Cooperative threads can be efficiently implemented at user level, but they cannot benefit from multiprocessor machines. Moreover, they need special means to deal with blocking I/O. Thus, purely cooperative threads are not sufficient to implement important applications such as servers.

It is often claimed that reuse of sequential code is made easier by using threads. What is meant is that a sequential program can be easily embedded in one thread, and then added into a system to be run concurrently with the others programs present in it.

However, one generally cannot be sure that a sequential program never enters a loop in which actions leading to releasing the processor, such as I/Os, will never be performed. In a cooperative scheduler, such a non-cooperative program would block the whole system (supposing that the processor is unique). In a way, this is a major justification for preemptive scheduling: a non-cooperating program is no more a problem because it can now be preempted by the scheduler.

This is however only one aspect of the problem, because a sequential program cannot generally be used directly as it, even in a preemptive context.  The first reason is that some data may have to be protected from being accessed by other threads, which needs locks which were of course absent in the sequential code. A second reason is that in some cases, for example libraries, the sequential code must be made reentrant, because several threads can now make concurrent calls to it. Finally, the granularity of the execution, which is under control of the scheduler and only of it, can be too large and can need the introduction in the initial code of supplementary cooperation points.

In the larger sense, portability means that a system should run in the same way, independently of the scheduling strategy. This is of course a quite impossible challenge in the general case: data should be protected, for the case of a preemptive scheduling, but cooperation points should also be introduced, for the case of a cooperative scheduling, and the conjunction of these two requirements would lead to very inefficient code. Portability is, thus, often considered as a goal that can only be partially achieved with multi-threaded systems. Note that this is a major problem in Java which claims to be portable but does not specify the scheduling strategy that should be used for multi-threaded applications.

The choices made by the scheduler are a major source of nondeterminism which make thread programming complex. In particular, debugging is more difficult than in sequential programming because one may have to take in account the choices of the scheduler when tracking a bug. Moreover, the replay of a faulty situation may be difficult to achieve, as it may actually depend on the scheduler choices. For example, it may happens that the introduction of printing instructions to trace an execution change the scheduling and makes the bug disappear.

Nondeterminism seems inherent to preemption as it is very difficult to conceive a multi-threading framework both deterministic and preemptive. For the reader who is not convinced, imagine two threads running in a preemptive context, one which cyclically increments a counter, and one which prints the value of the same counter. What should be the (unique, because of the determinism) printed value and how can one simply find it?

However, it should be noticed that it is possible to design completely deterministic frameworks based on cooperative threads, with clear and simple semantics. This is actually the case of fair threads which are introduced later.

First, as any standard sequential program, each thread needs a private memory stack to hold its local variables and the parameters and intermediate results of executed procedures. The use of a stack is actually mandatory in the context of a preemptive scheduler, because the moments context-switches occur are independent of the thread, which has thus no possibility to save its local data before the release of the processor. Note that the situation is different in a cooperative context, where context-switches are predictable.  The necessity of a private stack for each thread certainly contributes to waste memory.

Second, user threads are often mapped to kernel threads which are under supervision of the OS. Of course, this is only meaningful with a preemptive OS, in order to avoid the risk of freezing the whole machine when a non-cooperative thread is encountered. The need to perform context-switches at kernel level is generally costly in CPU cycles. An other problem that can occur with kernel threads is the limitation which generally exists on the number of such threads (typically, the number of allowed threads can vary on a Linux system from 256 to about 4 thousands). Several techniques can be used to bypass these problems, specially when large numbers of short-lived components are needed. Among these techniques are thread-pooling, to limit the number of created threads, and the decomposition of tasks in small pieces of code, sometimes called "chores" or "chunks", which can be executed in a simpler way than threads are.

Preemptive threads (threads designed to be run by a preemptive scheduler) are also subject to an other problem: some unnecessary context-switches can occur which are time consuming.  Actually, threads have no way at all to prevent a context-switch.  Unnecessary context-switches causes a loss of efficiency, but this is of course the price to pay for preemptive scheduling.

Actually, programming with threads is difficult because threads generally have very "loose" semantics, which strongly depend on the scheduling strategy in use. This is particularly true with preemptive threads. Moreover, the semantics of threads may also depends on many others aspects, for example, the way priorities of threads are mapped at the kernel level.  As a consequence, portability of multi-threaded systems is very hard to achieve. Moreover, multi-threaded systems are most of the time nondeterministic which makes debugging difficult.

Cooperative threads have several advantages over preemptive ones: it is possible to give them a precise and simple semantics, which integrates the semantics of the scheduler. They can be implemented very efficiently. They lead to a simple programming approach, which limits the needs of protecting data. However, purely cooperative systems are not usable as it, and preemption facilities have to be provided in a way or an other. The question is thus to define a framework providing both cooperative and preemptive threads, and allowing programmers to use these two kinds of threads, according to their needs.

There exist instants shared by all the threads linked to the same scheduler. Thus, all threads linked to the same scheduler execute at the same pace, and there is an automatic synchronization at the end of each instant.

Threads. This API mixes threads with the reactive approach, by introducing instants and broadcast events in the context of threads. Loft can be implemented in a very direct way by a translation into FairThreads (this implementation is described in section Implementation in FairThreads7.1).

Section The Language LOFT2 contains the description of the language. First, an overview of Loft is given. Then, modules and threads are considered.  Atomic and non-atomic instructions are described. Finally, native modules are considered.  A first serie of examples is given in section Examples - 13. Amongst them is the coding of a small reflex-game which shows the reactive programming style. The case of data-flow programming is also considered. Various sieves are coded, showing how the presence of instants can benefit to code reuse.  Section Programming Style4 contains a discussion on the programming style implicitly supposed by Loft.  Section Semantics5 contains the formal semantics of the cooperative part of Loft by means of a set of rewriting rules.  FairThreads is described in section FairThreads in C6.  Several implementations of Loft are described in section Implementations7. One consists in a direct translation in FairThreads. Another is a direct implementation of the semantics rules of section Semantics5. One implementation is suited for embedded systems.  Section Examples - 28 contains a second serie of examples. Amongst them are some example which can benefit from multiprocessor architectures.  A prey/predator demo running on an embedded system (the Game Boy Advance of Nintendo) is also described.  Related work is described in section Related Work9 before the conclusion.  A first annex gives the API of FairThreads. A second one is the Reference Manual of Loft. The third one is a quick description of the compiling command.

Threads are created from modules.  A thread created from a module is called an instance of it. A module can have parameters which define corresponding parameters of its instances. Arguments provided when an instance is created are associated to these parameters. A module can also have local variables, new fresh instances of which are automatically created for each thread created from it.

The body of a module is basically a sequence of instructions executed by its instances. There are two types of instructions: atomic instructions and non-atomic ones.  Atomic instructions are run in one single step by the same processor. Usual terminating C code belongs to this kind of instructions. Another example of atomic instruction is the generation of an event, described later, which is broadcast to all the threads.

Execution of non-atomic instructions may need several steps up to completion. This is typically the case of the instruction which waits for an event to be generated. Execution steps of non-atomic instructions are interleaved, and can thus interfere during execution. Note that all the execution steps of a non-atomic instruction may not be necessarily executed by the same processor.

The basic task of a scheduler is to control execution of the threads that are linked to it. The scheduling is basically cooperative: linked threads have to return the control to the scheduler to which they are linked, in order to let other threads execute. Leaving the control can be either explicit, with the instruction cooperate, or implicit, by waiting for an event which is not present.

All linked threads are cyclically considered in turn by the scheduler until all of them have reached a cooperation point (cooperate, or waiting instructions). Then, and only then, a new cycle can start. Cycles are called instants. Note that the same thread can receive the control from the scheduler several times during the same instant; this is for example the case when the thread waits for a first event which is generated by another thread, later in the same instant. In this case, the thread receives the control a first time and then blocks, waiting for the event. The control goes to the others threads, and returns back to the first thread after the generation of the event.

A schedulers define some kind of automatic synchronization which forces the threads linked to it to run at the same pace: all the threads must have finished their execution for the current instant, before the next instant can start.

The order in which threads are cyclically considered is always the same: it is the order in which they have been linked to the scheduler. This leads to deterministic executions, which are reproducible. Determinism is of course an important point for debugging.

At creation, each thread is linked to one scheduler. There exists an implicit scheduler to which threads are linked by default when no specific scheduler is specified.  Several schedulers can be defined and actually running in the same program. Schedulers thus define synchronized areas in which threads execute in cooperation.

During their execution, threads created from special modules, called native modules, can unlink from the scheduler to which they are currently linked, and become free from any scheduler synchronization. Such free threads are run by kernel threads of the system. Of course, native modules and native threads have a meaning only in the context of a preemptive OS.

Local variables that are instances of local variables of modules. These variables are local to threads. Their specific characteristic is that their value is preserved across instants: they have thus to be stored in the heap.

Automatic variables which are defined in atomic instructions, and which are automatically destroyed when the atomic instruction in which they appear is left.  The value of an automatic variable is not preserved from one instant to the next. As in C, automatic variables can be stored in registers or in the stack.

Note that non-native threads need a stack only for execution of their atomic instructions. Indeed, atomic instructions cannot be preempted during execution, by definition. Thus, in this case, the stack is always in the same state at the beginning and at the end of the execution of each atomic instruction. Thus, the content of the stack needs not to be saved when a context switch occurs. The situation is of course different for native threads: because they can be preempted arbitrarily by the OS, they need a specific stack, provided by the native thread in charge of running them.

The simpler way for threads to communicate is of course to use shared variables. For example, a thread can set a boolean variable to indicate that a condition is set, and others threads can test the variable to know the status of the condition. This basic pattern works if all threads accessing the variable are linked to the same scheduler.  Indeed, in this case atomicity of the accesses to the variable is guaranteed by the cooperativeness of the scheduler.  A general way to protect a data from concurrent accesses is thus to associate it with one unique scheduler to which threads willing to access the data should first link to.

However, this solution does not work if some of the threads are non-native and belong to different schedulers or are unlinked. This is actually the standard situation in concurrent programming, where protection is basically obtained with locks. Standard POSIX mutexes can be used for this purpose.

Events are synchronizing data basically used by threads to avoid busy-waiting on conditions. An event is created in a scheduler which is in charge of it during all its lifetime. An event is either present or absent during each instant of the scheduler which manages it. It is present if it is generated by the scheduler at the beginning of the instant, or if it is generated by one of the thread executed by the scheduler during the instant; it is absent otherwise. The presence or the absence of an event can change from an instant to another, but it cannot change during the course of an instant: all the threads always "see" the presence or the absence of an event in the same way, independently on the order in which they are scheduled. This is what is meant by saying that events are broadcast.

The basic implementation of Loft is build on top of a C library of native threads. Each scheduler and each instance of a native module is implemented as a native thread. Threads which are instances of non-native modules do no need the full power of a native thread to execute. Actually, they don't need any specific stack as they can use the one of the native thread of the scheduler to which they are linked. In this way, the number of native threads can be limited to a minimum. This is important when a large number of concurrent activities is needed, as the number of native threads that can be created in systems is usually rather low.

M:N architectures: M linked threads and N schedulers running them. An important point is that these architectures become programmable directly at language level, and not through the use of a library (as for example in the Solaris system of Sun).

Modules are templates from which threads are created. A thread created from a module is called an instance of it. A thread is always created in a scheduler which is initially in charge of executing it. Modules are made from atomic and non-atomic instructions that are defined in the next sections.

A module can have parameters which define corresponding parameters of its instances. Arguments provided when an instance is created are associated to these parameters. A module can also have local variables, new fresh instances of which are automatically created for each thread created from it.

This module is a non-native one and it has a parameter which is a character string.  The body is reduced to a single while loop (actually, an infinite one) considered in section Loops2.4.4.  At each instant, the loop prints the message in argument and cooperates.  Note the presence of the do and end keywords around the loop body; indeed, as in Loft "{" and "}" are used to delimit atomic instructions (see C Statements2.3.4), one needs a different notation for loop bodies.

The parameter s is actually a local variable which is passed at creation to the instances of trace. In Loft, all accesses to local variables, and thus also to parameters, must be of the form local(...)  (local is actually a macro).

Threads can have local variables which keep their values across instants. These are to be distinguished from static variable which are global to all the threads, and from automatic variables which loose their values across instants.

This is not correct because the variable i is allocated in the stack at the beginning of the atomic instruction, and vanishes at the end of it. Thus, a new instance of the variable is used at each instant.

Threads are instances of modules. Threads which are instances of a module m are created using the function m_create which returns a new thread.  Threads are of the pointer type thread_t.  Note that, as in many C APIs, all types defined in Loft have their name terminated by "_t".  Arguments given to m_create are passed to the created instance (as in C, arguments are passed by value).

Threads are always incorporated in the scheduler at the beginning of an instant, in order to avoid interferences with already running threads. Moreover, if the current scheduler and the one in which the thread is created are the same, then this instant is the next one.

In this section, one considers the atomic instructions which terminate at the same instant they start. We have already seen two examples in previous sections: call to the C function printf, and creation of instances of a module m with the m_create and m_create_in functions.

A scheduler, called the implicit scheduler, always exists in every program.  Two atomic instructions are available to get the implicit scheduler and also the current scheduler, which is the one to which the executing thread is linked (the NULL value is returned if the thread is not linked to any scheduler).

A event is created in a scheduler whose instants determine its presence/absence status. event_create creates an event in the implicit scheduler. event_create_in creates an event in the scheduler given as argument. Events are of the type event_t.

Generation of an event makes it present in the scheduler in charge of it (the one in which the event has been created).  If the thread running the generation is linked to the scheduler of the event, then the generation becomes immediately effective.  In this case, all the threads waiting for the event will be re-scheduled during the same instant, and thus will see the event as present.  If the scheduler of the event and the one of the thread are different, then the order to generate the event is sent to the scheduler of the event. In this case, the event will be generated later, at the beginning of the next instant of the target scheduler. Note that this can occur at an aritrary moment if the target scheduler is run asynchronously by a dedicated native thread.

A value can be associated to an event generation; in this case one speaks on a valued generation of the event; in the other case, the generation is said to be pure. The value must be of a pointer type, or of a type that can be cast to such a type.  All the values generated for a same event are collected during the instant and are available during this instant using the get_value non-atomic instruction (see section Generated Values2.4.8).

A pure generation of a present (that is, already generated) event has no effect. This is of course different for a valued generation: then, the value is appended to the list of values of the event. Note that, as for the presence/absence status, the list of values of an event is automatically reset to the empty list at the beginning of each instant.

The first call is the pure generation of the event evt. The second call generates the same event, but with the value val.  Note that a valued generation with a null value is not equivalent to a generation without any value.

Three means for controlling threads execution are provided: the way to stop the execution of a thread which is thus forced to terminate definitively; the way to suspend and resume the execution of a thread. With these means, the user can design its own scheduling strategies for controlling threads.

Threads can be suspended and resumed using the two atomic instructions suspend and resume. Suspension of a thread means that its execution is suspended until it is resumed. Suspension and resuming are orders given to the scheduler running the considered thread, and are always processed at the beginning of new instants. Like for stop, if the executing thread and the concerned threads are both linked to the same scheduler, then the thread execution status will be changed at the beginning of the next instant.

Basic atomic instructions are standard C blocks, made of C statements enclosed by "{" and "}". Of course, the C statement must terminate and one must keep in mind that it should not take too much time to execute it. Indeed, the others threads belonging to the same scheduler cannot execute while the current thread has not finish to execute it (see the discussion on this point in Necessity of Cooperation4.1).

Almost any C code can syntactically appear in atomic instructions, between "{" and "}".  It is of the programmer's responsibility to avoid the use of any statement that would prevent the complete execution of an atomic instruction. For example, setjump/longjump should absolutely be avoided.  However, some forbidden statements are detected, and lead to program rejection. This is the case of the C return statement. break statements not enclosed in a C bloc are also forbidden, as well as goto statements.

The basic non-atomic instruction is the cooperate instruction which returns the control back to the scheduler. When receiving the control after a cooperate instruction, the scheduler knows that the executing thread has finished its execution for the current instant, and thus that is is not necessary to give it back the control another time during the instant.  When the thread will receive the control in a future instant, the cooperate instruction terminates and passes the control in sequence.  Execution of a cooperate instruction thus needs two instants to complete.

Execution of an await instruction suspends the executing thread until the event is generated. There is of course no waiting at all if the event is already present. Otherwise, the waiting can just take a portion of the current instant, if the awaited event is generated later in the same instant, by a thread scheduled later; the waiting can also last several instants, or can even be infinite, if the awaited event is never generated.

There is a way to limit the time during which the thread is suspended waiting for an event.  The limitation is expressed as a number of instants. The thread is resumed when the limit is reached. Of course, the waiting ends, as previously, as soon as the event is generated before reaching the limit. For example, the following instruction suspends the executing thread at most 10 instant, waiting for the event e.

Note that the message "was absent" is printed at the instant that follows the starting of the waiting, while "is present" is printed at the same instant.  Reaction to the absence of an event (here, the printing action) cannot be immediate, but is always postponed to the next instant.

The join instruction suspends the executing thread until another one, given as argument, has terminated; this is called joining the thread. Note that there are actually two ways for a thread to terminate: either because execution has returned, or because the thread has been stopped.

There are two kinds of loops: while loops, that cycle while a boolean condition is true, and repeat loops that cycle a fixed number of times. There is no equivalent of a for loop, as such loops would need in most cases an associated local variable; for loops are thus, when needed, to be explicitly coded.

A repeat loop executes its body a fixed number of times. It could be coded with a while loop and a counter implemented as a local variable; the repeat instruction avoids the use of such a local variable.

Both then and else branches are optional. The boolean expression exp is evaluated once, when the control reaches the if for the first time. Its value determines which branch is chosen for execution. The chosen branch is then executed up to completion, which can takes several instants, as it can be non-atomic.

In this code, the if instruction tests exp and forbids the control to pass in sequence if it is false. In this case, an event is generated which should be used by an other thread to recover from this situation.

The get_value instruction is the means to get the values associated to an event by the valued generations of it. The values are indexed and, when available, returned in a variable of type void**.  The instruction get_value (e,n,r) is an attempt to get the value of index n, generated for the event e during the current instant. If available, the value is assigned to r during the current instant; otherwise, r will be set to NULL at the next instant, and the function return_code () will return the value ENEXT.

A module can run another one, using the run non-atomic instruction.  The calling thread suspends execution when encountering a run instruction.  Then, an instance of the called module is created with the arguments provided. Finally, the calling thread is resumed when the instance of the called module terminates.  Moreover, a thread which is stopped retransmits the stop order to the thread it is running, if there is one. Thus, the instance of a called module is automatically stopped when the calling thread is.

In this sequence, an instance of mod1 is first executed. When it terminates (if it does), then an instance of mod2 is executed with a string argument. Finally, the sequence terminates when the last instance does.

When created, a thread is always linked to a scheduler. During execution, the thread can link to others schedulers, using the link instruction.  The effect of execution the instruction link (sched) is to extract the executing thread from the current scheduler and to add it to sched, in the state in which it has left the current scheduler. Thus, after re-linking, the thread will resume execution in the new scheduler. This can be seen as a restricted migration of threads.

Native modules only have meaning in the context of a preemptive OS as instances of native modules should be run by native threads belonging to the kernel. The presence of the native keyword just after the keyword module defines the module as native. The unlink non-atomic instruction unlinks the instance of a native module from the scheduler to which it was previously linked. After the unlink instruction, the thread is free from any synchronization.  However, an unlinked thread can always re-link to a scheduler using the link non-atomic instruction (see Link12.7.2).

The two lists of messages produced are merged in an unpredictable way in the output: nondeterminism is introduced by unlinked instances of native modules. Note that the loop in pr is instantaneous; this is not a problem as the thread is unlinked. The granularity of each thread is, however, under the dependance of the OS, which can be unacceptable in some situations (see Granularity of Instants4.2).

Let us consider a system made of two threads implementing two variants of a service, say a fast one and a slow one. Two events are used to start each of the variants. After a variant is chosen, the other one should become unavailable, that is each variant should be able to stop the other variant. The coding of such an example is straightforward.

Now, suppose that the same example is coded using standard pthreads, replacing events by condition variables and stop by pthread_cancel.  The resulting program is deeply non-deterministic. Actually, one of the two threads could cancel the other and run up to completion.  But the situation where both threads cancel the other one is also possible in a multiprocessor context (where each thread is run by a distinct processor); however, in this case, both variants execute simultaneously while they are not canceled, which produces unpredictable results.

One considers thread synchronization using conditions which basically correspond to (simplified) condition variables of POSIX.  A thread can wait for a condition to be set by another thread. The waiting thread is said to be notified when the condition is set.  In a very first naive implementation, conditions are simply boolean variables (initially false). To notify a condition means to set the variable, and to wait for the condition means to test it.

Note that no mutex is needed: because of the cooperative model, simple boolean shared variables are sufficient to implement atomic test and set operations needed. There is however a major drawback: the module wait performs busy-waiting and is thus wasting the CPU resource.

Note that once the event is received, the condition must be tested again because an other thread waiting for the same condition could have been scheduled before. In this case, the wakening is not productive and the thread has just to cooperate. Without the second test, an instantaneous loop would occur in this situation.

The solution proposed does not allow single notifications, where only one thread is notified at a time. Actually, all threads waiting for the same condition are simultaneously awaken and all but one will be able to proceed, the other ones returning to their previous state. This can be inefficient when several threads are often simultaneously waiting for the same condition.

To be able to notify threads one by one, an event is associated to each waiting thread. Thus, a condition now holds a list of events managed in a fifo way and storing the waiting threads. There are two notifications: notify_one which notifies a unique thread and notify_all which, as previously, notifies all the threads.

The notification of a unique thread does not imply the competition of all the other threads waiting for the same condition because they are actually waiting on distinct events. Note that the choice of a fifo strategy to manage events in conditions is quite arbitrary (while reasonable). This is of course a question which is inherent to the notify_one primitive: how is the notified thread chosen?

Either which thread is notified is left unspecified, which introduces some nondeterminism, or the way threads are managed is specified, which can be felt as an over-specification.  This is actually an issue which can only be solved by application programmers according to their needs.

If the threshold is reached, then the counter is reset to 0 and the event go is generated. Thus, all the waiting threads can immediately proceed. If the threshold is not reached, then the counter is incremented and the thread awaits go to continue.

The convention for lock_count is the following: 0 means that the lock is held by nobody; when held by the writer, lock_count has value -1; when positive, lock_count is the number of readers currently reading.

The processing module cyclically gets a value from the buffer, tests if it is zero, and if it is not, processes the value. When it is finished, the value decremented by one is put back in the buffer. The event new_input is used to avoid busy-waiting while the buffer is empty (one considers that the buffer is rarely empty; so, a unique event is preferred to single notifications of section Wait-Notify3.1.2).

All accesses to the shared buffer are atomic under the condition that all instances of process are created in the same scheduler. This is of course the case when the implicit scheduler is the unique scheduler in use.

One now considers a situation where there are two buffers in and out, and a pool of threads that take data from in, process them, and then put results in out. A distinct scheduler is associated to each buffer.

The process_value module process its parameter and then links to out_sched to deliver the result in out. At delivery, the event new_output is generated to awake threads possibly waiting for out to be filled.

This code shows a way to manage shared data using schedulers. The use of standard locks is actually replaced by linking operations. Of course, locks still exist in the implementation and are used when linking operations are performed, but they are totally masked to the programmer who can thus reason in a more abstract way, in terms of linking actions to schedulers, and not in terms of low-level lock take and release actions.

The purpose of the game is to measure the reflexes of the user.  Four keys are used.  The c key means "put a coin", the r key means "I'm ready", the e key means "end the measure" and the q key means "quit the game".  After putting a coin, the user signals the game that he is ready; then, he waits for the GO! prompt; from that moment, the measure starts and it lasts until the user ends the measure. After a series of four measures, the game outputs the average score of the user. The game is over when an error situation is encountered. There are actually two such situations: when the player takes too much time to press a button (the player has abandonned); or when e is pressed before GO! (this is considered as a cheating attempt).

Five events: coin_evt is generated when c is pressed; ready_evt is generated when r is pressed; end_evt is generated when e is pressed; tilt_evt is generated by the game when an error is detected; the value of display_evt holds the measures times to be printed.

The first phase starts by creating an instance of beep_on which reacts on end_evt. Then, ready_evt is awaited during at most limit_time instants. If the timeout is reached then tilt_evt is generated and the execution blocks. In all cases, the previously created instance of beep_on is stopped.

The module phase2 begins by creating a cheating detector which generates tilt_evt as soon as e is pressed. Then, one waits for a random number of instants (returned by the function myrandom) before printing the prompt message. At that moment, the cheating detector is stopped.

Phase 3 consists in measuring the number of instants taken by the player to press e.  An abandon (e is not pressed during limit_time instants) terminates the game.  Moreover, mistakes (here, pressing r instead of e) are detected and signaled.  Finally, the value measured is associated to display_evt to be printed.

Two points are to be noticed. First, the order in which the threads are created corresponds to the intuitive sequence: input processing - reaction - output processing. Second, the values of pause_length and limit_time, and the definition of myrandom must be adapted to the executing platform, in order to get a playable system.

Actually, there are two types of sieves: the number of elements of bounded sieves is statically fixed, while in unbounded sieves the number of elements is potentially infinite. Only unbounded sieves are considered here.

The type list_t is the type of lists made of elements of type cell_t which contains an integer field val and a pointer next to the next cell. The definition of these two types is standard and not given here.

Dynamic memory allocation is somewhere needed in unbounded sieves. Actually, in Loft memory allocation can be masked by the creation of threads. The Eratosthenes's sieve can be thus basically implemented in Loft without the need of any user-defined data type..

One considers programs made of processes connected through channels. Channels are basically unbounded FIFO files. Processes can put values in channels (this is always possible as channels are unbounded) and get values from them. Each channel as at most one producer (a process that fills it) and at most one consumer (a process that empties it). Thus, there is no concurrency on channels accesses, except between producers and consumers.  These programs are called data-flow programs because processes are basically creating and transforming flows of values. They were first introduced in [24], and they are actually the initial computing model at the basis of dataflow synchronous languages.

There are two variants: in Nets of Sequential Processes, the consumer of an empty channel remains stuck until some value is (possibly) produced by the producer of the channel. In Nets of Reactive Processes, all processes share the same instants, and a process can thus detect that a channel is empty (and thus it can avoid to get stuck on it) during one instant. In what follows, one does not distinguish between the two variants.

Channels are basically lists of cells containing values, with an access to the first cell and to the last cell.  Moreover, an event is associated to each channel for signaling that a new value is put in it. Cells hold integers of type value_t.

The specificities of Loft leads to a programming style which can be sum-up by the following rules of thumb: don't forget to cooperate; define a good granularity of time for instants; don't loose events; choose a smart decomposition into distinct synchronous areas.

Fair threads are basically cooperative, that is they have to leave the control periodically and to return it to the scheduler they are linked to in order to let the others threads execute. There are basically two ways for a thread to be non-cooperative: to fall in an instantaneous loop, or to execute a never-terminating atom. It must be noticed that recursion cannot by itself lead to a lack of cooperation. One now consider these points in more details.

Then, the infinite cycle does not immediately starts, but it does when the event becomes present. Indeed, from that moment, the await statement will always consider the event as present, and the loop becomes then instantaneous.

This code cannot lead to an instantaneous loop provided evt1 and evt2 are never simultaneous. However, there is an infinite cycle if both events are present at the same instant during the loop execution. Note that this may occur if evt1 and evt2 actually denote the same event.

This piece of code can lead to an infinite loop (and also to the generation of an infinite number of values). Indeed, to get the ith value leads to generate the (i+1)th one. Thus, an instantaneous loop appears as soon as the first value is generated.

Supposing that there is no instantaneous loop to prevent the passing of instants, the problem still remains to get a correct granularity for instant durations. Indeed, if instants take too much time, reactivity of the whole system could be lost. This problem is actually central in the context of Loft.

Granularity of unlinked threads is not under control of the user, but only of the scheduler. Of course, standard methods can then be used, for example based on the use of the yield primitive, but with all their standard problems too. One does not consider this case in more details here.

Introducing supplementary cooperation points in a program will give others programs more opportunities to execute.  The point however is that the introduction of supplementary cooperating points must remain compatible with the use of events. Remember indeed that events are not persistent data and are automatically reset as absent at the beginning of each new instant.

Note that no race condition on X can occur, as the framework is cooperative.  This solution is however unsatisfactory because the processing thread tests X at each instant while it is false, which is of course inefficient.

Now, the processing thread does not consume any resources while waiting for X. As a side effect of using events, one is sure that the processing starts at the very same instant X is generated. This is to be compared with the previous solution using a boolean variable, where the processing is delayed to the next instant if X is tested before being set to true.

Actually, such a situation could be called a "communication deadlock". Real deadlocks are at implementation level: they appear because some data are to be protected by locks.  Real deadlock introduces the risk that a data become inaccessible forever because some lock used to protect it is never released. This problem concerning data does not appear with communication deadlocks which can be seen as occuring at a higher, more "logical", level.

Architectural design is of major concern in Loft. Indeed, the language allows programmers to decompose a system in several sub-systems, implemented as distinct schedulers. These schedulers can either be run synchronously or asynchronously.

One can also imagine many situations where several instants of a scheduler should actually correspond to one instant of another. Loft gives the possibility to code these various situations very easily.

Schedulers that are run asynchronously define reactive areas in which threads share the same instants and the same events. Asynchronous schedulers are especially interesting in the context of multiprocessing, as each of them can be run by a dedicated native thread, on a distinct processor.  The example of the sieve in section Lucky Prime Numbers8.1.2 shows how this can be achieved quite simply.

However, one has to be very cautious using unlinked threads, as, then, all the problems of standard threads come to the foreground. For example, unlinked threads should never access data used by linked threads, because these are usually not protected. Data shared by two unlinked threads should be protected by locks exactly as if they were standard threads (actually, they are standard threads!).

Unnecessary uses of native modules should be avoided. Indeed, each instance of a native module requires a native thread to execute. This is required because such an instance can be unlinked, and in this case it behaves exactly as a standard pthread.

Instances of non-native modules do not need the full power of a native thread to execute and they can be simply implemented as automata. The reason is that, when making a thread react, the stack state is the same at the beginning and at end of the reaction.  Actually, the stack is only needed for atoms which by definition should always terminate instantly. Thus, only the state of the execution and the local variables have to be preserved between instants, which can be done using the heap. Thus, instances of non-native modules can be simply run by the thread of the scheduler to which they are linked.

One also have to keep in mind that there exist partial implementations of Loft which do not have any support for native modules (see Direct Implementation7.5). This is for example the case when the targets are embedded systems with limited resources (memory and CPU).

Loft. To simplify, one supposes that there is only one scheduler to which all the created threads are linked. One first considers the basic semantics, called Rewrite, then two variants of it, called Replace and Optim.  Replace puts the focus on memory use by limiting the number of intermediate instructions that are created during execution of an instant. The Optim variant puts the focus on CPU usage, by avoiding busy-waiting on absent events.

The semantics is expressed in the structural operational semantics (SOS) format defined in [30].  First, one defines the data structures corresponding to schedulers and threads; then, an intuitive description of the semantics is given to make the reading of the rest of the semantics easier; then, one defines the various formats of the rewriting rules; finally, the BNF syntax of the instructions is described.

CONT: the thread needs to be continued during the current instant.  This is the initial state, and the one of a thread waiting for an event which is not present, or trying to get a non-available event value.

Now, let's decompose instants: each instant consists in cyclically running phases where all the threads are run in turn. Running a thread t means to resume execution of its associated instruction t.run.  A thread which needs to be continued is a non-suspended thread that has not already cooperated during the instant. The instant is over when there is no such thread.

Threads which are started are placed in the linked list of the scheduler. At the beginning of each instant, threads that are terminated (TERM) and threads stopped during the previous instant are removed from linked.

Note that the order in which the threads are executed always remains the same during an instant. Note also that suspensions and resumptions of threads never change the order in which the other threads are executed.

The number of phases depends on the events generated. For example, consider a situation where linked = (t1,t2) and t1 awaits the event e generated by t2. Then, after t2 execution, a new phase is needed to resume t1. Otherwise, t1 would not consider e as present despite the fact that it is generated; in such a situation, one could not say that e is broadcast. Note that a third phase would be necessary if, after generating e, t2 is waiting for another event generated by t1. Actually, new phases are needed until one reaches a situation where no new event is generated; then, the end of the current instant can be safely decided.

The flag move is set each time a new event is generated; it is reset by the scheduler at the beginning of each phase. The scheduler does not decide the end of the current instant when move is true, to give threads waiting for new generated events the possibility to react to them.

The flag eoi is set by the scheduler when the end of the current instant is decided; it is reset at the beginning of each new instant. It is used to inform threads which are waiting for events that these events are definitely absent. Then, the threads can cooperate, and the next instant can safely take place.

Awaiting an event which is absent blocks a thread up to the end of the current instant. This forbids immediate (that is, during the same instant) reaction to the absence of an event; reaction, if any, is thus postponed to next instant. This is important to avoid situations where one could react to the absence of an event during one instant by generating it during the same very instant, which would contradict the fact that the event is absent. These kind of contradictions, known as "causality problems" in synchronous languages [19], do not exist here. In the same way, trying to get a not available generated value blocks a thread up to the end of the current instant.

In such a rewriting, the initial instruction is inst, the scheduler sched, and the environment of data env. As a result, the rewriting produces a status s, a new instruction inst', a new scheduler sched' and a new environment env'.

An important point must be noticed: the previous rules describe a busy-waiting mechanism: actually, the await* instruction should activated at each micro-step of each instant, until the awaited event is present (except of course during instants where the executing thread is suspended).

The auxiliary while* instruction runs the loop body up to termination, without re-evaluating the boolean condition; then, it rewrites as a standard while loop which evaluates the condition to determine if the body has to be run one more time.

The get_value instruction returns the with index n (it it exists) associated to a given event. First, three expressions are evaluated: the event, the index n, and the place where the result should be placed.

The instruction cooperates if the value is still not available at the end of the current instant. In this case, the return code is set to ENEXT which will indicate at the next instant that the value has not been got.

Limited join is similar to join, except that the delay is also tested for termination. The instruction immediately terminates if the thread to be joined is already terminated. In this case, the return code of the executing thread is set to OK.

To run a module means to create a new instance of the module and to join it.  Moreover, the instance is stored in the component called of the calling thread in order to be stopped when the calling thread is.

Instants are macro-steps of schedulers. Basically, an instant is a sequence of phases leading to a stable situation, where no thread remains to be continued. One first defines the function stable that determines if a scheduler is in a stable situation or not.

If the phase leads to an unstable situation, then the scheduler cyclically re-schedule all the threads. If no event is generated during a phase (move is still false at the end of the phase), then the scheduler decides that the current instant can be finished by setting the flag eoi to true.

One finally considers the chaining of instants and more specifically the actions performed between two successive instants. Actually, these actions are regrouped at beginnings of instants and are specified by the function start_instant.

Stopped threads are places into the to_finalize list in order to be processed later. Thus, orders issued from finalizer execution will be performed at the next instant, and not during the current one.  As a consequence, no instantaneous can occur from a finalizer sending orders to the scheduler running it.

To finalize a thread means to set its state to TERM, to add the signaling event in the list of events, to call the finalizer of the thread, and finally to recursively finalize the called thread, if there is one.

One now considers the Replace semantics, which is a variant of the basic semantics Rewrite, designed to limit the creation of new instructions during the rewriting process. Actually, no new instruction is created by Replace during rewritings, and to rewrite an instruction basically means to change its state.

Non-atomic instructions have states. We only give the semantics of some of them to show the introduction of states and the way they are managed. The semantics of others instructions should be straightforward.

Replace, loops bodies are not duplicated as in Rewrite (using the extended instructions repeat* and while*), but are reset at the end of each cycle, in order to be ready for the next cycle. One only considers here while loops.

The reset function is used by loops to reset their body at the beginning of each cycle.  To reset a term actually means to erase all indices appearing in it.  The recursive definition of reset is straightforward and is left to the reader.

In Replace, the rewriting is thus just a change of instruction states. This is the reason why it can be implemented more efficiently than Rewrite, without creation of new instructions during execution (except of course when new threads are created).

One now considers a variant of the previous semantics Replace, called Optim, in which threads are not busy-waiting for events. This variant basically uses queues associated to events in which waiting threads are stored. A special queue to store threads that are submitted to deadlines (because they execute limited forms of await and join) is also defined.  There are few changes with the previous semantics and only the major ones are given in the sequel.

To awake a thread means to change its state to CONT and to unregister it from the queues where it is registered. Of course, this is for threads that are effectively waiting for the event and that are not suspended.

A point must be noted: to perform supplementary calls to the awake function is not dangerous, in the sense that it cannot change the meaning of a program. Indeed, to awake a thread which has not to be awaken will leads to reintroduce it into the game, and does not change the actions that the thread has to perform. This basically means that spurious awake actions are not a problem. The consequence is that one can choose to never unregister threads from the timer, without risk of perturbating the execution later. This actually can be useful for optimizing implementations.

In a first step, one has described the semantics Rewrite with a set of about 50 rules covering all the aspects of the cooperative part of the language. The rules are simple to be understood one by one, and one can be rather confident that they capture the essence of the language. Actually, a way to make this confidence stronger is to implement the semantics as is, and to execute tests covering the largest possible set of various aspects of the language. This is of course possible because the semantics is basically deterministic, which allows one to implement it in a straightforward way.

All the threads linked to a scheduler are considered in turn during each phase. Thus, to determine which is the next thread to execute is not constant in time, but linear in the number of threads linked to the scheduler.

The variant Replace of Rewrite is defined to deal with the first previous point. In it, the construction of new instructions is replaced by the introduction of states in instructions. Instead of creating a new instruction from an old one, one just changes the state.

Replace is transformed to avoid busy-waiting (previous point 2), using queues in which threads that are waiting for events are stored. This leads to the variant Optim which is closer to an efficient implementation of Loft than the previous semantics.

To end with semantics concerns, one should notice that the non-cooperative part of Loft is not considered by any of the previous semantics. To cover the whole language, a way that should be explored is the chemical abstract machine paradigm[10] to deal with nondeterministic aspects arising in this case.

In order to be executed, a scheduler must be started by a call to the function ft_scheduler_start. Note that several schedulers can be used without problem simultaneously in the same program. Each scheduler is run by a dedicated native thread which gives the control in turn to the threads linked to the scheduler.

Fair threads are of type ft_thread_t. The call ft_thread_create(s,r,c,a) creates a thread in the scheduler s. The thread is run by a dedicated native thread. The creation becomes actual at the beginning of the next instant of s.

The call ft_scheduler_stop(t) gives to the scheduler which executes the thread t the order to stop it.  The stop will become actual at the beginning of the next instant of the scheduler, in order to assure that t is in a stable state when stopped.

The call ft_scheduler_suspend(t) gives to the scheduler which executes t the order to suspend t.  The suspension will become actual at the beginning of the next instant of the scheduler.  The function ft_scheduler_resume is used to resume execution of suspended threads.

The function ft_scheduler_broadcast(e) gives to the scheduler of the event e the order to broadcast it to all the threads running in the scheduler. The event will be actually generated at the beginning of the next instant of the scheduler. The call ft_scheduler_broadcast_value(e,v) associates the value v to e (v can be read using ft_thread_get_value).

The call ft_thread_cooperate() is the explicit way for the calling thread to return control to the scheduler running it. The call ft_thread_cooperate_n(i) is equivalent to a sequence of i calls ft_thread_cooperate().

The call ft_thread_join(t) suspends the execution of the calling thread until the thread t terminates (either normally or because it is stopped). Note that t needs not to be linked to the scheduler of the calling thread. With ft_thread_join_n(t,i) the suspension takes at most i instants.

The call ft_thread_generate(e) generates the event e in the scheduler which was associated to it, when created. The call ft_thread_generate_value(e,v) adds v to the list of values associated to e during the current instant (these values can be read using ft_thread_get_value).

The call ft_thread_await (e) suspends the execution of the calling thread until the event e becomes generated. Execution is resumed as soon as the event is generated. With ft_thread_await_n (e,i), the waiting takes at most i instants.

The call ft_thread_select(k,array,mask) suspends the execution of the calling thread until the generation of one element of array which is an array of k events. Then, mask, which is an array of k boolean values, is set accordingly.  With ft_thread_select_n(k,array,mask,i), the waiting takes at most i instants.

The call ft_thread_get_value(e,i,r) is an attempt to get the ith value associated to the event e during the current instant. If such a value exists, it is returned in r and the call immediately terminates. Otherwise, the value NULL is returned at the next instant.

The call ft_thread_unlink() unlinks the calling thread t from the scheduler in which it was previously running. Then, t will no longer synchronize, instant after instant, with other threads linked to the scheduler. Actually, after unlinking, t behaves as a standard native thread.

The call ft_thread_link(s) links the calling thread to the scheduler s.  The calling thread must be unlinked when executing the call. The linkage becomes actual at the beginning of the next instant of s.

In presence of unlinked threads, locks can be needed to protect data shared between unlinked and linked threads. Standard mutexes are used for this purpose.  The call ft_thread_mutex_lock(p), where p is a mutex, suspends the calling thread until the moment where p can be locked. The lock is released using ft_thread_mutex_unlock.  Locks owned by a thread are automatically released when the thread terminates definitively or when it is stopped.

The call ft_pthread(t) returns the native pthread which executes the fair thread t.  This function gives direct access to the Pthreads implementation of FairThreads. In the rest of the paper, native thread and pthread will be considered as synonymous.

The function ft_exit is equivalent to pthread_exit. The basic use of ft_exit is to terminate the pthread which is running the function main, without exiting from the process running the whole program.

The program outputs Hello World! cyclically. Note the call of ft_exit to prevent the program to terminate before executing the two threads. Execution of linked fair threads is round-robin and deterministic: the two messages Hello and World! are always printed in this order.

The following automaton switches control between two threads, according to the presence of an event.  The automaton switch_aut has three states. The first state resumes the first thread to run (initially, one assumes that both threads are suspended).  The switching event is awaited in the second state, and the threads are switched when the event becomes present. The third state is similar to the second, except that the threads are exchanged.

The first main difference relies of course on the fact that Loft is a language while FairThreads is an API. It indeed implies two very different styles of programming. In Loft, one writes reactive programs which are linked with standard C code through atoms. In FairThreads, one basically writes C code in which some function calls are reactive primitives. Thus, the reactive structure of Loft programs certainly appears more clearly than in FairThreads programs.

FairThreads as there is no need in Loft to be unlinked in order to be able to link to another scheduler. Actually, when linking to a target scheduler, the unlinking of the source scheduler is implicit in Loft. The important point is that is does not implies that the thread stays unlinked, which would need the use of a native thread.

The arguments of threads in FairThreads have to be passed through an unique parameter of type void*. This complicates things when several arguments have to be passed to a same thread. Actually, these arguments have to be packed in one new structure whose reference is passed to the thread. In case of an automaton, the arguments are accessed with the macro ARGS.

FairThreads offers possibilities that do not exist in Loft and which are related to the stacks. Actually, in FairThreads all the threads, except automata, use their own private stack, as they are basically pthreads. The opposite holds in Loft where threads, except instances of native modules, do not need a private stack to execute.

There is no counterpart in Loft of the ft_thread_select functions.  Thus, the waiting of one amongst several events must be coded indirectly in Loft.  Next versions of Loft should certainly propose a primitive similar to ft_thread_select of FairThreads.

When comparing FairThreads with POSIX, the first point to note is of course that FairThreads is basically cooperative while POSIX is basically preemptive. More precisely, threads linked to the same scheduler are executed cooperatively. As a consequence, data protection is considered very differently in the two contexts: in POSIX mutexes are basically used for that purpose, while in FairThreads schedulers are used for the same purpose. If one is sure that a data can only be accessed by the threads linked to a given scheduler, one can safely deduce that no race condition occur for the data. If accessing the data needs more than simple atomic instructions, a boolean variable can be used to lock and unlock the variable. In this case, however, one is in a situation very similar to the one using mutexes, with all their identified problems.

FairThreads proposes the notion of an automaton which does not need the full power of a kernel thread to execute. Using automata, one can pass around the limitations of POSIX implementations in which threads are mapped onto kernel threads.

As stated before, schedulers in FairThreads can be used to structure applications around protected data which are only accessed by linked threads; in this respect, schedulers are playing a role very similar to the one of mutexes.

To generate an event corresponds to pthread_cond_broadcast and to await it corresponds to pthread_cond_wait. The limited variant pthread_cond_timedwait is the counterpart of ft_thread_await_n except that in FairThreads deadlines are counted in instants. There is no direct counterpart for the nondeterministic pthread_cond_signal of POSIX which must be coded in FairThreads in a way similar as the one presented in Single Notification3.1.2.2.

To kill a thread is done in FairThreads with the ft_scheduler_stop function.  In POSIX, the cancellation mechanism with the related functions (for example, pthread_setcancelstate) can be used for that purpose.  However, it implies that the cancelled thread is in the correct mode and has set meaninful cancellation points. In FairThreads thread cancellation can naturally only occurs at beginning of instants. In this respect, FairThreads is much more simpler than POSIX.

OS. In this context, unlinked fair threads are run by dedicated native threads, at the kernel level. This is exactly what is needed to implement native modules of Loft. The implementation described in this section is complete, as opposite to implementations considered later, that deal only with the cooperative part of Loft.

Each instance of a module is mapped onto a fair thread of type ft_thread_t. This thread is either a standard fair thread in case of a native module, or an automaton in case of a non-native one. Thus, only instances of non-native modules are run autonomously as standard pthreads. The translation will be described through the example of a module.

One first describes the translation of m, then one considers the change where m is a non-native module.  In both cases, the module translates into a data structure for local variables, a function that describes the module behavior, and two functions to create new instances of the module.

Third, the m_create_in function is defined.  It first allocates a structure _locals for parameters and local variables of the returned thread _th. A special allocation function is used, called mymalloc. Actually it just adds some tracing possibilities to the standard malloc function of C.  The parameter are copied in _locals. Then, a fair thread is created using ft_thread_create. Finally, the new pthread is detached (using the pthread_detach function of Pthread), in order to avoid the limitation on the number of pthreads that can be attached in an application. Actually, the join primitive of FairThreads is not implemented using pthtread_join which supposes that threads are attached.

State 1 contains initialization of the local variable i. States 2,3, and 6 implements the repeat loop, using the local variable _loc0, which is initialized in state 2, tested in 3, and decremented in 6.  State 4 contains the atomic printing action. State 5 corresponds to the cooperate instruction.  State 7 is an auxiliary state (which should probably be removed). Finally, state 8 contains the call to the exit function.

There is no busy-waiting on absent events because fair threads waiting for an event are placed into a list associated to it, and then become transparent for the scheduler.  Transparent fair threads return to the visible state as soon as the event they are waiting for becomes generated. Thus, one gets an implementation using queues to store waiting threads which actually implements the method described in section OPTIM Semantics5.5.

The use of automata for non-native threads is very efficient. Actually, an automaton is implemented as a switch instruction which dispatches the control to the appropriate state. Moreover, there is no limit on the number of automata that can be created, which is not true for native threads.

However, the implementation in FairThreads has a major drawback: it absolutely needs the presence of pthreads (even if they are not started, with non-native modules) and thus suffers of the problems related to pthreads. Amongst them, one can cite the need of a private stack for each pthread, which is memory consuming, and the presence of uncontrolled context-switches, which is inherent to the preemptive basis of pthreads. This last characteristic is clearly time consuming. Because pthreads are mandatory, the described implementation cannot be used for embedded systems with limited resources; this is the reason why the implementation described in section Direct Implementation7.5 is proposed.

Loft.  In this section, one directly implements the semantics rules of section Instructions in REWRITE5.2.  As the semantics, this implementation is called Rewrite to emphasize on the fact that it mimics the rewriting rules execution. The main purpose of Rewrite is to serve as a reference for others implementations.

The function make_wrapper returns a wrapper which is a structure which contains a selector, as the previous m_selector, and an index.  The execution of an atom made from a wrapper returns the evaluation of the case corresponding to the index of the selector .  Thus, the selector is evaluated at execution time and not when the thread is constructed.

The  field run is the instruction executed by the thread. locals points to the thread local variables. The state of the thread is contained in state. The thread is suspended when suspended is different from 0. The event signal is generated when the thread terminates its execution. The field called is set while a thread is under execution through a run instruction. The field code holds the return code of some instructions (namely, await, join, and get_value). Finally, scheduler denotes the scheduler in which the thread is currently executed.

One now consider the variant Replace of Rewrite.  The basic idea is to introduce states in instructions and to change instructions states during the rewriting process in order to limit to the maximum the creation of new instructions. One just gives here the main changes with the previous Rewrite implementation, concerning cooperate, sequences, and loops.

Two functions are defined to register threads returning the WAIT status: register_in_event (e) registers the executing thread (actually self ()) in the waiting list associated to the event e, and register_in_timer (s) registers the executing thread in the timer list of the scheduler s.

One considers now an implementation of Loft which mixes the previous implementation of the Optim semantics described in Implementation of OPTIM7.4 and the automata-based approach of the implementation in FairThreads considered in Implementation in FairThreads7.1, but without the need of pthreads anymore. One calls this implementation Direct as it consists in a rather direct translation in C, without the need of some particular library. Moreover, Direct use an efficient algorithm to access the next thread which needs execution.

One gets an efficient implementation with low consumption of memory. This implementation is suited for using Loft on embedded systems with limited resources. An experiment described in section Prey-Predator Demo8.3 has been made with the GBA (Game Boy Advance) platform of Nintendo.

Event queues are used to avoid busy-waiting not only during one instant, but also accross several instants. A thread which is awaiting a not present event registers itself in a queue associated to the event. Up to this point, the thread falls into a new WAIT state, and will not be considered for execution by the scheduler to which it is linked, until the event is generated.  When an event is generated, elements of the queue associated to it all return in the normal execution state. Note that the order in which the threads are executed is not perturbed by this mechanism which is actually just a way to suspend execution of threads awaiting non generated events. In this case, suspension and resumption are immediate, i.e. they become effective in the current instant and not in the next one as it is the case with the suspend/resume instructions.

The code of state 1 implements the await (go) instruction. If go is not present, then the executing thread (returned by self) is registered in the event and the status returned is WAIT. Thus, the thread will never be considered for execution until go will be generated. When it will be the case (if it happens), then the thread status returns to CONT and thus the execution will resume. An important point to note is that the order in which threads are executed always remains the same and is not changed by awaiting events.

Note the initialization of the automaton state.  The function make_thread returns a thread executing the function passed as first parameter with the finalizer as second parameter and the local data as third parameter. The new thread is added in the implicit scheduler by the call to add_to_link.

The threads placed in linked are considered in turn fot execution. When a thread is in the state WAIT it should not be considered for execution and the scheduler should pass on it without any other action to perform. Of course, the state can later return to CONT when the thread is awaken, and in this case the scheduler will have to reconsider it again.

To avoid to consider threads that are in state WAIT, one uses a masking 1: threads with the state WAIT are masked and disapear from linked.  However, they are not definitively extracted from the list and can be reintroduced in it at the same place. This of course happens when a masked thread is awaken. In this way, the efficiency of the scheduler do not depend anymore from threads that are registered in events or in the scheduler timer.

To implement masking, linked is implemented as a list of cells with two series of pointers. The first serie describes the structure of the list which does not change except when a thread terminates or when new threads are linked to the scheduler. Note that this can only appear in-between instants. The second serie of pointers gives the next and previous unmasked cell. This pointers are changed when a thread returns WAIT and when it is awaken. Using the structure pointers allows to reinsert a thread at its previous position when awaken.

The cost of a masking action is constant.  However the cost of unmaking depends on the number of threads (masked and unmasked) present in the list. This is basically because threads are reintroduced in linked at their initial place. One thus gets a very efficient mechanism that is specially useful when a large number of threads is in use while, at each instant, few of them are really executed, the others ones waiting for absent events.

Loft. From this point of view, Loft can be seen as a mean to replace an API by a language, in order to ease the programming of fair threads. The implementation is complete, as native modules are taken in account. Actually, instances of native modules are implemented as standard kernel threads, which are provided by the pthread library.

In the variant Replace of Rewrite, the construction of new terms is limited to the minimum. Basically, in Replace, new allocation occurs only when new threads are added in the system. Thus, the memory remains stable while no new thread is created.

Both Rewrite and Replace are using a polling strategy for awaiting events.  Actually, a thread executing await (e) tests for the presence of e at each micro-step and during all instants, until e is generated (if it is).  This is clearly inefficient. The Optim implementation avoids busy-waiting for absent events, using queues in which waiting threads are placed.

Finally, the fifth implementation Direct is suited for embedded systems. As Optim, it uses queues to store threads awaiting for an event are used, instead of busy-waiting. As the implementation in FairThreads, it translates non-native modules in automata. However, no library of kernel threads must be used in this case. Moreover, Direct uses a masking technique to get direct access to the next thread to be executed. One thus gets a very efficient with low memory consumption implementation of the cooperative part of Loft.

Section Direct Access8.2 considers the masking optimization included in the Direct implementation.  Finally, section Prey-Predator Demo8.3 describes the code of an embedded system which runs on a platform with very limited resources (the GBA of Nintendo).

Lucky Prime Numbers8.1.2. The system is decomposed in two uncoupled sub-systems, one for producing prime numbers and one for lucky numbers, that can be run by distinct kernel threads on distinct processors.  The sub-systems naturally correspond to schedulers. As the two sub-systems do not share the same instants, result produced have to be stored elsewhere. For this purpose, one uses two fifo channels (of type channel_t defined in Data-Flow Programming3.4). Finally, a comparison thread is defined which goes between schedulers to detect equal values and output them.

The filter module has been slightly changed to store produced values in a channel instead of, as previously, generating them.  Note that the scheduler in which the instance of compare is created is actually irrelevant; the instance could be as well created in any of the two schedulers lucky_sched or prime_sched.

Processor) bi-processor machine made of 2 PIII 1Ghz processors running on Linux 2.20 with 512Mb memory. One uses the implementation based on FairThreads to produce the first 300 lucky-prime numbers. The previous program is compared with a variant in which there is only one scheduler (both lucky_sched and prime_sched are mapped to the implicit scheduler). The time taken by the initial system with 2 schedulers is 10.5s, while it is 19.2s with the variant with a single scheduler. This shows that the presence of two processors is fully exploited by the program.

At the beginning of the second instant, the linked list of the implicit scheduler contains THREADS+2 elements. All but the active threads are registered in the waiting list of the event go during the second instant. Then, at the beginning of the third instant, linked contains only the 2 active threads, the other ones being masked. Thus execution of the system do not depend any more of the THREADS number of blocked threads, and can be extremely fast as only 2 threads are run from that moment.

From the rather academic previous examples, one sees that the gain increases as there are more and more threads that are rarely awaken. In real situations the gain is of course less important than the one of the best case. This is the case with the sieve of Sieve Examples3.3 for producing prime numbers.  For producing the 3000 first prime numbers with the making technique it takes 13.7s and without it 17.4s. For producing 5000 prime numbers, it takes 38s with masking and 1m without it. For 10000 numbers and masking: 2m37s and without masking: 4m24s. Thus, in this example the gain obtained by using masking is significant.

A predator moves using the arrow keys. Preys are running away from predators and are killed when a predator is sufficiently close to them. New preys are automatically created.  A predator is put in an automatic chasing mode with key 'a' and returns in the manual mode with 'b'.  More predators can be created with 'l', and more preys with 'r'. Here is a screenshot of the demo running on the VisualBoyAdvance emulator.

The types s16 and u8 are integer types (actually, signed 16 bits, and unsigned 8 bits). Fields x and y are the sprite coordinates. sx and sy define the speed vector of the sprite. index is the index of the sprite in the table where sprites are stored. behaviors is an array of threads in elementary behaviors of the sprite can be stored. The size of behaviors is stored in behav_num. The event destroy is used to signal the destruction of the sprite. Finally, the boolean dead is used to note that the sprite is destroyed.

First, all components of behaviors are stopped. Then, at the next instant, they are deallocated (by thread_deallocate) with the sprite structure itself. Finally, the executing thread (returned by self) is deallocated.

Because of the cooperate, threads are actually stopped at instant N+1, and are deallocated at instant N+2 (remember thar calls to stop and to thread_deallocate produce orders which are not immediately processed, but are delayed to the next instant).

The purpose of the module key_handler is to convert at each instant, the key press (obtained through the function pressed_key) into the corresponding events (remark that several keys can be simultaneously processed).

Then, the collision behavior of a sprite is described in the module collide. Collision detection is related to a special event which is generated by all sprites subject to collision. This event is generated by all these sprites, at each instant.

The body of the module collide is an infinite loop in which the collision event collide_evt is generated at each instant.  The sprite which generates the event is passed as value to the generate_value function. Then, all generations of collide_evt are considered in turn, and the function collide is called for all (except of course itself) the generated values, that are the other sprites. The return code becomes different from OK (more precisely: ENEXT) when all the sprites are processed. This is detected at the next instant, and there is thus no need of an explicit cooperate to prevent the loop to be instantaneous.

Actually, the collision function implements a very basic algorithm which leads to some unrealistic moves; it can of course be replaced by more realistic (but more expensive!) collision treatments. Moreover, each sprite considers all others sprites, at each instant which is inefficient (complexity in the square of the number of sprites). The algorithm could certainly also be improved in this respect.

Several threads are created, all of them taking s as parameter: an instance of sync_sprite to perform synchronisation of the sprite with the corresponding entry in the table of sprites; four instances of move to move the sprite in the 4 directions, according to 4 corresponding events; an instance of bounce_on_borders to let the sprite bounce on the borders of the applet; an instance of collide to let the sprite collide with other predators.

The overall behavior is made of several components: the specific one, called prey, an inertia behavior, a bouncing one, a synchronisation behavior and a collision one. All these elementary behaviors are stored in behaviors because they must be destroyed when the prey is killed. The definition of the module prey is very close to the one of predator, with 2 changes: first, the events generated and observed are inverted; second, the chase function is changed by a function that make the prey run away from the predator.

After creation of the elementary behaviors, the destroy event is awaited (let us recall that it is generated when the prey is killed by the the predator). Then, an instance of the destroy_sprite module is run in order to deallocate the various behaviors of the prey, and finally the executing thread is deallocated.

At each instant, the event generated by preys (prey_evt) is observed, using the get_value function. If no value with index 0 is available, which means that no prey was present during the previous instant, then new preys are created.  Otherwise, the thread simply cooperates.

First, the two events generated at each instant by preys and predators are created. Then, events corresponding to keys are created with an instance of the module key_handler which convert key presses into events.  An instance of automatic and one of predator_sprite are created. Finally, some global variables are set to correctly parametrize the demo.

One considers three domains related to Loft. The first is the one of threads which either appear as libraries or are incorporated in existing languages.  The second domain is the synchronous-reactive approach from which Loft takes its major constructs.  The third domain contains approaches in which computations are decomposed into small pieces that can be combined to build complex behaviors.

Quick Threads[25] provides programmers with a minimal support for multi-threading at user-space level.  Basically, it implements context-switching in assembly code, and is thus a low-level solution to multi-threading.

Java introduce threads at language level. Actually, threads are generally heavily used in Java, for example when graphics or networking is involved. No assumption is made on the way threads are scheduled (cooperative or preemptive schedulings are both possible) which makes Java multi-threaded systems difficult to program and to port[23].  This difficulty is pointed out by the suppression from the recent versions (1.2) of the language of the primitives to gain fine control over threads[3].

It should be mentioned that the initial version of FairThreads has been proposed in the context of the Java language[12] in order to simplify concurrent programming in Java; this version was however limited to cooperative threads.

FairThreads has been recently introduced in the Bigloo[1] implementation of Scheme.  The present version does not support unlinked threads, but special constructs are introduced to deal with non-blocking cooperative I/Os.

FairThreads and Loft actually belong to the so-called reactive approach[6] which is issued from synchronous languages. One first compare synchronous languages and the reactive approach before describing several reactive programming languages.

To the family of synchronous languages[19] belong several programming languages which all share the same notion of an instant which is supposed to be of zero duration. In this context, the output of a program at a given instant is synchronous with its input; the synchronous characterization of these languages comes from this hypothesis.

Lustre and Signal are two data-flow synchronous languages in which one programs nets of operators, in a style very close to the one of section Data-Flow Programming3.4. At the basis of these dataflow languages are the nets of processes of [24].

The Esterel synchronous language[9] introduces broadcast events, called signals, in an imperative style. However, in Esterel, the absence of an event can be decided immediately and consequences of this absence can take place in the very same instant. This leads to "causality problems" as for example in present S else emit S end. In this program, indeed, the signal S is emitted if it is absent during the instant, which is of course contradictory.

As opposite to Esterel, in reactive programming the absence of an event during one instant cannot be decided before the end of this very instant. As a consequence, the reaction to the absence of one event is delayed to the next instant. This is a way to solve the causality problems which are obstacles to modularity.

All synchronous languages are static in the sense that they disallow the creation at run time of new parallel components and of new events.  Moreover, they do not give users any way to deal with multiprocessor machines. However, synchronous languages generally put the focus on hardware circuits in which dynamic creation does not appear. This is a major difference with reactive programming which limits to software systems.

A major claim of synchronous languages is that they make possible proofs and validations of programs. This is a consequence of the existence of a formal semantics and of the static characteristics of these languages. Program proofs and validations have not yet be considered in reactive programming.

The Reactive-C[11] language was the first proposal for reactive programming in C; in this respect, Loft can be considered as a descendant of it. Reactive-C proposes instants and the merge operator which implements deterministic parallelism. A reaction of the instruction merge i1 i2 consists in a reaction of i1 followed in the same instant by a reaction of i2. Thus, one has a deterministic left-right operator with which parallelism can be introduced at any level.  Reactive-C does not define events, as they are defined in Loft. Reactive-C is basically implemented as a straightforward preprocessor of C.

Reactive-C introduces primitives for remote execution of reactive programs over the network. Remote execution is based on the use of the Remote Procedure Call (RPC) mechanism. Distribution is not yet possible neither in Loft nor in FairThreads.

The definition of Rewrite and Replace in Implementations7 is strongly linked to the implementations with the same names of the Java Junior framework [22]. The use of waiting queues has appeared in the implementation of Junior, called 1, which has been proposed by Laurent Hazard to deal with large number of parallel components and events. The Direct semantics is strongly inspired from it.

As opposite to SugarCubes and Junior, standard Java code can be freely mixed with reactive code. Rejo also introduces primitives for migration of reactive code, implemented using the serialization and the RMI mechanisms of Java.

Chores[16] and filaments[27] are small pieces of code that do not have private stack and are never preempted. Chores and filaments are designed for fine-grain parallelism programming on shared-memory machines.  Chores and filaments are completely executed and cannot be suspended nor resumed. Generally, a pool of threads is devoted to execute them.

Chores and chunk-based techniques are described in details in the context of the Java language in [15] and [23].  Automata in FairThreads are close to chores and filaments, but give programmers more freedom for direct coding of states-based algorithms.  Automata are also related to mode automata[28] in which states capture the notion of a running mode in the context of the synchronous language Lustre[19].

Cohort scheduling[26] dynamically reorganizes series of computations on items in an input stream, so that similar computations on different items execute consecutively. Staged computation intends to replace threads.  In the staged model, a program is constructed from a collection of stages and each stage has scheduling autonomy to control the order in which operations are executed.  Stages are thus very close to instants of FairThreads and cohort scheduling looks very much like cooperative scheduling. In the staged model, emphasis is put on the way to exploit program locality by grouping similar operations in cohorts that are executed at the same stage; in this way, cohorts and staged computations fall in the family of data-flow models.

In Loft, the units of concurrency are threads which are defined as instances of modules. There are basically two kinds of threads: threads which are linked to a scheduler and threads which are unlinked.  A thread cannot be linked simultaneously to several schedulers, but it can link to distinct schedulers during its execution.

All the threads linked to a same scheduler are run in a cooperative mode under the supervision of the scheduler. Moreover, they are sharing events. The threads are run cyclically until all have either cooperated or have reacted to events which are present. The current instant is finished when a stable situation is found in which all the events which are not present can be safely considered as absent. The scheduler can then proceed to the next instant after having incorporated in the system orders sent to it during the instant. These orders can be orders to stop, suspend or resume threads, or to add new created threads.

Several schedulers can be simultaneously present in the same Loft program. Each scheduler defines a synchronous area in which threads run at the same pace, because they share the same instants, and in which events are broadcast, because all threads have exactly the same information on the presence and the absence of events.

It is possible for some threads instances of native modules to run autonomously, unlinked from any scheduler. When it is the case, these threads behave exactly as standard native threads scheduled by the preemptive operating system. However, unlinked threads still have the possibility to link to a scheduler, and then to behave as a cooperative thread. Of course, they can later on return in the unlinked state if they want.

This framework is flexible as the structure of schedulers can evolve dynamically. It actually proposes N:M architectures, with the advantage that there exist a syntax to deal with them (as opposite for example with the threads of the Solaris system of Sun).

Cooperative systems can be coded in a simple way, without the need of locks to protect data. Moreover, instants give automatic synchronizations that can greatly simplify programming in certain situations. Linked threads have a precise and clear semantics. The point is that systems exclusively made of threads linked to one unique scheduler are completely deterministic. This simplifies reasonning about program. It also makes debugging easier.  Thus, in the cooperative context, one gets a simple language for concurrent programming which is deterministic and have a precise semantics.

When a thread unlinks from a scheduler, it becomes an autonomous native thread which can be run in real parallelism, on a distinct processor. Schedulers can also be executed by native threads, on distinct processors. Thus, Loft give the user access to multiprocessing in a very simple way.

Loft has a formal semantics. Actually the semantics is an operational one which describes the steps that should be executed to reach a result. The presence of a formal semantics is not anecdoctical and is useful for at least two reasons: first, it give the exact meaning of programs which can be much more complex than in traditional programming, as a result of concurrency and of the new dimension introduced by instants. The purpose of the semantics is to exactly define what should be the execution of a program made of several concurrent threads along the passing of instants. Second, variants of the semantics are defined in order to model various aspects of the execution. More precisely, a series of semantics variants defines relatively small steps starting from the basic Rewrite semantics and reaching the Direct semantics which is designed to be extremely efficient. One can get strong confidence in each of these steps, and thus see this whole process as a way to validate the implementation. The presence of a formal semantics is in this respect a means for a safer programming.

The language has several implementations. The first one is a direct translation in FairThreads which is an API of threads closely related to Loft. The second implementation Rewrite, which serves as a reference for the cooperative part of the language, is a direct translation of the rewriting rules of the semantics. The Replace implementation optimises the memory use, while the Optim implementation optimizes the waiting of events, to avoid busy-waiting, and can be used for embedded systems with few ressources.

Finally, one would say that the external syntax of Loft could be subject to change in the future. This should not be shocking as, after all, syntax is rather secondary compared to the programming model and to the semantics.

In Loft, as in FairThreads, parallelism is only at top-level. Indeed, there is no parallel construct which can be used at any level, as in Esterel for example. Consider for example a statement of the form (A || B);C, where || is the parallel operator. In it, the parallel operator is not at the root of the syntax tree, but on the left branch of a sequence instruction.  In Loft one must use indirect constructions for expressing parallelism at arbitrary levels of nesting. The previous example could be for instance coded using a join instruction to wait for the termination of both A and B.  A possible extension of Loft would be to introduce a deterministic parallel operator, as for example the one of Reactive-C. Others constructs could also be added to the language; for example, the until module of section Run12.9.10 could be directly introduced in the language as a preemption instruction. One could also consider local events whose extend is defined syntaxically by a language construct, as it is the case in standard reactive programming, such as Junior.

A rather natural extension of Loft would be to interface it with the network.  Thus, distributed synchronous areas could be defined, running on distinct machines.  The difficulty is to give a way for a thread to link to a distant machine. This is a kind of thread migration that would open programming to systems based on agents.

Loft could be rather easily extended to C++. This would simplify the code produced by the Loft translator as classes encapsulating the local data of threads could be generated. Of course, other target languages could also be considered.

Basic units of concurrency are threads which are created as instances of modules and are run under the control of schedulers. Threads can synchronize and communicate using broadcast events. Threads linked to the same scheduler run in a cooperative way, leading to deterministic systems. Threads can dynamically change their linking to schedulers. Moreover, special native threads have the possibility to stay unlinked from any scheduler, becoming then autonomous.  Unlinked threads can be executed in real parallelism.

Loft code is a mix of standard C code and of modules.  Loft code is first preprocessed (typically by the gcc -E command), then translated into C, and finally compiled by the C compiler in order to get executable code.

A module is native when the keyword native follows module. Native modules should only be used in programs run by a preemptive operating system (Linux for example).  Instances of a native module must be implemented as kernel threads.  Instances of non-native module do not need specific kernel threads to execute (they can use the one of the scheduler to which they are linked).

A program containing a module named main can be directly executed. The parameters of main must follow the argc/argv conventions of C.  The translation of the main module, first creates a new instance of the module and an implicit scheduler, then adds the new thread in the implicit scheduler, and finally makes the implicit scheduler react cyclically.

Automatic variables declared in blocks of C instructions (of the form {...}). These variables can appear in declarations of C functions, or in atomic instructions, in module definitions. Automatic variables are allocated when the control enters the block in which they are declared, and destroyed when the block is left.

Local variables and parameters must always be explicitly tagged by the keyword local to distinguish them from global or automatic variable with same names: all uses of a local variable or parameter x must be of the form local(x).

A phase of a scheduler consists in giving the control in turn to all the ready threads which are linked to it. The order in which the threads receive the control is the order in which they have been linked to the scheduler. During an instant, the scheduler executes cyclically a serie of phases, up to a situation where no thread remains blocked. Then, the scheduler decides that the current instant is finished, and it can then proceed to the next instant. Thus, at the end of each instant, all ready threads either have terminated or have cooperated.

The scheduler decides that the current instant is finished when, at the end of a phase, there is no possibility for any blocked thread to progress: no awaited event has been generated, and no new value has been produced which could unblock a thread trying to get it.

Events are used by thread to synchronize and to communicate.  Events are of type event_t. An event is always created in a specific scheduler which is in charge of it during all its lifetime. The function event_create returns an event created in the implicit scheduler. The function event_create_in returns an event created in the scheduler in argument.

At each instant, events have a presence status which can be present, absent, or unknown. All events managed by a scheduler are automatically reset to unknown at the beginning of each new instant (thus, events are non-remanent data). All events which are unknown become absent when the scheduler decides to terminate the current instant (see Instants12.4.1).

One can associate values to generations of events. All values associated to the generations of the same event during one instant are collected in a list, as they are produced. They are available only during the current instant, using the get_value instruction (Get Value12.9.6).

The execution of generate(exp) starts by the evaluation of exp which should return an event e. If the executing thread is unlinked or if the scheduler sched in charge of e (the one in which e has been created) is different from the one of the thread, then the order is sent to sched to generate e at the beginning of its next instant.  Otherwise, e is immediately generated in sched.

The execution of generate(exp,exp) starts by the evaluation of the two expressions in argument.  The first one should return an event e, and the second one a value v of a pointer type (void*). The execution is the same as the one of the previous call, except that v is added as last element to the list of values associated to e at the instant where e is generated.

The unlink instructions should only appear in native modules.  It has no effect if the executing thread is already unlinked. Otherwise, the thread executing the instruction returns back the control to the scheduler, signaling it that it cooperates. In this case, the thread is removed from the scheduler which thus will never consider it again (except, of course, if the thread re-links to it later).

A thread executing link(exp) first evaluate exp which should return a scheduler sched.  If the thread is already linked, it unlinks from the scheduler to which it is linked, and then waits for sched to give it the control.  If the thread is unlinked, it just waits for the control from sched.  In all cases, sched will resume execution of the thread, as it does for new created thread, at the beginning of the next instant.

Atomic instructions have the form of blocks of C code or of C function calls. They can be executed by linked and unlinked threads, with the same semantics, which is actually the one they have in standard C. However, when executed by a linked thread, execution of an atomic instruction is instantaneous, which means that it terminates in the same instant it is started.

All orders received by a scheduler during one instant are systematically processed at the beginning of the next instant (to avoid interference with executing threads) in the order in which they are issued.

The execution of stop(exp) starts by the evaluation of exp which should return a thread th. The effect of the call is undefined if th is unlinked.  Otherwise, the order to terminate th is sent to the scheduler to which it is linked.

The execution of suspend(exp) starts by the evaluation of exp which should return a thread th. The effect of the call is undefined if th is unlinked.  Otherwise, the order to suspend th is sent to the scheduler to which it is linked.

Non-atomic instructions should only be executed by linked threads, and their semantics is undefined when they are executed by unlinked threads. Execution of non-atomic instructions can take several instants to complete.

A thread executing cooperate returns the control to the scheduler, signaling it that it cooperates. If the thread regains control in the future, it will resume execution in sequence of the cooperate instruction.

A thread executing halt returns the control to the scheduler, signaling it that it cooperates. If the thread regains control in the future, it will re-execute the same halt instruction. Thus, halt blocks the thread forever, without never terminating it.

The expression should evaluate to an event e. If e is present, then the thread proceeds in sequence of the await instruction.  Otherwise, if the current instant is finished (which means that e is absent), then the thread returns the control to the scheduler, signaling it that it cooperates.  If the thread regains control in some future instant, execution will restart at the same place, waiting for the same event e.  If the current instant is not finished, then the thread returns the control to the scheduler, signaling it that it is blocked.  When the thread will regain the control, it will, as previously, continue to test the presence of e.

A thread executing await(exp,exp) first evaluates the two arguments. The first one should evaluate to an event e, and the second one to an integer value k. Then, the thread behaves as the previous instruction, but the waiting of e is limited to at most k instants. If e is generated during the next k next instants, then the return code of the thread is set to OK.  Otherwise, if e is still absent at the end of the kth instant, then the thread returns the control to the scheduler, signaling it that it cooperates ; moreover, the return code of the thread is set to ETIMEOUT. In this case, the thread will proceed in sequence when receiving the control back (just as the cooperate instruction does).

The expression should evaluate to a thread th.  If th is terminated, then the thread proceeds in sequence of the join instruction. Otherwise, the thread behaves as if it was awaiting a special event generated by the termination of th.

A thread executing join(exp,exp) first evaluates the two arguments. The first one should evaluate to a thread th, and the second one to an integer value k. Then, the thread behaves as the previous instruction, but the waiting of the termination of th is limited to at most k instants.  The return code of the thread is set to ETIMEOUT if the limit is reached, and it is set to OK otherwise.

Then, the thread tests if there are at least k values generated for e during the current instant. If it is the case, the kth value is assigned to var, the return code of the thread is set to OK, and the thread proceeds in sequence.

Otherwise, if the current instant is not finished, then the thread returns the control to the scheduler, signaling it that it is blocked. When the thread will regain the control, it will, as previously, continue to test the existence of the kth value.

If the current instant is finished, then the return code of the thread is set to ENEXT, and the thread returns the control to the scheduler, signaling it that it cooperates. When the thread will regain control, it will proceed in sequence (just as a cooperate instruction would do).

A thread executing if(exp)then i else j end first evaluates exp. If the evaluation returns true (a non-zero value) then the thread switches to i, else it switches to j. If the chosen branch is empty, the thread proceeds in sequence immediately.

A thread executing while(exp)do i end first evaluates exp. If the evaluation returns false (zero) then the thread proceeds in sequence of the loop. Otherwise, the thread behaves as if it was executing i, with one difference: when execution of i terminates, then exp is re-evaluated and the same process restarts: execution is left if evaluation returns false, and otherwise i is re-executed. Thus, the thread cyclically executes i while exp is true, exp being evaluated at the first instant and, after that, only when i terminates.

A thread th executing run m(e1,...,en) first creates a new instance of the module m with e1,...,en as arguments, and then joins the new created thread. Moreover, the new created thread is stopped if th is.

Stands for Symetric Multi-Processor.  An architecture of a multi-processor machine in which the assignment of the processors to the threads is highly dynamic and depends on the operating system, and only of it.

It is light (the running process occupies less than 4MB) and fast. The patch (applicable to the version 0.1.3) fixes a nasty bug of window focus and a incompatibility with Emacs focus/unfocus operations. I use pekwm in conjunction with a thin toolbar.

Scheme based programming style where C(++) is usually required. Bigloo attempts to make Scheme practical by offering features usually presented by traditional programming languages but not offered by Scheme and functional programming. Bigloo compiles Scheme modules. It delivers small and fast stand alone binary executables. Bigloo enables full connections between Scheme and C programs, between Scheme and Java programs, and between Scheme and C# programs.

The Bigloo run-time system and the libraries are distributed under the terms of the GNU Library General Public License The compiler and the tools are distributed under the terms of the GNU General Public License.

Bigloo. It aims at helping the debugging of Bigloo programs that are compiled into JVM bytecode. It is implemented by means of the JVM Debugging Architecture, a set of standard APIs provided by Sun to make debuggers and profilers.

Currently, Bugloo can debug Bigloo programs, Java programs or a mix of both by instrumenting their execution. It is based on the debugging model found in GDB, but provides additional fonctionalities to deal with the features of modern programming languages. Such fonctionalities include debug sessions, traces, memory debugging, programmable breakpoints or embeddable interpreters.

Bugloo is a command-line debugger: users control the execution of their program by means of a Scheme-like command language. For the sake of simplicity, it provides a complete debugging environment for the GNU Emacs and XEmacs editors. Parts of the debuggers are also accessible through a Swing-based GUI thanks to the Biglook toolkit.

Fair threads are cooperative threads run by a fair scheduler which gives them equal access to the processor. Fair threads can communicate using broadcast events, and are fully portable as their semantics does not depends on the executing platform. Fine control over fair threads execution is possible allowing the programming of specific user-defined scheduling strategies. FairThreads is implemented in Java through an API.  Reactive programming is at the basis of the fair threads proposal.

FairThreads is fully compatible with the standard Pthreads library and has a precise and clear semantics for its cooperative part; in particular, systems exclusively made of threads linked to one unique scheduler are actually completely deterministic.

Special threads, called automata, are provided for short-lived small tasks or when a large number of tasks is needed. Automata do not need the full power of a native thread to execute and thus consume less resources.

Description:Reactive-C is a preprocessor for reactive programming in C. Reactive-C is used as a "reactive assembly language" to implement several reactive formalisms, as the synchronous language SL, Reactive Scripts, or Icobjs Programming.

Description:Junior defines an API for reactive programming in Java. Junior can be seen as the SugarCubes kernel.  There are several implementations, some of them for processing huge number of parallel components and events.

Description:FairThreads is a basically cooperative thread framework in which fair threads are run by a fair scheduler that gives them equal access to the processor.  FairThreads has a formal semantics, and an efficient implementation.

Description:LOFT is an extension of C which introduces fair threads run by fair schedulers. Fair threads which are linked to a same scheduler are basically run in a cooperative way, with an equal access to the processor.  LOFT has a formal semantics, and several implementations. One of them is based on FairThreads. An other one is dedicated to embedded systems with limited resources.

One describes the main parts of the code of a demo of a small preys-predators system implemented for the GBA platform.  A predator moves using the arrow keys. Preys are running away from predators and are killed when a predator is sufficiently close to them. New preys are automatically created.  A predator is put in an automatic chasing mode with key 'a' and returns in the manual mode with 'b'.  More predators can be created with 'l', and more preys with 'r'. A screenshot of the demo running on the VisualBoyAdvance emulator is shown on figure Demo. The predator is the ghost and the preys are the pacmans. This demo is available at the Web site http://www.gbadev.org.

Destruction of a sprite is performed using the module destroy_sprite shown on figure Destruction.  First, all components of behaviors are stopped. Then, at the next instant, they are deallocated (by thread_deallocate) with the sprite structure itself. Finally, the executing thread (returned by self) is deallocated.

The purpose of the module key_handler of figure Key Handler is to convert at each instant, the  key press (obtained through the function pressed_key) into the corresponding events (remark that several keys can be simultaneously processed).

The module key_processing of Key Processing associates a callback (of type void (*callback_t) ()) to a key. 10 instants are passed when a key press is detected, in order to give enough time for the key to be released.

The collision elementary behavior of a sprite is described in the module collide of figure Collision. Collision detection is related to a special event which is generated by all sprites subject to collision. This event is generated by all these sprites, at each instant.

The collision function implements a very basic algorithm which leads to some unrealistic moves\; it can of course be replaced by more realistic (but more expensive!) collision treatments. Moreover, each sprite considers all others sprites, at each instant which is inefficient (complexity in the square of the number of sprites). The algorithm could certainly also be improved in this respect.

The prey sprite is defined in the module prey_sprite of figure Prey Sprite. The overall behavior is made of the specific one, called prey, an inertia behavior, a bouncing one, a synchronisation behavior and a collision one. All these elementary behaviors are stored in behaviors because they must be destroyed when the prey is killed. The definition of the module prey is very close to the one of predator, with 2 changes: first, the events generated and observed are inverted\; second, the chase function is changed by a function that make the prey run away from the predator.

With the module automatic of figure Automatic, new preys are automatically created, after a while, when there is none in the system. At each instant, the event generated by preys (prey_evt) is observed, using the get_value function. If no value with index 0 is available, which means that no prey was present during previous instant, then new preys are created.

Nowadays a big number of applications react with another systems, this interaction led to the construction of systems specially adapted to this kind of behavior and to the development of new techniques to build it, for instance the synchronous approach. The notion of reactive system was introduced by D. Harel and A. Pnueli [1] who were the first that identified these systems. Using this definition, there were created an important number of languages that use the reactivity, for example Esterel, Lustre, Signal, etc.

This section presents the general concepts of one of the implementations of the synchronous approach which is used for implementing REJO, Junior. In fact Junior presents some important differences with the Synchronous model that allows it to eliminates causalities problems, for instance the delayed reaction to the absence and the weak preemption. For more information about Junior and the Synchronous approach read [3, 4, 5] and respectively [2, 12].

They are cyclic because they do not stop. They do not correspond to the traditional notion of program that we execute with data and that, after some time, finishes giving a result. The reactive system reacts with its environment.

They must be sufficiently fast so as to follow the environment evolutions. Actually we consider that the environment determines the rhythm of its activations: a reactive system reacts to each activation according to the environment state, transforming them, then it waits the following activation and so on.

A reactive instruction defines a reactive behavior. In Junior, for example, there are 16 reactive instructions that allow programmers to describe a widely set of behaviors, for instance, to wait for an event, to implement loops, to preempt instructions and soon. The set of reactive instructions used in REJO is described in detail in the following section.

SUSP (by suspend) means that the execution of an instruction has not achieved a stable state and that it must follow its execution in the following instant. It's the case when an instruction waits for an event that has not been generated; the execution is suspended so as to allow the other instructions the possibility of generating it.

A reactive machine has two main roles: to define the instants of its program and to carry out its events. A machine finishes the actual instant when all the parallel instructions of the program are finished or stopped (any instruction of the program is suspended). Otherwise, while there are suspended instructions, the machine activates cyclically the program. At the end of each activation, the machine tests whether there was a change during the activation (in fact the machine tests if there was generated a new event), if there isn't anyone, there is no possibility that other activations unblock the situation. In that case a flag is set for defining the end of instant, this allows the suspended instructions to be stopped.

This section presents a brief description of the main syncronous languages as well as pointers to documentation, online information and people. In general the description was taken from the home web page.

Extensive optimization is available. We provide a graphical symbolic debugger for Esterel. We also provide support for explicit or BDD-based verification tools that perform either bisimulation reduction or safety property checking.

Esterel is now experimentally used by several companies and taught in several universities. Esterel and SyncCharts are commercialized by the Simulog company. They are used by companies such as Dassault Aviation for avionics, Thomson for telecommunication, Texas Instruments for DSP circuits development, etc. Cadence and University of California Berkeley are using Esterel in their Polis hardware / software codesign environment. CMA and INRIA also cooperate with Synopsys and Intel on Esterel.

LUSTRE is a synchronous declarative language for programming reactive systems. It is declarative because a description is a set of equations that must be always verified by the program variables. This approach was inspired by formalisms familiar to control engineers, like systems of differential equations or synchronous operator networks (block diagrams). A program variable in LUSTRE is considered to be a function of multiform time: it has an associated clock which defines the sequence of instants where the variable takes its values. LUSTRE is the kernel language of the SCADE (formerly SAO+/SAGA) industrial environment developped by Telelogic.

Compilation: The compiler Lustre-V4 produces sequential code by synthesizing the control structure of the object code in the form of an extended finite automaton. Several levels of details of this control structure (ranging from a single loop structure to a very detailed automaton) can be chosen.

Code Distribution: A tool for the distribution of sequential code produced by the LUSTRE compiler according to directives of the programmer, has been developed in cooperation with Merlin Gerin. The tool will be integrated in an execution environment for distributed programs. Finally, a partial order semantics for LUSTRE is under study to provide the user of the tool a better insight about the meaning of distributed synchronous systems based on a relaxation of the synchrony assumption.

Verification: It has been shown that LUSTRE can be considered as a temporal logic allowing the expression of safety properties. This allows the description of both the program and the specifications in the same language.

The verification tool LESAR is a model-checker for verifying Lustre programs specified in that way. It considers a finite model of the program, similar to the automaton produced by the compiler. So it is only able to verify properties depending on the control (i.e., the Boolean part) of the program. Some extensions towards numerical properties are also studied.

Automatic Testing: Given the same kind of specification than for verification, the tool LURETTE is able to generate an arbitrary number of arbitrarily long input sequences to a program, satisfying specified assumptions, while testing that the specifyed properties are satisfied.

Signal is a data-flow language (although not in the exact sense of Kahn's process networks). So the objects are flows, i.e., infinite sequences of values. They are called signals. Each signal has a clock which is the sequence of instants where the signal has a value. At any instant of its clock, a signal can be present and have a defined value, or be absent and have the value bot.

Unlike in Lustre, there is no global clock. Instead, the notion of clock is local. If two signals have the same clock, then whenever one has a value, the other one must also have one, and when one has no value (i.e., a bot), the other one must also have a bot.

Lucid Synchrone is a synchronous stream language dedicated to the implementation of reactive systems. It combines features of Lustre and ML languages. The name Lucid Synchrone is built from Lucid a data-flow language managing streams and from the French word ''synchrone'' (for ''synchronous'').

It is a strongly typed, higher-order functional language managing infinite sequences or streams as primitive values. These streams are used for representing input and output signals of reactive systems.

Several static analysis (e.g, type inference, clock calculus, causality, initialization check) are provided. In particular, the language is founded on the notion of clocks as a way to specify different execution rates in a program. The program must in turn verify some clocking rules, insuring reactivity (i.e, compilation into a finite transition system).

David Harel introduced statecharts to extend finite state machine for complex behavior and to describe a visual formalism. Objectcharts were then presented by Derek Coleman et.al. as an extension to describe how to use statecharts in object-oriented environment to describe the lifecycle of an object. Statecharts were used by Bran Selic as an implementation mechanism for Recursive Control. Alternatively, we perceive that statecharts are frequently used as a behavior description technique and using an object-oriented design of statechart provides flexibility at the design level and facilitates the design maintainability.

Statechart is a specification language which enables you to construct a model and further check it. Some case tools allow you to genertae code from your specification. Using the generated code might not be useful because it is usually bulky and not comprenhensible for the designer. Thus you want to translate the specification into design that allow you to have a higher level of maintenance and to embed this design into your overall application design.

Mixing Lustre and Argos would allow a mixed imperative/declarative style for programming reactive systems. Mixing Argos and Esterel can be viewed as a way of introducing a automaton-like control structure in Esterel.

The SL language is a synchronous language in which reactions are instantaneous. Its syntax is close to esterel, but in SL hypotheses about signal presence/absence are disallowed. One decides that a signal is absent during an instant only at the end of this instant, and so reaction to the absence is delayed to the next instant.

Sources of causal circularities (the so-called causality cycles) are avoided, and the main features of the synchronous approach still remain: the expressive simplicity and power of parallelism, the ease of specification and debugging for deterministic programs, and the power and modularity of broadcast and instantaneous dialogs. However, "strong" preemptions are not possible in SL, and only "weak" ones can be used.

Forbidding immediate reactions to signal absences simplifies the implementation to a large extent (the existing implementation is less than 1000 Reactive-C lines). In addition to directly execute programs, the implementation can also be used to produce automata by symbolic evaluation.

The language is ANSI-C with added constructs inspired by Esterel for specifying reactivity (signal communication, pre-emption, and concurrency). It conveniently supports specification of mixed control/data modules. The compilation is performed by splitting the source code into reactive Esterel code and data-dominated C code. The reactive portion can be robustly optimized and synthesized to either hardware or software, while the C residual code must be implemented in software as is.

The project started in 1988 with the idea of allowing a programming style close to C, in which program behaviors are defined in terms of reactions to activations. Reactive-C (RC) programs can react differently when activated for the first time, for the second time, and so on. Thus a new dimension appears for the programmer: the logical time induced by the sequence of activations.

The present RC compiler is the rcc version 3 compiler. It works as a pre-processor of C, and is about 2500 lines of Ansi-C. It runs on several Unix platforms and also on DOS/PC. It is free software. Actually, Reactive-C appeared rapidly as being a kind of reactive assembly language that could be used to implement higher level formalisms based on the notion of an instant.

A first implementation, called REWRITE, is the direct implementation of the semantics. It is thus the reference implementation. In REWRITE, the program syntax tree is analysed and rebuilt at each activation. A second implementation, called REPLACE, avoids program rebuildings and is thus much more efficient than REWRITE. The technics used by REPLACE is actually very close to the one of SugarCubes. A third implementation, called SIMPLE, avoids the traversal of the whole program at each activation. Instructions waiting for an event are posted in a file associated to the event. Thus, posted instruction are no more processed until the firing event becomes generated. This leads to the possibility of using huge numbers of events while preserving good response time.

A boolean flag move(E) which is set to true to indicate that some change has appeared in the system; in this case, the end of the current instant must be dalayed to let the system possibility to react to this change.

There are two REJO sentences to invoke a reactive methode: in-line and call. In-line is not a Junior instruction; it just puts the Junior instructions in the line where the keyword appears. Unlike in-line sentence, call is really a Junior instruction (called Run) that behaves like another instruction, i.e. it executes a program returned by a Wrapper. In other words, one can see the in-line instruction as the static execution of a reactive method and call as the dynamic execution.

Note that, in all the rules of Par, production of a flag different from SUSP is only possible when both branches have also produced a flag different from SUSP; this reflects the synchronous characteristics of the parallel operator which, at each instant, executes its two branches.

Note that the body t is executed in both rules; preemption of Until is said to be weak, by contrast with the strong preemption used in the synchronous approach, which basically implies instantaneous reaction to absence.

Execution context rewritings have the forme e => e' meaning that reaction of the execution context e leads to the new execution context e'; b is a boolean which is true if the execution context e' is completely terminated.

Add the notion of Reactive Method. For doing this the section two of the previous description was modified to insert a new production rule ( RMethodDeclaration ), in particular it was modified the class production rule.

The following table shows the number of production rules used by Java and REJO. As you can see REJO defines less than the half Java productions because it reuses Java productions. The only case where REJO has more productions rules is in the definition of Flow Control Structures; this is normal because REJO is richer describing behaviors.

GeneralSolutionWithThreads contains the generic thread-based solution using a synchronizer object in Synchro.java. The basic code is in SyncThreads.java and the corresponding applet is in SyncThreads.html.

The package inria.meije.rc.sugarcubes contains the programming interface of the SugarCubes framework. The user founds in it Java interfaces and classes needed for building and executing reactive programms. The inner package inria.meije.rc.sugarcubes.implementation contains classes implementing reactive primitives of the SugarCubes and classes implementing reactive machines and execution environment.

Copy of programs are added in a reactive machine. This alows reactive machines to do some manipulations over a program in order to release memory of terminated components and to reconfigure the instruction tree to get full gain of the new algorithm of execution called Storm. It also prevents external manipulations of the program. This can be safer in a multithreaded environment.

Local variables dynamicaly bound (at this time) has been also introduced. The scope of these local variables is structurally defined as for local event declarations. But nested Link operators (and by that way Cubes and Machines) restrict the scope of these variables.

This simple example illustrates the use of reactive instants. During five instants, the program progress (one step at each reaction of the execution machine) and the stop primitive is used to set the boundaries of an instant in a sequence of instructions.

The HelloCube example illustrates the use of a Cube in a SugarCubes program. The Cube here implements a window which contains a button. By pressing the button the user generates an event "Hello" in the reactive machine, which trigger the execution of the body of the cube which awaits for the event "Hello" (windowBehavior). This causes the Window to change its title from nothing to "Hello World!" (the HC_DisplayHello java atomic action).

On the other hand by clicking the close box of the window, the user generates the destruction event associated to the window/cube, triggering its preemption which results in the termination of the program, executing the termination notification to Java (HC_Dispose).

This package contains an implementation of the famous reflex game designed by Frederic Bousssinot in ReflexGame. There is a basic version and a distributed version that use a dedicated process for the counter and another process for the game client communicating with RMI.

This demo illustrates the use of the new communication mechanism between parallel components introduced by SugarCubes v3.0: Valued occurences of event. This mechanism is fully compatible with the notion of event introduced since SugarCubes v1.0, but it allows now to communicate more informations (numerical values or objects) between parallel components.

When an event is generated, for example using the Generate primitive (SC.generate), a list of numerical values or objects can be associated to this generation. This list is memorized by the event structure as a new occurence during the instant. At each end of instant occurences of events are discarded.

This doesn't interfere with the classical pure event communication, as valued occurences are only handled by one special primitive called Callback (SC.callback). A Callback can scan every occurences of an event during one instant. All Callback primitives will be activated once for each occurences of an event during the instant they appear, and this in the same order as they are generated in the environment. So, every parallel components that have a Callback on the same event will see exactly the same occurences in the same order during one instant.

When activated a Callback receives a set of values associated to the occurence that has triggered the activation of the Callback. The Callback reacts by executing an atomic action which can handle those values. A Callback only terminates at the end of the instant, when no more generation of the event, to which it is bound to, can occure.

This demo makes an intensive use this powerfull broadcast communication mechanism. All reactive objects in this demo (spiders and workspaces) are parallel components (cubes) communicating together using this broadcast event mechanism. No one of those objects has any reference to the other objects in the system. So, by that way,objects are designed without having to take care of any other objects. The only point to be careful with, in order to acheive a good communication, is the event protocol and types of values associated to an occurence of event. This provide a great modularity in the design of applications.

To display things, a workspace generates at each instant an event "Display Here" with its graphical context as a value. As events are broadcast, the workspace doesn't have to take care about how many and which objects in the system have to be displayed. Spiders in this example have a Callback which scans the event "Display Here" and reacts to any occurence of this event by drawing their image in the associated graphical context. If their is no spiders in the system nothing will be displayed. If their is no workspace, spiders will not be displayed but they continue to be executed. If their is more than one workspace, spiders will be displayed during the same instant in each of them, so, one gets exactly the same picture in all workspaces (Coherence between the pictures is acheived naturally by the synchronous model - no need to implement synchronization protocol -).

To handle collision with each other, a spider generates at each instant an event "I am Here" with associated values made of the current position of the spider and its current speed. Every spider also has in its behavior a Callback on the event "I am Here". This Callback scans every occurences of the event and reacts by executing an atomic action which handles the collision for this particular spider. This protocol is very heavy because you have an N^2 algorithm. But the symetry of the computation of a collision between two objects can rather be easilly split other a distributed system for example.

The jar file contains sources and compiled classes. So, you can directly execute the callback demo just by adding the SugarCubesv3.0.3.jar package and the callback.jar package directly in your CLASSPATH.

The first button of the control panel allows you to build new Icobjs which in this case are small spiders animated by an inertial behavior. Spiders bounce on borders of the workspace (windows named MainFrame x) and can collide together.

While dying (because the workspace they are attached to has been closed) spiders still exist for a period of random duration. but they move no more and no more interract with other living spiders. Then they desappear for ever.

This will enable other threads to be executed as the react method will explicitly release the control in order to fit the timming constraints. The enableTimeReserve will enforce the react method to sleep (if needed) in order to have a duration of at least 1/30 milliseconds.

This rather complex demo illustrates the code migration capabilities of SugarCubes. It shows how to use the ability to freeze some components of a program at the end of an instant (when the reactive system is known to have reach a consistent state). It also shows how the support of the serialization mechanism of Java in SugarCubes provides a powerfull mean to marshall, to communicate and then to unmarshall programs very easly using RMI. Finally, it demonstrates the use and the flexibility of hierarchical constructions made of Cubes and reactive machines (which are particular kind of Cubes in SugarCubes), to implement migration of a group of components without loosing synchronization among components of the group.

In this demonstration, one uses RMI as the network communication mechanism between reactive sites. This provides very simple mechanism to implement code migration. Most of the migration examples presented in the demo are what one calls objective migration examples. That is to say the user of the demo decides when and where some executing code (Cubes) should be frozen and migrated to another location. On the other hand, subjective migration (a piece of code decides to migrate itself to another location according to its own behavior) can also be exibited in the demo.

A reactive site is a simple process that handles a reactive machine. Basically this reactive machine only contains a halt instruction to avoid termination of the reactive machine. This reactive machine can receive new program from the network asynchronously using a dedicated rmi server (when received programs are added in parallel in the reactive machine, between two instants).

The user can start many reactive sites on different computers or even on the same if they have different names. Reactive sites are identified by the name of the host machine and a name of the site, which should be unique.

On the top of that network of reactive sites, one builds an application demo, which is made of a reactive machine (not a the same as the reactive machines used by reactive sites), which encapsulates some reactive programs. One calls this applicative reactive machine the "Agent Sin/Cos Demo". Remember that a reactive machine is also a reactive program so we have made a tool that can send a new instantiation of the "Agent Sin/Cos Demo" to a reactive site.

The applicative machine is added into a reactive site as any other reactive program (because in SugarCubes a Reactive Machine is also a program as any other instructions). When executed on reactive site, an applicative reactive machine executes its own program, which process the reactive objects it encapsulates.

The first one awaits for the event "cos" (generated when the user clicks on the cos button or on the sin & cos button) and then execute cyclically an horizontal movement according to a displacement following a cosines function.

The second one waits for the event "sin" (generated when the user clicks on the sin button or on the sin & cos button) and then execute cyclically an vertical movement according to a sinusoidal displacement.

The first label of this window indicates the object in which this group is encapsulated (in this example this is the applicative reactive machine toto). the label on the second line of components indicates the name of the group (which is also indicated in the title of the window) using the color associated to the group (green in this case). Then a text field allow the user to type the name of a new object to add to the group (in this case the Icobj named toto_icobj_0) and finally the button "move in" validate the operation and take the indicated object in the reactive machine and adds it into the group to be executed in parallel with other components of the group. When added to a group, an Icobj gets a mark of the color of the group.

First one gives the name of the target host (or the IP address) where the target applicative reactive machine running. In the next text field, the user enters the name of the target reactive machine (in this example: titi). Finally, the last text field should contain the name of the object to migrate (for example in this case the Icobj toto_icobj_0). The user validates the action by clicking the button "OK". Then, the Icobj is frozen and extracted from the current reactive machine (toto) and then sent across the network to the distant applicative reactive machine (titi), where, if it can retrieve an execution environment, it will be executed. Groups of objects can be migrated also.

After execution of the previous command, the targeted reactive site is populated with a new reactive program (obtained through the network) which is a nested reactive machine which executes the Agent SinCos demo. This nested machine is bound to a Java Frame titled "Agent Sin/Cos Demo: toto" which has a reference to another Frame acting as a Control panel with a set of buttons (This Frame is titled "Controller toto").

Witnesses and counterexamples produced by model checkers provide very useful source of diagnostic information. They are usually returned in the form of a single computation path along the model of the system. However, a single computation path is not enough to explain all reasons of a validity or a failure. Our work in this area is motivated by the application of action-based model checking algorithms to the test case generation for models formally specified with a CCS-like process algebra. There, only linear and finite witnesses and counterexamples are useful and for the given formula and model an efficient representation of the set of witnesses (counterexamples) explaining all reasons of validity (failure) is needed. This paper identifies a fragment of action computation tree logic (ACTL) that can be handled in this way.

Moreover, a suitable form of witnesses and counterexamples is proposed and {\em witness} and {\em counterexample automata} are introduced, which are finite automata recognizing them and an algorithm for generating such automata is given.

In this presentation identify a set of common problems that exist when trying to do peer-to-peer interactions for Web Services that are behind firewalls or not generally accessible. In particular we describe methods to support reliable long running conversation through firewalls of Web Service peers that have no accessible endpoints.

WSD can forward HTTP RPC connections or use WS-Addressing for asynchronous messaging between clients and Web Services. Additionally we describe how Web Services clients such as applet that can not have public endpoint can become Web Service peer by using additional message store-and-forward services provided by WSD.

Distributed Java applications use remote method invocation as a communication means between distributed objects. The ProActive library provides high level primitives and strong semantic guarantees for programming Java applications with distributed, mobile, secured components. We present a method for building finite, parameterized models capturing the behavioural semantics of ProActive objects. Our models are symbolic networks of labelled transition systems, whose labels represent (abstractions of) remote method calls. In contrast to the usual finite models, they encode naturally and finitely a large class of distributed object-oriented applications. Their finite instantiations can be used in classical model-checkers and equivalence-checkers for checking temporal logic properties in a compositional manner.

We present the complete process of a formal specification and verification of the Chilean electronic invoice system which has been defined by the tax agency.  We use this case study as a real-world and real-size example to illustrate our methodology for specification and verification of distributed applications.  Our approach is based on a new hierarchical and parameterized model for synchronised networks of labelled transition systems. In this case study, we use a subset of the model as a graphical specification language. We check this formal specification of the invoice system against its informal requirements, described in terms of parameterized temporal logic formulas. Their satisfiability cannot be checked directly on the parameterized model\,: we introduce a method and a tool to instantiate the parameterized models and properties, allowing to use standard (finite-state, bisimulation-based) model-checkers for the verification.  We also illustrate the use of different methods to avoid the state explosion problem by taking advantage of the parameterized structure and instantiations.

Most implementations of object systems base their communication mechanisms on costly protocols at the level of passing of messages. The most popular example is TCP with its excessive exchange of messages on the transport layer (or network according to OSI model).

In this brief seminar, the design and implementation of a communication protocol among remote objects in the Aleph system is presented. The protocol seeks to minimize message exchange on the network and therefore to improve the performance of invocations. This protocol is based on the integration of several traditional techniques: sequence of messages, management of epochs for the treatment of failures, beatings for service delays and taking advantage of messages toward other objects for the delivery of acknowledgments.

We present techniques for analyzing the source code of distributed Java applications, and building finite models of their behaviour. The models are labelled transition systems, representing the communication events between the distributed objects. When combined with techniques for abstracting the data values used by the programs, and especially values used in the creation of distributed objects, to bounded domains, our construction terminates.

We provide models suitable for automatic verification, and typically for model checking. Moreover our models are structured in a compositionnal way, so that we can use verification techniques that scale up to applications of realistic size.

Some attractive point is that IRC algorithm supposes good behavior in losely-coupled distributed environments. Uses of soft-state techniques will be considered for possible for performance improvements.

Regarding that the DGC must be comprehensive, correct, expedient and efficient. The work must achieve a tunnable DGC that probably will combine several garbage collection techniques mainly adapted for structures like Network Objects.

ProActive is a GRID Java library for parallel, distributed, and concurrent computing, also featuring mobility and security in a uniform framework. With a reduced set of simple primitives, ProActive provides a comprehensive API allowing to simplify the programming of applications that are distributed on Local Area Network (LAN), on cluster of workstations, or on Internet Grids.

The central component of the platform is a method for generating finite models for distributed applications, from static analysis of source code. We base this generation procedure on the strong semantic features provided by the ProActive library, and we generate compositional models using synchronised labelled transition systems.

One long term goal of this work is to integrate the various techniques and tools involved in this software platform, so that the platform can be integrated in a development environment, and used by non-specialists.

The C++// language (pronounce "C++ parallel") has been designed and implemented with the aim of importing reusability into parallel and concurrent programming, in the framework of a MIMD model. C++// defines a comprehensive and versatile set of libraries using a small set of simple primitives, without extending the syntax of C++.

Centaur system, this semantics permits to generate an interactive environment for parallel object-oriented programming and  visualization. We  provide  features  such  as  graphical representation of objects, visualization of closure and semantic rules, and animation tools to show  the  concurrent  activities  of objects.

The interest of this approach is to formally introduce parallelism within the framework of the Eiffel language, and more generally in object-oriented programming, leading towards formal transformations and parallelization for object-oriented languages.

It provides a parallel version of the sequential class binary_tree, which describes the management of a sorted binary tree with two routines  insert and  search: each node of the tree has two children ( left and  right), an information ( info) and an associated key ( key); keys of the left (resp. right) subtree of a node are smaller (resp. greater) than the key of this node.

In that example, the default fifo behavior and the wait-by-necessity ensure that all insertions are handled in a correct order, and before the search; the parallel system preserves the semantics of the sequential one.

We need to define some structures which describe the global configuration of a system. During execution, an Eiffel// system is composed of objects. Each object in the system has a configuration (attribute values, activity, pending requests); the collection of all object configurations is the configuration of the system. For modeling objects (with their activity) during execution, we need a structure (based on an abstract syntax).

We present a graphical environment for parallel object-oriented programming. It provides visual tools to develop and debug object-oriented programs as well as parallel or concurrent systems. This environment was derived from  a structural operational semantics of Eiffel//.

The outcome of such an approach is twofold: (i) a pedagogic environment to demonstrate concepts of object-oriented programming, actor computation, and formal semantics; (ii) a step towards environments for the formal study of parallel object-oriented programming.

Using the  Centaur system, this semantics permits to generate a Development Environment called Jitan for parallel object-oriented programming and  visualization; the specified semantics communicates with the environment thanks to notifications as in the above rule with the ENVchangeObjectStatusInStatusList predicate (in the do clause).

For these applications, it is very important to choose properly the neighbors in the networks because of the delay and bandwidth constraints. This is why we launched a research activity on inferring network topology. In fact, the peer to peer overlay is seen as a virtual space in which we should define the path to reach the destination(s) that are not direct neighbors. It is therefore essential that this space corresponds as much as possible to the real topology.

In classical peer to peer networks, only the look-up phase is affected by a bad overlay structure. In multimedia transmission between peers, data transfer will be done through the virtual space (recall the need to support group communication). This puts harder constraints on the design of the overlay structure. We also need to manage the participants dynamicity in the design. Other interesting problems to solve are congestion control algorithms in such heterogeneous environment (using a layered coding may help, with different flows could be handled by different nodes in the overlay network.

In parallel, wireless communication has become widespread. In order for these applications to be deployed everywhere, it is mandatory that new (wireless) transmission media provide support for quality of service.

The benefits of Ubiquitous Computing without communication are very limited. Networking support is required to derive the most out of the Ubiquitous Computing experience. This is referred to as Ubiquitous Networking (UN). UN of the future will heavily rely on sensor networks deployed to assist human users at the workplace, at home or while traveling. Such sensors are usually small devices with limited power, CPU and communication capabilities. Sensor networks are ad-hoc in nature with the composition of the network determined at the time of deployment. Nodes can die or be added, therefore the routing is dynamic. The connectivity is expected to be intermittent. The network topology might not be fixed, i.e., the sensors might move and form so-called mobile ad-hoc networks (MANETs).

My main research topics are high performance communication protocols, congestion control, reliable multicast protocols, audio and video conferencing over the Internet, efficient and flexible protocol architecture design and the integration of new transmission media such as satellite links in the Internet. I am co-chair of the UDLR  working group at the IETF.

My main research interests are Internet measurement and traffic analysis, the TCP protocol, modelling and performance evaluation of communication networks, network coding, data collection, and integration of new transmission media as satellite and wireless links into the Internet.

Member of the recruitment committee at the computer science department of the University of Nice-Sophia Antipolis, member of the directorial board for the Master RSD of the University of Nice, and responsible of the internship program at the latter Master.

In this group, I have been working in the SpectrumWare project headed by David Tennenhouse. I have designed and implemented in software part of a GSM base station which has been integrated into the VuSystem.

Huitema) were focused on designing, implementing, and evaluating multimedia applications over the Internet. Specifically, I have developed IVS, one of the first videoconferencing application for the Internet. This software videoconferencing system allows multicast delivery of audio and video over the Internet. I also developed specific error control and rate control mechanisms for transmission of video streams. These mechanisms regulate the output rate of the codecs based on feedback information about the network state. They have been designed specifically to work in a multicast environment.

The goal of MECCANO is to provide all the technology components of high quality multimedia distance education and collaboration tools, and to use these tools over as large a variety of network environments.

An important part of INRIA's contribution in MECCANO revolves around videoconferencing components and tools. The goal is to develop tools that provide better and more consistent quality, thus making them well suited for productive use in ``real'' environments. We are working on two such tools, a stand alone audio tool called Free Phone, and an integrated audio/video tool called Rendez-Vous.

Work on FreePhone within MECCANO will focus on a new joint rate/FEC control scheme for optimal quality over paths with characteristics (delay, available bandwidth, loss statitics) varying with time. Work  on RendezVous will focus on scheduling (dynamic CPU allocation to audio and/or video related tasks for smooth rendition) and handling of heterogeneous links.

Our approach combines measurements with analytic models. The goal is to use the results to design better control mechanisms for audio and video tools, in particular playout delay adjustment mechanisms (to minimize the impact of jitter on audio and video quality), rate control mechanisms, and adaptive error control mechanisms. Regarding the latter, we are designing a joint rate/FEC-based error control scheme which adjusts adjusts the amount of FEC information at any given point in time so as to provide the best subjective quality to the destination, while at the same time taking into account rate constraints and delay constraints (from the playout adjustment mechanism).

We are also investigating the characteristics of radio/wireless channels, and the impact they have on videoconferencing applications. The goal then is to design efficient application level FEC schemes for video applications over wireless links. Refer to Frank Lyonnet's page.

We are investigating the transmission of multimedia conferences over unidirectionnal links such as direct broadcast satellite links. Check out a this description of the satellite activities at INRIA and refer to the home page of our satellite guru, Emmanuel Duros, for details of ongoing work at INRIA and at the IETF.

The IP over DVB technology used in Meccano has been used to retransmit the Oct 9 workshop in Marseille on "Information technology" all over Europe, including the speech by Claude Allegre, minister of education, science, and technology.

Task 3, called "WAGON benchmark tool", aims to extend this tool with IP telephony and multimedia trafic generation. The idea is to show that a high speed network such as VTHD++ is an efficient way to transport a large number of of IP telephony communications.

In a first phase, V-Eye will support SCORE communication architecture based on the general ASM multicast model. Then, in a second phase, V-Eye will support a new communication architecture, based on the SSM multicast model. Moreover, as the next generation of the Internet is likely not to include only very high speed links such as VTHD++ but a large number of heterogeneous links (very high speed backbones, LAN, Wireless LAN, Personal Area Networks, etc.), we are very interested in the support of IP differentiation services on top of such heterogeneous environments. We are developing such an heterogenous network platform in our lab and are currently working on the support of differentiated services for 802.11 WLAN. We will experiment multimedia applications on top of that such as V-Eye.

Internet in which a large number of participants can move and interact with each others by sending and receiving multimedia flows. The aim of this tool is to experiment on a real application, scalability of multicast transmission protocols and optimization of multimedia transmission over very heterogeneous environments. V-Eye also handles audio and video flows, and text messages. In addition, a DV-compliant movie theater is located at the center of the world, each participant can watch the movie.

Our filtering approach is done at the transport-layer, using multiple multicast groups and multiple agents. Our approach involves the dynamic partitioning of the virtual environment into spatial areas and the association of these areas with multicast groups (see Interactive Multi-users Applications ).

The overall architecture is detailed in the papers quoted above. Let us just outline that the management of user groups and related communication services are handled in the SCORE component, that was implemented for both ASM and SSM.

The audio and video communication between participants in a given group are implemented through a modified version of the Rat (Robust Audio Tool) and Vic (VIdeoConferencing tool) application from UCL.  We also take advantage of the MBus protocol that comes with these two tools, for implementing local IPC.

The development is done on Fedore Core 2, and the binary linux distribution should work on most current linux distributions. Special care might be needed for proper installation of some drivers, especially the NVIDIA linux driver and the Philips Webcam. See Installation instructions for more details.

Please note that the zaurus distribution relies on  kathrin release . The compiled application is fully functional but in practice cannot support 3D world rendering, due to lack of hardware-based 3d rendering and poor cpu capabilities. For working around this issue, a 'tracker' mode was implemented so that one can virtually 'follow' another participant in the world; under this mode only the video and audio tools are involved, but the multicast group logics is still relevant.

In this work, we evaluate the gain from using network coding for file sharing applications running on top of wireless mesh networks. With extensive simulations carried out on a simulator we developed specifically for this study, we confirm that network coding can improve the performance of the file sharing application, but not as in wired networks. The main reason is that nodes over wireless cannot listen to different neighbors simultaneously. Nevertheless, one can get more from network coding if the information transmission is made more diverse inside the network. We support this argument by varying the loss rate over wireless links and adding more sources.

LCC provides library to handle different useful application-layer functions. However, it is first designed to address topology-aware construction, so focus is set on two major processes : Locating and Clustering.

You need to get these original tools installed before you run different scripts in the test dir. Once you choose your favorite tool, run its corrspondant wrapper as: p2px RP/session_name:port. This intiates the RP service. Newcomers should run the same process. If nodes are on a local multicast-enabled network, the p2p service will not run, only the specified multicast address would be used in this case.

Not all traffic can be captured by only one wireless enabled terminal, since processing speed, fading and distance generate packet loss. If multiple data sources are used, most (around 99%) of wireless traffic can be captured.

Packets are acquired by the probes, and only the relevant parameters are extracted at the source. These parameters are transmitted to a central data collector engine, which adds them to a merged packet buffer, avoiding duplicates (since the same packet may arrive simultaneously to different probes).

A probe is a station with at least two interfaces: one wireless 802.11 and one wired ethernet. Packets are captured in promiscuous mode on the wireless side; each packet timestamp is correlated with the beacon of the associated AP, and then specific parameters are extracted to transmit to the main packet processor.

A circular buffer is built in one-second time buckets, which accumulate the parameter values and events seen during that period. The buffer length is 30 seconds. Data is saved when the circular buffer is full, the oldest bucket is saved in a log.

The main window contains the list of recognized MAC interfaces, with a summary of current values. A new station is added when a packet whose source or destination are new to the server. If the server has been running for enough time to see at least one packet per station, then the full station list will be available.

In our scheme, relative priorities are provisionedby adjusting the size of the Contention Window of each traffic class taking into account both applications requirements and network conditions. We evaluate the performance of AEDCF and compare it with the EDCF scheme proposed in the upcoming standard of 802.11e. Results show that AEDCF outperforms the basic EDCF, especially at high traffic load conditions. Indeed, our scheme increases the medium utilization ratio and reduces for more than 50% the collision rate. While achieving delay differentiation, the overall goodput obtained is up to 25% higher than EDCF. Moreover, the complexity of AEDCF remains similar to the EDCF scheme, enabling the design of cheap implementations.

MiMaze distributed (multicast) game to enhance the sense of immersion in the game and to add live 3D voice interaction between players -- however the feature is not available on the public release of FreePhone yet).

Adaptation to network conditions: Includes a rate control mechanism (adaptation to available bandwidth), a FEC-based error recovery scheme (adaptation to  and recovery from loss process in the network), and an adaptive playout adjustment scheme (adaptation to delay variations).

This work focusses on the transmission control mechanisms that have to be used to make it possible to play a real-time multiplayer game on the Internet. Our major contribution is to have designed and implemented a completely distri buted communication architecture based on IP multicast. The major elements of MiMaze architecture are a multicast communication system based on RTP/UDP/IP, and a distributed synchronization mechanisms to guarantee the consistency of the game, regardless network delay.

With stateless networks, resource allocation is done using edge (i.e. end-to-end) mechanisms. Our emphasis these past few years have been on mechanisms that integrate multicast delivery, flexible flow and error control, etc. These mechanisms are used in particular in the FreePhone Internet telephony tool, in the Rendez-Vous videoconferencing tool (successor of IVS, one of the first s/w videoconferencing tool for the Internet) , and in the  MiMaze distributed game.

MAVROS compiler, and of fast algorithms for the management of data transparency in heterogeneous systems. We are extending this work so as to allow the compiler to handle detailed specifications of the applications. This will lead to further optimizations.

We expect the two research areas described above to eventually merge within the framework of the Application Layer Framing (ALF) architecture. It will then be possible to take into account specifications of an application, of the network ressources required by the application, and to automatically generate tailored communication modules that handle both data transparency, synchronization, and transmission control for this application.

Our work is carried out over IP networks using a variety of underlying technologies. Recently, we have carried out specific work on wireless links (robust coding for wireless links), satellite links (routing over unidirectional links, check out the  UDLR page), and over ATM links (specifically over the regional ATM testbed dubbed EuroSud155 - check out experimental results).

My main areas of research revolve around the design and evaluation of control mechanisms for adaptive applications, the measurement and analysis of Internet traffic. and the design of ``lightweight'' resource allocation and pricing schemes for the Internet, All three areas above are related and (I believe) form a coherent whole, as I try to explain briefly.

From a connection's point of view, the current single class best effort service in the Internet amounts in practice to offering a channel with time varying characteristics such as delay and loss distributions. These characteristics are not known in advance since they depend on the (a priori unknown) behavior of other connections on the network.

One approach to this problem is to adapt applications to the channel characteristics -i.e. to the service provided by the network-, the goal being to maximise the quality of the data received at the destination(s).

This approach is attractive because  it can be implemented relatively easily (it does not require any change in routers) in the current Internet, and it provides immediate benefits. For example, rate control mechanisms make sure that no application would hog Internet bandwidth unfairly (which is not what is done by many applications such as commercial telephony software which keep sending constant bit rate data independently of the level of congestion  in the Internet).

Work on resource allocation and control in general, and adaptive applications in particular, require good characterization and estimation of Internet connection parameters such as end-to-end delay or loss. My approach to this problem combines measurements with analytic models. The results have proved important to design efficient control mechanisms for audio and video applications. For example, measurements show (and analytic models confirm) that the number of consecutive losses in a CBR stream sent into the Internet is generally small.

Grossglauser, we have examined under which conditions the salient long range dependence feature of network traffic must be taken into account in network performance evaluation. Our results confirm that "it is all a matter of time scales". Specifically, when studying the performance of a networking system or an application, many time scales must be taken into account -- the time scales in the input traffic, but also the time scales of the system (they show up for example because of finite buffer queues) and the time scales of the performance metric of interest.

The "adaptive application" approach above is attractive, but it still does not provide performance guarantees in the current single class FIFO Internet. Another approach to providing users with good quality applications  is to augment the service model of the Internet and include services which provide (deterministic or statistical) performance garantees. This approach requires that specific mechanisms be implemented at the edge and inside the network. Many such mechanisms have been examined. However, it is important to keep such mechanisms (including their interface(s) to applications) simple.

Martin May, we have examined simple schemes in which service discrimination in routers is done on the basis of one (or a few) bits in packet headers. These bits indicate preferential treatment expressed in terms of throughput, delay, or a combination of these.

Our current work aims at quantifying the service provided by such schemes, designing appropriate tariffing policies for them, and experimenting with them. We started this work a year and a half ago, so this fits in well with the general current interest in differentiated services in the IETF.

I have also worked on caching schemes for distributed systems such as the DNS or the Web. The main idea is that cache replacement algorithms should take document size and document retrieval time into account, in addition to usual parameters such as locality of reference.

Sacha Fosse-Parisis works on pushing Internet audio beyond what most people think it is today, namely "low quality, low cost telephony". In practice, this means working on high quality audio, and on using audio in novel ways such as 3D live voice in distributed games.

I teach two DEA (that's French for ``graduate'') courses at the University of Nice - Sophia Antipolis. One course is a core course in networking which mostly covers resource allocation and control issues. The other course is an advanced course which covers recent topics related to multicast transmission and resource allocation.  DEA students can get to the official DEA page or to my DEA page (with links to papers/slides/etc I refer to during class).

Broadcast satellite networks can access an area potentially spanning nations and provide high bandwidth services independent of the user's location . Integrating broadcast satellite networks in the Internet is therefore an important issue because they can bypass bottlenecks offering high-speed transmission over long distances.

However, this type of network is by nature unidirectional and is not supported by common routing protocols. Routing protocols assume that links are bidirectional and therefore routers connected to an "outgoing" unidirectional link cannot be aware of the existence of networks reachable through this link.

Basically, there are two approaches, the first one is to modify routing protocols to take into account unidirectional links, the second one is to set up link layer tunnels between receivers and feeds. The latter emulates below IP level a bidirectional connectivity in the presence of a unidirectional link: a receiver can send routing messages (through link layer tunnels) to feeds without having to provide modifications to routing protocols.

Beside the routing issues, Eutelsat provides us the satellite capacity and the hardware (up-link station and satellite dishes) to experiment IP over satellite. I developed the Unix drivers for the unidirectional interfaces (emission and reception boards for PC). These drivers are written for FreeBSD platforms and are available. FreeBSD platforms can be configured as IP routers and various routing protocols are supported by this operating system.

I have been experimenting point to point video-conference sessions as well as multicast sessions over the satellite link (taking advantage of high bandwidth services). The latter including dynamic multicast routing which has been demonstrated during the retransmission of the SIGCOMM'97 sessions over the MBone via satellite.

I have been working on various aspects of computer networking including queueing disciplines, protocol design and optimized implementations. I worked during my Phd on the automatic generation of optimized implementations of protocols.

High performance is usually achieved through code customization and efficient implementation. Earlier experiments with an user-level implementation of TCP, which I implemented, has shown that code customization is difficult and impractical to apply manually. Thus, an automatic approach appears preferable.

This automatic approach is pursued in the European Community-funded project HIPPARCH (HIgh Performance Protocol ARCHitecture). The goal of the project is to design a protocol compiler which automatically generates the code of the communication module required by a distributed application using application and network specific knowledge. The application requirements and network characteristics are expressed using high level language constructs. This information is then used by the protocol configurator to select the protocol building blocks from a library and to generate the communication module specification. The specification is compiled into an integrated automaton, which is optimized and converted into an performant implementation.

I have studied two aspects of the compiler: basic block design and generation of the optimized code. I have investigated how to decompose protocol code into modular building blocks, and have applied this decomposition approach to the protocol TCP. This has led to a modular and configurable specification of TCP in the high level language Esterel. Then, I have designed and implemented HIPPCO, a protocol code optimizer. HIPPCO optimizes the communication module automaton and generates a highly optimized and integrated implementation in the "C"

The objectives of the project are the definition and the experimentation of communication protocols for very high speed  networks, at one Gbit/s or more. This includes the study of high speed transmission control protocols, of their parametrisation and of their insertion in the operating systems, and the study of the synchronisation functions and of the management of data transparency between heterogeneous systems. Amongst the output of the RODEO project, one can count one of the most performant ASN.1 compiler, MAVROS, and the IP based H.261 videoconferencing system, IVS.

I got my Phd in 1995 in the field of Software Engineering. I have adressed the problem of translating automatically the Natural Semantics of programming languages to the Coq proof development system, in order to prove formally (with mechanized support) general properties of languages. I have designed and implemented a tool available in the generic programming environment Centaur. I have also provided some useful tactics, thus contributing to the design of a library for proof development.

Then, in 1996, I did a postdoc (whitout annex, with annex ) in the Esterel team. It was a first step towards the proof of correctness of the new Esterel compiler in Coq. The problem was firstly to provide a good formalisation of the translation of Esterel programs into constructive circuits, and secondly to perform the proof of correctness.

Esterel  while the data processing part is written in Java. The specific requirements are used by the compiler to select the appropriate protocol mechanisms available from an Esterel library, and generate the specification of the integrated automaton in Esterel. Finally, this integrated specification is compiled in Java which is the target implementation environment. To achieve a performant execution scheme we need of course to add some JIT stuff to the process ...

The general architecture of the next version of the compiler is based on previous work synthetised in References. Moreover, it should provide a refined mapping between QoS requirements and protocol mechanisms.

OreModules is a Maple implementation of algorithms which compute free resolutions, extension modules, left/right/generalized inverses and other algebraic objects for linear systems of differential equations (ODE, PDE), differential time-delay systems, discrete systems etc.

The OreModules packages QuillenSuslin (implementation of the Quillen Suslin theorem and its applications to mathematical systems theory) and  Morphisms (a homological algebra package for factoring and decomposing linear functional systems) will be soon available.

Presto-HF is a matlab based toolbox dedicated to the identification problem   of low pass coupling parameters of band   pass microwave filters. In this problem one wants to recover the coupling   parameters of the low pass electrical equivalent circuit of a filter using   scattering measurements of the latter. This information is then typically   used for tuning purposes.

The research effort that underlies this toolbox was partly (but constantly) supported by the french spatial agency (for short CNES). We want here to   thank the microwave team of the university of Limoges (IRCOM) as well as  the filter department of Alcatel Space for their feedback as "real world"   users of our software that allowed us to improve the latter in a significant   way.

In what follows we present some screen shots of a typical identification session performed on some scattering data provided by the french space agency   (CNES). The corresponding filter is made out of 4 dual mode cavities.

The optimizer of the toolkit OPTIM is used to find a local minimum of the nonlinear L2-criterion. Thanks to the parametrization, it is not too computationally demanding and the result is necessarily stable.

Like the proceedings of the previous MCQMC conferences, the proceedings of this conference will be published by Springer-Verlag. Thus, wide distribution and excellent marketing of the proceedings are guaranteed. Harald Niederreiter and Denis Talay will serve as the editors of the proceedings.

Every speaker at the conference is invited to submit a full paper based on his or her talk. Each submission will be strictly refereed and there will be a limit on the size of the volume. As a guideline, manuscripts based on special session or technical session presentations should not exceed 15 pages. These manuscripts should contain original research contributions not published elsewhere, whereas manuscripts based on invited plenary talks can also contain material of survey character.

One bus will be organized the last day of the conference (June 10) after the last session  to Nice International Airport. If you want to use this bus, please cross the option offered at the end of the registration form.

INRIA has already pre-reserved  a number of rooms in the following hotels located in the centre of Juan-Les-Pins at 5 minutes walking distance from the Convention Centre where the conference will be held.

Most often physicists, economists, biologists, engineers need a stochastic model because they cannot describe the physical, economical, biological, etc., experiment under consideration with deterministic systems either because of its complexity and/or its dimension or because precise measurements are impossible. Then, they renounce to get the description of the state of the system at future times given its initial conditions and, instead, try to get a statistical description of the evolution of the system. For example, they desire to compute occurrence probabilities for critical events such as overstepping of given thresholds by financial losses or neuronal electrical potentials, or to compute the mean value of the time of occurrence of interesting events such as the fragmentation up to a very low size of a large proportion of a given population of particles.

By nature such problems lead to complex modeling issues : one have to choose appropriate stochastic models, which requires a thorough knowledge of their qualitative properties, and then one has to calibrate them, which requires specific statistical methods to face the lack or the inaccuracy of the data. In addition, having chosen a family of models and computed the desired statistics, one has to evaluate the sensitivity of the results to the unavoidable model specifications.

The stochastic differential calculus allows one to represent solutions of certain deterministic partial differential equations in terms of probability distributions of functionals of appropriate stochastic processes. For example, elliptic and parabolic linear equations are related to classical stochastic differential equations, whereas nonlinear equations such as the Burgers and the Navier--Stokes equations are related to McKean stochastic differential equations describing the asymptotic behavior of stochastic particle systems. In view of such probabilistic representations one can get numerical approximations by using discretization methods of the stochastic differential systems under consideration. These methods may be more efficient than deterministic methods when the space dimension of the P.D.E. is large or when the viscosity is small. The Omega team develops new probabilistic representations in order to propose probabilistic numerical methods for equations such as conservation law equations, kinetic equations, nonlinear Fokker--Planck equations.

Industrial collaborations and application domains Since its creation the Omega team collaborated with various industrial companies, some of them, such as Electricit de France, on a long term basis. We now describe a short list of past success stories and of new application fields which we aim to develop in the next future.

For a long time now the Omega team has collaborated with financial institutions and researchers in finance and insurance. We are particularly interested in calibration methods, risk analysis (especially model risk analysis), optimal portfolio management, Monte Carlo methods for option pricing and risk analysis, asset and liabilities management. We also work on the partial differential equations related to financial issues, for example the stochastic control Hamilton--Jacobi--Bellman equations. We study existence, uniqueness, qualitative properties and appropriate deterministic or probabilistic numerical methods. At the time being we pay a special attention to the financial consequences induced by modeling errors and calibration errors on hedging strategies and portfolio management strategies.

The designing of original schemes for applicative cases. A first example concerns the micro-macro model of polymeric fluid (the FENE model). A second one concerns the Lagrangian modeling of turbulent flows and its application in combustion for two--phase flows models (joint collaboration with Electricit de France).

Its permeability is discontinuous, rapidly varying and generally unknown. Similarly, it is interesting to consider as random media turbulent fluids and unknown or deficient materials in which polymers evolve or waves propagate.

Generally, a random medium is described at a small scale. A lot of techniques, such as the techniques issued from the homogenization theory, allow one to approximate some properties of the media by a simpler model at a higher scale by using its statistical properties. Although some of these change of scales techniques can be done analytically, most often a practical description of the media at a higher scale can only be achieved by using intensive numerical computations, including Monte Carlo methods.

The Omega team has a good expertise in analytical and numerical computations of change of scales techniques. In addition, the Omega team is now developing a new class of Monte Carlo methods aiming to simulate diffusion phenomena in discontinuous media with applications to inverse problems in electro-encephalography and geophysics.

For all these applications we are led to consider kinetic equations using coagulation and fragmentation kernels (a typical example being the kinetics of polymerization reactions). The Omega team aims to analyze and to solve numerically these kinetic equations.

By using a probabilistic approach we describe the behavior of the clusters in the model and we develop original numerical methods. Our approach allows to intuitively understand the time evolution of the system and to answer to some open questions raised by physicists and chemists.

More precisely, we can compute or estimate characteristic reaction times such as the gelification time (at which there exists an infinite sized cluster) the time after which the degree of advancement of a reaction is reached, etc.

We take benefit from our strong experience on the programming of probabilistic algorithms on various architectures including intensive computation architectures (see our joint collaboration <<Amazone>> with Bull company).

We have developed demonstrators such as the LICS software for financial and insurance problems and a solver for diphasics fluids within a collaboration with Electricit de France, etc. We also are interested in designing algorithms of resolution of specific equations in relationship with practitioners.

There are many ways to obtain derivatives. Maybe the most straightforward is to go back to the equations that led to the program. Suppose that some result is defined by some equations, and the program solved these equations for this result. Then one can write a new set of equations, whose solutions are the derivative of the initial result. Consequently, one can write a new program that solves these new equations for the desired derivatives.

This is mathematically very sound, but it probably is the most expensive way, since it implies discretizing new equations, then writing a new program. We all know how difficult this is, and how many errors can be done! Moreover, in some cases there are no simple original equations, and only the program is at hand.

For a given set of program's inputs, X, the program P has computed a result P(X)=Y. In the general case, both X and Y are vectors, i.e. are composed of several real numbers. Given now some normalized direction dX in the space of the inputs, one can run the program P again, on the new set of inputs X+dX, where  is some very small positive number.

But this makes no sense on a real computer, since very small values of lead to truncation errors, and therefore to erroneous derivatives. This is the main drawback of divided differences: some tradeoff must be found between truncation errors and approximation errors. Finding the best requires numerous executions of the program, and even then the computed derivatives are just approximations.

Automatic Differentiation, just like divided differences, requires only the original program P. But instead of executing P on different sets of inputs, it builds a new, augmented, program P', that computes the analytical derivatives along with the original program. This new program is called the differentiated program.

Moreover, each time the original program performs some operation, the differentiated program performs additional operations dealing with the differential values. For example, if the original program, at some time during execution, executes the following instruction on variables a, b, c, and array T: a = b*T(10) + c then the differentiated program must execute additional operations on the variables and their differentials da, db, dc, and array dT, that must somehow amount to: da = db*T(10) + b*dT(10) + dc The derivatives are now computed analytically, using the well known formulas on derivation of elementary operations. Approximation errors have just vanished.

The advantage is that the original program is virtually unchanged, since everything is done at compile time. The drawback is that the resulting program runs slowly because it constantly builds and destroys pairs of real numbers.

Source transformation consists in adding into the program the new variables, arrays, and data structures that will hold the derivatives, and in adding the new instructions that compute these derivatives.

The advantage is that the resulting program can be compiled into an efficient code, and the "reverse mode" is possible. The drawback is that this is an enormous transformation, that cannot be done by hand on large programs. Tools are needed to perform this transformation correctly and rapidly. Our team studies this sort of tools. Our TAPENADE engine is just one such Automatic Differentiation tool that uses source transformation.

In the above, we have been very vague on the notions of differentials and derivatives. This is because there are many "derivative objects" one may want, and each of them is obtained through a specific Automatic Differentiation.

This leads to carrying partial Jacobian matrices along with the main computation stream. This is usually expensive in time and memory space. This drawback can be partially coped for, using sparse representations for the derivative objects.

This effect is actually dY = J * dX, but one can evaluate it without explicitly computing J. For that, the derivative object that must be computed along with each value v is its "differential" dv, i.e. (the first-order approximation of) the quantity by which v varies when the input X varies by dX. As expected, this is far less expensive than building the whole Jacobian.

This can be computed without explicitly computing J. For that, the derivative object is called an "adjoint", and it is computed in the reverse of the original program's order, and will be shown later.

Like with the directional derivatives, one can compute the whole Jacobian matrix by repeatedly computing gradients, for each canonical direction in the output space, or fewer than that when the Jacobian is sparse. It is easy to check that this approach is advisable when there are far more inputs than outputs.

One may want directional higher-order derivatives. Given a direction vector dX in the input space, one computes along the original program a derivative object that contains the first and higher derivatives of each intermediate value in the direction dX. Higher-order derivatives are useful to get a more accurate approximation, or to optimize more efficiently.

The ADIFOR tool computes directional derivatives, gradients, and Jacobians, taking advantage of sparsity. All the above tools are based on source transformation. In contrast ADOL-C, based on overloading, has been used for directional derivatives and gradients, but these are relatively slow, and also for directional higher-order derivatives and Taylor series.

Of course each of these functions are extended to operate on the domain of all the program variables, but variables not overwritten by the instruction are just transmitted unchanged to the function's result.

We wrote f'n for the derivatives of function fn. The f'n are thus Jacobian matrices. To write the above in a shorter form, we introduced xn, which is the values of the variables just after executing the first n functions (we set x0 = x).

Activity can be found by a static analysis. The set of the varying variables, those who depend on some independent, is propagated forwards through the program. At the beginning of the program, the varying variables are just initialized to the independent.

Things are easy here, because x0 is required first, then x1, and so on. Therefore differentiated instructions, that compute the Jacobian matrices and multiply them, can be done along with the initial program. We only need to interleave the original instructions and the derivative instructions. This is called the tangent mode of Automatic Differentiation.

Each active variable gives birth to a new variable, of same type and size, which is called its derivative variable. The control structures of the program are unchanged, i.e. the Call Graph and Flow Graph keep the same shape.

Since a routine call is in fact a shorthand for another piece of program, and that this piece of program will be augmented with differentiated instructions too, the call to the differentiated routine sub1_d simply replaces the call to sub1. In other words sub1_d does the previous work of sub1 plus the derivatives computations.

Of course, these derivative instructions use the derivative variables, and therefore each parameter which is active at the beginning or at the end of the routine requires an extra parameter holding its derivative.

This matrix can capture precise behavior. For example it also implies here that although the entry active v2 is used to compute the exit, active, v4, the exit v2 is not active any more, because it only depends on the input p1, which is not active.

AD tool TAPENADE, that will describe conventions about variable names and declarations, differentiation of individual instructions and control structures, and in general all you must know to understand and use differentiated programs produced by TAPENADE.

However, we observe that the Xn are required in the inverse of their computation order. If the original program overwrites a part of Xn, the differentiated program must restore it before it is used by f'n+1(Xn).

One can see that before the adjoint of each instruction, the necessary part of the original program is recomputed. Notice that this requires that we save the environment before the rirst run (big black dot), and restore it (big white dots) before each duplicate run.

Checkpointing consists in selecting some part of the program, and in not storing the values overwritten by this part (in SA mode) nor repeating execution of this part (in RA mode), at the cost of some extra memorization of the complete state of the program, that we call a snapshot.

In Store All (SA) mode, the result of checkpointing part P is shown on the top of next figure. The snapshot (big black dot) memorizes the state of the program just before P. There is an additional cost, which is the duplicate execution of P.

In the model case where the program is a sequence of N parts, all of them with grossly the same cost. it was shown that the cost of the reverse differentiated program, in terms of memory size and in terms of number of duplicated executions, grow only like the logarithm of N, which is very good.

The structure of a reverse differentiated program is therefore more complex than in the tangent mode. There is first a forward sweep, identical to the original program augmented with instructions that memorize the intermediate values before they are overwritten, and instructions that memorize the control flow in order to reproduce the control flow in reverse during the backward sweep. Then starts the backward sweep, that actually computes the derivatives, and uses the memorized values both to compute the derivatives of each instruction and to choose its flow of control.

Notice that the adjoint of one original instruction is now very often a sequence of instructions. Notice also that subroutine sub1_b is the result of checkpointing on sub1, and therefore itself consists of a forward sweep followed by a backward sweep.

If an argument is not active at the entry into the procedure nor at the exit from the procedure, then we need not pass a derivative argument. Otherwise we must pass one, and it must be initialized when necessary.

The first step in using TAPENADE is to identify and load the input source program. In normal use, you know which routine (i.e. a subroutine or function) implements the mathematical function that you want to differentiate. Let us call it the top differentiation routine.

TAPENADE will make some conservative assumptions about it, which may degrade the execution time and memory consumption of the differentiated program. Of course this is a problem only if the top differentiation routine (recursively) calls this black box routine (TAPENADE provides a way to treat these "black box" routines correctly and efficiently).

It will select any one of the topmost routines in the call graph defined by the files you have given. Except in very simple cases, this might not be the choice you want, so use this default mechanism with caution.

Some advanced features of Fortran95 are not properly differentiated yet. TAPENADE will issue a warning message if one such feature is met. We are currently working to accept the missing features. More info in the FAQ.

Of course in normal use, you already have your source program, and TAPENADE does not require you to modify it, except in rare situations. But for this example, please cut and paste the following piece of source into some file that you will call, say, mainpart.f, somewhere on your disk.

Otherwise, if you want to differentiate only the function defined by a routine fragment, you must first split this routine, so that this fragment becomes a new separate routine, which will be your top differentiation routine.

Finally, notice that if there is no dependency between the selected dependent and independent variables, the derivatives are certainly all zero. TAPENADE detects this degenerate situation statically, and this results in an empty differentiated program.

All 5 formal parameters are outputs, and only the first 3 parameters, namely "first", "other", and "third", are inputs. Suppose we want the derivatives with respect to "first" and "other", of all possibly dependent outputs. To this end, leave the "Dependent output variables" field blank, and type "first other" into the "Independent input variables" field.

To put it shortly, the "forward mode" will build a program that, given some small variations of the independent variables, computes the resulting (1st order) variations of the dependent variables. In other words, if we call "J" the Jacobian matrix of the partial derivatives of each dependent "Yj" with respect to each independent variable "Xi", the forward mode gives a program that computes "dY=J.dX" for each given "dX".

The "forward vectorial mode" also computes the variations of the output variables, but simultaneously for several directions in the input space. For n directions, it is therefore equivalent to running the forward mode n times, but this is done in a single call, and is therefore more efficient because the original function is evaluated only once.

Conversely, the "reverse mode" gives a program that computes the transposed Jacobian product "J*.dY" for each given "dY". In other words, given a weighting of the dependent output variables "dY", the generated program computes the gradient of the original program.

Clicking on one of the buttons "Forward Mode", "Forward Vectorial Mode" and "Reverse Mode" triggers actual analysis and differentiation of the uploaded files. For large files, this may take some time before our server builds the differentiated files.

In the above sections of this tutorial, the illustrative example is based on the TAPENADE web server. The same behavior can be achieved with TAPENADE installed locally on your system. In that case, differentiation is called from the command line instead of through a Web interface.

Suppose you have downloaded the small example, as described in the first section. Therefore you have put the three files "mainpart.f", "utilities.f", and "globals.inc" into one directory. Go to this directory.

When the call graph is large, TAPENADE avoids duplicate display of identical sub-graphs. External routines are displayed in smaller type. Each routine name is in fact a HTML link, that triggers display of the corresponding routine in the frame below. the top right frame displays the call graph of the differentiated routines. It may very well happen that some differentiated routine calls a non-differentiated routine. However, for clarity, these non-differentiated routines are not displayed here.

Here also, each routine name is in fact a HTML link, that triggers display of the corresponding differentiated routine in the frame below. the middle left frame displays the text of some routine of the original program. Colors are used to highlight syntactic structure, e.g. keywords, data types, function names, labels or comments. Notice that this may differ from the actual contents of the original file, because the routine has been preprocessed, and this results in normalized declarations or indentations. Each line of the subroutine is in fact a HTML link, that triggers display of the corresponding line of the differentiated routine, if any, in the frame on the right. the middle right frame displays the text of some generated differentiated routine. The syntactic structure is highlighted as usual, and each line of the subroutine is in fact a HTML link, that triggers display of the corresponding line of its original routine, in the frame on the left. the bottom frame displays some error or warning messages that may have been emitted during the analysis of the original program.

Do not overlook these messages: even if your program compiles well, they may indicate serious problems with the differentiated program. In many cases, you will neglect these messages in the end, but only after making sure none of these serious problems occur in this particular case.

"sub1_d", "f_d", and "g_d". The "d" suffix designates files and variables differentiated in forward mode. It is a reminder of the dot above, which is the conventional sign used to denote derivatives in the forward mode.

If you look more closely at "sub1_d", you notice that one instruction has been added before each original instruction, to deal with the derivatives. The derivative of a variable "v", by convention, is put into a variable called "vd".

Declarations of differentiated variables are inserted automatically, and differentiated visible variables appear as additional formal parameters or commons. Arithmetical operations and system numerical subroutines are differentiated as could be expected.

For example the first instruction: out = first * other + 3.0 * third is differentiated as outd = firstd * other + first * otherd because of the well-known differentiation of a product, and noticing that at that time in the program, variable "thirdd" is certainly zero because variable "third" was not selected as an independent input variable.

Finally, calls to user routines are simply replaced by calls to the differentiated subroutine, with suitable values for the additional parameters that hold the derivatives. For example instruction: other = G(out) becomes in the differentiated routine otherd = G_D(out, outd, other) where the argument outd is inserted after the original argument out, the original result other has been moved to the arguments list (but is still an output!), and the derivative of the result is returned in the new result otherd Take a look at routines G and G_D, by clicking on their names in the call graphs.

The interface also shows some warning and error messages, that were detected during the preliminary analyses required by TAPENADE. These messages should be examined, because some of the problems they show might lead to an incorrect differentiation.

The end-user can often find out that a warning message can be neglected, but bear in mind that this is not always the case. For example, incompatible array sizes between actual and formal arguments may result in insufficient storage of intermediate values in the reverse mode. Similarly, aliasing problems (see FAQ) can lead to bad differentiation.

Using the Web server, if you are satisfied with the differentiated program, and you want to use it, you may cut-and-paste it. However, since this is tedious on large files, you'd better download it using the "Download differentiated file" button in the top right frame. This will download a single gzip'ed file that contains all differentiated routines. You may then include these differentiated routines in your application, feeding it with values for the derivatives of the independent input variables, and using the returned derivatives of the dependent output variables.

You may very well want to modify some of your original files, for example to fix an error or to improve differentiation result. After doing so, don't forget to use the "Remove selected files" button to remove the uploaded copy of the file, then upload the new version as indicated above.

You should be back to the differentiation request page, with the three files still uploaded. Then type "sub2" as the name of the top differentiation routine. Leave blank the fields for the dependent and independent variables. The click on the "Reverse Mode" button.

The page that displays the differentiated program is identical for the reverse mode and the forward mode. But of course the differentiated programs differ completely. You may refer to section "Reverse differentiation model" for a more complete description of the reverse mode.

Sometimes, TAPENADE performs some optimizations, that yield a better code, but somewhat harder to understand. For example, instruction a = 0.5 * x(20) corresponds to no differentiated instructions. This is because a is a local variable which plays no role in the differentiation of the outputs with respect to the inputs. We say that a is not "active", and thus need not be differentiated.

Although the temptation is strong, these messages should not be ignored right away. Especially when AD is concerned, these messages can be the indication that the program runs into one limitation of the AD technology. So even if the original program compiles and runs correctly with your compiler, these messages warn you that differntiation may produce a faulty program.

Some messages are requests for help: when TAPENADE needs some help from the user, e.g. because it needs and does not know the size of an array, it issues a message that asks you to give this size after differentiation is done. Otherwise the resulting program will not run.

In particular when types are concerned, remember that differentiation occurs only on REAL (or COMPLEX) typed variables. Therefore some variable may have no derivative whereas you think it should have one. Also for DD13 or DD10, the flow of control may be different from what you think, or from what your local compiler used to build.

What can you do? Remove the declaration or definition in excess, or modify conflicting declarations so that they combine well into the type that you expect. For DD11, clean up the library file by merging the data about a given function into one single entry.

Even if this original program actually compiles and runs well, remember that differentiation occurs only on REAL (or COMPLEX) typed variables. If some sub-expression becomes of another type, there will be no derivative associated, even if you think there should be one.

Why should you care?  As far as AD is concerned, equality tests on REAL's are sometimes used as the stopping criterion for some iterative process. Then it relates to a well-known problem: do the derivatives converge when the function does, and if yes, do they converge at the same speed?

They can indicate that the code relies on FORTRAN weak typing to perform hidden equivalence's between two arrays, or to resize, reshape, or split an array into pieces. Since TAPENADE cannot possibly understand what is intended, it might not propagate differentiability and derivatives from the old array shape to the new array shape.

Why should you care?  In general, if you let the system choose the return type of a function, you run the risk that it becomes REAL while you don't want, or the other way round. And this in turn impacts differentiation.

These messages indicate problems in the flow of control of the program. Message CF01 comes from jumps that go from outside to inside a loop, without going through the loop control header. The meaning of this is not well defined and is probably implementation dependent.

It is better to avoid aliasing. When aliasing is really a problem, one can easily avoid it by introducing temporary variables, so that memory locations of the parameters do not overlap. Variables should be initialized before they are used.

What can you do? Do not use files as temporary storage. Use arrays instead. You may also use TAPENADE "Black-box" mechanism to disconnect differentiation on the calling subroutines, and differentiate them by hand, with an ad-hoc mechanism to propagate derivatives.

Sometimes, the checkpointing mechanism of the reverse mode requests to save some variables, which are declared in some called subroutine, but not in the current, calling, subroutine. Think for example of a SAVE variable, or a COMMON which is not declared at the calling subroutine level.

You must provide the differentiated program with a new function, differentiated from Func with respect to the input and output parameters of Func specified in the arguments. Probably Func is an external function, for which TAPENADE has no source, and therefore it couldn't differentiate it.

What can you do? Define this new function. You have the choice of the method. Maybe you know explicitly the derivative mathematical function, which can be implemented efficiently. Maybe you have the source and you may use AD again, with TAPENADE or with another tool.

In any case, make sure that you provide a differentiated function in the correct mode (tangent, reverse...), and which adheres to the conventions of TAPENADE about the name of the function and the order of its parameters.

For example, there is still no syntax for structured argument types ("derived types"), although they are handled well inside Tapenade. Nothing exists for named arguments, nor for a variable number of arguments.

For example here, the result in parameter 2 depends on the input parameters 1 and 2, the result in the first variable in common /c2/ doesn't depend on any input, and the result in the tail array of /c2/ depends on the inputs in parameter 2 and in the whole of /c2/. An "id" entry instead of a complete line states that the argument is left unmodified, which is a stronger information than a line with just one "1", because it implies that the partial derivative is certainly "1.0". This is the case here for parameters 1, 4, and 5. On the other hand, parameter 3 is overwritten, but of course depends on nobody, since it has a non-differentiable type.

In this example, one can find in order the pattern that must match the actual call, therefore instantiating the metavariables X and Y, then an expression which is a common factor to all partial derivatives (which can be "none()" if there is no common factor), then the list of each partial derivative of the function's result with respect to each metavariable: for each metavariable key, there is an expression that defines the corresponding partial derivative expression, which has to be multiplied by the common factor if present.

Syst: The Fortran file does not contain a top routine : strangely enough, this message may appear as a result from a syntax error. Syntactically correct files must declare subroutines or functions. If, for any reason, no routine can be found, differentiation cannot start.

Otherwise this is a "real" syntax error. Our Fortran parser accepts all of the Fortran77 standard, plus most of the usual constructor's extensions, present or past (vax, sun, gould, connexion-machine, cray).

Notice furthermore that our parser does not support the cpp directives. For instance, we cannot parse files containing #define or #ifdef directives. Please run your files through cpp before sending them to Tapenade.

Be careful with comments delimitor in the free format style: comments must start with a "!" modules, BLOCKDATA : accepted and differentiated. overloading : accepted and differentiated. keyword arguments and optional arguments : accepted and differentiated. derived types : accepted and differentiated CASE statements : accepted and differentiated pointers : accepted, analyzed and differentiated except still in reverse mode dynamic allocation, malloc's, free's : accepted and differentiated in tangent mode.

The concept of "black box" routines and the syntax used in these *Lib files are described in the Reference Manual part, and it now contains a description of the (heavy) syntax used in there for types.

Sometimes writing *Lib files fails, and Tapenade does not understand this information and doesn't differentiate a black-box procedure correctly. Then you may consider writing a dummy definition of the problematic procedure, like a standard procedure, with statements that just "represent" the data dependences inside the actual procedure. Give this dummy definition only to the differentiation process, and then link with correct differentiated procedures that you have to write by hand.

This can even be improved by computing the derivatives for many directions in the same run. This is the so-called vector mode, found in ADIFOR. This can even use some parallelism, as shown in BuckerLangMeyBischof01.

So at the minimum you should check that the sizes of these types match on the machine/compiler you will use, and that these are the sizes that Tapenade will use. To check the sizes on your machine/compiler, refer to the beginning of the FAQ section on validation of the differentiated programs. To modify the sizes used by Tapenade to adapt them to the results of the above check, use the command-line options -r8 etc.

Nevertheless it still occurs sometimes, especially with Fortran95, that these messages indicate bugs in Tapenade. For instance Tapenade may have lost a dimension of an array. In this case, it is unlikely that differentiation will works. In this situation, when you see that your program is obviously correct and Tapenade complains, please send us a message so that we can improve Tapenade.

Also, it is frequent that, although there is aliasing, the differentiated program will run fine. It is the responsibility of the end-user, who knows the program, to check that his aliasing is harmless.

This is probably better than silently returning a wrong derivative that may lead to other wrong results later. The end-used can then analyse the original program, and maybe transform it to make it differentiable.

Therefore, in the very frequent case where the compiled code does not stop when the Nan appears, computation goes on as usual and it is very difficult to find the place where the problem originated. We are aware of this problem and this should be improved.

NaN's can also appear for a slightly different reason: for some given inputs, some functions have an output which is large, but not yet in overflow, whereas the derivative is definitely in overflow. Think of 1/x, whose derivative is -1/x**2.

If the Tapenade-differentiated code is executed right on a non-differentiable input, it may happen that the differentiated program returns NaN's as derivatives. See the FAQ item about divisions by Zero and NaN's.

Therefore, you probably need to go through the validation process to make sure that the derivatives are correct, compared to Divided Differences. Although inaccurate and expensive, Divided Differences are robust and therefore return good enough derivatives for validation.

But AD will return 0.0, and this can be explained: the dichotomy-based program actually sees f as a piecewise constant function, where each piece is of the size of machine precision. In other words, for values of x that differ only very slightly, the value of y is exactly the same, and thus the derivative is rightly 0.0.

Apart from the immediate rule of thumb which is "don't even think of differentiating dichotomy-based code, don't even write it!", the conclusion is that programming often introduces discontinuities into perfectly differentiable mathematical functions, and AD can't do much about it (true, Divided Differences behave better on this question!). When this happens, the derivatives computed by AD are just useless or plainly wrong.

In Tapenade, there is an experimental differentiation mode that evaluates the domain of differentiabillity around the current point, following a given direction in the input domain. The command-line argument -directValid builds a special differentiated program which, given a point in the input space and a direction in the input space (very much like in the tangent mode), evaluates the interval of differentiability along this direction.

Caution: If, inside the same execution, you need to perform several independent calls to the "directional validity" differentiated code, for different inputs or for different directions, then don't forget to reset the validity interval to ]-infinity,+infinity[ between two successive calls. Do this by resetting both infmin and infmax to .TRUE.

The internal representation of a program is now a Call Graph, with one node per subroutine, and each subroutine is now a Flow Graph, whose nodes are Basic Blocks. Each Basic Block is equipped with a Symbol Table, and Symbol Tables are nested to capture scoping. Basic Blocks contain instructions, represented as Abstract Syntax Trees.

We provide two ways of using Tapenade: either by connecting to the web server, or by downloading it to install it locally. There is a graphical user interface based on XHTML, and a simple command-line interface.

If you subscribe to the tapenade-users mailing list, you will have access to the archive of previous discussions at the address: https://lists-sop.inria.fr/wws/arc/tapenade-users You will need to use the "Login" button.

This means that some statements from the original program, which were "live" i.e. which computed something needed by the rest of the program, are not live anymore in the reverse differentiated program. This often occurs around the end of a forward sweep, just before the backward sweep. The reason is: a priori the only result you expect from the reverse differentiated program is the derivatives. In particular the original result of the original program is not considered as a necessary result of the reverse differentiated program. Therefore statements that are needed only for this original result become dead code. More explanations and a small example are in the TAPENADE 2.1 user's guide, specifically on page 33-34. A command-line option can toggle this mechanism off, see "-nooptim adjointliveness" on page 38.

However this is not enough, because the PUSH/POP mechanism will naturally destroy several of the program's original results. We advise that you modify the differentiated program by hand, saving the variables you want into temporary variables at the end of the forward sweep, and restoring these variables at the end of  the backward sweep.

Unfortunately, this is a difficult issue. Differentiated programs are complex and you may find it hard to check them by hand because they can be long and very complex. We try to keep them readable, but we're not sure they are...

In the example pieces of programs, actual pieces of code are written in this sort of dark red, short strings in double quotes are "patterns" as above, and      "entiere lines between double quotes and drawn in the pattern color" represent a piece of code that you must write at that place.

These procedures compare dynamically (at run-time) the derivatives obtained by divided differences (see below how they are built) with the derivatives obtained normally by the tangent differentiated program.

Since this verification mechanism needs to perform two runs of F_D on the same inputs, you will need to store all these inputs (we call this "taking a snapshot") before the first run of F_D, and restore them before the second run. If you know your code very well and you are certain that some inputs are never modified between the 1st and the 2nd run of F_D, then you may omit them from the snapshot.

On the first sweep (ddphase=1), it will just store the current value of the variable, which is the value "with " into a temporary file epsvalues. If this file really grows too big, you might consider modifying the present strategy, for example building two separate processes that communicate through a UNIX pipe.

This derivative is in turn compared with the AD analytic derivative. if the divided difference is far from the AD derivative (this is parametrized inside ddTest.f, where the percentage of difference is in variable diff), then the word "DIFFERENCE" is printed on the standard output close to the faulty derivatives.

Also, the dot-product test requires a preliminary run of a tangent differentiated code, so you should use Tapenade to generate both a tangent and a reverse differentiated code, both being aware of the dot-product test on F through the -dpTest option.

Running the test code will print on the standard output the values of the dot-products for each fragment between the milestone points placed in the code, printing the products (Yd | Yd) when going forward, and the products (Xd | Xb) when going backward.

If there is no bug, corresponding forward and backward dot-products should return the same value, and the validation process is complete. If this is not the case, assuming that you have validated the tangent mode as indicated above, this shows there is a problem with the reverse mode of the fragments for which the dot-products differ.

For example the -dptest "F" has set only the minimal two milestones, at the entry and at the exit of F, plus one "somewhere in the middle". These milestones appear in the summary with default names: EntryIntof, Inf, and ExitFromf respectively.

We advise you not to create new milestones by hand, except by copy-paste as explained above, because this is rather delicate. The order of PUSH and POP's matters, and it is extremely important that no active variable goes through a milestone without being caught by one PUSH/POP.

There are AD tools that rely on program overloading rather than program transformation. In general this makes the tool easier to implement. However some overloading-based AD tools can become very sophisticated and efficient, and represent a fair bit of hard work too. Overloading-based AD tools exist only for target languages that permit some form of overloading, e.g. C++ and Fortran95. Overloading-based AD-tools are particularly adapted for differentiations that are mostly local to each statement, i.e. no fancy control flow rescheduling is allowed.

These tools share their general architecture, with a front-end very much like a compiler, followed with an analysis component, a differentiation component, and finally a back-end that regenerates the differentiated source.

However it is based on a completely different architecture, from the OpenAD framework. This framework, very similar to Tapenade's architecture, claims that only front-end and back-end should depend on the particular language, whereas the analysis and differentiation part should work on a language-independent program representation.

In fact, these are extensions to the compiler so that differentiated code is added at compile time. For instance the NAGWare Fortran95 compiler has AD facilities inside, that are triggered by user directives in the Fortran source. It so far provides tangent-mode differentiation.

With its present user interface, Tapenade supposes that you want to differentiate one "top" procedure TOP, with one activity context, which is the set of independent inputs of TOP together with the set of dependent outputs of TOP.

This poses a problem if you want to differentiate many different "top" procedures, which is the case when you differentiate a library, or similarly when you want to differentiate some "top" procedure for different activity contexts.

Essentially the problem lies with code reuse and clash of procedure names. With the present user interface of Tapenade, you are obliged to run several differentiation sessions. Now suppose one "top" procedure calls subroutine SUB with one activity context, and another "top" procedure calls subroutine SUB with another activity context.

Until we build a better user interface of Tapenade, that would let you ask for multiple differentiation "top" routines and contexts, we advise that you write a single dummy top routine that has, say, one REAL active input and output, and this dummy routine just calls each of the top routines that you want, with each of the activity contexts that you want.

The only thing that matters is that Tapenade sees that the activity is propagated from the dummy top's active input to the actual calls active inputs, and from the actual calls active outputs to the dummy top's active output.

It will take only a dozen lines or so to write, and then a single differentiation of the new dummy top routine will return the desired differentiated "library", with only one differentiated version of each procedure, each for an activity context which is the envelope of all possible calls activity contexts.

If the Tapenade server rejected your files because they are too large, it probably means that you must download a Tapenade executable on your local system. Remember it is free for research non-commercial use.

The total size of all the programs you upload during a Tapenade session is limited to 300000 characters, because many users can access the server simultaneously and too large files make is swap and slow down, or even crash.

By the way, it still happens that the server crashes because of too many users differentiating too large files. In this case the server should restart automatically, so please wait for a moment and retry.

There is a new directive that lets the end-user specify that some procedure calls must not be checkpointed. If used wisely, this functionnality may produce a reverse differentiated code that is far more efficient, sometimes at the cost of an extra memory use.

When using the Tapenade server on the web, there can be only one differentiation page opened at a time. Do not try to open two different web browser pages, and call one Tapenade in each, because your Tapenade session is unique: therefore the files you upload would all go into the same directory here, causing strange behavior.

Also this is not so easy because the internal representation of Tapenade has digested every declaration into symbol tables that do not remember where declarations came from. For the same reason, we have nowhere to keep comments attached to declarations. Therefore they are kept in a list and reproduced at the end of the declaration part. They may be lost sometimes, but this is a bug and we will be grateful if you signal it to us.

The problem is that the extra dimension is not placed at the correct end of the structure, which is the "deep" end for a "record", or the leftmost dimension for a Fortran array. This should be fixed soon.

If Tapenade fails to find the correct type REAL of the temporary variable, puts INTEGER instead, this looses activity. We put the warning message (TC43) to signal the problem. The workaround is to do the splitting beforehand, on the source program, and to declare the intermediate variables with the correct type.

For procedure calls in the reverse mode of AD, there is now an option between the "joint" mode that existed previously, and the "split" mode that does no checkpointing for a particular call. Deactivation of checkpointing may yield huge performance improvements of the differentiated code.

In the reverse mode, all statements that were useful for the original program, but are not necessary to compute the derivatives (known as "dead adjoint code") are automatically removed, and the associated tape is reduced consequently.

End-user can specify types of external or library procedures, specifying that some type may be arbitrary, or else must be equal to another arbitrary type. e.g. one can tell that F(x,y) can accept any type for x and y, provided it is the same type.

Aliasing inside instructions in reverse mode: instructions such as a(i) = 2*a(j) are split, introducing a temporary variable, because reverse differentiation must absolutely tell whether the two references to a are the same address or not.

I-O statements are now differentiated more correctly: derivatives of overwritten variables are reset to zero. A message warns the user when a potentially active variable may loose its derivative across an I-O instruction.

Following a suggestion from Andreas Griewank, the default suffixes are now: in forward mode,"d" for variables and "_D" for routines ("d" stands for "dot" or "direct"), and in reverse mode, "b" for variables and "_B" for routines ("b" stands for "bar" or "backwards").

Preliminary analysis of programs include syntax checkings, type checking, in-out analysis Dependency analysis for differentiation detects not only variables that depend on independent inputs, but also variables that influence dependent outputs. Only the intersection of those two sets need be differentiated.

The inversion of the control, in the reverse mode, is done on the Flow Graph. This gives a better, more readable transformed source, that the compiler can compile better. The generated code is not "flattened" as by O∂yssée 1.7.

The reverse mode uses the TBR analysis (validated on O∂yssée 1.7). It finds variables which, although they are overwritten during the forward sweep, need not be saved because they will not be used during the reverse sweep.

New storage strategy for the reverse mode, named the global trajectory. This stores intermediate values on an external stack rather than on static arrays that thad to be dimensioned by hand by the user of O∂yssée Snapshots in the reverse mode are smaller, because they use In-Out analysis to find out variables that are really necessary for duplicate execution of the checkpointed piece of code.

Available as a web server, with a XHTML user interface. No need to install! Colors highlights in the source and differentiated files. Anchor mechanism for correspondence between source and differentiated files. Basic display of the call-graph.

Fundamentally, AD transforms a program that computes a mathematical function into a new program that computes its derivatives. Being automatic, AD can spare a large amount of development effort. AD is increasingly used in Scientific Computing, but some problems still delay its widespread use. In this thesis we propose elements of solution for two of these problems. The first problem is non-differentiability of most real-life programs for some particular inputs. AD tools often overlook this problem. However users need a strong degree of confidence in the derivatives they obtain, to use them e.g. in optimization engines. Non-differentiability in programs may come from various causes, from the mathematical model to the actual implementation choices.  Practically, non-differentiability in programs is embodied by the presence of control. Rather than studying notions of extended derivatives, our approach is to describe the domain in the input space for which the function actually remains differentiable.  We describe several alternatives to find this domain of validity and we evaluate their complexity. We formally study one method to compute the complete domain, but we discard it because of its cost. Alternatively, we propose a simpler directional method that we have implemented and validated on several examples. The second problem is efficiency of the reverse mode of AD, which computes gradients and is therefore of high interest. Reverse AD programs use the intermediate values from the original program in the reverse order, and this has a cost, whatever the strategy used.  Available strategies all rely on a combination of storing and recomputing intermediate values, thus costing memory space and execution time. The central tactique, called "checkpointing", trades duplicate execution of complete segments of the code for memory space. In this work, we formalize the static data-flow behavior of reverse AD programs, taking checkpointing into account. Based on these formal results, we contribute two improvements to reverse AD strategies. First, the data-flow analysis lets us reduce the number of stored values to a minimum, and we give elements of proof of minimality. Second, we obtain indications on the code segments that are most appropriate for checkpointing. To experiment on checkpointing schemes, we extend the data-flow analyses and the reverse mode in our AD tool. We show the benefits on several large Scientific Computing codes.

However, checkpointing also uses a non-negligible memory space for the so-called ``snapshots''. We analyze the data-flow of checkpointing, yielding a precise characterization of all possible memory-optimal options for snapshots. This characterization is formally derived from the structure of checkpoints and from classical data-flow equations.

In particular, we select two very different options and study their behavior on a number of real codes. Although no option is uniformly better, the so-called ``lazy-snapshot'' option appears preferable in general.

August 2001 : Rose-Marie Greborio joins Tropics as a "specialist engineer". She will participate in developments on the platform for program analysis and on the A.D. tool on top of it, as well as tests and documentation.

The subject of my PhD thesis was the design of a typed language suitable to express the level of polymorphism necessary to express the mathematical algorithms of computer algebra in their full generality.

The resulting language,  XFun , is a strongly typed functional programming language. XFun is not a language specialized  for algebraic computation but a general purpose language, intended to explore what a sophisticated type system can bring to software engineering: to write reusable software components and to manage large software systems and their evolution.

The Central Control is a software component that has been designed to be the kernel of an environment for scientific computations which can offer a common and concurrent  access to the tools needed by scientists and engineers: general purpose and specialized computer algebra systems, visualization tools, links with numerical libraries and tools to manipulate numerical programs... The Central Control can abstract the syntaxic and semantic differences of the systems so that, for example, an expression computed by Mathematica can be used as input to Maple. The Central Control is in fact an extended Scheme interpreter.

The Central Control supports asynchronous (batch) computations with a mechanism of promises that is very similar to the future construct of Multilisp. The Central Control can  associate a handle to a result that is stored in a server to avoid the effective transmission of large objects.

The subject of the PhD thesis of Olivier Arsac is the design and implementation of a customisable equation editor,  Emath . Emath embeds a Lisp interpreter (Klone) as its extension language in the same spirit as the  Emacs  text editor.

The database itself is a stand-alone program which can run as a server in a client/server environment and it has been designed to be a powerful assistant for computer algebra systems as well as for other applications.

Piz Bernina is a 4049-meter peak in Graubunden, in the south-east corner of Switzerland. Its gleaming summit, pictured above, dominates the majestuous Morteratsch and Tschierva glaciers. This page describes however bernina, an interactive interface to the Sum^it library that provides some efficient computations revolving around operators in Q[x,d/dx] or Q(x)[d/dx]. In fact, the main goal of bernina is to provide access to selected functionalities of the Sum^it library to other computer algebra systems, or to users who do not own an Aldor compiler, or who feel more confortable with interactive access to a library.

If you do not need any of the above computations, then you probably will not have much use for bernina. Otherwise, since bernina provides implementations of several recent algorithms for those computations, it is worth giving it a try.

Aldor programmers and the abstract machine, as well as several standard data structures, allowing its users to start programming with a fairly complete set of basic types and data structures already built into the language.

Algebra is a new general-purpose computer algebra library designed to provide reusable and efficient algorithms for manipulating the standard objects of algebra, namely polynomials, series and matrices.

Sum^it is a computer algebra library designed to provide reusable and efficient implementations of algorithms for manipulating and solving linear ordinary differential and difference equations and systems.

A classical method to compute the number of irreducible components of an hypersurface P(x1,...,xn) = 0 is to factor the polynomial P over an algebraically closed field. In the case of curves (n=2) a new method was introduced in [1]. That method first computes a linear ordinary differential operator L(x,d/dx) associated with the curve, and shows that the number of irreducible components is equal to the dimension of the space of rational solutions of L(x,d/dx)(y) = 0. The authors also claim that a generalisation to hypersurfaces is possible, provided that one uses an overdetermined system of linear partial differential equations instead. The goal of this internship is to verify the proposed generalisation on various examples using algorithms (existing and under development) for computing the rational solutions of such systems, then to check whether their genericity condition on P remains needed, and finally to attempt to prove that the number of irreducible components is indeed equal to the dimension of the rational solutions.

Research is a difficult enterprise.  The problems are hard and require creativity and persistence.  Their solution benefits from a critical mass of investigators of diverse backgrounds.  Those researchers depend on an infrastructure of financial support, periodic public gatherings, archival document and software media, and industrial production.  I will attempt to assess the impact of Manuel's involvement in ISSAC, JSC, SIGSAM, Axiom/Aldor and elsewhere.  Finally, I will make some personal observation about the research community in symbolic computation and possible future goals.

To implement this method, one needs an algorithm to find hypergeometric solutions of linear recurrence systems. The cyclic vector approach introduces significant expression swell. Thus, to factor difference operators efficiently, one needs a direct method for finding hypergeometric solutions of systems. Manuel had ideas on how to do this efficiently and we had planned a joint paper on this issue.

In his thesis Manuel Bronstein improved the algorithms for symbolic (or closed form) integration. Such an first order linear differential equation is often solved by finding simpler solutions of higher order linear differential equations.

Therefore, shortly after his thesis, Manuel Bronstein devoted a substantial part of his research to closed form solution of linear differential equations and published one third of his papers on this subject. Manuel Bronstein's most contributions in this area concerned symmetric or alternating products and their rational or exponential solutions. His main objective was always to obtain practical algorithms, who would solve the problem in reasonable time, even by resorting to heuristics. Guided by his strong computer science background, he tackled the basic algorithms by reducing field extensions and showed how to avoid unnecessary or costly steps like factorisation.  He was open to any new ideas that would speed up the algorithms and was able to integrate them very quickly. Manuel always tested his algorithms by a solid implementation which he would make publicly available, providing researchers in the field with precious tools.  This central position made him always aware of new progress in the field and he played a significant role in the spread and publication of new ideas as a member of the editorial board of the journal of symbolic computation.

Computer algebra software has evolved considerably since the 1980s, but only a very few individuals have embraced the new technologies and used them effectively to extend the reach of their research.  Manuel Bronstein was a leader in this group.  He was an early adopter of the categorical formulation of algorithms to structure software libraries and the use of mathematical network services.  Not only did he see how these software directions could be used, but by fully integrating them into his own work he significantly influenced their evolution.  This talk presents some of the software innovations that Manuel Bronstein drove.

Up to recently I have mainly worked in game theory, mostly approximation techniques and applications to  economics. I moved recently to interval analysis, with the aim to understand how uncertainty (intervals) propagates in a model.

Here is an example you can program in a few minutes: it's the Connoly surface. Consider two fixed spheres (in thick lines) on which roll a sphere (represented in four differents positions and in thin lines).

The natural evaluation allows one to determine efficiently lower and upper bound for the real values of a function whatever are the mathematical operators appearing in the function. These bounds may be overestimated (i.e. there is no value of x such that f(x) is either fInf or fSup but the difference between the real lower and upper bound and the interval evaluation will decrease with the width of the intervals in the box.

There are numerous packages that implement interval arithmetics (for example BIAS/Profil). All of them allows to take round-off errors into account, i.e. the real lower and upper bounds of the function are guaranteed to be included in the computed interval evaluation.

The principle of the algorithm is quite simple: for a given box we compute the interval evaluation of the inequalities. If the lower bound of one evaluation is positive, then the box cannot contain a solution to  S, so we consider the next box in the list. If the upper bound of all the evaluation is negative or 0, then any point within the box is a solution. Otherwise if at least one evaluation has a negative lower bound and strictly positive upper bound, then we split the largest interval in the box and create 2 new boxes having the same interval than the initial box, except for the variable that has been bisected. This bisection is done only if the width of at least one interval in the box is larger than a given threshold e.

We proceed until one solution has been found or until all the boxes have been processed. In the later case if the threshold e has been chosen very small, then we may assume that there is no solution to the problem.

Note that it is easy to modify the algorithm so that if for a given e the ratio VIn/VNeg is not satisfactory we may decrease the value of e and process only the boxes that have been neglected during a previous run.

Hence whatever is x in the range [2,3] the derivative will always be positive. Hence we will compute the interval evaluation of f by setting the lower bound of the evaluation to f(2)=2 and the upper bound to f(3)=6. The interval evaluation is now [2,6] which is the correct answer. This process may be used for functions having multiple unknowns but has to be recursive: indeed fixing a variable to a constant value may change the interval for an already computed evaluation of the derivative of the function with respect to another unknown.

Let U=[UInf,USup] be the interval evaluation of the right hand side of this inequality computed for a given box {x,y}. If xInf > USup, then the inequality will never be satisfied and the box can be rejected. Otherwise if xSup > USup, then the inequality will never be satisfied for any x in [USup,xSup]: hence we may change the x interval of the box from [xInf,xSup] to [xInf,USup], thereby reducing the width of this interval. Note that changing the interval x will lead to a change in the interval U: hence the procedure may be repeated until no noticeable change is observed on x. We may then start the same procedure for the unknown y.

ALIAS is a C++ library using the interval arithmetics of the package BIAS/Profil. An originality of this library is that it is partially interfaced with Maple. A specific Maple library allows to generate automatically the C++ code of the algorithms described in this document (including the 2B and 3B methods), to compile it, to execute a C++ program and to get the result without having to leave Maple. The results presented in the following section have been obtained using this process.

Finding a solution of problem M1 with a width of the solution box of order 1 using the Maple interface takes a total time of 6.51s on a Sun Blade workstation. Here we use only the 2B method as simplification rule.

Note that it is possible to search for a solution within another search space without having to restart the code generation and compilation. The executable created during the first run can then be re-used with another search space. In that case the computation time for finding the first solution is 0.08s.

The purpose of this section is to present problems for which interval analysis has failed or has experienced difficulties (large computation time for the total system or for a number of equations equal or greater than 10).

The derivatives of  with respect to  are combined to eliminate . The optimality equations constitute then a system of 3 equations in . The roots  of this system are used to calculate and the lowest value of this quantity is the square of the largest singularity-free disc.

There is a linear relation ship between the velocities (translational and angular) X of the end-effector of a robot and the velocities T ot its actuator, which may be written as T=JX where J is called traditionally as the jacobian matrix of the robot. This jacobian is usually known in closed-form for parallel robots.

A problem occur when this matrix become singular. Indeed for a zero velocity of the actuators, the velocity of the end-effector can be no more 0: even if the actuators are locked the end-effector is still moving and the robot control has been lost. Furthermore in that case the forces/torques to which are submitted the actuators may go to infinity, leading to a breakdown of the robot. Hence it is essential to be able to determine if such case may occur within a given workspace for the end-effector.

This is a complex issue as even if the jacobian is known in closed-form, it may be impossible to calculate analytically its determinant due to its very large size or complexity. Furthermore geometrical parameters of the robot appears in the jacobian, which are known only with some uncertainties. It is therefore essential to be able to manage these uncertainties.

Much of the research is centered around the proof assistant Coq, which is used as a common framework to combine each group's specific domain of competence. Coq has been successfully used to certify a large subset of the Java Card platform, including the Virtual Machine, the Runtime Environment, the Converter and the Byte Code Verifier, as well as to certify algorithmic techniques for program verification, namely model-checking and abstract interpretation. These formalisations form the basis of INRIA's contribution to the project.

Further, CertiCartes contains the specification of the  bytecode verifier as a data-flow analyzer based on the abstract virtual machine; currently the bytecode verifier does not deal with object initialization. Finally, CertiCartes establishes the correctness of our bytecode verifier by showing that the offensive and defensive virtual machines coincide on those programs that pass bytecode verification.

The proof relies on showing that the abstract virtual machine is a sound abstraction of the defensive virtual machine, and that the offensive abstract virtual machine is a sound abstraction of the defensive virtual machine.

The tool takes the JavaCard Virtual Machine specification that is developed in Coq - in the context of the CertiCartes project - as input. This is a defensive virtual machine, and by abstraction it can be transformed into a byte code verifier plus an offensive virtual machine.

Typical for the new-generation multi-application smart cards is that applets can be loaded post-issuance, i.e. after initialisation of the card. In this project we look at compositional verification of smart card programs, stating which properties should be satisfied by the components of the system, to ensure the global correctness of the system. When issuing a new applet on the card, one has to check that this new applet satisfies these required properties, in order to know that other applets can safely cooperate with it.

Specifications for JavaCard programs To verify JavaCard programs, one first has to specify their intended behaviour. Therefore, it is important that the specification language that is used is expressive enough. Also, it is useful if one can do quickly an approximate correctness check on the specification, that can find the most common mistakes. This can be done by using for example the static checker ESC/Java. Within this project, we investigate appropriate specification languages and appropriate specification checking techniques.

Benchmark Kit, containing the complete source code for a purse applet.  We annotate the code with specifications (pre-post conditions, class invariants etc., and check the annotations with ESC/Java.  While specifying, we found several bugs in the original source code.  The corresponding ESC/Java annotations are available here.

ESC/Java does not check the assignable clauses (or frame condition, or modifiable clause) of a method specification, which states which variables may be modified by a method. Therefore, we develop a checker for such assignable clauses, called ChAsE.

Based on a syntactical analysis of the program, for each statement it is checked that it does not violate the assignable clause, and a warning is issued if this might be the case. ChAsE is not sound or complete, but it designed to be efficient and to find the most common specification errors. ChAsE can be downloaded.

To increase the expressiveness of the specification language we use, we propose an extension of JML with temporal logic specifications. This allows to specify how objects interact. Part of the extension is only syntactic sugar and can be translated back into ``standard'' JML, but part also allows to express properties which were not expressable in JML before.

Using contextual equivalence (a.k.a. observational equivalence) to specify security properties is an important idea in the field of formal verification of cryptographic protocols. While contextual equivalence is difficult to prove in general, in typed lambda calculi, one is usually able to deduce it using so-called logical relations.

Moggi's computational lambda calculus. To explore the difficult aspect of dynamic key generation, we use Stark's name creation monad. The general construction of logical relations for monadic types (by Goubault-Larrecq et al.) then allows us to derive logical relations on Stark's semantic model.

This study also leads us to an exploration of what should be the right definition of contextual equivalence for cryptographic protocols. We argue that contextual equivalence defined over Stark's model cannot represent honestly the power of contexts or attackers. Actually, although Stark's category is a perfectly adequate model of dynamic key generation, it lacks in some aspects when we study relations between programs in the metalanguage. We then propose a refined category for studying contextual equivalence and defining logical relations in the cryptographic metalanguage. We show that the cryptographic logical relation derived over this category is sound, and complete for a certain subset of types up to first order. We explore questions of decidability of cryptographic logical relations relating two given terms in certain cases.

We then extend our soundness and completeness results at all higher-order types, which requires us to switch from logical relations to lax logical relations. We define logical relations which are lax at function types but strict (non-lax) at various other types, and show that they are sound and complete for contextual equivalence at all types.

Verification of concurrent Java programs, together with my PhD students Clement Hurlin and Gustavo Petri. We have a particular interest in thread-modular verification. This work is done in the context of the Mobius project.

JML: use and semantics. Particular interest in annotation generation to specify security protocols. Currently, I am working on this with Alejandro Tamalet. This work is done in the context of the Mobius project.

I am a PhD student working on the verification of multi-threaded programs under the guidance of Marieke Huisman at Inria Sophia-Antipolis in the Everest team. Previously, I graduated from the Esial and the university of Nancy.

Program slicing is a program analysis and transformation technique that has been successfully applied in a wide range of applications including program comprehension, debugging, maintenance, testing,  security, and verification.

This talk presents an overview of Indus -- a robust framework for analysis and slicing of concurrent Java programs, and Kaveri -- a feature-rich Eclipse-based GUI for Indus slicing.  For Indus, we describe the underlying tool architecture, analysis components, and program dependence capabilities required for slicing.  In addition, we present a collection of advanced features useful for effective slicing of Java programs including calling-context sensitive slicing, scoped slicing, control slicing, and chopping.  For Kaveri, we discuss the design goals and basic capabilities of a graphical presentation of slicing information that is integrated into a Java development environment.  We will also briefly overview the Indus scripting framework that allows developers easy access to a variety of information collected by the underlying Indus program analysis framework.

Proof-Carrying Code (PCC) is a technique for downloading mobile code on a host machine while ensuring that the code adheres to the host's security policy.  We show how certified abstract interpretation can be used to build a PCC architecture where the code producer can produce program certificates automatically.  Code consumers use proof checkers derived from  certified analysers to check certificates.  Proof checkers carry their own correctness proofs and accepting a new proof checker amounts to type checking the checker in Coq.

The PCC architecture has been evaluated experimentally on a byte code language for which we have designed an interval analysis that allows to generate certificates ascertaining that no array-out-of-bounds accesses will occur.

We present F^, a lambda calculus for which termination is guaranteed by the typing rules and show some ideas used to design an inference algorithm for it. F^ (read as F sombrero) results from enriching Girard's system F with size annotations. This allows constructor depth to be bounded, making it possible to guarantee strong normalization of well typable expressions. This property together with a type inference algorithm, allows static verification of many terminating programs.  More importantly, it guarantees correctness of "inductive" proofs in logical systems based on the Curry-Howard isomorphism.

ESC/Java2, a static analyser for Java code has been written between 1996 and 1999 by Compaq. At that time the only efficient prover was Simplify, that's why ESC/Java2 was entirely relying on it. With the arrival of new provers and the satisfiability modulo theory (SMT) standard, there was an opportunity to benefit of the lastet advances in that area. It raised problems related to logic (need for new many-sorted logics) and generic design (how to handle different provers easily).

I am working with Lilian Burdy on the definition and the implementation of a framework for Java bytecode program verification. This involves the definition of a bytecode specification language and a compiler from the high level specification language JML(the Java Modeling Language) to the bytecode specification language.

In order to perform bytecode verification we define a bytecode verification condition generator. The latter is based on  a weakest precondition calculus defined for almost all sequential bytecode instructions (except for 64 bytes data and floating point arithmetic). We have both the implementations of the weakest precondition calculus and the JML compiler. They are integrated into the  JACK  (Java Correctnes Kit ) eclipse plugin.

Memory consumption policies provide a means to control resource usage on constrained devices, and play an important role in ensuring the overall quality of software systems, and in particular resistance against resource exhaustion attacks. Such memory consumption policies have been previously enforced through static analyses, which yield automatic bounds at the cost of precision, or run-time analyses, which incur an overhead that is not acceptable for constrained devices.

Security models for mobile code typically rely on typing mechanisms that statically enforce basic safety policies (e.g. code containment or absence of pointer arithmetic) and mechanisms such as stack inspection in Java and .NET that dynamically enforce access control policies. While these mechanisms are intended to enforce confidentiality and integrity policies, it is difficult to assess the policies that they guarantee. In particular, they do not guarantee information-flow policies that are needed in scenarios involving the execution of untrusted code.

To enforce these stronger security guarantees, one can use information-flow type systems, which provide a means to track data flows and control dependencies, and thereby to reject any program that may leak confidential information. While information flow type systems provide an attractive means to enforce non-interference, they reject too many secure programs to be practical. In order to circumvent this difficulty, it is possible to use standard program logics, via the self-composition technique proposed by Barthe, D'Argenio and Rezk, and further extended by Naumann in the context of Java. While program logics permit a precise analysis of information flow, they require developers to prove that their program respects confidentiality using an appropriate proof tool. In order to curb the complexity of verification, Terauchi and Aiken proposed to combine the self-composition technique with a program transformation that minimizes the number of proofs to be done.

The objective of the internship is to develop a method to prove confidentiality of programs using a combination of type systems, program logics, and program transformations. The method will be developed on a core programming language, and experimented on relevant case studies. In the second phase of the internship, the method will be implemented in a tool to reason about Java programs, or will be proved correct using the Coq proof assistant.

Mobile devices, such as mobile phones and television set top boxes, provide new challenges to security, since they allow the dynamic loading of new software. This software can be user applications, for which we need to ensure that they do not corrupt the security of the other applications on the device, or they can be system components (a game might require for example a faster implementation of memory access). For the latter, one does not only have to ensure security but also functionality, i.e. does the component behave as it is supposed to, so that the operating system will keep on functioning well.

The implementation can then be verified using an existing verification tool for JML (ESC/Java2, Jack, ..). The translation should be such that correctness of the implementation w.r.t. the JML specification implies correctness w.r.t. the high-level protocol.

With the emergence of Internet and other models of global computing, privacy guarantees are becoming more and more important. Typical applications such as electronic banking and health care information systems only are acceptable to users if their privacy is sufficiently guaranteed. Non-interference is a standard notion of security that allows to preserve privacy. Basically, an application is said to be non-interfering if changes to the private (or secret) data are not reflected in the public data, in other words public data only depend on public data.

Several analyses have been developed to check for non-interference, of which type checking is the most used approach. The type checking analysis has been shown to be sound, and in addition it is fully automatic. However, it is necessarily incomplete, because it cannot take context-sensitive information into account. Therefore, reformulations of the definition of non-interference have been proposed that allow to use classical logic-based verification techniques; expressing non-interference for example as a Hoare triple [BDR04], [DHS04].

However, the standard definition of non-interference only considers the input and output of an application. For concurrent and reactive systems it is often considered more appropriate to also look at the intermediate states of the application, and to require that private data are never revealed. Therefore, in the literature various definitions of non-interference for concurrent programs exist.

The ACS project aims at advancing the state of the art in computing with complex shapes. Current technolgy can cope well with curves in the plane and smooth surfaces in three-dimensional space. We want to address a larger class of shapes, including piecewise smooth surfaces, surfaces with singularities, as well as manifolds of codimension larger than one in moderately high dimension.

Increasingly demanding applications require efficient and robust algorithms for complex shapes. Topics that arise and that we address are shape approximation (including meshing and simplification), shape learning (including reconstruction and feature extraction), as well as robust modeling (including boolean operations). Our work on these topics will be closely intertwined with basic research on shape representations.

A unique and ambitious feature of our approach is the guaranteed quality of all data structures and algorithms we plan to develop. Through certified topology and numerics, we will be able to prove that the output is topologically and numerically consistent, according to prespecified criteria. A software prototype, dealing with a restricted class of complex shapes, will demonstrate the feasibility of our techniques in practice.

The focus of this project is the solution of polynomial systems by matrix methods. Our approach leads naturally to problems in structured and sparse matrices. Real root isolation, either of one univariate polynomial or of a polynomial system, is of special interest, especially in applications in geometric modeling, CAD or computational geometry. We are interested in computational geometry, actually, in what concerns curves and surfaces. The framework of this work is the european project ECG.

Geometric computing aims at manipulating forms for real world simulation or analysis purposes. The application domains (Computer Aided Geometric Design, architecture, molecular biology, virtual plants, ...) are numerous and still in expansion. Behind these approaches, we find semi-algebraic models such as quadrics, rational or implicit curves or surfaces. Their effective treatment requires in fine, to solve polynomial equations, which is usually performed by a combination of symbolic and numeric methods, for approximating the (real) roots and for certifying the result.  In problems such as computing of arrangements of curves and surfaces on which we are working, operations such as approximation and isolation of roots or evaluation of predicates have to be conducted intensively and with guarantees.  The objective of this work is to study and develop high performance methods for solving polynomial equations of "small" degree, which appear in this geometric problems. We are interested, in particular, in subdvision approaches, which allow filtering and certification techniques. These investigations will be validated by implementation based on the software library Synaps.  Contact : Bernard Mourrain.

Real root isolation of univariate polynomials is a fundamental task incomputer algebra. One of the algorithms for achieving this taskgoes back to Vincent. His algorithm, however, has a worst-case exponentialrunning time. To overcome this drawback two algorithms were proposed:the Descartes method by Collins and Akritas in 1976, and a modificationof Vincent's algorithm by Akritas in 1978. Both algorithms performcomparably in practice, but there is a huge gap between the two algorithms when it comes to comparing their worst-case complexities. For the Descartes method, the worst-case complexity has been studied extensively, and there have been a lot of improvements recently; in particular, it has been showed that for a square-free integer polynomial of degree $n$ and coefficients of bit-length $L$ the bit-complexity of the Descartes method is $O(n^4L^2)$. Similar worst case bounds on the bit-complexity of Akritas' algorithm were not known in the literature. We provide the first such bound, $O(n^{11}L^3)$, for a square-free integerpolynomial of degree $n$ with coefficients of bit-length $L$.

My main research interests are on topics commonly referred to as Geometry Processing: geometry compression,  surface approximation, mesh parameterization, surface remeshing and mesh generation. I received the Eurographics Young Researcher Award 2005 (see citation).

Abstract: We introduce a framework for quadrangle meshing of discrete manifolds. Based on discrete differential forms, our method hinges on extending the discrete Laplacian operator (used extensively in modeling and animation) to allow for line singularities and singularities with fractional indices. When assembled into a singularity graph, these line singularities are shown to considerably increase the design flexibility of quad meshing. In particular, control over edge alignments and mesh sizing are unique features of our novel approach. Another appeal of our method is its robustness and scalability from a numerical viewpoint: we simply solve a sparse linear system to generate a pair of piecewise-smooth scalar fields whose isocontours form a pure quadrangle tiling, with no T-junctions.

We consider the problem of reconstructing a surface from scattered points sampled on a physical shape. The sampled shape is approximated as the zero level set of a function. This function is defined as a linear combination of compactly supported radial basis functions. We depart from previous work by using as centers of basis functions a set of points located on an estimate of the medial axis, instead of the input data points. Those centers are selected among the vertices of the Voronoi diagram of the sample data points. Being a Voronoi vertex, each center is associated with a maximal empty ball. We use the radius of this ball to adapt the support of each radial basis function. Our method can fit a user-defined budget of centers: The selected subset of Voronoi vertices is filtered using the notion of lambda medial axis, then clustered to fit the allocated budget.

Hello! Welcome to my very own page. I am presently in Hanoi for the Chinese New Year. If you cannot wait, you may visit the web page at your own risk. Please leave a message after the beep. I'll get back to you as long as I...

Geometric modeling, until now limited to computerassisted design and engineering, enlarges its range of applications. First of all, one aims at modeling discrete structures of ever increasing sizes. Concrete examples are the modeling of biological cells to understand their growing and evolution process in cancerology or agronomy, the modeling of pockets or proteinprotein interfaces to understand how molecules dock in structural biology, and the modeling of the Internet or other telecommunication networks to simulate data transfer and bandwidth. Another aspect of geometric modeling is the approximation of complex shapes. In order to simulate ﬂows or physical behaviors of solid or biological objects, it is common to decompose them into simple elements such as triangles or tetrahedra. For graphics or robotics applications, it is often necessary to approximate complex shapes by simpler ones in order to allow efﬁcient visualization and animation. Although the problems mentioned herein often arise in two or three dimensions, they also happen to arise in higher dimension for modeling conﬁguration spaces in robotics, conforming spaces in molecular biology, and for parametric spaces in statistical analysis and data mining. Geometric modeling also plays a role for information society technologies and sciences. Measuring a geometric information is notoriously more difﬁcult than measuring a signal or taking a picture. The 3D shape digitization systems (laser scanners, tomography, 3D cameras) are quickly evolving and become more accurate, efﬁcient and for some of them even cheaper. Nevertheless, processing such a geometrical “signal” requires different techniques, as earlier digital signal processing algorithms do not carry over to digital geometry. The challenge is substantial as it is foreseen that after text, sound, image and video, geometry will be an intrinsic part of multimedia, for which we foreseen an economic and social impact for remote collaborative activities, eshopping, education and culture.

Three major challenges structure our research in geometric modeling : dealing with massive data sets, reliable and certiﬁed software for geometric computing and elaborating upon a geometric approximation theory.

Massive Data. Some volume of data to be processed are now gigantic and quickly increase in size : Current measurement systems such as laser scanners provide millions of points per second, and million polygon models are now common in Computer Graphics. A less visible but difﬁcult issue is the growing (usually exponential) of geometric structures with the dimension of the underlying space. It is specially the case for conﬁguration spaces of mechanical or biological linkages. The search for efﬁcient algorithms yields to a careful analysis of the algorithms. In particular, the way the data are stored for real data sets should be different from the theoretical worst case asymptotic complexity. The design of compact memory representations, the management of auxiliary storage devices or parallelism become topics of great practical interest.

Reliability and certiﬁcation. Geometric computing algorithms are notoriously sensible to numerical issues. These main difﬁculties come from the fact that the geometric models often embed topological and combinatorial information, as well as numerical attributes (in other words, both discrete and continuous aspects). The application areas of geometric computing being increasingly more, as for the systems which embed geometric computing software, more and more application domains where software reliability is critical are concerned (medical, air trafﬁc control). The geometric software being complex by nature, the risk is substantial. In order to prove the software correctness, it is required on the one hand to elaborate upon solid theoretical foundations, and on the other hand to ﬁnd the best means to efﬁciently implement the corresponding mathematical tools.

One solution to solve the robustness issues of geometric computing software is to use the paradigm of exact computing (not to be confused with exact arithmetic !). The work carried on within the CGAL library has shown this paradigm relevant when all geometric primitives are simple enough, as for points or triangles. Extending this paradigm to more complex primitives such as curves or algebraic surfaces (even of low degree) is a major challenge. Taking up this challenge would make an impact for computeraided design, where some data sets used for machining are composed of circle arcs or segments, and for structural biology where it is required to compute with large sets of spheres.

Recent advances in mesh generation has led to several techniques for surface and volumetric meshing. Some of them generate meshes with certiﬁed properties in terms of geometry, topology and shape of the elements. The challenges to be undertaken in the near future are the generation of timeevolving (dynamic) meshes and mesh optimization.

Dynamic meshes are useful to model deformable materials, be they plastic, ﬂexible or vibrating. As an example, surgical simulation by medical image processing requires taking into account the cardiac or respiratory movements. Molecular modeling requires integrating the ﬂexibility of some bonds as well as the molecular vibrations into the model, since they play a crucial role into the molecular dynamics.

All certiﬁed meshing techniques developed by computational geometers are greedy and mainly deal with combinatorics. A complementary approach consists of optimizing the mesh connectivity and geometry by minimizing an energy functional. Optimized meshing techniques, aimed at optimizing a discrete problem by numerical optimization, are notoriously difﬁcult to analyze, but exhibit promising results. It is a challenging problem to combine the advantages of both combinatorial and numerical approaches.

Developing new ideas and codes useful for applications require to rely on a software development model which is both perennial and close to ongoing research. The example of CGAL demonstrates that it is possible to produce, in a research environment, some large, cooperative, longterm and reliable quality software. CGAL is both a precious repository of peerreviewed implementations of standard and stateoftheart geometric algorithms, and also a useful platform for geometric computing used in various application domains. The advantages of choosing this path is that, once the software has reached a good level of maturity and size, we have a way to demonstrate our expertise in practice and it makes us attractive towards application areas. Moreover, it helps supporting further research in two ways : more applied research based on this existing software (even in other projectteams), and suggesting core research motivated by concrete experience, which can be hard to get from external industrial software. Finally, such software helps by structuring communities and promote collaboration. However, maintaining large software has a cost in the longterm. INRIA does not currently provide support for such tasks as engineers, which are almost all allocated on speciﬁc shortterm projects. We therefore suggest that speciﬁc resources should be allocated to support selected perennial software projects, based on evaluations of these projects. This also raises the question of the evaluation criteria of the software projects and their authors.

Information geometry investigates the geometric structure possessed by families of probability distributions [0]. For example, the set of normal distributions can be viewed as a 2-dimensional space with mean and variance as a coordinate system. Such a space is not a metric space.

The notion of Bregman divergence emerged recently as a general concept that encompasses many of the standard divergences used in information theory, statistics, machine learning, image and signal processing.

The goal of this internship is to design and implement data structures and algorithms for Information Geometry. The work will be a first step towards revisiting the whole core of Computational Geometry in the context of Information Geometry. The proposed work will build upon recent results on minimal enclosing balls [1], Voronoi diagrams [2] and clustering algorithms [3]. Information Geometry usually implies to work in high dimensional spaces. Since the combinatorial complexity of most geometric data structures depends exponentially upon the dimension of the embedding space, complexity issues are critical. Recent concepts like core-sets and witness complexes might appear to be useful. Finally, the tools developped during the internship will be validated on some applications in image processing, structural biology or non linear manifold learning.

One of the most popular methods in flow visualization consists of placing a set of streamlines which are always tangential to the flow in order to emphasize the global field coherency. Beside, high quality placement of streamlines has recently proven relevant for other applications such as non-photorealistic rendering or curve-based surface remeshing.

The goal of this internship is to elaborate upon an algorithm for high quality placement of streamlines on triangulated surfaces. Although a high quality streamline placement has no formal definition, it is admittedly related to the uniformity of streamlines as well as to the spacing with respect to the desired density. In particular, we will investigate the possibility to avoid the need for any parameterization stage, and will resort to a 3D Delaunay triangulation restricted to the input surface instead.Targeted applications are anisotropic remeshing of surfaces and visualization of flow fields on surfaces.

Extending geometric algorithms to the case of curved objects is currently a very active research topic. This was at the heart of the European project ECG and is central again in the following project ACS.

Beside   industrial applications (both    civilian and military), computer simulation of electromagnetic wave propagation is nowadays increasingly  applied  to societal  questions.   Of particular interest is the area concerned  with the interaction  of electromagnetic wave with  humans or, more precisely,  living tissues.  There are  at least two situations  that are concerned  with this   subject: the  study of   potential  adverse  effects of electromagnetic  waves and,   the   use  electromagnetic  waves   for  medical applications.  A classical  example  in relation with the  first  point is the study of the propagation of an electromagnetic  wave emitted by a mobile phone in the tissues of the user head.

The accomplishments  of the  HeadExp  project [scarella-etal:05] have  clearly demonstrated the benefits  of using unstructured  mesh based numerical methods for  numerical dosimetry studies of  electromagnetic waves.  However they have also raised a number of issues that motivate further investigations especially for what concern the  construction of geometrical  models. In particular,  two points deserve attention: a) the simultaneous generation of  surfacic (triangular) and volumic (tetrahedral) meshes for several tissues (e.g skin, external and internal skull, brain, etc.) with different resolutions. b) the local refinment of volumic meshes.

This subject  proposes  to run   further investigations on  unstructured  mesh generation from medical imaging  data.  The goal would be  in a first step  to improve the numerical models  of the head  obtained in the HeadExp project and then to obtain reliable numerical  models of the  whole human body taking into account different tissues.  Those   studies  will be  perform using  the  mesh generation tool provided  by the library CGAL.  Based  on Delaunay refinement, this   unstructed mesh generation   tool offers   wide  possibilities for  the handling of several surfaces in the volume to be meshed and the respect of non uniform sizing  field [oudot-etal:05].   The tool is   able to work  on  three dimensional  images resulting  from medical   imaging  data.  This tool  is  a powerfull, recently developped  tool  and its   use  in such a   project would contribute to its final tuning.

Given a set of antenna for mobile phone, we want discretized the space depending on the best antenna visible from the phone. Such a modelization can be done in different way for different purpose, precise wave propagation simulation gives good result to simulate the actual behavior but is not very useful to really design the network. We are interested here in a more abstract modelization using a Voronoi-like diagram. Unfortunately, the anisotropic metric associated to antennas make the direct computation of such a diagram difficult.

We intend to develop a discretization solution, where a mesh of the diagram is constructed. From a course mesh, if an element is evaluated to belong to several Voronoi region, then an oracle will produce points on the boundary of Voronoi regions to add them in the mesh.

I will talk about an algorithm that, given a sufficiently dense but not necessarily uniform sample from the surface of a shape with smooth boundary, computes a core for its medial axis approximation, in form of a piecewise linear cell complex, that captures the topology of the medial axis of the shape. We also provide a natural method to freely augment this core in order to enhance it geometrically all the while maintaining the topological guarantees.

The definition of the core and its extension method are based on the steepest ascent flow induced by the distance function to the sample. If time permits I will also discuss geometric guarantee on the closeness of the core and the actual medial axis.

In the last decade, the concept of restricted Delaunay triangulation, developed in computational geometry, has led to a number of provably correct algorithms for mesh generation and mesh reconstruction from point clouds. In this talk, we show how these advances can benefit to the shape reconstruction problem in computer vision and in medical imaging.

In a first part, we propose a principled Lagrangian approach for modeling moving surfaces undergoing large deformations and topology changes, to be used in the deformable models (aka active contours) methodolody, with applications to 3D medical image segmentation.

How can a 3-dimensional object be approximated with a small error by a union of spheres in an efficient manner? The solution to this problem is used for Collision Detection as well as for the computation of the Minkowski sum of 3-dimensional objects, both are common tasks in motion planning. This talk is about an implementation of an efficient approach. We use CGAL for a method that first computes a large number of spheres with their centers on the medial axis of an object. In the next step we compute a minimal subset of those spheres such that the whole object is still covered and a user specified approximation quality is kept.

The optimal solution to the last problem is known to be NP-hard and it is proven that a really simple greedy algorithm has an asymptotically best possible approximation guarantee. However, we have implemented software that does not only compute a solution using various techniques but also computes lower bounds on the optimal solution for concrete instances. This allows us to show that our solution is usually much better than the approximation guarantee.

Each cell of dimension two consists of two connected components  bounded, respectively, by 3 and 1 of these branches. The proof technique, which uses modern  tools of formal algebraic computation, is of interest in its own right.

Real algebraic numbers are the numbers that are real solutions of a univariate polynomial with integer coefficients. We present algorithmic and complexity results about exact algorithms for computations with real algebraic numbers and applications of these algorithms to non-linear computational geometry.

We represent the real algebraic numbers using the isolating interval representation, i.e a square-free polynomial and an isolating interval. In order to construct a real algebraic number we need to isolate the real roots of univariate polynomial.

Sturm, Descartes and Bernstein and also the CF algorithm which is based on the continued fraction expansion of the real numbers. Using projection we extend the real solving algorithms to bivariate polynomial systems.

As for the computations that involve one or two real algebraic numbers, we consider comparison, sign evaluation and the problem of simultaneous inequalities. For these computations we exploit the Sturm-Habicht sequences.

For all the previous computations, when the degree the univariate polynomials is $\leq 4$ and/or the total degree of the bivariate polynomials is $\leq 2$ we present special purpose algorithms with constant time arithmetic complexity.

We will use the previous algorithms in order to tackle the predicates needed in some problems of (non-linear) computational geometry. We will consider the problems of the arrangement of conics arcs and curves in the plane and the Voronoi diagram of ellipses.

Finally, we consider algorithms that given a convex lattice polygon test whether it can be decomposed into a Minkowski sum of two other such polygons and if so, find one or all such decompositions. The problem is closely related to the problem of bivariate polynomial factorization.

We propose four simple algorithms for greedy routing on planar graphs using virtual coordinates (i.e. an embedding of the graph in R^2 or R^3), such that delivery of the routed message is guaranteed. By greedy routing we mean that a message is forwarded from a node based only on knowledge present at the node and its immediate neighbors. These algorithms are superior to existing algorithms in that they are oblivious, work also for non-triangular graphs, and their virtual coordinates are easy to construct.

Faced with the significant complexity of the structures and interactions that they want to simulate, computational biologists may typically resort to two possible strategies: they can either increase the processing power (e.g. use costly parallel supercomputers), or use simplified representations of the geometry or of the dynamics of the involved molecules.

Frequently, these simplification methods involve representations in reduced coordinates (e.g. modeling the molecule as an articulated body), where subsets of atoms are replaced by idealized structures, or performing normal-mode or principal components analysis in order to determine the essential dynamics of the system. Because they contain fewer degrees of freedom, these simplified representations allow the biologists to accelerate the computation of the molecular dynamics, and facilitate the study of the molecular interactions by focusing on the regions of interest. However, current geometry or dynamics simplification methods have a fundamental flaw: they are unable to automatically determine the level of detail which best describes a given molecular interaction. Thus, the biologist must have some prior structural knowledge about the interaction he wishes to model before choosing the best representation; he must choose the simplest representation of the molecules, i.e. the most efficient in terms of computational cost, which still allows precise simulations of the biological phenomenon under study. In other words, there is currently no method that automatically determine which parts of the molecule must be precisely simulated, and which parts can be simplified without affecting the study of the molecular interaction. Such an adaptive simplification method would greatly facilitate the study of biological phenomena for which there lacks sufficient structural information, and would help reduce the need for costly supercomputers currently required to simulate complex biological molecules. Other applications of an adaptive molecular dynamics simulation would include rapid prototyping of molecular dynamics simulation, nano-system design, study of macromolecular motions and docking, de novo protein design, etc.

Molecular Dynamics (AMD) framework. Unlike previous "a priori" simplification approaches, adaptive molecular dynamics can predict the set of active joints at each time step, based on the current state of the molecular system (atom positions and velocities), the internal forces (van der Waals, electrostatic, dihedral), the applied external forces (e.g., the force applied by the user through a haptic device), and the precision threshold specified by the user (i.e. maximum number of active joints, or total acceleration threshold). We will introduce some underlying algorithms and present preliminary results.

D. Cohen-Steiner. In this work, we develop a reconstruction algorithm handling objects that may be non manifold. We shall use it to investigate the topology of 3D point clouds, in cunjunction with flexibility studies.  See section 2.4 of the proposal.

Computational Geometry for Curves and Surfaces solid mathematical and algorithmic foundations, to provide solutions to key problems and to validate our theoretical advances through extensive experimental research and the development of software packages that could serve as steps towards a standard for safe and effective geometric computing.

Several operations on nonlinear geometric objects, often lying at the algorithm's bottleneck, are equivalent to manipulating polynomials.  A fundamental question is the solution of algebraic systems, ubiquitous in the construction of new objects, such as intersections. Another crucial goal is the implementation of primitives with Boolean or discrete output, such as an object is contained in some bounding object.

Geometric programs are notorious for their non-robustness: algorithms are designed for a model of computation where real numbers are dealt with exactly and geometric algorithms are frequently only formulated for inputs in general position.  This is not simply an academic problem. It is easy to crash any commercial CAD-system.

Progress has been made only in recent years.  A significant part of the progress was made by the proposers and centers around the so-called exact computation paradigm. We will extend this paradigm to curved objects.

Since algorithms for curves and surfaces are more involved, more difficult to make robust and typically several orders of magnitude slower than their linear counterparts, there is a need for approximate representations.  Our objective is to provide robust and quality guaranteed approximations of curves and surfaces.

The results should be directly useful to various application areas such as computer graphics, geographic information systems, design and manufacturing, robotics, and molecular modeling. Special attention will be paid to the impact of our research, especially in industry.

For users who already have Coq on their machine, beware that you need to use exactly Coq version 7.4 for this version of pcoq to run with it. If you have an older version, you may want to look at the older versions of pcoq too. Pcoq is simply available as a java archive in jar format, with a small shell script, in which three variables must be updated when it is installed. These files and the files describing copyright and license policies are provided in a compressed tar archive. To install Pcoq from this archive, build the directory of your choice (for instance /usr/lib/pcoq, extract the tar archive in this directory, and execute the install command that appears in this directory. This creates a pcoq that can be copied everywhere (for instance, in /usr/bin/pcoq).

The other files should not be moved. If you need to move them, then you will need to re-run the install command. Before you use this installation of pcoq, make sure you use the right version of java (see below).

There is not much documentation available so far.  It will be coming as we gather the time to write it down.  For now, we have a little tutorial on using Pcoq, which can also be used to see its most basic capabilities.

The goal of this work is to produce a formal description of theorems in real analysis which are related to Newton's method for the computation of roots of diffentiable functions.  This formal description should lead to a document that can be processed by the computer program Coq to verify the correctness of all mathematical statements.  A practical outcome of this work is a collection of programs that implement the root searching algorithms and are guaranteed by construction.

In particular, we want to study Kantorovitch's theorem, a theorem that describes the conditions under which Newton's method is guaranteed to converge towards a unique solution within a given interval.  This theorem gives bounds on the size of this interval and the precise computation of these may bounds may have a strong practical impact for the optimization of root finding algorithms for certain classes of input functions.

The work will consist in learning how to use a proof verifying tool such as Coq and applying this tool to the development of programs that perform computations about continuous real functions.  The first step will be to study the theorem for functions of one variable.  If possible, students will have to generalize the development to functions with several arguments.

This formal description will be a Coq proof document and it should lead to the possibility to extract a Delaunay triangulation algorithm or the possibility to prove the correctness of a program to perform Delaunay triangulations written using a tool like Caduceus or Why.

Given a set of points in the plane, it is possible to partition the convex hull of this set of points into a collection of triangles such the corners of these triangles are the points from the set and no point is inside the circumcircle to another triangle.

In a previous study of convex hull algorithms, we were able to consider separately the logical part of the algorithm and its numerical part.  We expect to obtain and prove the same partition for this algorithm.

In particular, we want to formalize all the theorems that relate the convergence conditions of a series with the convergence conditions of its formal derivative.  This work should culminate in a complete library of results for the formal study of analytic functions.

As an application, we expect this theory to be used in the justification that series computed with our implementation of real arithmetics do implement the corresponding analytic functions: exponentiation, arctangent, sine and cosine, et cetera.

Implementation-defined: Implementation-defined constructs are those which must have a definite meaning, but for which the standard has passed responsibility to the implementation. The implementation is required to document its choice of meaning. An example is the byte-ordering with in multi-byte numeric objects (big-endian vs little-endian).

We handle implementation-defined behaviour by defining, but underspecifying some constant in the semantics. In this way, we model the fact that there is a well-defined behaviour, but make it impossible for a user to rely on it being a particular behaviour.

For example, the order of evaluation of expressions is unspecified. Here an implementation need not document its behaviour, and thus may choose to do different things in quite similar, if not identical, situations.  We handle unspecified behaviours by always allowing all possible behaviours. In the case of expression evaluation, all possible evaluation orders can arise. One cannot then claim that a program's behaviour will have a particular result without confirming that all possible behaviours lead to the same result.

Undefined: Undefined behaviour results when a program attempts to do something which is semantically illegal. For example, undefined behaviour occurs when uninitialised memory isaccessed, when a null pointer is dereferenced, or when a side effect attempts to update a memory object which has already been accessed in the same phase of expression evaluation. We treat all such behaviour as equivalent to a transition into a special state where no further action takes place. In implementations, a program which attempts an undefined behaviour will in all likelihood do something, and this something may in fact be quite reasonable.

Nonetheless, there is no way of relying on undefined behaviour to do anything in particular, so our approach of effectively aborting the abstract machine as soon as undefined behaviour occurs is safest. To do anything else would be to suggest that a particular behaviour could be relied upon, and this would necessarily be erroneous.

Related to the above notions is that of being a strictly conforming program. Such a program's behaviour doesn't depend on any implementation defined, unspecified or undefined behaviour. Though strictly conforming C programs are the ideal, it is still the case that there are legal programs that are not strictly conforming. For example, there are legal programs that behave non-deterministically, and thesemantics as presented here and in the standard reflects this.

The workshop is informal and presentations on subjects such as work in progress, problem areas for AD, or possible application areas, as well as completed work are welcome. We particularly encourage PhD students and those new to the field to attend and present their work.

There is a break-even fee to defray reprographic and refreshment costs. This fee includes two lunches but not the Workshop dinner on Thursday night. If you have no means of recovering your registration costs, please indicate this as a concessionary rate may be available in such case.

The intent of this book is to settle the foundations of non-linear computational geometry. It covers combinatorial data structures and algorithms, algebraic issues in geometric computing, approximation of curves and surfaces, and computational topology.

Each chapter provides a state of the art, as well as a tutorial introduction to important concepts and results. The focus is on methods which are both well founded mathematically and efficient in practice. References to open source software and discussion of potential applications of the presented techniques are also included.

This book can serve as a textbook on non-linear computational geometry. It will also be useful to engineers and researchers working in computational geometry or other fields, like structural biology, 3-dimensional medical imaging, CAD/CAM, robotics, and graphics.

I recently obtained a PhD degree in computer science from the university of Nice - Sophia Antipolis, for my work on "Components for Grid Computing". The thesis aimed at defining a component model and a framework that answer the requirements of Grid computing. My PhD advisor was Denis Caromel.

My research work is in the field of mathematical cardiac analysis . A first part deals with the computation and analysis of the deformation of the cardiac wall from ultrasound DTI images. My current work handles  the estimation of the parameters of an electrophysiological model  of the heart from in vivo electrical measures.

I am an assistant teacher in the department of mathematics of Nice university. I am involved in the use of a interactive mathematics server,  WIMS  with first year students to help them practising mathemtical analysis. Follow the link and have a look:  WIMS .

Traditional security mechanisms (e.g. authentication, integrity, confidentiality), are usually offered at the level of network or system. As all the enterprise applications do not feature the same security demands, we believe there is a need for application-level security.

Using application security, a user is able to define specific security policies for each part of the application. According to the deployment of his application, the user can enable or not security between communicating objects.

My work is, first, to add security notions like authentication, integrity and confidentiality. On distributed systems, it is hard to keep tracks of exchanged datas. My thesis is to propose and develop a model based on Meta Objects Protocol to manage the access and the distribution of data.

Currently, my research topic focuses on the conception of autonomous grid applications based on peer-to-peer overlay networks. Ever-growing grids make application development, administration, and maintenance more and more complex. Autonomic computing partially answers these issues thanks to self-management mechanisms.

Peer-to-peer networks assure the scalability and robustness of a system. Combined, they offer an efficient framework to build large grid applications. To illustrate this concept, I develop an automated monitoring tool for large scale grids.

ProActive, which is available in open-source as part of the ObjectWeb consortium. I actively participated to core developments and maintenance activities, and I am responsible for the group communication framework of ProActive.

To this purpose, a suitable station keeping strategy is implemented, the objectives of which are the set of manoeuvres that have to be executed in order to thwart the effects of natural perturbing forces affecting the spacecraft position.

The strategy is decided by predicting the changes of the orbital parameters on the basis of models for the spacecraft dynamics which take into account only the main natural perturbing forces: the luni-solar attraction force, the solar radiation pressure and the Earth gravitational force.

Nowadays, in order to achieve the objectives of a station keeping strategy most geostationary satellites are equipped with chemical propulsion systems: in order to compensate changes in the orbit parameters, chemical thrusters are typically fired once every two weeks during a time interval T of few tens of minutes, providing forces of some tens of Newton.

Given the small ratio between T and the geostationary orbital period, chemical thrusts can be considered with good approximation as impulsive. It thus makes sense to define station keeping strategy excluding from the dynamics equations the non conservative forces (i.e., the thrusters forces).

More recently, however, the use of electric propulsion systems is being considered as a viable alternative to the classical chemical actuators and is rapidly becoming the baseline on new telecom satellite platforms.

This is achieved thanks to the increase in specific impulse of a factor between 5 and 10 which makes it possible to reduce by the same factor the propellant mass needed for station keeping throughout the life of the satellite.

Since electric thrusters can only provide a very low thrust level (of the order of milliNewtons), in order to achieve the same station keeping objectives that would be given for chemical propulsion it is necessary to fire the electric thrusters for some hours every day. It is then important to re-think the control strategy as a continuous process to be optimised.

Therefore, starting from the derivation of a complete nonlinear model for the dynamics of a geostationary satellite, the goal is to solve the station keeping problem (formulated as a constrained optimal control problem) by a direct method based on the differential inclusion approach.

The station keeping problem by longitude and latitude control is formulated as a constrained optimal control problem; the linear model is advisably handled in order to apply the differential inclusion approach for the solution of the problem.

Within the framework of driving simulation, control is a key issue to providing the driver realistic motion cues. Visual stimulus (virtual reality scene) and inertial stimulus (Gough-Stewart platform motion) induce a self motion illusion. The challenge is to provide the driver with the sensations he would feel in real car maneuvering. This is an original control problem. Indeed, the first goal is not classical path tracking but fooling the driver awareness. Constrained workspace is the second issue classically addressed by motion cueing algorithms.

Our purpose is to study offline platform responses, to check maneuvers feasibility and to analyze the evolution and magnitudes of the articular forces. In other words our approach does not address real-time algorithms. Nonetheless it answers the question: given the geometric constraints, what is the best that the platform can do?

The Ariana project aims to provide image processing tools to aid in the solution of problems arising in a wide range of concrete applications in Earth observation and cartography, for example cartographic updating, land management, and agriculture, while at the same time advancing  the state of the art in the image processing methods used to construct those tools.

In addition to applying these techniques to specific cases, the project advances these techniques more generally, through innovative modeling and theoretical analysis, and a comparative study of the two classes. An important recent theme, for example, is the incorporation of geometric information into both classes of techniques, in the probabilistic case via the use of stochastic geometry, and in the variational case via the use of higher-order active contours.

The project also concerns itself with a number of important, related problems, in particular the development of the parameter estimation procedures necessary to render the above methods automatic or semi-automatic, and the study of the optimization algorithms used to solve the problems (for example, reversible jump Markov chain Monte Carlo (RJMCMC)).

Following a Bayesian methodology as far as possible, probabilistic models are used within the Ariana project, as elsewhere, for two purposes : to describe the class of images to be expected from any given scene, and to describe prior knowledge about the scene in the absence of the current data.

Markov random fields were introduced to image processing in the Eighties, and were quickly applied to the full range of inverse problems in computer vision. They owe their popularity to their flexible and intuitive nature, which makes them an ideal modeling tool, and to the existence of standard and easy-to-implement algorithms for their solution.

In the Ariana project, attention is focused on their use in image modeling, in particular of textures, on the development of improved prior models for segmentation, and on the lightening of the heavy computational load traditionally associated with these techniques, in particular via the study of varieties of hierarchical random field.

The development of wavelets as an alternative to the pixel and Fourier bases has had a big impact on image processing due to their spatial and frequency localization, and the sparse nature of many types of image data when expressed in these bases. In particular, wavelet bases have opened up many possibilities for probabilistic modeling due to the existence of not one but two natural correlation structures, intra- and inter-scale, leading to adaptive wavelet packet models and tree models respectively.

In Ariana, attention is focused on the use of tree models for denoising and deconvolution, adaptive wavelet packet models for texture description, and on the use of complex wavelets for their improved translation invariance and directional selectivity.

One of the grand challenges of computer vision and image processing is the expression and use of prior geometric information. For satellite and aerial imagery, this problem has become increasingly important as the increasing resolution of the data results in the necessity to model geometric structures hitherto invisible. One of the most promising approaches to the inclusion of this type of information is stochastic geometry, which is a new and important line of research in the Ariana project.

Instead of defining probabilities for different types of image, probabilities are defined for configurations of an indeterminate number of interacting, parameterized objects located in the image. Such probability distribution are called "marked point processes". For instance, two examples that have been developed in Ariana use interacting cuboids of varying length, width, height and orientation for modeling buildings; and interacting line segments of varying length and orientation for modeling road and other networks.

Attention in Ariana is focused on the theoretical study of these models and their associated algorithms, and in particular on the convergence of sequences of functionals and on projection algorithms. Recent research concerns the definition and computation of a function space containing oscillatory patterns, a sort of dual space to the BV space that captures the geometry of the image. Variational methods are also applied to a variety of problems, including phase unwrapping and image decomposition.

In addition to the regularization of inverse problems, variational methods are much used in the modeling of boundaries in images using contours. In Ariana, attention is focused on the use of such models for image segmentation, in particular texture segmentation; on the theoretical study of the models and their associated algorithms, in particular level set methods; and on the incorporation of prior geometric information concerning the regions sought using higher-order active contour energies.

Wavelets are important to variational approaches in two ways. They enter theoretically, through the study of Besov spaces, and they enter practically, in models of texture for segmentation, and in the denoising of the oscillatory parts of images.

Ariana project is how to estimate the parameters that appear in the models. For probabilistic models, the problem is easily framed, but is not necessarily easy to solve, particularly in the case when it is necessary to extract simultaneously from the data both the information of interest and the parameters. For variational models, there are few methods available, and the problem is consequently more difficult.

The problems treated by the project run the gamut of image processing, applied to satellite and aerial images. Examples include image restoration and denoising, multicamera reconstruction and super resolution, the extraction of various complex structures in the scene, and retrieval from remote sensing image databases.

One thing all the problems have in common is that they are ill-posed inverse problems. Even in those rare cases for which the existence and uniqueness of the solution is guaranteed, the solution is unstable to the perturbing effects of observation noise. It is therefore necessary to introduce prior knowledge concerning the solution, both in order to limit the set of possible solutions and to stabilize the solution against perturbations.

These are perhaps the most basic of the applications with which Ariana is concerned, and two of the most studied problems in image processing. Yet progress can still be made in these problems by improving the prior image models used, for example, by using hidden Markov trees of complex wavelets or by decomposing the image into several components. Ariana is also interested in blind deconvolution.

Many applications call for the image domain to be split into pieces, each piece corresponding to some entity in the scene, for example, forest or urban area, and in many cases for these pieces to be assigned the appropriate label. These problems too are long-studied, but there is much progress to be made, in particular in the use of prior geometric information.

As the resolution of remote sensing imagery increases, so the full complexity of the scene comes to the fore. What was once a texture is now revealed to be an arrangement of individual houses for example, or a number of separate trees. Many new applications are created by the availability of this data, but efficient harvesting of the information requires new techniques.

Earth observation and cartography is not solely concerned with 2D images. One important problem is the construction of 3D digital elevation models (DEMs) from high-resolution stereo images produced by satellites or aerial surveys. Synthetic aperture radar (SAR) imagery also carries elevation information, and allows the production of more accurate DEMs thanks to interferometry techniques, for example.

Every day, vast quantities of data are accumulated in remote sensing data repositories, and intelligent access to this data is becoming increasingly problematic. Recently, the problem of retrieval from large unstructured remote sensing image databases has begun to be studied within the project.

You will find here Masters internships, PhdThesis and PostDocs proposals of project Ariana. If you are  interested by one of them, please send a cover letter and a detailed CV by email to the director in the column Contact.

Abstract (english) :We propose here new wavelet-based geometric transforms: the dual-tree M-band wavelet analyses. These decompositions allow to perform a multi-scale, directional and local analysis of images. They are in the trend of recent works aiming at better representing geometric informations (textures, contours) and to perserve it while processing data.

This work is based on previous works by N. Kingsbury and I. Selesnick who have obtained several results concerning the dyadic case. Their conclusions are extended to the M-band case. The proposed decompositions (based on two M-band wavelet transforms, the primal and the dual one, operating in parallel) typically introduce a redundancy of a factor 2 (4 in the complex case) and they constitute frames from which we can derive an optimal reconstruction. These new transforms have recently been generalized to biorthogonal and complex cases.

We choose to apply these analysis tools to image denoising, which led us to study the statistical properties of coefficients generated by an M-band dual-tree analysis of a wide-sense stationary random process.

Cross-correlations between primal and dual wavelets play a major role in our study. Numerical simulations allowed us to validate our theorical results as well as evaluate the influence area of the correlations.

We first show that for gaussian as well as for speckle noise and using levelable priors, the shape of the restored object does not change in a ``statistical'' sense, so that only its brightness decreases whereas that of background increases (loss of contrast).

We then show how to prevent the result to have this loss of contrast using nice-levelable priors. Some examples are given and appear concluding. This work is described in the research report [Darbon, Tupin and Sigelle 2006].

Abstract (english) :Predicting stand structure parameters for tropical forests from remotely sensed data has numerous important applications, as estimating aboveground biomass and carbon stocks and providing spatial information for forest mapping and management planning. We shall present the results obtained for both temporarily flooded and terra firme natural forests in French Guiana by applying an approach of "textural ordination" which ordinate or classify canopy image windows of adequate size on the basis of their Fourier spectra.

Whatever the initial information used (IKONOS or digitized photograph contacts) the approach proved able to identify one or two prominent textural gradients, which were interpretable in terms of canopy coarseness/fineness with strong relationships with forest variations as observed from field measurements. Textural indices (i.e. windows scores along the gradients) were good predictors of forest parameters with reasonable estimation errors, and there are good prospects for broad-scale implementations. Potential improvements of the approach, which include standardization of spectra originating from images with heterogeneous technical features and fusion of "global" vs. "local" textural measures, will be discussed.

Abstract (english) :Multichannel imaging systems provide several observations of the same scene which are often corrupted by additive noise and blurred. In this work, we are interested both in multispectral image denoising and restoration in the wavelet domain.

Focusing on the problem of restoration, our approch has two main novelties. At the first step, we show how to combine M-band Wavelet Transforms (WT) with Fourier analysis to restore multicomponent images. At the second step, we point out that the multichannel deconvolution procedure takes advantage of exploiting multivariate regression rules. Simulations experiments carried out on multispectral satellite images indicate the good performance of our method.

As a first step, a visibility test on SPOT5 panchromatic 5m resolution data fused with multi-spectral data has been performed to assess the possibility for a photo-interpretor to detect the buildings and the road network in various type of Belgian landscapes. As this test was positive, an automatic system could be envisaged.

An automatic system to estimate the urbanization changes on the Belgian territory, using SPOT5 data  and the National Geographic Institute vectorial database is thus proposed. The images and the vectorial data are first co-registered. Then, the vectorial database is projected and dilated to produce a mask representing the old status of the database. On the other hand, a fusion of two classification processes on the images enables to extract the built-up area and the communication network, generating a mask representing the actual state of the urbanization in the zone. The first process uses simplified Gabor filters to extract structures and texture, while the second is based on the vegetation index and the knowledge about hydrography. The comparison between the two masks provides coarse information on the changes.  A validation of the process shows that the system provides about 20% of false alarms for an average of 92% of good detection.

Abstract (english) :Image restoration is usually formulated as the  minimization of the sum of two convex functions: A quadratic data term and a nonquadratic regularizer (prior in the Bayesian framework). In recent work, a class of iterative denoising  algorithms has been proposed. The denoising operator depends on the regularizer (prior).

Abstract (english) :Interaction with image database should be as user friendly as possible; that is, it should be as close as possible to the user's normal mode of communication. This concept is the basis for the so-called content-based image retrieval. To answer user's queries dealing with images containing a specific object, tools to detect the presence of such objects are necessary. We propose in this talk a strategy to detect objects from images. The approach relies on combining two types of models: a perceptual and a structural model. The algorithms that are proposed for both types of models make use of a region-based description of the image relying on a Binary Partition Tree. Perceptual models link the low-level signal description with semantic classes of limited variability. Given that we are dealing here with still images, the temporal evolution of low-level descriptors will not be considered to characterize the objects. Structural models represent the common structure of all instances! by decomposing the semantic object into simpler objects and by defining the relations between them.

Abstract (english) :Rather than regarding images as given entities to be processed, richer information is gained by modifying and analyzing the imaging process itself. Such "hybrid imaging" exploits the power to affect both the sensor and the algorithmic components of a vision system. This is especially effective when having multiple sensing inputs.

As examples, we briefly show how mosaicing can be generalized to overcome various radiometric problems (e.g.,  on-uniformity) or  obtain high dynamic range, multispectral images. Then, we describe a bio-inspired method for recovering visibility in scattering media (haze,water). It is based on independent component analysis (ICA) of multiple frames, aided by a physical model of image formation. This model also easily leads to spatially varying regularization, overcoming inherent distance-dependent noise amplification. Finally, we address cross-modal scenarios: we seek correlating features between different inputs (or input-output), as done in climatology, medical research, and other fields. Here, we overcome insufficient data by a general mathematical principle, based on a sparsity  prior.

Abstract (english) :Compressive sampling (CS), or "Compressed Sensing", has recently generated a tremendous amount of excitement in the image processing community. CS involves taking a relatively small number of non-traditional samples in the form of randomized projections.  Such samples are capable of capturing the most salient information in an image. If the image being sampled is compressible in a certain basis (e.g., wavelet), then under noiseless conditions the image can be much more accurately recovered from random projections than from pixel samples.  We extended this type of result to show that compressible signals can be accurately recovered from random projections contaminated with noise, in many cases also much more accurately than is possible using an  equivalent number of conventional point samples.

I will review the basic theory and methods of CS, and discuss potential applications of CS in imaging and remote sensing.  In particular, I will compare CS to conventional imaging by considering a canonical class of piecewise smooth image models. This analysis shows that CS can be advantageous in noisy imaging problems if the underlying image is highly compressible or if the signal-to-noise ratio is sufficiently large.

Abstract (english) :Owing to recent advances in modern harmonic analysis, oriented (e.g. curvelets) and non-oriented (e.g. wavelets) multi-scale transforms have proven powerful in sparsely representing a wide class of images and signals (over some smoothness space classes). This work is concerned with bayesian denoising within the context of these sparse representations. A general univariate bayesian prior model, namely the scale mixture of gaussians, on the representation coefficients is introduced and its properties are established. We prove that such a prior is well adapted to capture sparsity of the representations (leptokurticity and heavy tailness). We also shed the light on the relationship between the hyperparameters of this prior and those of the Besov space within which realizations of such a prior are likely to fall. Several bayesian estimators (conditional posterior mean and maximum a posteriori) are also given. All these results are extended to the multivariate case where dependency between neighbouring coefficients in the multi-scale pyramid is imposed. Some special cases of the general prior are finally considered (e.g. the bessel K form) and their computational issues are solved.

However, accounting for possible transformations between the different object views, as part of the segmentation process, remains a challenge. Recent works address this problem by using comprehensive training data. Other approaches are applicable only to limited object classes or can only accommodate similarity transformations.

Extending the Chan-Vese level set framework, we propose a region-based segmentation functional that includes explicit representation of the projective homography between the prior shape and the shape to segment. The formulation is derived from two-view geometry.

Abstract (english) :A novel color texture unsupervised segmentation algorithm is presented which processes independently the spectral and spatial information. The algorithm is composed of two parts. The former provides an over-segmentation of the image, such that basic components for each of the texture which are present are extracted. The latter is a region growing algorithm which reduces drastically the number of regions, and provides a region-hierarchical texture clustering. The over-segmentation is achieved by means of a color-based clustering (CBC) followed by a spatial-based clustering (SBC). The SBC, as well as the subsequent growing algorithm, make use of a characterization of the regions based on shape and context. Experimental results are very promising in case of textures which are quite regular.

Abstract (english) :We propose to develop new multisource data fusion and reconstruction methods. The originality of the project lies in considering data fusion as the estimation of a single model, of arbitrary spatial and spectral resolutions. The model is to be inferred from a number of observations, possibly from different sensors under various conditions.

In astronomical imaging, we will aim at a sharp, correctly sampled, noise-free and possibly super-resolved image. In the Virtual Observatory framework for instance, one wishes to combine large numbers of multispectral images from various sources. In planetary imaging or remote sensing, both terrain topography and camera parameters must be taken into account to efficiently combine several images. Therefore, the topography will be included in the model. The object provided by the fusion-reconstruction method will be a 3D surface, possibly super-resolved regarding both geometry and reflectance.

The first objective is to provide a flexible framework for bandlimited signal reconstruction from multiple data. We obtained promising results in one dimension: a super-resolved signal was successfully reconstructed from two blurred and noisy shifted observations. In this framework, the sampling resolution, the geometric distortions, the blur kernel and the regularity of the sampling grid can be arbitrary for each sensor. The method was designed to handle realistic Gauss+Poisson noise and a simple Gaussian Markov chain was used for regularization purposes.

Abstract (english) :In the talk I introduce a new Markovian model regarding foreground and shadow detection in video sequences. The model works without detailed a priori object-shape information, and is also appropriate for low frame-rate video sources. I present three novelties: an improved shadow model, a new foreground calculus and a new integration technique of different color-texture features.

Abstract (english) :The recent domain of image retrieval in large databases has induced a  revision of the topics of image processing and pattern recognition.  Image retrieval and extraction of visual information from image  databases are useful in many applications.

Abstract (english) :Feature reduction has proved to be an important preprocessing step able to reduce the complexity of hyperspectral image analysis and to allow an improvement in the accuracy of the supervised classification of such images to be obtained. An approach is proposed in this talk aimed at reducing the number of features for the classification of hyperspectral remote sensing images, which is based on an iterative search for local maxima of a distance functional. The proposed search is performed in a discrete space of solutions and is based on progressive moves in the direction of the 'steepest ascent' of the functional. Two kinds of formulation of the feature reduction problem are defined: the former is related to the feature selection problem; the latter is related to a special case of feature transformation, i.e., the case of the averaging of groups of contiguous hyperspectral bands. In both cases, the solution space is a binary (discrete) space, in which a notion of neighbourhood is defined, depending on a size parameter. The convergence properties of the algorithms derived from the proposed approach are analysed. Finally the performances of such algorithms are compared with one each other and with the performances of other well-known feature reduction algorithms by reporting on the experiments with a real hyperspectral image.

Abstract (english) :In this presentation, I'll discuss sequential state estimation problems where the filtering distribution is a mixture. Two generic problems, which are of particular interest for visual tracking, fall in this category: (1) sequential estimation of multi-modal filtering distributions, (2) tracking with auxiliary discrete state variables. We shall see that standard filters can be easily extended to handle these problems. In particular, popular sequential Monte Carlo techniques (particle filters) can be readily mobilized. This yields to a clustered particle filter in (1) and to interacting particle filters with no sampling of the auxiliary variable in (2). In both cases, experimental illustration will be provided in the context of colour-based visual tracking.

Abstract (english) :We shall present a general image segmentation method adapted to the noise present in the image but which does not need an a priori knowledge of the probability density functions of the grey levels. This method is based on the minimization of the stochastic complexity which leads to a criterion without parameter to be tuned by the user. We shall demonstrate that one can apply this method to different contour descriptors (polygonal active contour, level set implementation and polygonal active grid). We shall analyze on synthetic images the performances of this approach in comparison to those obtained with parametric approaches adapted to the noise model. This technique will finally be illustrated on various real images.

Abstract (english) :We consider the problem of classifying or labeling a test sample based on a database of known samples and their labels. This is a standard statistical learning problem often solved by neural nets, support vector machines, Gaussian mixture models, or decision trees. In this talk research is presented into methods which learn based on near-neighbors; simple examples of this local learning approach are k-nearest neighbor and linear interpolation. Theoretically, we discuss how estimation bias can be reduced by using a convex neighborhood of samples, and by using weights that solve a linear interpolation and maximum entropy objective (LIME). Given weighted neighbors, we show that Bayesian minimum expected risk estimates will significantly outperform maximum likelihood estimates for classification when costs are asymmetric, as is often the case in medical, defense, and non-destructive evaluation applications.

Abstract (english) :In the image segmentation problem, one seeks to determine and label homogeneous subregions in an image scene, based on pixel-wise measurements. Motivated by current challenges in the field of remote sensing land cover characterization, we introduce a framework that allows for adaptive choice of both the spatial resolution of subregions and the categorical granularity of labels. Our framework is based upon a class of models we call "mixlets," a blend of recursive dyadic partitions and finite mixture models. The first component allows for sparse representation of spatial structure at multiple resolutions, while the second enables us to capture the varying degrees of mixing of pure categories that accompany the use of different resolutions. A segmentation is produced in our framework by selecting an optimal mixlet model, through complexity-penalized maximum likelihood, and summarizing the information in that model with respect to a categorical hierarchy. Both theoretical and empirical evaluations of the proposed framework are presented.

Abstract (english) :Malignancies occurring in the epithelium lining the internal surfaces of organs (e.g., aerodigestive tract or colon) typically are discovered late in the course of the disease, usually because they are "hidden" from the physician, and are not usually found on routine physical exam. If there is suspicion of a lesion, endoscopy with biopsy is often necessary. Depending on the location, biopsy may be difficult to obtain, lead to potential complications, or have a low yield. For example, traditional biopsy of the larynx is difficult, because of the sensitivity of the structures and their constant movement. In the esophagus, biopsy of Barrett's mucosa (precancerous tissue), is made more difficult because areas of high malignant potential appear the same as areas of low malignant potential. This makes biopsy in this area fairly low yield. Our work attempts to increase the likelihood of selecting a precancerous sample during biopsy through the use of optoelectronically enhanced endoscopy by developing a tissue characterization technique that is sensitive to changes in the morphology of the tissue as it undergoes changes from normal tissue, to inflammation to oncogenesis. We attempt to establish correlation between changes in parameter values corresponding to changes in the tissue morphology such as cell sizes, shape, density, absorption, index of refraction, etc. Based on the fact that pre-cancerous cells demonstrate shape anisotropy compared to healthy cells, we develop minimally invasive optical techniques that detect the resulting pre-cancerous reflectance signatures. Non-invasive and minimally invasive optical techniques are becoming staples of modern medical technology. An on-chip, high sensitivity probe is created to image the tissue area and placed directly at the tip of an optical fiber, which is em! ployed at the end of an endoscope. In this investigation, we intend to image the tissue area under investigation through the use of scanning with our detector array in order to construct a 3-D "image" of the cellular structure. From this image, we will perform a stochastic decomposition and extract parameter values beyond currently available cell size determination. The parameters will be individually and in combination analyzed to construct a detailed map of pre-cancerous regions. We create a tool that can spatially differentiate between different grades of dysplasia in an inexpensive, portable package.

In this talk we concentrate on the theory (Mie scattering), the image decomposition model and report on simulation results, on tissue mimicking phantom, and finally on animal tissue using imaging at one wavelength as well as using white light.

Abstract (english) :While motivated by a particular application, the work described is quite generalizable. Although present in the literature, Simulated Annealing for the synthesis of porous media has met with limited success due to computational costs and practical modelling constraints. An alternative method based on hierarchical annealing will be presented. Inherently multiscale, such approaches may dramatically reduce the computational cost. Energy functions (based on e.g. chord-length distribution) in a hierarchy allow separately treating structures of different length scales, reducing convergence issues for samples with multiple natural scales. Such an approach naturally leads to methods of explicitly multiscale modelling.

Abstract (english) :This talk is concerned with the analysis of multispectral observations, provided e.g., by space or ground telescopes. The large amount and the complexity of heterogeneous data to analyse lead to develop new methods for segmentation tasks, which aim to be robust, fast and efficient. Some prior knowledge on the information to be extracted from the original image is available, and Bayesian statistical theory is known to be a convenient tool to take this a priori knowledge into consideration, even if the 'curse of dimensionality' often limits these approaches in a multispectral framework. The main goal of this presentation, consists in showing different processing chains describing the power, the efficiency and the fruitfulness of different hierarchical Markovian modeling based on a quadtree topology. We will see that such modeling allows to deal with a large varieties of data : missing data, multiresolution data, multiband data, strongly noised data. In particular, we show how such approach is general and how this tool is able to face with a large number of various image processing tasks.

Abstract (english) :We describe a new framework of multitree dictionaries which includes many previously proposed dictionaries as special cases. We show how to efficiently find the best tree in a multitree dictionary using a recursive tree pruning algorithm. We illustrate our framework through several image compression examples. We then show that it can also be used to construct novel hierarchical stochastic image models called spatial random trees (SRTs). In previously proposed stochastic hidden tree models, the nodes of the tree are labeled with random variables; however, the structure of the tree is fixed and nonrandom. Our key innovation is that both the states and the structure of the tree are random, and are generated by a probabilistic context-free grammar. We describe inference algorithms associated with our SRT models and illustrate them through several image classification and segmentation examples.

Abstract (english) :An early detection and estimating the spread of a biochemical contaminant is important in security and pollution monitoring. We present an integrated approach combining the measurements by an array of biochemical sensors with a physical dispersion model and statistical analysis to optimize the system performances. We develop a computational dispersion model of a contaminant in a complex environment through Monte Carlo simulations of reflected stochastic diffusions describing the microscopic transport phenomena due to wind and chemical diffusion. We consider arbitrary geometries and account for wind turbulences. We present examples for two realistic but synthetic scenarios: dispersions in a city environment and an indoor ventilation duct.

Using the proposed numerical transport model, we develop an optimal sequential detector. For a fixed false alarm rate, we obtain the detection probability of a substance release as a function of its location and initial concentration. We also compute the expected delay before detection as a function of the source location and initial concentration. Once a contaminant has been detected, localizing the dispersive sources is useful for decontamination purposes and cloud evolution estimation. To solve the associated inverse problem, we propose a Bayesian framework that proved to be powerful for localizing sources with insufficient measurements.

Abstract (english) :Reversible jump Markov chain Monte Carlo (RJMCMC) is a recent method which makes it possible to construct reversible Markov chain samplers that jump between parameter subspaces of different dimensionality. We propose a novel RJMCMC sampler for multivariate Gaussian mixture identification and we apply it to color image segmentation. For this purpose, we consider a first order Markov random field (MRF) model where the singleton energies derive from a multivariate Gaussian distribution and second order potentials favor similar classes in neighboring pixels. The proposed algorithm finds the most likely number of classes, their associated model parameters and generates a segmentation of the image by classifying the pixels into these classes. The estimation is done according to the Maximum A Posteriori (MAP) criterion. The algorithm has been validated on a database of real images with human segmented ground truth.

Abstract (english) :For years, the image analysis community has used methods which attempt to combine spatial and statistical methods to describe image data of various forms. In recent years, this problem has been compounded by the widespread interest in video data and data from multiple cameras. For the last few years, I have been developing an image representation based on Gaussian mixture modelling, which attempts to address these issues. Cast in a framework of Bayesian estimation, multiresolution GM modelling can be used for data of arbitrary dimensions; the model can be computed efficiently and, crucially, it can be adapted to deal with smooth motions of the underlying co-ordinate system.

State-of-the art sensors deliver images with high spatial, spectral and radiometric resolution, producing a huge amount of data which must be transmitted to the ground station on limited-capacity channels, archived for possibly long periods of time, and finally disseminated to the end users on common transmission facilities.

A general problem of supervised remotely sensed image classification assumes prior knowledge to be available for all thematic classes that are present in the considered data set. However, the ground truth map representing this prior knowledge usually does not really describe all the land cover typologies in the image and the generation of a complete training set represents a time-consuming, difficult and expensive task. This problem may play a relevant role in remote sensing data analysis, since it affects the classification performances of supervised classifiers, which erroneously assigns each sample drawn from an unknown class to one of the known classes.

In the present talk, a classification strategy is proposed, which allows the identification of samples drawn from unknown classes, through the application of a suitable Bayesian decision rule. The proposed approach exploits a functional approximation architecture based on support vector machines (SVMs) to perform probability density function estimation, and adopts a recursive procedure to generate prior probability estimates for both known and unknown classes.

We propose a new summary statistic for exploring the interaction structure in marked point patterns which generalises a J-function for multivariate point processes introduced in collaboration with Baddeley. The statistic captures simultaneously the range and strength of interaction. We discuss the relation to Stoyan's mark correlation function, derive an expression in terms of the Papangelou conditional intensity and a mixture formula, then turn to estimation and testing for independent random mark allocation, and finally illustrate the approach by means of a forestry data set.

Statistical analysis techniques have been mainly developped for strongly structured data. Typically, data are obtained from the observation of a given set of variables on a set of individuals. In this case, data can be stored into an array or on a regular grid.  In this talk, we deal with data which cannot be stored in such a way.

One of the problems that hinders standard methods for SFS is the presence of local specularities which may be misidentified as high curvature surface features. To address this problem we develop a maximum a posteriori probability estimation method for estimating the mixing proportions for Lambertian and specular reflectance, and also, for recovering local surface normals. The framework for our study is provided by the iterated conditional modes algorithm. Once improved estimates of surface normal directions are obtained, we can also remove the specular highlights from the raw image using the reconstructed specular intensity image.

It is also well known that the non-specular reflectance from both rough and shiny surfaces depart significantly from the predictions of Lambert's law. These effects are particularly marked at the occluding boundary where the surface is highly inclined to the viewer direction. Hence, Lambertian SFS methods can not be applied directly to the analysis of rough and shiny surfaces. In order to overcome this difficulty, we consider how to reconstruct the Lambertian component when the object is illuminated in the viewing direction. To do this we make use of the diffuse reflectance models described by Oren and Nayar, and by Wolff.

Next, we focus on how reflectance models based on wave scattering theory and reported in the physics literature can be used for rough surface analysis. For dielectrics, the models investigated are derived from the Beckmann-Kirchhoff scatter theory, while for metals the starting point is the Davies scattering model. We show how these models can be used to estimate surface roughness parameters using simple reflectance measurements. With estimates of these parameters to hand, we take our analysis one step further by demonstrating how the Vernold-Harvey modification of the Beckmann model may be used for curved surface analysis.

Finally, we describe a new surface normal smoothing process which can be used in conjunction with SFS. Rather than directly smoothing the surface normal vectors, we exert control over their directions by smoothing the field of principal curvature vectors. To do this we develop a topography sensitive smoothing process which overcomes the problems of singularities in the field of principal curvature directions at the locations of umbilics and saddles.

Depth of Field simulation. Then we will introduce two novel anisotropic diffusion equations that adequately model these phenomena, offering accurate results and allowing for real-time implementation with programmable graphics cards. The equations are well posed, with existence and uniqueness results.

Within the framework of wavelet analysis we describe a novel technique for removing noise from digital images. We design a bivariate maximum a posteriori (MAP) estimator, which relies on the family of isotropic alpha-stable distributions. Using this relatively new statistical model we are able to better capture the heavy-tailed nature of the data as well as the interscale dependencies of wavelet coefficients. We test our algorithm for the Cauchy case, in comparison with several recently published methods. The simulation results show that our proposed technique achieves state-of-the-art performance in terms of root mean squared error. Finally, we also show results obtained by applying our method to astrophysical image data.

Wavelet-based methods had a strong impact on the field of image processing, especially in coding and denoising. Wavelet-based image denoising methods yield state-of-the-art performance at very low computational cost. However, image restoration (deconvolution) is a more challenging problem than denoising, and applying wavelets to it has proved to be a non-trivial task.

In this talk, after briefly reviewing wavalet-based image modelling and denoising, I will describe recently proposed algorithms for wavelet-based image deconvolution. These algorithms provide maximum penalized likelihood (MPL) estimates, under wavelet-based penalties, for which there are no closed-form solutions. I will show how such iterative algorithms can be derived from two different approaches. In the first approach, the observation model is re-written by inserting auxiliary latent variables which open the door to the use of the expectation-maximization (EM) algorithm. In the second approach, the iterative algorithm is derived directly in a bound optimization framework. In both cases, the resulting algorithms, which are very simple, alternate between a Fourier-based step and a wavelet-based step. Experimental results show that these algorithms achieve state-of-the-art performance on benchmark image deconvolution problems.

We seek to model signal and to take account of resolution scale.  For model-based clustering, using a Gaussian mixture model and a Markov spatial model, we briefly discuss practical limitations in the multiband image and 3D image volume cases. We seek to avoid such limitations through use of spatial modeling in wavelet transform space.

However the BIC (Bayes information criterion) approximation to a Bayes factor is of limited use in this general context.  We show that a suitable criterion of goodness of fit is given by Renyi quadratic entropy.  We will illustrate this work using 3D image volumes from medicine and astronomy.

We present a new image segmentation algorithm based on a tree-structured binary MRF model. The image is recursively segmented in smaller and smaller regions until a stopping condition, local to each region, is met. Each elementary binary segmentation is obtained as the solution of a MAP estimation problem, with the region prior modeled as a MRF.

The seminar will consist of two parts. I will start with presenting a method for extracting small tracks from the remotely sensed imagery. The method is Bayesian and the MAP estimate is sought by the Gibbs sampler coupled with simulated annealing. Second half of the seminar will be devoted to the results of evaluation of the Gibbs sampler ability to improve the quality of the initial classification (by QDA or ICM) of the multispectral noisy images.

Discrete Wavelet transforms are usually realised using the filterbank framework. The polyphase matrix of such filterbanks can be factored into lifting steps, to achieve the lifting framework of wavelet transforms.

The lifting framework provides an useful and flexible tool for constructing new wavelets from the existing ones. In this talk, we present the designing of spatially adaptive wavelet transforms using the lifting framework. The high pass and low pass filters of the resulting in wavelet transform are chosen spatially adaptively by considering the statistics of the underlying signal. The perfect reconstruction can be achieved without coding any side information regarding to the filter selection. The performance of such transforms in lossless, lossy and scalable image and video coding is presented.

The estimation of large-scale images from sparse and/or noisy data is highly-developed, however although estimates are optimum under some criterion, they do not represent a typical or representative sample of the system being studied, which may be desired for purposes of visualization, further analysis, Monte Carlo studies etc.  Instead, what is required is that we find a random sample from the posterior distribution, a much more subtle and difficult problem than estimation, and, crucially, one which cannot be formulated as an optimization problem.  I will present a little-known property of multiscale statistical models to formulate a posterior sampler, exact in the case of Gauss-Markov random fields, and approximate for other distributions.

For parameterized models, widely-scattered problems such as formant tracking, boundary estimation and phase-unwrapping can all be approached as the annealed minimization of continuous parameters.  In virtually all such annealing problems the Metropolis sampler is used, where the effectiveness of the annealing is highly-dependent on a user-formulated query function.  I will propose an alternative - to use the Gibbs sampler, which requires no query, but which requires the difficult sampling of nonparametric, multimodal distributions.

Image segmentation is the art of describing image data, which tend to be highly complex, in terms of simpler entities, such as regions of homogeneous gray level, colour or texture. This amounts to attaching an integer label to each pixel in an image, representing its class.

In the last decade or so, it has become widely accepted that the problem can be formalised as a maximisation of a posteriori probability, based on a stochastic image model, such as a Markov Random Field (MRF). While this puts segmentation on a firm footing, it raises a significant issue in terms of computation: how can one possibly maximise the posterior probability over the huge number of possible image segmentations, given a set of data?

In recent years, two methods have found widespread use: stochastic simulation samples from the posterior distribution of the image model; multiresolution methods exploit the self-similarity of image data to solve a sequence of successively finer approximations to the problem. It has occurred to a number of authors that these two approaches might be usefully combined in a multiresolution MRF. The work we have done using these models has thrown up interesting results in both the theory and practice of image segmentation.

One of the major problems in geographical information systems (GISs) consists in defining strategies and procedures for a regular updating of land-cover maps stored in the system databases. This crucial task can be carried out by using remote-sensing images regularly acquired by space-born sensors in the specific investigated areas. Such images can be analysed with automatic classification techniques in order to derive updated land-cover maps. However, at the operating level, such techniques are usually based on supervised classification algorithms.

Consequently, they require the availability of ground truth information for the training of the classifiers. Unfortunately, in many real cases, it is not possible to rely on training data for all the images necessary to ensure an updating of land-cover maps that is as frequent as required by applications.

In this seminar, advanced classification techniques for a regular updating of land-cover maps are proposed that are based on the use of multitemporal remote sensing images. Such techniques are developed within the framework of partially supervised Bayesian approaches and are able to address the updating problem under the realistic but critical constraint that, for the image to be classified (i.e., the most recent of the considered multitemporal dataset) no ground truth information is available. Two different approaches are considered. The first approach is based on an independent analysis of the information contained in each single image of the considered multitemporal series; the second approach exploits the temporal correlation between pairs of images acquired at different times in the classification process. In the context of these approaches, both parametric and non-parametric classifiers are considered. In addition, in order to design a reliable and accurate classification system, multiple classifier architectures composed of partially supervised algorithms are investigated.

Since the discovery of the cosmic microwave background (CMB) radiation in 1965 by Penzias and Wilson, a number of missions have been planned to measure the CMB including the ESA satellite PLANCK. CMB radiation is of interest from a number of aspects: 1) it is the most important evidence for the hot big-bang model, 2) it provides us a picture of the universe in its very early moments 3) the anisotropies in it provide the seed map of the universe of today 4) It provides us information about the fundamental constants of the universe. Unfortunately, the task of measuring CMB is not an easy one, since radiation measurements of the sky contain contributions from various sources from our galaxy such as syncrotron, galactic dust and free-free emission as well as extragalactic radio sources. In this talk, I will present our efforts at ISTI-CNR to separate various radiation sources in astronomy images. We adopt a source separation rather than a noise elimination approach since we value the information in other sources as well. I will start with our work using independent component analysis (ICA) as a fully blind technique and then will move into more informed techniques such as independent factor analysis (IFA) which assume a generic source model and a full Bayesian approach using MCMC. Talk will end with the description of the future activities we plan.

The light microscope is unique in its ability to image cells and display morphology and molecular localization at sub-cellular resolutions. As such, it served biological research for centuries, based on human understanding of microscopic scenes. Digital imaging added the quantitative capability, mainly based on fluorescent immunostaining, which enabled to study molecular localization and displacements inflicted by various experimental manipulations and drugs. Today modified cDNA allows to express in cells inherently fluorescent tagged proteins and follow them as cells respond to stimuli. With cDNA libraries, the design of cell-based large scale experiments open ways to identify the protein networks that underlie complex cellular mechanisms.

The presentation is dedicated to emerging aspects of stochastic image modeling in critically sampled and overcomplete transform domains for image restoration and denoising and consists of three main parts. In the first introduction part, we briefly present stochastic image processing (SIP) group and its current research activity. The second part of presentation reviews robust image restoration for radar and radiometry imaging systems. First, we consider the general problem formulation and corresponding solution based on a penalized maximum likelihood estimate.

The relationship to robust M-estimators and maximum a posteriori probability methods will be indicated for different stochastic image priors and noise distributions. We also consider non-coherent imaging systems based on sparse antenna arrays and demonstrate some practical results. The third part of presentation is dedicated to the important problem of stochastic image modeling in the transform domains. We consider the! state-of-the-art stochastic image models and different classes of multiresolution transforms. We will focus on important class of non-stationary image models in different applications and will analyze its main shortcomings based on an example of estimation-quantization (EQ) model.

Finally, we will introduce a novel edge process (EP) model for critically sampled and overcomplete domains and demonstrate its main advantages. In conclusion, some upper bounds for the EP model performance in image denoising application will be demonstrated.

Sensor networks have emerged as a fundamentally new tool for monitoring spatial phenomena. This talk will describe a theory and methodology for estimating inhomogeneous fields using wireless sensor networks. Inhomogeneous fields are composed of two or more homogeneous regions (e.g., constant-valued, smoothly-varying, stationary Gaussian, etc.) separated by boundaries. The boundaries, which correspond to abrupt spatial changes in the field, are non-parametric 1-d curves or 2-d surfaces (in a 2-d or 3-d field, respectively). The sensors make noisy measurements of the field, and the goal is to obtain an accurate estimate of the field at some desired destination (typically remote from the sensor network). The presence of boundaries makes this problem especially challenging. There are two key questions: 1. Given n sensors, how accurately can the field be estimated? 2. How much energy will be consumed by the communications required to obtain an accurate estimate at the destination? Theoretical upper and lower bounds on the estimation error and energy consumption will be discussed. A practical strategy for estimation and communication will be presented. The strategy, based on a hierarchical data-handling and communication architecture, provides a near-optimal balance of accuracy and energy consumption.

The nonparametric multiscale algorithms presented here are powerful new tools for photon-limited signal and image denoising and Poisson inverse problems. Unlike traditional wavelet-based multiscale methods, these algorithms are both well suited to processing Poisson data and capable of preserving image edges. The recursive partitioning scheme underlying these methods is based on multiscale likelihood factorizations of the Poisson data model. These partitions allow the construction of multiscale signal decompositions based on polynomials in one dimension and multiscale image decompositions based on platelets in two dimensions. We originally developed platelets for medical image reconstruction problems, and more recently we have successfully applied them to problems in astronomical imaging. Platelets are localized functions at various positions, scales and orientations that can produce highly accurate, piecewise linear approximations to images consisting of smooth regions separated by smooth boundaries. Polynomial- and platelet-based maximum penalized likelihood methods for signal and image analysis are both tractable and computationally efficient. Simulations establish the practical effectiveness of these methods in applications such as Gamma Ray Burst intensity estimation and medical and astronomical image reconstruction; statistical risk analysis establishes the theoretical near-optimality of these methods.

This talk surveys recent research in this area and focuses on two information-hiding problems.  The first one is the development of binning schemes, which are fundamental to all problems of communication with side information. Here binning schemes will be introduced as noise shaping techniques. The second problem is the development of binning schemes in the context of a game between an information hider and an attacker.

The digital library project strives to digitise special collections of libraries; this consists in storing as binary data, photographs of the content of ancient or rare manuscripts. The object is typically not in a flat plane. One collects, along with the photograph of the unflattened object (and the inevitably distorted text), a positional reading of its surface using laserometer. It is then a mathematical problem of how to use the latter information to undo the distortion of the photograph before storing the digitised image. We discuss a variational formulation and implementation of this.

When segmenting their environment into meaningful regions, human observers exploit a number of low-level cues (such as intensity, color, texture or motion information) and higher level knowledge about objects of interest.

Metropolis moves. These moves, usually implemented by splitting and merging classes, can be very slow, making them impractical for large images. We investigate simpler reversible jump moves that are quick to implement but show that they may mix very slowly. We propose a more complex split and merge scheme and compare its performance. Tests are conducted on satellite and aerial images.

There currently exist two distinct paradigms for modeling images.  In the first, images are regarded as functions from a deterministic function space, such as a Besov smoothness class.  In the second, images are treated statistically as realizations of a random process.

This talk with review and indicate the links between the leading deterministic and statistical image models, with an emphasis on multiresolution techniques and wavelets.  To overcome the major shortcomings of the Besov smoothness characterization, we will develop new statistical models based on mixtures on graphs.  To illustrate, we will discuss applications in image estimation and segmentation.

Structures in data have to be mathematically defined and evaluated, e.g., partitions, hierarchies and projections  are widely studied in the literature. This design step is highly task dependent and might yield different answers for the same data.  (ii) Efficient search procedures should be devised for prefered structures. (iii) Solutions of this optimization process should be validated. As an example, this program for robust modeling and algorithms design is demonstrated for the problem of image segmentation based on texture and color cues. The assignment variables of pixels or image patches to segments are robustly estimated by entropy maximizing algorithms like Markov Chain Monte Carlo methods or deterministic annealing with EM-like iterative updates of model parameters. Multi-scale coarsening of the optimization variables yields a significant acceleration of the optimization process. To validate the optimization results we have to determine a minimal approximation precision to become robust against overfitting to data fluctuations. Information theoretic methods can be used to derive upper bounds for large deviations of the optimization procedure.

In the second part of the talk I will present applications of this program to selected data analysis problems, e.g., to joint color quantization and dithering, to the analysis of remote sensing data with adaptive polygonalization, to multi-scale shape description of line drawings and to the traveling salesman problem with unreliable travel times.

Supervised learning is one of the central topic of pattern recognition and machine learning; its goal is to find a functional relationship that maps an "input" to an "output", given a set of (maybe "noisy") examples. The obtained function is evaluated by how well it generalizes, that is, by how accurately it performs on new data, assumed to follow the same distribution from which the training data was obtained.

"complexity" of the learned function. In Bayesian approaches, this is done by placing a prior on the parameters defining the function being learned. We propose a Bayesian approach to supervised learning which leads to sparse solutions, that is, in which irrelevant parameters are automatically set exactly to zero.

Experiments with several benchmark data sets show that the proposed approach exhibits state-of-the-art performance. In particular, our method outperforms support vector machines and performs competitively with the best alternative techniques, although it involves no tuning or adjusting of sparseness-controlling hyper-parameters.

Tree-based methods are powerful tools for signal and image estimation and classification.  The CART (Classification and Regression Trees) program aims to balance the fitness of a tree (classifier or estimator) to data with the complexity of the tree (measured by the number of leaf nodes).  The basic idea in CART is a standard complexity regularization approach: the empirical error (squared error or misclassification rate) is balanced by a penalty term proportional to the number of degrees of freedom in the model (leaf nodes in the tree).  The form of the CART optimization criterion is error+a*k, where k is the number of leaf nodes in the tree.  This form of regularization leads to a very efficient, bottom-up tree pruning strategy for optimization, and is the ``correct'' form of complexity regularization for estimation/regression problems.  However, in the classification case the linear growth of the penalty outpaces the growth of the expected misclassification error, and consequently penalizes larger trees too severely.  Rather than employing the same regularization for classification *and* regression, one should consider classification *or* regression as two quite different problems.  The appropriate optimization criterion for classification trees takes the form error+a*k^{1/2}.

We review performance bounds for estimation/regression trees and derive new bounds on the performance of classification trees using the square-root complexity regularization criterion.  The adaptive resolution of tree classifiers enables them to focus on the d* dimensional decision boundary, instead of estimating the full d > d* dimensional posterior probability function.  Under a modest regularity assumption (in terms of the box-counting measure) on the underlying optimal Bayes decision boundary, we show that complexity regularized tree classifiers converge to the Bayes decision boundary at nearly the minimax rate, and that no classification scheme (neural network, support vector machine, etc.) can perform significantly better in this minimax sense.  Although minimax bounds in pattern classification have been investigated in previous work, the emphasis has been on placing regularity assumptions on the posterior probability function rather than the decision boundary.  Studying the impact of regularity in terms of the decision boundary sheds new light on the ``learning from data'' problem and suggests new principles for investigating the performance of pattern classification schemes.

In recent years curve evolution, applied to a single contour or to the level sets of an image via partial differential equations, has emerged as an important tool in image processing and computer vision. Curve evolution techniques have been utilized in problems such as image smoothing, segmentation, and shape analysis.  We give a stochastic interpretation of the basic curve smoothing equation, the so called geometric heat equation, and show that this evolution amounts to a tangential diffusion movement of the particles along the contour.

Moreover, assuming that a priori information about the shapes of objects in an image is known, we present generalizations of the geometric heat equation designed to preserve certain features in these shapes while removing noise. We also show how these new flows may be applied to smooth noisy curves without destroying their larger scale features, in contrast to the original geometric heat flow which tends to circularize any closed curve.

Many textures require complex models to describe their intricate structures. Their modeling can be simplified if they are considered composites of simpler subtextures. After an initial, unsupervised segmentation of the composite texture into the subtextures, it can be described at two levels. One is a label map texture, which captures the layout of the different subtextures.

For analyzing shapes of planar, closed curves, we propose a mathematical representation of closed curves using ``direction" functions (integrals of the signed curvature functions with respect to arc lengths). Shapes are represented as elements of an infinite-dimensional manifold and their pairwise differences are quantified using the lengths of geodesics connecting them on this manifold. Exploiting the periodic nature of these representations, we use a Fourier basis to discretize them and  use a gradient-based shooting method for finding geodesics between any two shapes. Lengths of geodesics provide a metric for comparing shapes.  This metric is intrinsic to the shapes and does not require any deformable template framework.

In this talk I will discuss a criterion for cluster-validity that is based on distribution-free statistics.  Given a dataset, the idea is to construct the simplest possible data-density that is still compatible with the data.  Compatibility is measured by means of statistical tests that quantify how likely the hypothesized underlying distribution is in view of the observed data. Combining this with a criterion for smoothness yields a functional that can be minimized explicitly. The advantage of this approach is that the resulting clustering depends on just one parameter that has a clear probabilistic interpretation.

With the extension, multiscale edge information of multiband images is extracted. Moreover, a wavelet representation is obtained that, after inverse transformation, accumulates all edge information in a single greylevel image. In this work, a redundant wavelet representation is presented using dyadic wavelet frames. It is then extended towards orthogonal wavelet bases using the Discrete Wavelet Transformation (DWT). The representation is shown to be a natural framework for image fusion. An algorithm is presented for fusion and merging of multispectral images. The concept is successfully applied to the problem of multispectral and hyperspectral image merging.

We shall discuss a variational approach for filling-in regions of missing data in 2D and 3D digital images. Applications of this technique include the restoration of old photographs and removal of superimposed text like dates, subtitles, or publicity, or the zooming of images.

The process underlying this approach can be considered as an interpretation of the Gestaltist's principle of good continuation. We study the existence of minimizers of our functional and its approximation by smoother functionals.

Efficient statistical modeling of SAR images is a prerequisite for developing  successful speckle cancellation techniques. Traditionally, due to the central limit theorem, it has been assumed that the amplitude image is distributed with a Rayleigh law. However, some experimental data does not follow Rayleigh law. The alternative empirical models that have been suggested in the literature are either generally empirical and do not have strong theoretical justification or are computationally expensive. In this talk, we develop a generalised version of the Rayleigh distribution based on the assumption that the real and imaginary parts of the received signal follow an isotropic alpha-stable law. We also present novel estimation methods based on negative order statistics for model fitting. Our experimental results show that the new model can describe a wide range of data (in particular urban area images) which could not be described by the classical Rayleigh model or other alternative models.

Information technology develops very fast, the role of image communication, exploration of distributed pictures archives, internet search engines, visualization, or other related information technologies, is very much increasing.

After a short overview a new method is introduced. The method is based on a hierarchical Bayesian modeling of the information content of images, and consists of two processing steps: i) an unsupervised classification followed by an ii) interactive learning procedure.

A common feature of computer vision systems is the use of levels of increasing abstraction to represent intermediate results and thus successively bridging the gap between raw image data and the final result.  To elaborate on such a hierarchical representation we propose a contour-based grouping hierarchy based on principles of perceptual organization.

Exploiting regularities in the image, we aim at enhancing efficiency and robustness of subsequent processing steps of an image analysis system by reducing ambiguities in the intermediate representation and by realizing image primitives at a higher level of abstraction. To this end, first grouping hypotheses are generated within the hierarchy using local evaluation strategies, which are motivated by different Gestalt principles. Since this generation is based on local evidence only, the hypotheses have to be judged in a global context. We employ a Markov Random Field to model context dependencies and energy minimization yields a consistent interpretation of image data with groupings from the hierarchy.

Since this grouping hierarchy is contour-based, it inherits from drawbacks of contour segmentation. Therefore, the second issue we address aims at the integration of cues from region segmentation into the contour-based grouping process and vice versa.

For several applications (such as disaster management and assessment of land erosion, deforestation, urban growth, and crop development) the contribution of remote sensing images can be valuable in particular by the use of techniques able to reveal the changes that have occurred in a given study area. The difficulty to collect ground truth information regularly in the time makes important to develop unsupervised change detection techniques to help in the analysis of temporal sequences of remote sensing images.

An unsupervised change detection problem can be viewed as a classification problem with only two classes corresponding to the change and no-change areas, respectively. A possible approach to solve this problem consists of the computation of the difference between the multiband images acquired at two different times, followed by the application of a simple thresholding procedure to the length of the difference vector (computed on a pixel basis). However, the selection of the best threshold value is not a trivial problem.

In the seminar, several thresholding methods will be considered and compared. The minimum-error thresholding method [1] suggests to compute the threshold that optimize the average pixel classification error assuming that the difference image histogram derives from a mixture of two normal components (corresponding to change and no-change pixels).

The second considered method [2] starts from the same assumption of normal mixture, but is based on an iterative estimation of the parameters of the two gaussian components by means of the Expectation-Maximization algorithm (EM); the Bayes rule for minimum error is then applied to select the decision threshold. The third considered method [3] makes use of fuzzy membership functions and of an entropy measure as a criterion function for optimal threshold selection.

Finally, a recent investigation is proposed which is based on two approaches: the former consists of the application of thresholding to data after projecting them along the Fisher direction; the latter is based on the application of EM to estimate the parameters of the two classes, under the gaussian distribution hypothesis, directly in the multidimensional space of the multiband difference image. For experimental purposes, two Landsat TM images of an area affected by a forest fire are considered, which were acquired before and after the event. The capability to reveal the burned zones is utilized for comparing the above mentioned unsupervised change detection methods.

Wavelets, recursive partitioning, and graphical models represent three frameworks for modeling signals and images that have proven to be highly successful in a variety of application areas.  Each of these frameworks has certain strengths and weaknesses, often complementary among them.

In this talk I will present a framework for a certain class of multiscale probability models that simultaneously shares characteristics of all three of these frameworks. These models are grounded upon a common factorized form for the data likelihood into a product of components with localized information in position and scale -- similar to a wavelet decomposition.

In fact, such factorizations can be linked formally with a probabilistic analogue of a multiresolution analysis.  Efficient algorithms for estimation and segmentation can be built upon these factorizations, with direct parallels to thresholding, partitioning, and probability propagation algorithms in the existing literature. Finally, estimators, deriving from this framework can be shown to have `near-optimality' properties similar to those now-classical results established for wavelets in the Gaussian signal-plus-noise model, but for other distributions as well, such as Poisson and multinomial measurements.

Fundamental to our framework is a quite general notion of recursive partitioning in a data space.  If time allows, I will demonstrate how this allows for the same core modeling and algorithmic structures to be used in examples from areas as diverse as high-energy astrophysics and census geography.

An image magnification algorithm based on the decimated wavelet transform is presented. The magnification is based on the conservation of the visual smoothness. Experimental results are given and show that the algorithm is robust. The conservation of the visual aspect is validated by the computation of a perceptual criteria.

In this talk, we focus on the analysis of road scene. These are sequences of numerical images of the road and its immediate environment, taken by vehicles, at a typical rate of one image every five meters.

They constitute huge image databases that become an increasingly demanded tool for road managers. Beyond simple visual interpretation, our goal is to extract information that can be useful in safety studies or for road management. Some tasks such as objects-of-interest location are still performed by human operators and need to be at least partially automated. The goal is to detect and recognize manufactured objects like road signs, safety elements, poles, and natural objects like trees.

In a pre-detection step, we propose to analyze the apparent motion of objects throughout the sequence. The camera motion being roughly a forward travelling, objects appear, grow and then disappear from the scene, while the background nearly remains unchanged. Considering an appropriate choice of image features it is possible to extract the statistics of changing objects from pairs of successive histograms.

In the second step, we aim to refine the detection and then to perform object recognition, using statistical appearance-based techniques. These are not robust to outliers that occur due to occlusions or cluttered background. The robust approach we propose uses M-estimators in continuation. Using results from robust estimation and half-quadratic theory, we come up with a simple least-squares (with modified residuals) algorithm. This scheme does not require any user interaction provided all necessary parameters have previously been estimated during the learning step.

I will introduce a new method for rectifying stereo pairs that does not require any calibration information or any knowledge of the epipolar geometry. I then describe a Bayesian stereo technique that fuses information from both monocular and binocular vision in order to overcome the complexity of data in cluttered/dense urban areas. Finally I describe a model for reducing perspective distortions, which otherwise could introduce severe errors in the actual 3D models.

